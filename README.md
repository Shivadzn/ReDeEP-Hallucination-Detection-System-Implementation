## ğŸ“ File Content Templates

### **1. README.md** (MOST IMPORTANT)

```markdown
# ReDeEP: Hallucination Detection in RAG Systems

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Implementation of **"Retrieval, Depth, and Flow: Understanding In-Context Examples through LLM Internals in RAG Systems"** (ICLR 2025) for detecting hallucinations in Large Language Model outputs.

ğŸ“„ [Original Paper](https://arxiv.org/abs/2410.11414) | ğŸ¯ [Results](#results) | ğŸ“Š [Visualizations](#visualizations)


## ğŸ¯ What This Does

Detects when LLMs fabricate information ("hallucinate") by analyzing **attention patterns** in the model's internal representations. Unlike traditional approaches that only look at outputs, ReDeEP examines:

1. **Retrieval (Re)**: How the model attends to retrieved context
2. **Depth (De)**: Which layers process the information
3. **Flow (F)**: How information flows through the network

## ğŸ“Š Results

### Performance Metrics
| Metric | Value | Interpretation |
|--------|-------|----------------|
| **AUC** | 0.689 | Moderate discriminative ability |
| **Accuracy** | 44.35% | Room for threshold optimization |
| **Precision** | 19.48% | Handles class imbalance |
| **Recall** | 38.83% | Catches ~39% of hallucinations |
| **F1-Score** | 25.95% | Balanced performance |
| **Pearson r** | 0.323 | Moderate linear correlation |

### Complete Analysis Dashboard
![Hallucination Detection Analysis](results/visualizations/analysis_dashboard.png)

**Key Insights:**
- âœ… 38% improvement over random guessing (0.50 â†’ 0.689 AUC)
- âœ… Clear score separation between factual and hallucinated content
- âœ… Correctly identifies 113/291 hallucinations (38.8% recall)
- âš ï¸ High false positive rate (467) suggests threshold tuning needed



## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/redeep-hallucination-detection.git
cd redeep-hallucination-detection

# Install dependencies
pip install -r requirements.txt

# Download dataset (optional)
python scripts/download_data.py
```

### Basic Usage

```python
from src.detection import HallucinationDetector
from src.model_loader import load_model_quantized

# Load model
model, tokenizer = load_model_quantized("meta-llama/Llama-2-7b-hf")

# Initialize detector
detector = HallucinationDetector(model, tokenizer)

# Detect hallucinations
results = detector.detect(
Â  Â  response="The Eiffel Tower was built in 1889.",
Â  Â  context="The Eiffel Tower construction began in 1887..."
)

print(f"Hallucination score: {results['score']:.3f}")
print(f"Likely hallucinated: {results['is_hallucination']}")
```

### Run Full Pipeline

```bash
# Detection only
bash scripts/run_detection.sh

# Regression analysis
bash scripts/run_regression.sh

# Complete pipeline
bash scripts/run_full_pipeline.sh
```

---

## ğŸ—ï¸ Architecture

```
Input Text â†’ LLaMA-2-7B (4-bit) â†’ Attention Extraction â†’ Feature Analysis â†’ Hallucination Score
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â†“
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  32 Attention Heads
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (Layers 0-30)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â†“
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  External Similarity +
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Parameter Knowledge
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â†“
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Regression Model â†’ Final Score
```

See [ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed system design.

---

## ğŸ”¬ Technical Highlights

### Memory Optimization
- **4-bit Quantization**: Reduces model size by 75% (28GB â†’ 7GB)
- **Balanced GPU Distribution**: Splits across 2x T4 GPUs (15GB each)
- **Smart Sequence Truncation**: Dynamic truncation to prevent OOM
- **Periodic Cache Clearing**: Maintains stable memory usage

### Implementation Innovations
1. **Universal Path Manager**: Handles Kaggle/Colab/local environments seamlessly
2. **Bounds-Safe Indexing**: Prevents IndexErrors with varying attention patterns
3. **Feature Extraction Pipeline**: Efficient batch processing of attention heads
4. **Comprehensive Visualization**: Publication-quality analysis dashboard

---

## ğŸ“ˆ Visualizations

### ROC Curve
![ROC Curve](results/visualizations/roc_curve.png)

### Score Distribution
![Score Distribution](results/visualizations/score_distribution.png)

### Confusion Matrix
Shows classification performance at optimal threshold (0.714):
- True Positives: 113
- False Negatives: 178
- True Negatives: 401
- False Positives: 467

---

## ğŸ”§ Configuration

Key parameters can be adjusted in `configs/`:

```yaml
# configs/model_config.yaml
model:
Â  name: "meta-llama/Llama-2-7b-hf"
Â  quantization: "4bit"
Â  max_memory:Â 
Â  Â  - "12GB"Â  # GPU 0
Â  Â  - "12GB"Â  # GPU 1

detection:
Â  attention_heads: 32
Â  sequence_length: 6000
Â  batch_size: 1

regression:
Â  top_external: 3
Â  top_parameter: 4
Â  alpha: 0.6
```

---

## ğŸ“Š Dataset

**RAGTruth**: Benchmark dataset for hallucination detection in RAG systems

- **Total Samples**: 17,790
- **Processed**: 1,159 (6.5%)
- **Class Distribution**: 75% Factual / 25% Hallucinated
- **Task Types**: QA, Summarization, Dialogue

---

## ğŸ› ï¸ Hardware Requirements

### Minimum
- GPU: 1x T4 (15GB VRAM)
- RAM: 16GB
- Storage: 20GB

### Recommended
- GPU: 2x T4 (30GB total VRAM)
- RAM: 32GB
- Storage: 50GB

### Tested Environments
- âœ… Kaggle Notebooks (2x T4)
- âœ… Google Colab Pro (A100)
- âš ï¸ Google Colab Free (limited by memory)

---

## ğŸ“š Documentation

- [Architecture Overview](docs/ARCHITECTURE.md)
- [Implementation Notes](docs/IMPLEMENTATION_NOTES.md)
- [Optimization Guide](docs/OPTIMIZATION_GUIDE.md)
- [Troubleshooting](docs/TROUBLESHOOTING.md)
- [Paper Summary](docs/PAPER_SUMMARY.md)

---

## ğŸ”® Future Work

- [ ] Process full 17,790 sample dataset
- [ ] Implement AARF (Attributed Auto-Regressive Flow)
- [ ] Token-level hallucination detection
- [ ] Hyperparameter optimization (grid search)
- [ ] Ensemble with other detection methods
- [ ] API endpoint for production deployment
- [ ] Support for LLaMA-3 and other models

---

## ğŸ¤ Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ Citation

If you use this implementation, please cite:

```bibtex
@article{redeep2024,
Â  title={Retrieval, Depth, and Flow: Understanding In-Context Examples through LLM Internals in RAG Systems},
Â  author={[Original Authors]},
Â  journal={ICLR},
Â  year={2025},
Â  url={https://arxiv.org/abs/2410.11414}
}
```

---

## ğŸ“ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

---

## ğŸ™ Acknowledgments

- Original ReDeEP paper authors
- HuggingFace Transformers team
- Kaggle for compute resources

---

## ğŸ“§ Contact

- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your Name](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

**â­ Star this repo if you find it useful!**
---

Want me to help you write any specific file? I can draft the complete README.md or any doc you need!
