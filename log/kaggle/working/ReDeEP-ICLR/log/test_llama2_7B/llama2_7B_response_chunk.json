[{"id": "27", "source_id": "15596", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "FBI charges Philadelphia woman with attempting to join ISIS after purchasing electronic visa for Turkey. Keonna Thomas, 30, also known as \"Young Lioness\" and \"Fatayat Al Khilafah,\" made numerous social media posts expressing desire to fight for ISIS. She could face 15 years in prison. Three women have been arrested this week on terror charges, including two in New York who were accused of planning to build an explosive device for attacks in the US.", "response_spans": [[0, 452]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6157336235046387, "(0, 16)": 0.6157336235046387, "(2, 0)": 0.6157336235046387, "(2, 16)": 0.6157336235046387, "(4, 0)": 0.6157336235046387, "(4, 16)": 0.7335631847381592, "(6, 0)": 0.6157336235046387, "(6, 16)": 0.9345447421073914, "(8, 0)": 0.6431934237480164, "(8, 16)": 0.6157336235046387, "(10, 0)": 0.6157336235046387, "(10, 16)": 0.6157336235046387, "(12, 0)": 0.6431934237480164, "(12, 16)": 0.9345447421073914, "(14, 0)": 0.6157336235046387, "(14, 16)": 0.9345447421073914, "(16, 0)": 0.9345447421073914, "(16, 16)": 0.9345447421073914, "(18, 0)": 0.9345447421073914, "(18, 16)": 0.9345447421073914, "(20, 0)": 0.9345447421073914, "(20, 16)": 0.6157336235046387, "(22, 0)": 0.6157336235046387, "(22, 16)": 0.9345447421073914, "(24, 0)": 0.9345447421073914, "(24, 16)": 0.9345447421073914, "(26, 0)": 0.9345447421073914, "(26, 16)": 0.9345447421073914, "(28, 0)": 0.9345447421073914, "(28, 16)": 0.6157336235046387, "(30, 0)": 0.9345447421073914, "(30, 16)": 0.9345447421073914}, "r_span": [564, 670], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005243420600891113}}]}, {"id": "45", "source_id": "15599", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Blue Bell ice cream has temporarily shut down one of its manufacturing plants after discovering listeria contamination in a serving of ice cream produced at the plant. The Centers for Disease Control and Prevention (CDC) has warned consumers not to eat any Blue Bell-branded products made at the Broken Arrow, Oklahoma plant, including 3-ounce servings of ice cream marked with certain codes. This is the third time Blue Bell has taken action due to a listeria outbreak at a Kansas hospital that served the company's ice cream. Investigations into the possible connection between the ice cream and the infections are ongoing. The company has recalled other products and advises individuals and institutions to check their freezers for the recalled items and throw them away. This is the first product recall in Blue Bell's 108-year history.", "response_spans": [[0, 506], [491, 840]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5868223905563354, "(0, 16)": 0.5868223905563354, "(2, 0)": 0.5868223905563354, "(2, 16)": 0.5868223905563354, "(4, 0)": 0.5868223905563354, "(4, 16)": 0.5868223905563354, "(6, 0)": 0.7885425686836243, "(6, 16)": 0.9701216220855713, "(8, 0)": 0.5868223905563354, "(8, 16)": 0.5868223905563354, "(10, 0)": 0.5868223905563354, "(10, 16)": 0.7643054723739624, "(12, 0)": 0.5868223905563354, "(12, 16)": 0.9701216220855713, "(14, 0)": 0.5868223905563354, "(14, 16)": 0.9701216220855713, "(16, 0)": 0.9701216220855713, "(16, 16)": 0.5868223905563354, "(18, 0)": 0.5868223905563354, "(18, 16)": 0.9701216220855713, "(20, 0)": 0.9701216220855713, "(20, 16)": 0.5868223905563354, "(22, 0)": 0.5868223905563354, "(22, 16)": 0.9701216220855713, "(24, 0)": 0.5868223905563354, "(24, 16)": 0.9701216220855713, "(26, 0)": 0.5868223905563354, "(26, 16)": 0.5868223905563354, "(28, 0)": 0.5868223905563354, "(28, 16)": 0.5868223905563354, "(30, 0)": 0.5868223905563354, "(30, 16)": 0.9701216220855713}, "r_span": [995, 1114], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018190741539001465}}, {"prompt_attention_score": {"(0, 0)": 0.5256012678146362, "(0, 16)": 0.7934976816177368, "(2, 0)": 0.5256012678146362, "(2, 16)": 0.5256012678146362, "(4, 0)": 0.5256012678146362, "(4, 16)": 0.5256012678146362, "(6, 0)": 0.5256012678146362, "(6, 16)": 0.786058783531189, "(8, 0)": 0.5256012678146362, "(8, 16)": 0.5256012678146362, "(10, 0)": 0.5256012678146362, "(10, 16)": 0.7934976816177368, "(12, 0)": 0.5256012678146362, "(12, 16)": 0.786058783531189, "(14, 0)": 0.5256012678146362, "(14, 16)": 0.5256012678146362, "(16, 0)": 0.786058783531189, "(16, 16)": 0.5256012678146362, "(18, 0)": 0.5256012678146362, "(18, 16)": 0.786058783531189, "(20, 0)": 0.786058783531189, "(20, 16)": 0.5256012678146362, "(22, 0)": 0.5256012678146362, "(22, 16)": 0.786058783531189, "(24, 0)": 0.5256012678146362, "(24, 16)": 0.786058783531189, "(26, 0)": 0.5256012678146362, "(26, 16)": 0.5256012678146362, "(28, 0)": 0.5256012678146362, "(28, 16)": 0.5256012678146362, "(30, 0)": 0.5256012678146362, "(30, 16)": 0.7117811441421509}, "r_span": [1112, 1189], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005135536193847656}}]}, {"id": "57", "source_id": "15601", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "According to a recent review by Columbia Journalism School professors, Rolling Stone failed in its reporting and editing processes, leading to a flawed article about a purported gang rape at the University of Virginia. The article has been widely criticized for its lack of factual accuracy and for damaging the reputations of innocent parties. The fraternity involved, Phi Kappa Psi, has announced that it will pursue legal action against Rolling Stone for defamation. However, the fraternity's ability to sue may be limited due to the fact that it is not a public figure and cannot demonstrate actual financial harm as a result of the article. Additionally, the law of defamation is complex and requires proof of falsity, intent, and harm to reputation. While UVA itself cannot sue for defamation, individual members of the university or the fraternity may have grounds for a lawsuit. However, the success of such a suit would depend on the specific circumstances and evidence presented.", "response_spans": [[0, 510], [496, 989]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6183366775512695, "(0, 16)": 0.6183366775512695, "(2, 0)": 0.6183366775512695, "(2, 16)": 0.6183366775512695, "(4, 0)": 0.6183366775512695, "(4, 16)": 0.6183366775512695, "(6, 0)": 0.6183366775512695, "(6, 16)": 0.8389602303504944, "(8, 0)": 0.7745664715766907, "(8, 16)": 0.6183366775512695, "(10, 0)": 0.8389602303504944, "(10, 16)": 0.6360747814178467, "(12, 0)": 0.6183366775512695, "(12, 16)": 0.8389602303504944, "(14, 0)": 0.6747177243232727, "(14, 16)": 0.8389602303504944, "(16, 0)": 0.8389602303504944, "(16, 16)": 0.6183366775512695, "(18, 0)": 0.6183366775512695, "(18, 16)": 0.8389602303504944, "(20, 0)": 0.8389602303504944, "(20, 16)": 0.6183366775512695, "(22, 0)": 0.8389602303504944, "(22, 16)": 0.8389602303504944, "(24, 0)": 0.71467125415802, "(24, 16)": 0.8389602303504944, "(26, 0)": 0.8389602303504944, "(26, 16)": 0.7378032207489014, "(28, 0)": 0.8389602303504944, "(28, 16)": 0.6183366775512695, "(30, 0)": 0.8389602303504944, "(30, 16)": 0.8389602303504944}, "r_span": [1347, 1461], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004476308822631836}}, {"prompt_attention_score": {"(0, 0)": 0.7795937061309814, "(0, 16)": 0.7795937061309814, "(2, 0)": 0.7795937061309814, "(2, 16)": 0.7748439311981201, "(4, 0)": 0.7795937061309814, "(4, 16)": 0.7795937061309814, "(6, 0)": 0.7795937061309814, "(6, 16)": 0.816985011100769, "(8, 0)": 0.7795937061309814, "(8, 16)": 0.7748439311981201, "(10, 0)": 0.7795937061309814, "(10, 16)": 0.7795937061309814, "(12, 0)": 0.8091179132461548, "(12, 16)": 0.7906554937362671, "(14, 0)": 0.7748439311981201, "(14, 16)": 0.8091179132461548, "(16, 0)": 0.7795937061309814, "(16, 16)": 0.7748439311981201, "(18, 0)": 0.7748439311981201, "(18, 16)": 0.7925572991371155, "(20, 0)": 0.7748439311981201, "(20, 16)": 0.7748439311981201, "(22, 0)": 0.5895369052886963, "(22, 16)": 0.8091179132461548, "(24, 0)": 0.7748439311981201, "(24, 16)": 0.7748439311981201, "(26, 0)": 0.5895369052886963, "(26, 16)": 0.7795937061309814, "(28, 0)": 0.5895369052886963, "(28, 16)": 0.7795937061309814, "(30, 0)": 0.7748439311981201, "(30, 16)": 0.5895369052886963}, "r_span": [1459, 1560], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001112818717956543}}]}, {"id": "69", "source_id": "15604", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Rand Paul, a Republican Senator from Kentucky, announced his candidacy for President of the United States. However, his record has been criticized for questioning landmark voting rights and civil rights legislation, which has led some to believe that he is out of touch with the mainstream and lacks commitment to minority communities. Despite his attempts to position himself as a bridge builder between the GOP and minority groups, his policies have been seen as regressive and disqualifying for a potential President. The author argues that the American people deserve a leader who respects their intelligence and will work towards progress, rather than rolling back the gains made over the past five decades.", "response_spans": [[0, 509], [494, 712]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7110828757286072, "(0, 16)": 0.7110828757286072, "(2, 0)": 0.7837662696838379, "(2, 16)": 0.7837662696838379, "(4, 0)": 0.7837662696838379, "(4, 16)": 0.7837662696838379, "(6, 0)": 0.7110828757286072, "(6, 16)": 0.831282377243042, "(8, 0)": 0.7837662696838379, "(8, 16)": 0.7110828757286072, "(10, 0)": 0.831282377243042, "(10, 16)": 0.7837662696838379, "(12, 0)": 0.7110828757286072, "(12, 16)": 0.831282377243042, "(14, 0)": 0.7110828757286072, "(14, 16)": 0.831282377243042, "(16, 0)": 0.831282377243042, "(16, 16)": 0.7110828757286072, "(18, 0)": 0.7110828757286072, "(18, 16)": 0.831282377243042, "(20, 0)": 0.831282377243042, "(20, 16)": 0.7110828757286072, "(22, 0)": 0.831282377243042, "(22, 16)": 0.7837662696838379, "(24, 0)": 0.7110828757286072, "(24, 16)": 0.831282377243042, "(26, 0)": 0.831282377243042, "(26, 16)": 0.7110828757286072, "(28, 0)": 0.831282377243042, "(28, 16)": 0.7110828757286072, "(30, 0)": 0.831282377243042, "(30, 16)": 0.831282377243042}, "r_span": [887, 990], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009282231330871582}}, {"prompt_attention_score": {"(0, 0)": 0.7997385263442993, "(0, 16)": 0.6769225597381592, "(2, 0)": 0.7997385263442993, "(2, 16)": 0.7997385263442993, "(4, 0)": 0.6769225597381592, "(4, 16)": 0.7997385263442993, "(6, 0)": 0.7997385263442993, "(6, 16)": 0.7997385263442993, "(8, 0)": 0.6769225597381592, "(8, 16)": 0.7997385263442993, "(10, 0)": 0.7997385263442993, "(10, 16)": 0.7997385263442993, "(12, 0)": 0.7997385263442993, "(12, 16)": 0.7997385263442993, "(14, 0)": 0.7997385263442993, "(14, 16)": 0.7997385263442993, "(16, 0)": 0.7997385263442993, "(16, 16)": 0.7997385263442993, "(18, 0)": 0.7997385263442993, "(18, 16)": 0.7997385263442993, "(20, 0)": 0.7997385263442993, "(20, 16)": 0.7997385263442993, "(22, 0)": 0.6331275701522827, "(22, 16)": 0.6769225597381592, "(24, 0)": 0.7997385263442993, "(24, 16)": 0.6769225597381592, "(26, 0)": 0.6331275701522827, "(26, 16)": 0.7997385263442993, "(28, 0)": 0.6331275701522827, "(28, 16)": 0.7997385263442993, "(30, 0)": 0.6331275701522827, "(30, 16)": 0.6331275701522827}, "r_span": [988, 1030], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016060471534729004}}]}, {"id": "123", "source_id": "15613", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 241, "end": 323, "text": "they claim their marriage works due to their shared values and love for each other", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"they claim their marriage works due to their shared values and love for each other\" was not mentioned in the passages and original answer", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Mary Kay Letourneau, who served 7 years in prison for having an affair with her 13-year-old student, is still married to her husband Vili Fualaau and they are celebrating their 10th wedding anniversary this May. Despite their large age gap, they claim their marriage works due to their shared values and love for each other. Letourneau hopes to become a teacher again and has applied to have her sex offender status lifted.", "response_spans": [[0, 423]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8338503837585449, "(0, 16)": 0.7482390999794006, "(2, 0)": 0.7482390999794006, "(2, 16)": 0.7482390999794006, "(4, 0)": 0.7482390999794006, "(4, 16)": 0.7961786985397339, "(6, 0)": 0.8338503837585449, "(6, 16)": 0.8338503837585449, "(8, 0)": 0.7961786985397339, "(8, 16)": 0.7961786985397339, "(10, 0)": 0.7961786985397339, "(10, 16)": 0.8338503837585449, "(12, 0)": 0.8338503837585449, "(12, 16)": 0.7482390999794006, "(14, 0)": 0.8338503837585449, "(14, 16)": 0.7961786985397339, "(16, 0)": 0.8338503837585449, "(16, 16)": 0.8338503837585449, "(18, 0)": 0.8338503837585449, "(18, 16)": 0.7482390999794006, "(20, 0)": 0.7482390999794006, "(20, 16)": 0.8338503837585449, "(22, 0)": 0.8338503837585449, "(22, 16)": 0.8338503837585449, "(24, 0)": 0.8338503837585449, "(24, 16)": 0.7482390999794006, "(26, 0)": 0.8338503837585449, "(26, 16)": 0.8338503837585449, "(28, 0)": 0.8338503837585449, "(28, 16)": 0.8338503837585449, "(30, 0)": 0.8338503837585449, "(30, 16)": 0.8338503837585449}, "r_span": [372, 475], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00021576881408691406}}]}, {"id": "141", "source_id": "15616", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 159, "end": 249, "text": "West pleaded guilty to battery and was sentenced to probation and anger management classes", "meta": "EVIDENT CONFLICT\nOriginal: West pleaded no contest last year to a misdemeanor count of battery over the scuffle.\nGenerated: West pleaded guilty to battery and was sentenced to probation and anger management classes", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Kanye West has settled a lawsuit with a paparazzo he assaulted in 2013. The photographer, Daniel Ramos, sought damages for interfering with his right to work. West pleaded guilty to battery and was sentenced to probation and anger management classes. The settlement includes an apology from West to Ramos. This is the second time West has settled a legal dispute involving physical altercations, having previously reached a civil settlement with another man in 2014.", "response_spans": [[0, 466]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7354637384414673, "(0, 16)": 0.7354637384414673, "(2, 0)": 0.705785870552063, "(2, 16)": 0.705785870552063, "(4, 0)": 0.7354637384414673, "(4, 16)": 0.705785870552063, "(6, 0)": 0.705785870552063, "(6, 16)": 0.9226226806640625, "(8, 0)": 0.7078982591629028, "(8, 16)": 0.705785870552063, "(10, 0)": 0.705785870552063, "(10, 16)": 0.705785870552063, "(12, 0)": 0.705785870552063, "(12, 16)": 0.9226226806640625, "(14, 0)": 0.705785870552063, "(14, 16)": 0.9226226806640625, "(16, 0)": 0.9226226806640625, "(16, 16)": 0.705785870552063, "(18, 0)": 0.705785870552063, "(18, 16)": 0.9226226806640625, "(20, 0)": 0.9226226806640625, "(20, 16)": 0.705785870552063, "(22, 0)": 0.9226226806640625, "(22, 16)": 0.9226226806640625, "(24, 0)": 0.705785870552063, "(24, 16)": 0.9226226806640625, "(26, 0)": 0.9226226806640625, "(26, 16)": 0.9226226806640625, "(28, 0)": 0.9226226806640625, "(28, 16)": 0.705785870552063, "(30, 0)": 0.9226226806640625, "(30, 16)": 0.9226226806640625}, "r_span": [646, 754], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 5.900859832763672e-05}}]}, {"id": "147", "source_id": "15617", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "B.B. King, 89, was hospitalized for dehydration due to his Type II diabetes. His daughter Claudette King confirmed he is feeling much better and will return home to rest. King has 30 Grammy nominations and is known for using Gibson guitars, naming each one \"Lucille\". Last year, he canceled his tour due to dehydration and exhaustion after a show in Chicago.", "response_spans": [[0, 358]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7062678933143616, "(0, 16)": 0.7062678933143616, "(2, 0)": 0.7062678933143616, "(2, 16)": 0.7062678933143616, "(4, 0)": 0.7062678933143616, "(4, 16)": 0.7062678933143616, "(6, 0)": 0.7062678933143616, "(6, 16)": 0.8399902582168579, "(8, 0)": 0.7062678933143616, "(8, 16)": 0.7062678933143616, "(10, 0)": 0.8399902582168579, "(10, 16)": 0.8399902582168579, "(12, 0)": 0.8399902582168579, "(12, 16)": 0.8399902582168579, "(14, 0)": 0.6692593097686768, "(14, 16)": 0.8399902582168579, "(16, 0)": 0.8399902582168579, "(16, 16)": 0.8399902582168579, "(18, 0)": 0.8399902582168579, "(18, 16)": 0.8399902582168579, "(20, 0)": 0.8399902582168579, "(20, 16)": 0.6692593097686768, "(22, 0)": 0.8399902582168579, "(22, 16)": 0.6692593097686768, "(24, 0)": 0.8399902582168579, "(24, 16)": 0.747796893119812, "(26, 0)": 0.8399902582168579, "(26, 16)": 0.8399902582168579, "(28, 0)": 0.8399902582168579, "(28, 16)": 0.6692593097686768, "(30, 0)": 0.8399902582168579, "(30, 16)": 0.8399902582168579}, "r_span": [481, 580], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 2.956390380859375e-05}}]}, {"id": "183", "source_id": "15623", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Indiana Pacer Chris Copeland was stabbed outside a New York nightclub early Wednesday morning, and two Atlanta Hawks players, Pero Antic and Thabo Sefolosha, were arrested for obstruction and other charges after attempting to intervene in the incident. According to police, Copeland and a female companion were walking away from the club when a 22-year-old man approached them and there was a dispute before the suspect stabbed Copeland and the woman. Copeland suffered a knife wound to his elbow and abdomen and is in stable condition at a New York hospital. Antic and Sefolosha were taken into custody after they allegedly interfered with police officers trying to establish a crime scene and pushed a police officer. The Hawks players were in New York for a Wednesday night game against the Brooklyn Nets, and neither will be in uniform due to the incident.", "response_spans": [[0, 512], [497, 860]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6207649111747742, "(0, 16)": 0.6930111050605774, "(2, 0)": 0.6207649111747742, "(2, 16)": 0.6207649111747742, "(4, 0)": 0.6207649111747742, "(4, 16)": 0.6207649111747742, "(6, 0)": 0.6207649111747742, "(6, 16)": 0.8734318017959595, "(8, 0)": 0.6207649111747742, "(8, 16)": 0.6207649111747742, "(10, 0)": 0.6207649111747742, "(10, 16)": 0.6207649111747742, "(12, 0)": 0.6207649111747742, "(12, 16)": 0.8365646600723267, "(14, 0)": 0.6207649111747742, "(14, 16)": 0.6207649111747742, "(16, 0)": 0.6207649111747742, "(16, 16)": 0.6207649111747742, "(18, 0)": 0.6207649111747742, "(18, 16)": 0.8734318017959595, "(20, 0)": 0.7893444299697876, "(20, 16)": 0.6930111050605774, "(22, 0)": 0.6207649111747742, "(22, 16)": 0.7893444299697876, "(24, 0)": 0.6207649111747742, "(24, 16)": 0.7893444299697876, "(26, 0)": 0.6207649111747742, "(26, 16)": 0.6207649111747742, "(28, 0)": 0.6207649111747742, "(28, 16)": 0.6207649111747742, "(30, 0)": 0.6207649111747742, "(30, 16)": 0.6207649111747742}, "r_span": [1491, 1612], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00045180320739746094}}, {"prompt_attention_score": {"(0, 0)": 0.7311254739761353, "(0, 16)": 0.5358074307441711, "(2, 0)": 0.5358074307441711, "(2, 16)": 0.5358074307441711, "(4, 0)": 0.5358074307441711, "(4, 16)": 0.5358074307441711, "(6, 0)": 0.5358074307441711, "(6, 16)": 0.7157676219940186, "(8, 0)": 0.5358074307441711, "(8, 16)": 0.7311254739761353, "(10, 0)": 0.5358074307441711, "(10, 16)": 0.5358074307441711, "(12, 0)": 0.5358074307441711, "(12, 16)": 0.7157676219940186, "(14, 0)": 0.7311254739761353, "(14, 16)": 0.5358074307441711, "(16, 0)": 0.5358074307441711, "(16, 16)": 0.5358074307441711, "(18, 0)": 0.5358074307441711, "(18, 16)": 0.7157676219940186, "(20, 0)": 0.7157676219940186, "(20, 16)": 0.7311254739761353, "(22, 0)": 0.5358074307441711, "(22, 16)": 0.7890162467956543, "(24, 0)": 0.7311254739761353, "(24, 16)": 0.7890162467956543, "(26, 0)": 0.5358074307441711, "(26, 16)": 0.5358074307441711, "(28, 0)": 0.5358074307441711, "(28, 16)": 0.7311254739761353, "(30, 0)": 0.5358074307441711, "(30, 16)": 0.7375255823135376}, "r_span": [1608, 1689], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0014275312423706055}}]}, {"id": "207", "source_id": "15627", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Selena, the Tejano music icon who passed away 20 years ago, is set to make a comeback through a hologram-like figure created by her family using advanced technology. The digital embodiment will allow the singer to walk, talk, sing, and dance, and will be the first of its kind using the new technology developed by Acrovirt LLC. The project, called \"Selena the One,\" aims to expand her legacy by releasing new songs and videos, collaborating with current hit artists, and going on tour in 2018. Fans can support the launch through an Indiegogo campaign starting April 16, with a goal of raising $500,000.", "response_spans": [[0, 511], [495, 604]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7312444448471069, "(0, 16)": 0.7312444448471069, "(2, 0)": 0.7312444448471069, "(2, 16)": 0.7312444448471069, "(4, 0)": 0.7312444448471069, "(4, 16)": 0.7312444448471069, "(6, 0)": 0.7312444448471069, "(6, 16)": 0.8612819910049438, "(8, 0)": 0.7312444448471069, "(8, 16)": 0.7312444448471069, "(10, 0)": 0.7312444448471069, "(10, 16)": 0.7312444448471069, "(12, 0)": 0.7312444448471069, "(12, 16)": 0.8198028802871704, "(14, 0)": 0.7312444448471069, "(14, 16)": 0.8612819910049438, "(16, 0)": 0.8612819910049438, "(16, 16)": 0.7312444448471069, "(18, 0)": 0.7312444448471069, "(18, 16)": 0.8612819910049438, "(20, 0)": 0.8612819910049438, "(20, 16)": 0.7312444448471069, "(22, 0)": 0.7312444448471069, "(22, 16)": 0.8612819910049438, "(24, 0)": 0.7312444448471069, "(24, 16)": 0.8198028802871704, "(26, 0)": 0.8612819910049438, "(26, 16)": 0.8612819910049438, "(28, 0)": 0.8612819910049438, "(28, 16)": 0.7312444448471069, "(30, 0)": 0.8612819910049438, "(30, 16)": 0.8612819910049438}, "r_span": [697, 827], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014847517013549805}}, {"prompt_attention_score": {"(0, 0)": 0.6447652578353882, "(0, 16)": 0.6447652578353882, "(2, 0)": 0.6447652578353882, "(2, 16)": 0.6447652578353882, "(4, 0)": 0.6447652578353882, "(4, 16)": 0.6447652578353882, "(6, 0)": 0.6447652578353882, "(6, 16)": 0.6447652578353882, "(8, 0)": 0.6447652578353882, "(8, 16)": 0.6447652578353882, "(10, 0)": 0.6447652578353882, "(10, 16)": 0.6447652578353882, "(12, 0)": 0.6447652578353882, "(12, 16)": 0.6447652578353882, "(14, 0)": 0.6447652578353882, "(14, 16)": 0.6447652578353882, "(16, 0)": 0.6447652578353882, "(16, 16)": 0.6447652578353882, "(18, 0)": 0.6447652578353882, "(18, 16)": 0.6447652578353882, "(20, 0)": 0.6447652578353882, "(20, 16)": 0.6447652578353882, "(22, 0)": 0.6447652578353882, "(22, 16)": 0.6447652578353882, "(24, 0)": 0.6447652578353882, "(24, 16)": 0.6447652578353882, "(26, 0)": 0.3896823525428772, "(26, 16)": 0.6447652578353882, "(28, 0)": 0.3896823525428772, "(28, 16)": 0.6447652578353882, "(30, 0)": 0.3896823525428772, "(30, 16)": 0.3896823525428772}, "r_span": [824, 855], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0001932382583618164}}]}, {"id": "213", "source_id": "15628", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 46, "end": 76, "text": "unexpected stop in Los Angeles", "meta": "EVIDENT CONFLICT\nOriginal: was just barely on its way to Los Angeles\nGenerated: unexpected stop in Los Angeles", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "On Monday, Alaska Airlines Flight 448 made an unexpected stop in Los Angeles after the pilot heard strange noises coming from the cargo hold. Further investigation revealed that a ramp agent from Menzies Aviation had fallen asleep in the cargo hold. Although the passenger compartment was pressurized and temperature-controlled, the man's presence caused concern among the passengers. An emergency landing was made, and the agent was taken to the hospital as a precaution but was later released. The airline is investigating the incident.", "response_spans": [[0, 510], [496, 538]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.754285991191864, "(0, 16)": 0.7528464794158936, "(2, 0)": 0.754285991191864, "(2, 16)": 0.754285991191864, "(4, 0)": 0.754285991191864, "(4, 16)": 0.754285991191864, "(6, 0)": 0.754285991191864, "(6, 16)": 0.8818267583847046, "(8, 0)": 0.754285991191864, "(8, 16)": 0.754285991191864, "(10, 0)": 0.754285991191864, "(10, 16)": 0.754285991191864, "(12, 0)": 0.754285991191864, "(12, 16)": 0.8818267583847046, "(14, 0)": 0.754285991191864, "(14, 16)": 0.8201042413711548, "(16, 0)": 0.8201042413711548, "(16, 16)": 0.754285991191864, "(18, 0)": 0.754285991191864, "(18, 16)": 0.8818267583847046, "(20, 0)": 0.8818267583847046, "(20, 16)": 0.754285991191864, "(22, 0)": 0.754285991191864, "(22, 16)": 0.8818267583847046, "(24, 0)": 0.754285991191864, "(24, 16)": 0.8818267583847046, "(26, 0)": 0.8201042413711548, "(26, 16)": 0.8201042413711548, "(28, 0)": 0.8201042413711548, "(28, 16)": 0.754285991191864, "(30, 0)": 0.8201042413711548, "(30, 16)": 0.8201042413711548}, "r_span": [834, 944], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.001285254955291748}}, {"prompt_attention_score": {"(0, 0)": 0.7229304313659668, "(0, 16)": 0.7229304313659668, "(2, 0)": 0.6879189014434814, "(2, 16)": 0.6879189014434814, "(4, 0)": 0.6879189014434814, "(4, 16)": 0.6879189014434814, "(6, 0)": 0.6879189014434814, "(6, 16)": 0.6890048384666443, "(8, 0)": 0.6879189014434814, "(8, 16)": 0.6879189014434814, "(10, 0)": 0.6879189014434814, "(10, 16)": 0.7229304313659668, "(12, 0)": 0.6879189014434814, "(12, 16)": 0.6879189014434814, "(14, 0)": 0.6879189014434814, "(14, 16)": 0.6879189014434814, "(16, 0)": 0.6879189014434814, "(16, 16)": 0.6263923048973083, "(18, 0)": 0.6879189014434814, "(18, 16)": 0.6879189014434814, "(20, 0)": 0.6879189014434814, "(20, 16)": 0.6879189014434814, "(22, 0)": 0.6879189014434814, "(22, 16)": 0.6879189014434814, "(24, 0)": 0.6879189014434814, "(24, 16)": 0.6879189014434814, "(26, 0)": 0.6263923048973083, "(26, 16)": 0.6879189014434814, "(28, 0)": 0.6263923048973083, "(28, 16)": 0.6879189014434814, "(30, 0)": 0.6263923048973083, "(30, 16)": 0.6263923048973083}, "r_span": [941, 949], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004565715789794922}}]}, {"id": "249", "source_id": "15634", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Emy Afalava, a loyal American and decorated veteran, was born in American Samoa, a US territory since 1900. Despite being subject to US law his whole life, Afalava has been denied the right to vote due to the federal government's insistence that he is not a citizen. This is despite the Fourteenth Amendment's declaration that all persons born in the US are citizens. Afalava and other American Samoans are seeking to right this injustice through a federal lawsuit. The case has echoes of the Dred Scott decision, which ruled that free African Americans had no rights that white men were bound to respect. Despite being overturned in the Civil War, similar racial discrimination continues to affect the rights of Americans born in US territories.", "response_spans": [[0, 503], [486, 746]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7888827919960022, "(0, 16)": 0.7888827919960022, "(2, 0)": 0.7888827919960022, "(2, 16)": 0.7888827919960022, "(4, 0)": 0.7888827919960022, "(4, 16)": 0.7888827919960022, "(6, 0)": 0.7888827919960022, "(6, 16)": 0.954951286315918, "(8, 0)": 0.954951286315918, "(8, 16)": 0.7888827919960022, "(10, 0)": 0.8789530396461487, "(10, 16)": 0.7888827919960022, "(12, 0)": 0.7888827919960022, "(12, 16)": 0.954951286315918, "(14, 0)": 0.7888827919960022, "(14, 16)": 0.8789530396461487, "(16, 0)": 0.954951286315918, "(16, 16)": 0.7888827919960022, "(18, 0)": 0.7888827919960022, "(18, 16)": 0.954951286315918, "(20, 0)": 0.954951286315918, "(20, 16)": 0.6648436784744263, "(22, 0)": 0.7888827919960022, "(22, 16)": 0.954951286315918, "(24, 0)": 0.6648436784744263, "(24, 16)": 0.954951286315918, "(26, 0)": 0.954951286315918, "(26, 16)": 0.7888827919960022, "(28, 0)": 0.954951286315918, "(28, 16)": 0.954951286315918, "(30, 0)": 0.6648436784744263, "(30, 16)": 0.954951286315918}, "r_span": [982, 1106], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013052821159362793}}, {"prompt_attention_score": {"(0, 0)": 0.6598277688026428, "(0, 16)": 0.6598277688026428, "(2, 0)": 0.6743749380111694, "(2, 16)": 0.6743749380111694, "(4, 0)": 0.6743749380111694, "(4, 16)": 0.6743749380111694, "(6, 0)": 0.6743749380111694, "(6, 16)": 0.8211965560913086, "(8, 0)": 0.6598277688026428, "(8, 16)": 0.6743749380111694, "(10, 0)": 0.6743749380111694, "(10, 16)": 0.6743749380111694, "(12, 0)": 0.6743749380111694, "(12, 16)": 0.8211965560913086, "(14, 0)": 0.6739742159843445, "(14, 16)": 0.8211965560913086, "(16, 0)": 0.8211965560913086, "(16, 16)": 0.6743749380111694, "(18, 0)": 0.6739742159843445, "(18, 16)": 0.8211965560913086, "(20, 0)": 0.8211965560913086, "(20, 16)": 0.6739742159843445, "(22, 0)": 0.6372560858726501, "(22, 16)": 0.8211965560913086, "(24, 0)": 0.6372560858726501, "(24, 16)": 0.8211965560913086, "(26, 0)": 0.6136981248855591, "(26, 16)": 0.6743749380111694, "(28, 0)": 0.6136981248855591, "(28, 16)": 0.6136981248855591, "(30, 0)": 0.6372560858726501, "(30, 16)": 0.6136981248855591}, "r_span": [1102, 1154], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004458427429199219}}]}, {"id": "273", "source_id": "15638", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 53, "end": 68, "text": "Somali-Canadian", "meta": "EVIDENT CONFLICT\nOriginal: \"The sisters were born in the Somali capital but were forced to flee after war broke out in 1991. Along with their parents, the girls relocated to Canada as refugees...\"\nGenerative: \"Somali-Canadian singers...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure, here's a summary of the article in 200 words:\n\nSomali-Canadian singing sisters Iman and Siham Hashi, known as Faarrow, are set to release their debut album in Los Angeles after fleeing their home country due to war in 1991. They have been working with producer Elijah Kelley and have described their sound as a fusion of pop, hip-hop, and African rhythms. The sisters also work with the UNHCR and have started a non-profit organization to provide sustainable income for women in Kenya and Somalia. They hope to use their platform to inspire others and help rebuild their home country.", "response_spans": [[0, 51], [53, 562], [547, 590]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5292114019393921, "(0, 16)": 0.5292114019393921, "(2, 0)": 0.5292114019393921, "(2, 16)": 0.5292114019393921, "(4, 0)": 0.5292114019393921, "(4, 16)": 0.5238206386566162, "(6, 0)": 0.5292114019393921, "(6, 16)": 0.8295433521270752, "(8, 0)": 0.5238206386566162, "(8, 16)": 0.552704930305481, "(10, 0)": 0.8295433521270752, "(10, 16)": 0.552704930305481, "(12, 0)": 0.552704930305481, "(12, 16)": 0.8295433521270752, "(14, 0)": 0.5292114019393921, "(14, 16)": 0.552704930305481, "(16, 0)": 0.552704930305481, "(16, 16)": 0.5292114019393921, "(18, 0)": 0.552704930305481, "(18, 16)": 0.8295433521270752, "(20, 0)": 0.8295433521270752, "(20, 16)": 0.5292114019393921, "(22, 0)": 0.43680351972579956, "(22, 16)": 0.43680351972579956, "(24, 0)": 0.5292114019393921, "(24, 16)": 0.43680351972579956, "(26, 0)": 0.43680351972579956, "(26, 16)": 0.47004935145378113, "(28, 0)": 0.43680351972579956, "(28, 16)": 0.5292114019393921, "(30, 0)": 0.43680351972579956, "(30, 16)": 0.43680351972579956}, "r_span": [1367, 1385], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005775094032287598}}, {"prompt_attention_score": {"(0, 0)": 0.6755114793777466, "(0, 16)": 0.6755114793777466, "(2, 0)": 0.6755114793777466, "(2, 16)": 0.6755114793777466, "(4, 0)": 0.6755114793777466, "(4, 16)": 0.5405706167221069, "(6, 0)": 0.6755114793777466, "(6, 16)": 0.8101727366447449, "(8, 0)": 0.7544276714324951, "(8, 16)": 0.6755114793777466, "(10, 0)": 0.6755114793777466, "(10, 16)": 0.6755114793777466, "(12, 0)": 0.6755114793777466, "(12, 16)": 0.561920702457428, "(14, 0)": 0.6755114793777466, "(14, 16)": 0.8101727366447449, "(16, 0)": 0.6416336297988892, "(16, 16)": 0.6755114793777466, "(18, 0)": 0.6755114793777466, "(18, 16)": 0.561920702457428, "(20, 0)": 0.8101727366447449, "(20, 16)": 0.6755114793777466, "(22, 0)": 0.6755114793777466, "(22, 16)": 0.8101727366447449, "(24, 0)": 0.6755114793777466, "(24, 16)": 0.8101727366447449, "(26, 0)": 0.8101727366447449, "(26, 16)": 0.6755114793777466, "(28, 0)": 0.8101727366447449, "(28, 16)": 0.6755114793777466, "(30, 0)": 0.8101727366447449, "(30, 16)": 0.8101727366447449}, "r_span": [1387, 1516], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00017279386520385742}}, {"prompt_attention_score": {"(0, 0)": 0.597987949848175, "(0, 16)": 0.597987949848175, "(2, 0)": 0.5674405097961426, "(2, 16)": 0.5674405097961426, "(4, 0)": 0.5674405097961426, "(4, 16)": 0.42128199338912964, "(6, 0)": 0.42128199338912964, "(6, 16)": 0.5487704873085022, "(8, 0)": 0.597987949848175, "(8, 16)": 0.5674405097961426, "(10, 0)": 0.5674405097961426, "(10, 16)": 0.597987949848175, "(12, 0)": 0.597987949848175, "(12, 16)": 0.597987949848175, "(14, 0)": 0.597987949848175, "(14, 16)": 0.597987949848175, "(16, 0)": 0.597987949848175, "(16, 16)": 0.42128199338912964, "(18, 0)": 0.5674405097961426, "(18, 16)": 0.597987949848175, "(20, 0)": 0.597987949848175, "(20, 16)": 0.597987949848175, "(22, 0)": 0.597987949848175, "(22, 16)": 0.597987949848175, "(24, 0)": 0.597987949848175, "(24, 16)": 0.597987949848175, "(26, 0)": 0.5487704873085022, "(26, 16)": 0.597987949848175, "(28, 0)": 0.5487704873085022, "(28, 16)": 0.5487704873085022, "(30, 0)": 0.5487704873085022, "(30, 16)": 0.5487704873085022}, "r_span": [1514, 1522], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003267526626586914}}]}, {"id": "315", "source_id": "15645", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 84 words or less:\n\nThe US Senate approved a bipartisan Medicare reform bill with a permanent solution to the \"doc fix\" and a two-year extension of a popular children's health insurance program. The bill passed 92-8 despite opposition from some conservatives who wanted offsets for the $200 billion cost. The bill now heads to President Obama's desk for signing.", "response_spans": [[0, 397]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6892176270484924, "(0, 16)": 0.6892176270484924, "(2, 0)": 0.6892176270484924, "(2, 16)": 0.6892176270484924, "(4, 0)": 0.6892176270484924, "(4, 16)": 0.6892176270484924, "(6, 0)": 0.6892176270484924, "(6, 16)": 0.8983809351921082, "(8, 0)": 0.691263735294342, "(8, 16)": 0.6892176270484924, "(10, 0)": 0.7347312569618225, "(10, 16)": 0.6892176270484924, "(12, 0)": 0.6892176270484924, "(12, 16)": 0.8983809351921082, "(14, 0)": 0.8983809351921082, "(14, 16)": 0.8983809351921082, "(16, 0)": 0.8983809351921082, "(16, 16)": 0.8983809351921082, "(18, 0)": 0.8983809351921082, "(18, 16)": 0.8983809351921082, "(20, 0)": 0.8983809351921082, "(20, 16)": 0.8983809351921082, "(22, 0)": 0.8983809351921082, "(22, 16)": 0.8983809351921082, "(24, 0)": 0.8983809351921082, "(24, 16)": 0.8983809351921082, "(26, 0)": 0.8983809351921082, "(26, 16)": 0.8983809351921082, "(28, 0)": 0.8983809351921082, "(28, 16)": 0.8983809351921082, "(30, 0)": 0.8983809351921082, "(30, 16)": 0.8983809351921082}, "r_span": [554, 652], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0038523077964782715}}]}, {"id": "333", "source_id": "15648", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 55 words or less:\n\nZack Snyder's \"Batman v. Superman: Dawn of Justice\" trailer leaked online before being removed, showing footage of Superman and Batman facing off. The trailer will premiere in Imax theaters on Monday, and the film stars Henry Cavill and Ben Affleck.", "response_spans": [[0, 304]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8485209345817566, "(0, 16)": 0.8485209345817566, "(2, 0)": 0.8485209345817566, "(2, 16)": 0.8485209345817566, "(4, 0)": 0.8485209345817566, "(4, 16)": 0.8485209345817566, "(6, 0)": 0.8485209345817566, "(6, 16)": 0.8118635416030884, "(8, 0)": 0.8118635416030884, "(8, 16)": 0.8485209345817566, "(10, 0)": 0.8485209345817566, "(10, 16)": 0.8485209345817566, "(12, 0)": 0.8118635416030884, "(12, 16)": 0.6346664428710938, "(14, 0)": 0.8485209345817566, "(14, 16)": 0.8118635416030884, "(16, 0)": 0.8118635416030884, "(16, 16)": 0.8118635416030884, "(18, 0)": 0.8118635416030884, "(18, 16)": 0.8118635416030884, "(20, 0)": 0.8118635416030884, "(20, 16)": 0.8485209345817566, "(22, 0)": 0.8118635416030884, "(22, 16)": 0.8118635416030884, "(24, 0)": 0.8118635416030884, "(24, 16)": 0.8118635416030884, "(26, 0)": 0.8118635416030884, "(26, 16)": 0.8485209345817566, "(28, 0)": 0.8118635416030884, "(28, 16)": 0.8118635416030884, "(30, 0)": 0.8118635416030884, "(30, 16)": 0.8118635416030884}, "r_span": [401, 487], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0017023682594299316}}]}, {"id": "351", "source_id": "15651", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "The Pope faced a difficult decision during a recent mass in Rome, where he chose to acknowledge the deaths of over 1 million Armenians a century ago, while avoiding using the term \"genocide\". This move was seen as a balance between maintaining the church's moral and political clout, while also avoiding offending Turkey, a key ally in the fight against ISIS. The Pope cited a previous Pope's document, rather than using the word directly, in order to emphasize continuity in the church's stance on the issue. However, Turkey was not pleased with the Pope's remarks and recalled its ambassador to the Vatican, leading to a diplomatic spat. The Pope also spoke at a mass for priests on Monday, encouraging them to speak openly and without fear, as the early apostles did.", "response_spans": [[0, 509], [496, 770]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7617409825325012, "(0, 16)": 0.7617409825325012, "(2, 0)": 0.7617409825325012, "(2, 16)": 0.7617409825325012, "(4, 0)": 0.7617409825325012, "(4, 16)": 0.7617409825325012, "(6, 0)": 0.7617409825325012, "(6, 16)": 0.7984352111816406, "(8, 0)": 0.7617409825325012, "(8, 16)": 0.7617409825325012, "(10, 0)": 0.7896369099617004, "(10, 16)": 0.7617409825325012, "(12, 0)": 0.7617409825325012, "(12, 16)": 0.8427813053131104, "(14, 0)": 0.7617409825325012, "(14, 16)": 0.8427813053131104, "(16, 0)": 0.7984352111816406, "(16, 16)": 0.7617409825325012, "(18, 0)": 0.7617409825325012, "(18, 16)": 0.7770290374755859, "(20, 0)": 0.7984352111816406, "(20, 16)": 0.7617409825325012, "(22, 0)": 0.7617409825325012, "(22, 16)": 0.7984352111816406, "(24, 0)": 0.7617409825325012, "(24, 16)": 0.7984352111816406, "(26, 0)": 0.708625078201294, "(26, 16)": 0.7617409825325012, "(28, 0)": 0.708625078201294, "(28, 16)": 0.7617409825325012, "(30, 0)": 0.7617409825325012, "(30, 16)": 0.708625078201294}, "r_span": [1347, 1466], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0018765926361083984}}, {"prompt_attention_score": {"(0, 0)": 0.8081493973731995, "(0, 16)": 0.8081493973731995, "(2, 0)": 0.8081493973731995, "(2, 16)": 0.8081493973731995, "(4, 0)": 0.8081493973731995, "(4, 16)": 0.8081493973731995, "(6, 0)": 0.8081493973731995, "(6, 16)": 0.8087620139122009, "(8, 0)": 0.8081493973731995, "(8, 16)": 0.8081493973731995, "(10, 0)": 0.8081493973731995, "(10, 16)": 0.8081493973731995, "(12, 0)": 0.8081493973731995, "(12, 16)": 0.8081493973731995, "(14, 0)": 0.8081493973731995, "(14, 16)": 0.8081493973731995, "(16, 0)": 0.8081493973731995, "(16, 16)": 0.6615941524505615, "(18, 0)": 0.8081493973731995, "(18, 16)": 0.8081493973731995, "(20, 0)": 0.8081493973731995, "(20, 16)": 0.8081493973731995, "(22, 0)": 0.8081493973731995, "(22, 16)": 0.8081493973731995, "(24, 0)": 0.8081493973731995, "(24, 16)": 0.8081493973731995, "(26, 0)": 0.6615941524505615, "(26, 16)": 0.8081493973731995, "(28, 0)": 0.6615941524505615, "(28, 16)": 0.8081493973731995, "(30, 0)": 0.8081493973731995, "(30, 16)": 0.6615941524505615}, "r_span": [1463, 1529], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002730846405029297}}]}, {"id": "357", "source_id": "15652", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Free admission to US national parks this weekend! üèûÔ∏è Explore 128 fee-charging parks, including Yosemite and Yellowstone, during National Park Week (April 18-26). Find park sites near you & join events like stargazing parties, Revolutionary War programs, Earth Day festivities, and Junior Ranger activities. Share your park experiences with #FindYourPark.", "response_spans": [[0, 354]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8748666048049927, "(0, 16)": 0.7803357839584351, "(2, 0)": 0.8748666048049927, "(2, 16)": 0.7803357839584351, "(4, 0)": 0.8748666048049927, "(4, 16)": 0.8748666048049927, "(6, 0)": 0.7803357839584351, "(6, 16)": 0.8748666048049927, "(8, 0)": 0.8748666048049927, "(8, 16)": 0.8748666048049927, "(10, 0)": 0.8748666048049927, "(10, 16)": 0.8748666048049927, "(12, 0)": 0.8748666048049927, "(12, 16)": 0.8748666048049927, "(14, 0)": 0.8748666048049927, "(14, 16)": 0.8748666048049927, "(16, 0)": 0.8748666048049927, "(16, 16)": 0.8748666048049927, "(18, 0)": 0.8748666048049927, "(18, 16)": 0.7803357839584351, "(20, 0)": 0.8748666048049927, "(20, 16)": 0.8748666048049927, "(22, 0)": 0.8748666048049927, "(22, 16)": 0.8748666048049927, "(24, 0)": 0.8748666048049927, "(24, 16)": 0.7803357839584351, "(26, 0)": 0.8748666048049927, "(26, 16)": 0.8748666048049927, "(28, 0)": 0.8748666048049927, "(28, 16)": 0.8748666048049927, "(30, 0)": 0.8748666048049927, "(30, 16)": 0.8748666048049927}, "r_span": [284, 382], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017181634902954102}}]}, {"id": "411", "source_id": "15661", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 82 words:\n\nA second robot was sent into the crippled Fukushima nuclear plant to collect data on radiation levels, capturing images of a strange green glow. While the robot detected lower radiation levels than expected, the cause of the green glow remains unknown. The robotic probe is part of an unprecedented experiment to gather information on the damaged reactors, which are still unsafe for people to enter four years after the nuclear crisis.", "response_spans": [[0, 488]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8350224494934082, "(0, 16)": 0.8350224494934082, "(2, 0)": 0.8350224494934082, "(2, 16)": 0.8350224494934082, "(4, 0)": 0.8350224494934082, "(4, 16)": 0.8350224494934082, "(6, 0)": 0.8350224494934082, "(6, 16)": 0.867358922958374, "(8, 0)": 0.8350224494934082, "(8, 16)": 0.8350224494934082, "(10, 0)": 0.8350224494934082, "(10, 16)": 0.8350224494934082, "(12, 0)": 0.7662138938903809, "(12, 16)": 0.8350224494934082, "(14, 0)": 0.7662138938903809, "(14, 16)": 0.7662138938903809, "(16, 0)": 0.867358922958374, "(16, 16)": 0.7662138938903809, "(18, 0)": 0.7662138938903809, "(18, 16)": 0.8350224494934082, "(20, 0)": 0.8350224494934082, "(20, 16)": 0.7662138938903809, "(22, 0)": 0.7662138938903809, "(22, 16)": 0.867358922958374, "(24, 0)": 0.7662138938903809, "(24, 16)": 0.867358922958374, "(26, 0)": 0.7662138938903809, "(26, 16)": 0.7662138938903809, "(28, 0)": 0.7662138938903809, "(28, 16)": 0.7662138938903809, "(30, 0)": 0.7662138938903809, "(30, 16)": 0.7662138938903809}, "r_span": [523, 634], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005651712417602539}}]}, {"id": "435", "source_id": "15665", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "On Tuesday, the trial of Dzhokhar Tsarnaev, the Boston Marathon bomber, entered its sentencing phase. The prosecution presented emotional testimony from the victims' families and friends, describing the devastating impact of Tsarnaev's actions on their lives. The bombs he detonated tore through their bodies, causing severe injuries and death. The witnesses recounted their harrowing experiences, including the sound of explosions, the sight of blood and mangled flesh, and the feeling of intense pain and fear. One witness, Gillian Reny, described the chaos and horror she witnessed after the bombing, including the sight of her own broken leg and the blood everywhere. Another witness, Celeste Corcoran, lost both of her legs in the blast and described the intense pain and discomfort she experiences daily. The prosecution also showed jurors a photo of Tsarnaev, glaring defiantly into the camera from a holding cell. The defense will present its case later in the trial. The jury must now decide whether Tsarnaev should live or die for his crimes.", "response_spans": [[0, 512], [498, 1008], [990, 1052]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5610593557357788, "(0, 16)": 0.7161116600036621, "(2, 0)": 0.5610593557357788, "(2, 16)": 0.5610593557357788, "(4, 0)": 0.5610593557357788, "(4, 16)": 0.5610593557357788, "(6, 0)": 0.5610593557357788, "(6, 16)": 0.8290025591850281, "(8, 0)": 0.5610593557357788, "(8, 16)": 0.5610593557357788, "(10, 0)": 0.5610593557357788, "(10, 16)": 0.5610593557357788, "(12, 0)": 0.5610593557357788, "(12, 16)": 0.8290025591850281, "(14, 0)": 0.5610593557357788, "(14, 16)": 0.5610593557357788, "(16, 0)": 0.5610593557357788, "(16, 16)": 0.5610593557357788, "(18, 0)": 0.5610593557357788, "(18, 16)": 0.8290025591850281, "(20, 0)": 0.8290025591850281, "(20, 16)": 0.5610593557357788, "(22, 0)": 0.5610593557357788, "(22, 16)": 0.8290025591850281, "(24, 0)": 0.5610593557357788, "(24, 16)": 0.8290025591850281, "(26, 0)": 0.5610593557357788, "(26, 16)": 0.5610593557357788, "(28, 0)": 0.5610593557357788, "(28, 16)": 0.5610593557357788, "(30, 0)": 0.5610593557357788, "(30, 16)": 0.5610593557357788}, "r_span": [1571, 1693], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006049871444702148}}, {"prompt_attention_score": {"(0, 0)": 0.6470699310302734, "(0, 16)": 0.6470699310302734, "(2, 0)": 0.7149825096130371, "(2, 16)": 0.7149825096130371, "(4, 0)": 0.7149825096130371, "(4, 16)": 0.7149825096130371, "(6, 0)": 0.7149825096130371, "(6, 16)": 0.7090031504631042, "(8, 0)": 0.7149825096130371, "(8, 16)": 0.7149825096130371, "(10, 0)": 0.6470699310302734, "(10, 16)": 0.6470699310302734, "(12, 0)": 0.7149825096130371, "(12, 16)": 0.7852413654327393, "(14, 0)": 0.7149825096130371, "(14, 16)": 0.7149825096130371, "(16, 0)": 0.6470699310302734, "(16, 16)": 0.7149825096130371, "(18, 0)": 0.7149825096130371, "(18, 16)": 0.7852413654327393, "(20, 0)": 0.8333717584609985, "(20, 16)": 0.6470699310302734, "(22, 0)": 0.7149825096130371, "(22, 16)": 0.8333717584609985, "(24, 0)": 0.7149825096130371, "(24, 16)": 0.7852413654327393, "(26, 0)": 0.7149825096130371, "(26, 16)": 0.6470699310302734, "(28, 0)": 0.7149825096130371, "(28, 16)": 0.7149825096130371, "(30, 0)": 0.7149825096130371, "(30, 16)": 0.7149825096130371}, "r_span": [1690, 1806], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0035001039505004883}}, {"prompt_attention_score": {"(0, 0)": 0.4810297191143036, "(0, 16)": 0.4810297191143036, "(2, 0)": 0.4810297191143036, "(2, 16)": 0.4810297191143036, "(4, 0)": 0.4810297191143036, "(4, 16)": 0.4810297191143036, "(6, 0)": 0.4810297191143036, "(6, 16)": 0.7205640077590942, "(8, 0)": 0.4810297191143036, "(8, 16)": 0.4810297191143036, "(10, 0)": 0.4810297191143036, "(10, 16)": 0.4810297191143036, "(12, 0)": 0.4810297191143036, "(12, 16)": 0.7205640077590942, "(14, 0)": 0.4810297191143036, "(14, 16)": 0.4810297191143036, "(16, 0)": 0.4339839518070221, "(16, 16)": 0.4810297191143036, "(18, 0)": 0.4810297191143036, "(18, 16)": 0.7205640077590942, "(20, 0)": 0.7205640077590942, "(20, 16)": 0.4810297191143036, "(22, 0)": 0.4810297191143036, "(22, 16)": 0.4810297191143036, "(24, 0)": 0.4810297191143036, "(24, 16)": 0.7205640077590942, "(26, 0)": 0.4810297191143036, "(26, 16)": 0.4339839518070221, "(28, 0)": 0.4810297191143036, "(28, 16)": 0.4810297191143036, "(30, 0)": 0.4810297191143036, "(30, 16)": 0.4810297191143036}, "r_span": [1804, 1818], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003274083137512207}}]}, {"id": "447", "source_id": "15667", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 632, "end": 666, "text": "including Entertainer of the Year.", "meta": "HIGH INTRO OF NEW INFO\nAIGC: including Entertainer of the Year.\nOriginal: This is not mentioned in the source content.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 135, "end": 229, "text": "Hosts Blake Shelton and Luke Bryan kicked off the night with an energetic opening performance,", "meta": "EVIDENT CONFLICT:\nAIGC: Hosts Blake Shelton and Luke Bryan kicked off the night with an energetic opening performance, \nOriginal: It is Eric Church & Keith Urban who provided an opening wallop", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "The 50th Annual Academy of Country Music Awards held at the Dallas Cowboys Stadium was a grand event with plenty of memorable moments. Hosts Blake Shelton and Luke Bryan kicked off the night with an energetic opening performance, followed by standout performances from Eric Church, Keith Urban, and Taylor Swift. Reba McEntire proved why she's a country legend with her powerful vocals, while Garth Brooks paid tribute to the US military with an emotional performance. Christina Aguilera surprised fans by joining Rascal Flatts for a collaborative performance. Miranda Lambert dominated the awards category, winning several awards, including Entertainer of the Year. Other highlights included Jason Aldean's powerful medley, Little Big Town bringing their poignant ballad \"Girl Crush\" to the stage, and Steven Tyler's unique facial hair. However, some viewers criticized the length of the ceremony, which ran for three and a half hours, and felt that some of the milestone awards given to country legends like Reba McEntire, Kenny Chesney, and George Strait were rushed. Additionally, some Twitter users criticized Taylor Swift for attending the awards show despite transitioning to pop music.", "response_spans": [[0, 505], [488, 996], [980, 1193]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6123592853546143, "(0, 16)": 0.6123592853546143, "(2, 0)": 0.6123592853546143, "(2, 16)": 0.6123592853546143, "(4, 0)": 0.6123592853546143, "(4, 16)": 0.6123592853546143, "(6, 0)": 0.6123592853546143, "(6, 16)": 0.7787750363349915, "(8, 0)": 0.6123592853546143, "(8, 16)": 0.6123592853546143, "(10, 0)": 0.6123592853546143, "(10, 16)": 0.7393971681594849, "(12, 0)": 0.6123592853546143, "(12, 16)": 0.7787750363349915, "(14, 0)": 0.6123592853546143, "(14, 16)": 0.7787750363349915, "(16, 0)": 0.7787750363349915, "(16, 16)": 0.6123592853546143, "(18, 0)": 0.6123592853546143, "(18, 16)": 0.7787750363349915, "(20, 0)": 0.7787750363349915, "(20, 16)": 0.6123592853546143, "(22, 0)": 0.6123592853546143, "(22, 16)": 0.7787750363349915, "(24, 0)": 0.6123592853546143, "(24, 16)": 0.776709794998169, "(26, 0)": 0.7787750363349915, "(26, 16)": 0.6327165365219116, "(28, 0)": 0.7787750363349915, "(28, 16)": 0.6123592853546143, "(30, 0)": 0.6123592853546143, "(30, 16)": 0.7787750363349915}, "r_span": [1444, 1559], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0005385875701904297}}, {"prompt_attention_score": {"(0, 0)": 0.6810723543167114, "(0, 16)": 0.6810723543167114, "(2, 0)": 0.6810723543167114, "(2, 16)": 0.6810723543167114, "(4, 0)": 0.6810723543167114, "(4, 16)": 0.6810723543167114, "(6, 0)": 0.6810723543167114, "(6, 16)": 0.7466399669647217, "(8, 0)": 0.6810723543167114, "(8, 16)": 0.6810723543167114, "(10, 0)": 0.6810723543167114, "(10, 16)": 0.6810723543167114, "(12, 0)": 0.6810723543167114, "(12, 16)": 0.7466399669647217, "(14, 0)": 0.6810723543167114, "(14, 16)": 0.6810723543167114, "(16, 0)": 0.6810723543167114, "(16, 16)": 0.6810723543167114, "(18, 0)": 0.6810723543167114, "(18, 16)": 0.7466399669647217, "(20, 0)": 0.5161398649215698, "(20, 16)": 0.6810723543167114, "(22, 0)": 0.6810723543167114, "(22, 16)": 0.7688835263252258, "(24, 0)": 0.6810723543167114, "(24, 16)": 0.7466399669647217, "(26, 0)": 0.6220954060554504, "(26, 16)": 0.7466399669647217, "(28, 0)": 0.6220954060554504, "(28, 16)": 0.6810723543167114, "(30, 0)": 0.6810723543167114, "(30, 16)": 0.6220954060554504}, "r_span": [1557, 1671], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008374452590942383}}, {"prompt_attention_score": {"(0, 0)": 0.7982665300369263, "(0, 16)": 0.7982665300369263, "(2, 0)": 0.7221639156341553, "(2, 16)": 0.7982665300369263, "(4, 0)": 0.7221639156341553, "(4, 16)": 0.7221639156341553, "(6, 0)": 0.7221639156341553, "(6, 16)": 0.7982665300369263, "(8, 0)": 0.7221639156341553, "(8, 16)": 0.7221639156341553, "(10, 0)": 0.7221639156341553, "(10, 16)": 0.7221639156341553, "(12, 0)": 0.7221639156341553, "(12, 16)": 0.7982665300369263, "(14, 0)": 0.7221639156341553, "(14, 16)": 0.7221639156341553, "(16, 0)": 0.7221639156341553, "(16, 16)": 0.6528055667877197, "(18, 0)": 0.5935817956924438, "(18, 16)": 0.7982665300369263, "(20, 0)": 0.7221639156341553, "(20, 16)": 0.7221639156341553, "(22, 0)": 0.7221639156341553, "(22, 16)": 0.7221639156341553, "(24, 0)": 0.7221639156341553, "(24, 16)": 0.7221639156341553, "(26, 0)": 0.6528055667877197, "(26, 16)": 0.7221639156341553, "(28, 0)": 0.6528055667877197, "(28, 16)": 0.7221639156341553, "(30, 0)": 0.7221639156341553, "(30, 16)": 0.6528055667877197}, "r_span": [1669, 1716], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 3.635883331298828e-06}}]}, {"id": "465", "source_id": "15670", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "A Polish prince has challenged UK Independence Party (UKIP) leader Nigel Farage to a duel in Hyde Park over Farage's criticism of Polish immigrants in the UK. Prince Jan Zylinski, whose father was a World War II war hero, held a sword belonging to his father and issued the challenge in a video posted on YouTube. Zylinski criticized Farage for blaming migrants for traffic jams and accused him of spreading hatred towards Poles. Farage rejected the challenge, stating that he does not have a sword and does not intend to engage in a duel. Zylinski also offered an alternative challenge, suggesting a debate in a TV studio before the upcoming elections.", "response_spans": [[0, 511], [493, 653]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6775645017623901, "(0, 16)": 0.6775645017623901, "(2, 0)": 0.6775645017623901, "(2, 16)": 0.6775645017623901, "(4, 0)": 0.6775645017623901, "(4, 16)": 0.6775645017623901, "(6, 0)": 0.6775645017623901, "(6, 16)": 0.9047861695289612, "(8, 0)": 0.9047861695289612, "(8, 16)": 0.6775645017623901, "(10, 0)": 0.7482118606567383, "(10, 16)": 0.7482118606567383, "(12, 0)": 0.7482118606567383, "(12, 16)": 0.8680064678192139, "(14, 0)": 0.7482118606567383, "(14, 16)": 0.9047861695289612, "(16, 0)": 0.7482118606567383, "(16, 16)": 0.7482118606567383, "(18, 0)": 0.7482118606567383, "(18, 16)": 0.9047861695289612, "(20, 0)": 0.8680064678192139, "(20, 16)": 0.7482118606567383, "(22, 0)": 0.9047861695289612, "(22, 16)": 0.9047861695289612, "(24, 0)": 0.7482118606567383, "(24, 16)": 0.9047861695289612, "(26, 0)": 0.9047861695289612, "(26, 16)": 0.9047861695289612, "(28, 0)": 0.9047861695289612, "(28, 16)": 0.7482118606567383, "(30, 0)": 0.9047861695289612, "(30, 16)": 0.9047861695289612}, "r_span": [915, 1039], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002207517623901367}}, {"prompt_attention_score": {"(0, 0)": 0.7082674503326416, "(0, 16)": 0.5361819267272949, "(2, 0)": 0.5361819267272949, "(2, 16)": 0.5361819267272949, "(4, 0)": 0.5361819267272949, "(4, 16)": 0.5361819267272949, "(6, 0)": 0.7082674503326416, "(6, 16)": 0.6270550489425659, "(8, 0)": 0.5361819267272949, "(8, 16)": 0.5361819267272949, "(10, 0)": 0.7082674503326416, "(10, 16)": 0.7082674503326416, "(12, 0)": 0.7082674503326416, "(12, 16)": 0.7082674503326416, "(14, 0)": 0.7082674503326416, "(14, 16)": 0.7082674503326416, "(16, 0)": 0.7082674503326416, "(16, 16)": 0.5361819267272949, "(18, 0)": 0.7082674503326416, "(18, 16)": 0.7082674503326416, "(20, 0)": 0.7082674503326416, "(20, 16)": 0.7082674503326416, "(22, 0)": 0.5785647034645081, "(22, 16)": 0.7082674503326416, "(24, 0)": 0.7082674503326416, "(24, 16)": 0.7082674503326416, "(26, 0)": 0.5785647034645081, "(26, 16)": 0.7082674503326416, "(28, 0)": 0.5785647034645081, "(28, 16)": 0.5785647034645081, "(30, 0)": 0.5785647034645081, "(30, 16)": 0.5785647034645081}, "r_span": [1036, 1071], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0014520883560180664}}]}, {"id": "483", "source_id": "15673", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Seven people, including Illinois State University associate men's basketball coach Torrey Ward and deputy athletic director Aaron Leetch, died in a small plane crash near Bloomington, Illinois. The plane went down overnight Monday while returning from the NCAA tournament final in Indianapolis. Ward and Leetch were well-respected and much-loved colleagues in the athletics department, according to university president Larry Dietz. The cause of the crash is unknown, but the National Transportation Safety Board tweeted that it was a Cessna 414. Ward played professionally in China before becoming a coach, and Leetch had served as athletic director at several universities before joining Illinois State in 2005.", "response_spans": [[0, 512], [500, 713]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6502951383590698, "(0, 16)": 0.6652912497520447, "(2, 0)": 0.6502951383590698, "(2, 16)": 0.6652912497520447, "(4, 0)": 0.6652912497520447, "(4, 16)": 0.6502951383590698, "(6, 0)": 0.6502951383590698, "(6, 16)": 0.9538460969924927, "(8, 0)": 0.6502951383590698, "(8, 16)": 0.6652912497520447, "(10, 0)": 0.7666619420051575, "(10, 16)": 0.6652912497520447, "(12, 0)": 0.6652912497520447, "(12, 16)": 0.9538460969924927, "(14, 0)": 0.6652912497520447, "(14, 16)": 0.9538460969924927, "(16, 0)": 0.9538460969924927, "(16, 16)": 0.6652912497520447, "(18, 0)": 0.6652912497520447, "(18, 16)": 0.9538460969924927, "(20, 0)": 0.9538460969924927, "(20, 16)": 0.6652912497520447, "(22, 0)": 0.9538460969924927, "(22, 16)": 0.9538460969924927, "(24, 0)": 0.9538460969924927, "(24, 16)": 0.9538460969924927, "(26, 0)": 0.9538460969924927, "(26, 16)": 0.9538460969924927, "(28, 0)": 0.9538460969924927, "(28, 16)": 0.9538460969924927, "(30, 0)": 0.9538460969924927, "(30, 16)": 0.9538460969924927}, "r_span": [719, 824], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002776980400085449}}, {"prompt_attention_score": {"(0, 0)": 0.6560400724411011, "(0, 16)": 0.5919531583786011, "(2, 0)": 0.5919531583786011, "(2, 16)": 0.5919531583786011, "(4, 0)": 0.5919531583786011, "(4, 16)": 0.5919531583786011, "(6, 0)": 0.6560400724411011, "(6, 16)": 0.7849255204200745, "(8, 0)": 0.6560400724411011, "(8, 16)": 0.5919531583786011, "(10, 0)": 0.6940497159957886, "(10, 16)": 0.5919531583786011, "(12, 0)": 0.6940497159957886, "(12, 16)": 0.6940497159957886, "(14, 0)": 0.5919531583786011, "(14, 16)": 0.6940497159957886, "(16, 0)": 0.7849255204200745, "(16, 16)": 0.5919531583786011, "(18, 0)": 0.5919531583786011, "(18, 16)": 0.6560400724411011, "(20, 0)": 0.6560400724411011, "(20, 16)": 0.5919531583786011, "(22, 0)": 0.7958492040634155, "(22, 16)": 0.7958492040634155, "(24, 0)": 0.7384358644485474, "(24, 16)": 0.6940497159957886, "(26, 0)": 0.7958492040634155, "(26, 16)": 0.7958492040634155, "(28, 0)": 0.7958492040634155, "(28, 16)": 0.7958492040634155, "(30, 0)": 0.7958492040634155, "(30, 16)": 0.7958492040634155}, "r_span": [822, 874], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 9.316205978393555e-05}}]}, {"id": "543", "source_id": "15683", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 733, "end": 766, "text": "Heather Abbott, who lost her foot", "meta": "EVIDENT CONFLICT:\nAIGC: Heather Abbott, who lost her foot\nOriginal: It was Heather Abbott's leg that got amputated", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "On Thursday, survivors and family members of the Boston Marathon bombing victims testified against Dzhokhar Tsarnaev in the sentencing phase of his trial. Steve Woolfenden, a biomedical researcher, described how he and his 3-year-old son, Leo, were injured in the bombing. Woolfenden recalled holding onto Leo's stroller while he lay on the ground and saw that his son was conscious but bleeding from the left side of his head. He also described the gruesome scenes he witnessed, including the death of 8-year-old Martin Richard, who was close to one of the bombs and suffered rapid blood loss. Other witnesses included Dr. David King, a trauma surgeon who has treated hundreds of troops injured by improvised explosive devices, and Heather Abbott, who lost her foot in the bombing. The prosecution presented these testimonies to argue that Tsarnaev is cold-hearted and remorseless, while the defense will attempt to paint a different picture of him when they present their case.", "response_spans": [[0, 502], [490, 979]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6761305332183838, "(0, 16)": 0.7065824866294861, "(2, 0)": 0.6761305332183838, "(2, 16)": 0.6761305332183838, "(4, 0)": 0.6761305332183838, "(4, 16)": 0.6761305332183838, "(6, 0)": 0.6761305332183838, "(6, 16)": 0.8073580265045166, "(8, 0)": 0.6761305332183838, "(8, 16)": 0.6761305332183838, "(10, 0)": 0.6761305332183838, "(10, 16)": 0.6761305332183838, "(12, 0)": 0.6761305332183838, "(12, 16)": 0.8073580265045166, "(14, 0)": 0.6761305332183838, "(14, 16)": 0.6761305332183838, "(16, 0)": 0.6761305332183838, "(16, 16)": 0.6761305332183838, "(18, 0)": 0.6761305332183838, "(18, 16)": 0.80062335729599, "(20, 0)": 0.8073580265045166, "(20, 16)": 0.6761305332183838, "(22, 0)": 0.6761305332183838, "(22, 16)": 0.8073580265045166, "(24, 0)": 0.6761305332183838, "(24, 16)": 0.8073580265045166, "(26, 0)": 0.6761305332183838, "(26, 16)": 0.6761305332183838, "(28, 0)": 0.6761305332183838, "(28, 16)": 0.6761305332183838, "(30, 0)": 0.6761305332183838, "(30, 16)": 0.6761305332183838}, "r_span": [1599, 1725], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014746785163879395}}, {"prompt_attention_score": {"(0, 0)": 0.6474734544754028, "(0, 16)": 0.6474734544754028, "(2, 0)": 0.7357395887374878, "(2, 16)": 0.7357395887374878, "(4, 0)": 0.7357395887374878, "(4, 16)": 0.7357395887374878, "(6, 0)": 0.7357395887374878, "(6, 16)": 0.7126410007476807, "(8, 0)": 0.7357395887374878, "(8, 16)": 0.7357395887374878, "(10, 0)": 0.6474734544754028, "(10, 16)": 0.6474734544754028, "(12, 0)": 0.7357395887374878, "(12, 16)": 0.7126410007476807, "(14, 0)": 0.7357395887374878, "(14, 16)": 0.6474734544754028, "(16, 0)": 0.7357395887374878, "(16, 16)": 0.7357395887374878, "(18, 0)": 0.7357395887374878, "(18, 16)": 0.7599011063575745, "(20, 0)": 0.7599011063575745, "(20, 16)": 0.7357395887374878, "(22, 0)": 0.7357395887374878, "(22, 16)": 0.7599011063575745, "(24, 0)": 0.7357395887374878, "(24, 16)": 0.7599011063575745, "(26, 0)": 0.7357395887374878, "(26, 16)": 0.7357395887374878, "(28, 0)": 0.6474734544754028, "(28, 16)": 0.7357395887374878, "(30, 0)": 0.7357395887374878, "(30, 16)": 0.7357395887374878}, "r_span": [1723, 1835], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.001912534236907959}}]}, {"id": "585", "source_id": "15690", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 640, "end": 725, "text": "This case is similar to the Planned Parenthood of Central Missouri vs. Danforth case,", "meta": "HIGH INTRO OF NEW INFO:\nAIGC: This case is similar to the Planned Parenthood of Central Missouri vs. Danforth case, \nOriginal: Planned Parenthood of Central Missouri vs. Danforth case is mentioned in the source content but it did not state that it is similar to it. Rather, the source content states that he Planned Parenthood case cannot be used by the Sofia Vergara team to allege that the embryos would present some danger to her health, as they did in that case.\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Actress Sofia Vergara is embroiled in a legal battle with her ex-fiance Nick Loeb over two frozen embryos they created together. Loeb is suing Vergara to prevent her from destroying the embryos, which he wants to implant in a surrogate and raise as his own. The couple split in May 2014 and Loeb filed the lawsuit anonymously citing privacy concerns. Vergara's representatives have refused to comment on the matter. The lawsuit raises questions about who has the right to embryos and whether they are considered life or property. Experts say this is a gray area of law and a California court will have to decide to whom the embryos belong. This case is similar to the Planned Parenthood of Central Missouri vs. Danforth case, where the US Supreme Court declared a statute requiring parental and spousal consent for abortions unconstitutional.", "response_spans": [[0, 511], [492, 842]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6730824708938599, "(0, 16)": 0.6343793869018555, "(2, 0)": 0.6730824708938599, "(2, 16)": 0.6730824708938599, "(4, 0)": 0.6730824708938599, "(4, 16)": 0.6730824708938599, "(6, 0)": 0.6730824708938599, "(6, 16)": 0.8558762669563293, "(8, 0)": 0.6730824708938599, "(8, 16)": 0.6730824708938599, "(10, 0)": 0.6730824708938599, "(10, 16)": 0.6730824708938599, "(12, 0)": 0.6730824708938599, "(12, 16)": 0.8558762669563293, "(14, 0)": 0.6730824708938599, "(14, 16)": 0.6730824708938599, "(16, 0)": 0.6730824708938599, "(16, 16)": 0.6730824708938599, "(18, 0)": 0.6730824708938599, "(18, 16)": 0.8558762669563293, "(20, 0)": 0.8558762669563293, "(20, 16)": 0.6730824708938599, "(22, 0)": 0.6730824708938599, "(22, 16)": 0.8558762669563293, "(24, 0)": 0.6730824708938599, "(24, 16)": 0.8558762669563293, "(26, 0)": 0.6730824708938599, "(26, 16)": 0.6730824708938599, "(28, 0)": 0.6730824708938599, "(28, 16)": 0.6730824708938599, "(30, 0)": 0.6730824708938599, "(30, 16)": 0.6730824708938599}, "r_span": [1526, 1659], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016171932220458984}}, {"prompt_attention_score": {"(0, 0)": 0.6851555109024048, "(0, 16)": 0.6851555109024048, "(2, 0)": 0.4971890151500702, "(2, 16)": 0.4971890151500702, "(4, 0)": 0.4971890151500702, "(4, 16)": 0.4971890151500702, "(6, 0)": 0.6851555109024048, "(6, 16)": 0.8049653172492981, "(8, 0)": 0.6851555109024048, "(8, 16)": 0.4971890151500702, "(10, 0)": 0.6851555109024048, "(10, 16)": 0.6851555109024048, "(12, 0)": 0.4971890151500702, "(12, 16)": 0.7873492240905762, "(14, 0)": 0.6851555109024048, "(14, 16)": 0.6851555109024048, "(16, 0)": 0.6851555109024048, "(16, 16)": 0.4971890151500702, "(18, 0)": 0.4971890151500702, "(18, 16)": 0.7864629030227661, "(20, 0)": 0.7873492240905762, "(20, 16)": 0.6851555109024048, "(22, 0)": 0.6851555109024048, "(22, 16)": 0.7864629030227661, "(24, 0)": 0.6851555109024048, "(24, 16)": 0.8049653172492981, "(26, 0)": 0.6851555109024048, "(26, 16)": 0.6851555109024048, "(28, 0)": 0.6851555109024048, "(28, 16)": 0.6851555109024048, "(30, 0)": 0.6851555109024048, "(30, 16)": 0.4452785551548004}, "r_span": [1657, 1734], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0016131401062011719}}]}, {"id": "591", "source_id": "15691", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Hillary Clinton launched her 2020 presidential campaign in an unconventional manner, using a video, new logo, and a road trip to rebrand and reframe her message and image. Critics have dismissed her launch as \"vapid\" and \"boring,\" but her team may have successfully created an empathetic relationship with voters that eluded her in the past. Clinton's new logo, featuring a bold red arrow moving left to right in front of the letter \"H,\" represents the emotional connection she wants to establish with voters and her focus on supporting them. Her decision to break from traditional campaign norms and use unscripted moments to showcase her personality may pay off, especially if she can maintain consistency in her message and actions. Ultimately, the success of her campaign will depend on her ability to build a genuine connection with voters and avoid appearing hypocritical.", "response_spans": [[0, 512], [497, 878]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7004668712615967, "(0, 16)": 0.7004668712615967, "(2, 0)": 0.7004668712615967, "(2, 16)": 0.7004668712615967, "(4, 0)": 0.7004668712615967, "(4, 16)": 0.7004668712615967, "(6, 0)": 0.7004668712615967, "(6, 16)": 0.7669211626052856, "(8, 0)": 0.6730315685272217, "(8, 16)": 0.7004668712615967, "(10, 0)": 0.7704153060913086, "(10, 16)": 0.7004668712615967, "(12, 0)": 0.7004668712615967, "(12, 16)": 0.8018660545349121, "(14, 0)": 0.7004668712615967, "(14, 16)": 0.7675832509994507, "(16, 0)": 0.7675832509994507, "(16, 16)": 0.7004668712615967, "(18, 0)": 0.7004668712615967, "(18, 16)": 0.7675832509994507, "(20, 0)": 0.8018660545349121, "(20, 16)": 0.7004668712615967, "(22, 0)": 0.7004668712615967, "(22, 16)": 0.7675832509994507, "(24, 0)": 0.7004668712615967, "(24, 16)": 0.7704153060913086, "(26, 0)": 0.7675832509994507, "(26, 16)": 0.7004668712615967, "(28, 0)": 0.7675832509994507, "(28, 16)": 0.7004668712615967, "(30, 0)": 0.6730315685272217, "(30, 16)": 0.7675832509994507}, "r_span": [1420, 1544], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009121298789978027}}, {"prompt_attention_score": {"(0, 0)": 0.8426241874694824, "(0, 16)": 0.8426241874694824, "(2, 0)": 0.8426241874694824, "(2, 16)": 0.6871119737625122, "(4, 0)": 0.8426241874694824, "(4, 16)": 0.8426241874694824, "(6, 0)": 0.6871119737625122, "(6, 16)": 0.6466214060783386, "(8, 0)": 0.8426241874694824, "(8, 16)": 0.6871119737625122, "(10, 0)": 0.6871119737625122, "(10, 16)": 0.8426241874694824, "(12, 0)": 0.8426241874694824, "(12, 16)": 0.8426241874694824, "(14, 0)": 0.8426241874694824, "(14, 16)": 0.8426241874694824, "(16, 0)": 0.8426241874694824, "(16, 16)": 0.6589111089706421, "(18, 0)": 0.6589111089706421, "(18, 16)": 0.8426241874694824, "(20, 0)": 0.8426241874694824, "(20, 16)": 0.8426241874694824, "(22, 0)": 0.8426241874694824, "(22, 16)": 0.8426241874694824, "(24, 0)": 0.8426241874694824, "(24, 16)": 0.8426241874694824, "(26, 0)": 0.710984468460083, "(26, 16)": 0.8426241874694824, "(28, 0)": 0.710984468460083, "(28, 16)": 0.8426241874694824, "(30, 0)": 0.6289499402046204, "(30, 16)": 0.710984468460083}, "r_span": [1541, 1618], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008419156074523926}}]}, {"id": "603", "source_id": "15693", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 383, "end": 427, "text": "earned respect as a successful entrepreneur.", "meta": "EVIDENT CONFLICT:\nAIGC:  earned respect as a successful entrepreneur.\nOriginal:  who earned respect as a man", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 139 words:\n\nFor 43 years, Sissa Abu Dahou has dressed as a man to work and provide for her family in Luxor, Egypt. As a widow at 21, she had to fend for herself in a patriarchal society where women are underrepresented in the workforce. Despite facing discrimination and criticism, Dahou remained determined to support her daughter and eventually earned respect as a successful entrepreneur. Recognized by Egypt's President as one of the country's ideal mothers, Dahou continues to defy gender roles and prove that a strong, independent woman can overcome any obstacle.", "response_spans": [[0, 46], [48, 552], [536, 605]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.50025475025177, "(0, 16)": 0.50025475025177, "(2, 0)": 0.50025475025177, "(2, 16)": 0.50025475025177, "(4, 0)": 0.5029594302177429, "(4, 16)": 0.50025475025177, "(6, 0)": 0.50025475025177, "(6, 16)": 0.8276394605636597, "(8, 0)": 0.49442723393440247, "(8, 16)": 0.6030073165893555, "(10, 0)": 0.8276394605636597, "(10, 16)": 0.6030073165893555, "(12, 0)": 0.6030073165893555, "(12, 16)": 0.8276394605636597, "(14, 0)": 0.4944416582584381, "(14, 16)": 0.8276394605636597, "(16, 0)": 0.49442723393440247, "(16, 16)": 0.4944416582584381, "(18, 0)": 0.6030073165893555, "(18, 16)": 0.8276394605636597, "(20, 0)": 0.8276394605636597, "(20, 16)": 0.5029594302177429, "(22, 0)": 0.4944416582584381, "(22, 16)": 0.49442723393440247, "(24, 0)": 0.5029594302177429, "(24, 16)": 0.49442723393440247, "(26, 0)": 0.4944416582584381, "(26, 16)": 0.4944416582584381, "(28, 0)": 0.6030073165893555, "(28, 16)": 0.5029594302177429, "(30, 0)": 0.4944416582584381, "(30, 16)": 0.4944416582584381}, "r_span": [826, 840], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00041103363037109375}}, {"prompt_attention_score": {"(0, 0)": 0.7885953187942505, "(0, 16)": 0.7885953187942505, "(2, 0)": 0.7885953187942505, "(2, 16)": 0.7885953187942505, "(4, 0)": 0.7885953187942505, "(4, 16)": 0.7885953187942505, "(6, 0)": 0.7885953187942505, "(6, 16)": 0.829237163066864, "(8, 0)": 0.7885953187942505, "(8, 16)": 0.7885953187942505, "(10, 0)": 0.7885953187942505, "(10, 16)": 0.7885953187942505, "(12, 0)": 0.7885953187942505, "(12, 16)": 0.829237163066864, "(14, 0)": 0.6963116526603699, "(14, 16)": 0.7885953187942505, "(16, 0)": 0.829237163066864, "(16, 16)": 0.829237163066864, "(18, 0)": 0.7885953187942505, "(18, 16)": 0.7970020771026611, "(20, 0)": 0.829237163066864, "(20, 16)": 0.6963116526603699, "(22, 0)": 0.829237163066864, "(22, 16)": 0.829237163066864, "(24, 0)": 0.6963116526603699, "(24, 16)": 0.7970020771026611, "(26, 0)": 0.829237163066864, "(26, 16)": 0.829237163066864, "(28, 0)": 0.829237163066864, "(28, 16)": 0.829237163066864, "(30, 0)": 0.829237163066864, "(30, 16)": 0.829237163066864}, "r_span": [842, 967], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0001176595687866211}}, {"prompt_attention_score": {"(0, 0)": 0.45734554529190063, "(0, 16)": 0.45734554529190063, "(2, 0)": 0.45734554529190063, "(2, 16)": 0.45734554529190063, "(4, 0)": 0.45734554529190063, "(4, 16)": 0.45734554529190063, "(6, 0)": 0.45734554529190063, "(6, 16)": 0.47400546073913574, "(8, 0)": 0.45734554529190063, "(8, 16)": 0.46282070875167847, "(10, 0)": 0.45734554529190063, "(10, 16)": 0.45734554529190063, "(12, 0)": 0.45734554529190063, "(12, 16)": 0.45734554529190063, "(14, 0)": 0.46282070875167847, "(14, 16)": 0.45734554529190063, "(16, 0)": 0.45734554529190063, "(16, 16)": 0.45734554529190063, "(18, 0)": 0.45734554529190063, "(18, 16)": 0.45734554529190063, "(20, 0)": 0.45734554529190063, "(20, 16)": 0.46282070875167847, "(22, 0)": 0.46282070875167847, "(22, 16)": 0.47400546073913574, "(24, 0)": 0.46282070875167847, "(24, 16)": 0.43048667907714844, "(26, 0)": 0.47400546073913574, "(26, 16)": 0.47400546073913574, "(28, 0)": 0.47400546073913574, "(28, 16)": 0.47400546073913574, "(30, 0)": 0.47400546073913574, "(30, 16)": 0.47400546073913574}, "r_span": [964, 977], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0011506080627441406}}]}, {"id": "609", "source_id": "15694", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "The trial of Dzhokhar Tsarnaev, the surviving Boston Marathon bomber, has begun with the prosecution presenting its case. The prosecutors argue that Tsarnaev deserves the harshest punishment due to the heinous and cruel nature of the crime, which resulted in the deaths of three people and injured hundreds more. The prosecution highlights Tsarnaev's deliberate and calculated actions, including placing a bomb in a crowd of innocent civilians and showing a lack of remorse. The defense, however, is expected to argue that Tsarnaev was influenced by his older brother and was not fully responsible for his actions due to his age and lack of full brain development. The outcome of the trial is uncertain, but the jury is likely to vote for death despite the potential for a divided verdict. The author argues that requiring a unanimous verdict for death gives the defense an advantage and highlights the complexities of the justice system in dealing with heinous crimes.", "response_spans": [[0, 511], [497, 969]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6372157335281372, "(0, 16)": 0.6372157335281372, "(2, 0)": 0.6372157335281372, "(2, 16)": 0.6372157335281372, "(4, 0)": 0.6372157335281372, "(4, 16)": 0.6372157335281372, "(6, 0)": 0.7130526304244995, "(6, 16)": 0.8950198888778687, "(8, 0)": 0.7300705909729004, "(8, 16)": 0.6372157335281372, "(10, 0)": 0.8950198888778687, "(10, 16)": 0.7130526304244995, "(12, 0)": 0.7130526304244995, "(12, 16)": 0.8950198888778687, "(14, 0)": 0.7130526304244995, "(14, 16)": 0.8950198888778687, "(16, 0)": 0.8950198888778687, "(16, 16)": 0.7130526304244995, "(18, 0)": 0.6372157335281372, "(18, 16)": 0.8950198888778687, "(20, 0)": 0.8950198888778687, "(20, 16)": 0.7130526304244995, "(22, 0)": 0.7130526304244995, "(22, 16)": 0.8950198888778687, "(24, 0)": 0.7130526304244995, "(24, 16)": 0.8950198888778687, "(26, 0)": 0.8950198888778687, "(26, 16)": 0.7130526304244995, "(28, 0)": 0.8950198888778687, "(28, 16)": 0.7130526304244995, "(30, 0)": 0.7130526304244995, "(30, 16)": 0.8950198888778687}, "r_span": [1351, 1474], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0043784379959106445}}, {"prompt_attention_score": {"(0, 0)": 0.7870984077453613, "(0, 16)": 0.7870984077453613, "(2, 0)": 0.7870984077453613, "(2, 16)": 0.7621896862983704, "(4, 0)": 0.7870984077453613, "(4, 16)": 0.7870984077453613, "(6, 0)": 0.7621896862983704, "(6, 16)": 0.6970793008804321, "(8, 0)": 0.7870984077453613, "(8, 16)": 0.7621896862983704, "(10, 0)": 0.7870984077453613, "(10, 16)": 0.7870984077453613, "(12, 0)": 0.7621896862983704, "(12, 16)": 0.7870984077453613, "(14, 0)": 0.7621896862983704, "(14, 16)": 0.7621896862983704, "(16, 0)": 0.7621896862983704, "(16, 16)": 0.7621896862983704, "(18, 0)": 0.7621896862983704, "(18, 16)": 0.6171302795410156, "(20, 0)": 0.7621896862983704, "(20, 16)": 0.7621896862983704, "(22, 0)": 0.7621896862983704, "(22, 16)": 0.7621896862983704, "(24, 0)": 0.7621896862983704, "(24, 16)": 0.7621896862983704, "(26, 0)": 0.7621896862983704, "(26, 16)": 0.7621896862983704, "(28, 0)": 0.7193840146064758, "(28, 16)": 0.7621896862983704, "(30, 0)": 0.7621896862983704, "(30, 16)": 0.7193840146064758}, "r_span": [1472, 1569], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001844167709350586}}]}, {"id": "615", "source_id": "15695", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "After deliberating for 35 hours over 7 days, a jury has convicted former NFL star Aaron Hernandez of first-degree murder in the 2013 shooting death of his onetime friend Odin Lloyd. The jury, consisting of 12 men and women, was struck by the viciousness of multiple gunshots and the lack of empathy shown by Hernandez. Despite being a well-known football player, the jurors emphasized that his celebrity status did not influence their decision. They were also surprised by the calls they received from friends congratulating them after the verdict, and expressed the importance of treating all individuals equally under the law. The jurors declined to discuss the dynamics inside the jury room, focusing instead on the evidence presented during the trial. Hernandez faces a sentence of life in prison without parole.", "response_spans": [[0, 509], [497, 816]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5989972352981567, "(0, 16)": 0.6268583536148071, "(2, 0)": 0.5989972352981567, "(2, 16)": 0.5989972352981567, "(4, 0)": 0.5989972352981567, "(4, 16)": 0.5989972352981567, "(6, 0)": 0.5989972352981567, "(6, 16)": 0.7580322027206421, "(8, 0)": 0.5989972352981567, "(8, 16)": 0.5989972352981567, "(10, 0)": 0.5989972352981567, "(10, 16)": 0.5989972352981567, "(12, 0)": 0.5989972352981567, "(12, 16)": 0.7580322027206421, "(14, 0)": 0.5989972352981567, "(14, 16)": 0.7833577990531921, "(16, 0)": 0.7833577990531921, "(16, 16)": 0.5989972352981567, "(18, 0)": 0.5989972352981567, "(18, 16)": 0.7833577990531921, "(20, 0)": 0.7833577990531921, "(20, 16)": 0.6268583536148071, "(22, 0)": 0.6268583536148071, "(22, 16)": 0.7580322027206421, "(24, 0)": 0.6268583536148071, "(24, 16)": 0.7833577990531921, "(26, 0)": 0.7833577990531921, "(26, 16)": 0.7411468029022217, "(28, 0)": 0.7833577990531921, "(28, 16)": 0.5989972352981567, "(30, 0)": 0.7833577990531921, "(30, 16)": 0.7833577990531921}, "r_span": [1174, 1299], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 4.26173210144043e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6417108774185181, "(0, 16)": 0.6417108774185181, "(2, 0)": 0.750515341758728, "(2, 16)": 0.750515341758728, "(4, 0)": 0.750515341758728, "(4, 16)": 0.750515341758728, "(6, 0)": 0.750515341758728, "(6, 16)": 0.7343448400497437, "(8, 0)": 0.750515341758728, "(8, 16)": 0.750515341758728, "(10, 0)": 0.750515341758728, "(10, 16)": 0.750515341758728, "(12, 0)": 0.750515341758728, "(12, 16)": 0.750515341758728, "(14, 0)": 0.6417108774185181, "(14, 16)": 0.750515341758728, "(16, 0)": 0.750515341758728, "(16, 16)": 0.750515341758728, "(18, 0)": 0.750515341758728, "(18, 16)": 0.750515341758728, "(20, 0)": 0.750515341758728, "(20, 16)": 0.6417108774185181, "(22, 0)": 0.6417108774185181, "(22, 16)": 0.750515341758728, "(24, 0)": 0.6417108774185181, "(24, 16)": 0.750515341758728, "(26, 0)": 0.7406994700431824, "(26, 16)": 0.6271226406097412, "(28, 0)": 0.7406994700431824, "(28, 16)": 0.7406994700431824, "(30, 0)": 0.7406994700431824, "(30, 16)": 0.7406994700431824}, "r_span": [1298, 1363], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00014585256576538086}}]}, {"id": "621", "source_id": "15696", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 524, "end": 581, "text": "Thirty-one passengers were evaluated by medical personnel", "meta": "EVIDENT CONFLICT\nOriginal: \"Fifteen passengers were examined by medical personnel...\"\nGenerative: \"Thirty-one passengers were evaluated by medical personnel...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "On Wednesday, SkyWest Flight 5622 made an emergency landing in Buffalo, New York due to a pressurization issue. Passengers reported feeling dizzy, disoriented, and experiencing vision problems during the descent. The Federal Aviation Administration (FAA) is investigating the incident, but so far, no indication of a pressurization problem has been found on the aircraft. A nurse on board the flight, Mary Cunningham, administered oxygen to a sick passenger and later assisted with another passenger who lost consciousness. Thirty-one passengers were evaluated by medical personnel at the airport, but none were transported to the hospital. The flight was carrying 84 passengers and nine crew members.", "response_spans": [[0, 508], [490, 701]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7790951728820801, "(0, 16)": 0.7790951728820801, "(2, 0)": 0.7790951728820801, "(2, 16)": 0.7790951728820801, "(4, 0)": 0.7790951728820801, "(4, 16)": 0.6214760541915894, "(6, 0)": 0.7790951728820801, "(6, 16)": 0.8742234110832214, "(8, 0)": 0.7790951728820801, "(8, 16)": 0.7790951728820801, "(10, 0)": 0.8130769729614258, "(10, 16)": 0.8130769729614258, "(12, 0)": 0.7790951728820801, "(12, 16)": 0.8130769729614258, "(14, 0)": 0.7790951728820801, "(14, 16)": 0.6214760541915894, "(16, 0)": 0.782221794128418, "(16, 16)": 0.7790951728820801, "(18, 0)": 0.7790951728820801, "(18, 16)": 0.8742234110832214, "(20, 0)": 0.8742234110832214, "(20, 16)": 0.7790951728820801, "(22, 0)": 0.7790951728820801, "(22, 16)": 0.8271783590316772, "(24, 0)": 0.7790951728820801, "(24, 16)": 0.8742234110832214, "(26, 0)": 0.782221794128418, "(26, 16)": 0.782221794128418, "(28, 0)": 0.782221794128418, "(28, 16)": 0.7790951728820801, "(30, 0)": 0.782221794128418, "(30, 16)": 0.782221794128418}, "r_span": [823, 943], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0036391019821166992}}, {"prompt_attention_score": {"(0, 0)": 0.7588111758232117, "(0, 16)": 0.7588111758232117, "(2, 0)": 0.6109482049942017, "(2, 16)": 0.6109482049942017, "(4, 0)": 0.6109482049942017, "(4, 16)": 0.6109482049942017, "(6, 0)": 0.6109482049942017, "(6, 16)": 0.7346872091293335, "(8, 0)": 0.7588111758232117, "(8, 16)": 0.7588111758232117, "(10, 0)": 0.7588111758232117, "(10, 16)": 0.7588111758232117, "(12, 0)": 0.7588111758232117, "(12, 16)": 0.7346872091293335, "(14, 0)": 0.7588111758232117, "(14, 16)": 0.7588111758232117, "(16, 0)": 0.7588111758232117, "(16, 16)": 0.7588111758232117, "(18, 0)": 0.6109482049942017, "(18, 16)": 0.7346872091293335, "(20, 0)": 0.7346872091293335, "(20, 16)": 0.7588111758232117, "(22, 0)": 0.6615110635757446, "(22, 16)": 0.7346872091293335, "(24, 0)": 0.7588111758232117, "(24, 16)": 0.7588111758232117, "(26, 0)": 0.6615110635757446, "(26, 16)": 0.7588111758232117, "(28, 0)": 0.6615110635757446, "(28, 16)": 0.7588111758232117, "(30, 0)": 0.6615110635757446, "(30, 16)": 0.6615110635757446}, "r_span": [941, 983], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0011893510818481445}}]}, {"id": "645", "source_id": "15700", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 191, "end": 237, "text": "guilty of witnessing the killing of Odin Lloyd", "meta": "EVIDENT CONFLICT\nOriginal: \"... guilty of first-degree murder in the 2013 slaying of Odin Lloyd.\"\nGenerative: \"... guilty of witnessing the killing of Odin Lloyd...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Aaron Hernandez, a former New England Patriot, was convicted of first-degree murder and sentenced to life in prison without parole. Despite his arrogant demeanor in court, the jury found him guilty of witnessing the killing of Odin Lloyd, a friend, committed by someone he knew. Hernandez's troubled past, including bar fights and failed drug tests, was revealed before he was drafted by the Patriots in 2010. However, the NFL and the Patriots handled the situation correctly by releasing him hours after he was charged and not trying to defend him as a good person. The case highlights the difficulty in predicting the actions of individuals, even with extensive background checks, and the importance of holding perpetrators accountable for their crimes.", "response_spans": [[0, 511], [493, 755]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7365117073059082, "(0, 16)": 0.7365117073059082, "(2, 0)": 0.7365117073059082, "(2, 16)": 0.7365117073059082, "(4, 0)": 0.7365117073059082, "(4, 16)": 0.7365117073059082, "(6, 0)": 0.7365117073059082, "(6, 16)": 0.8099271059036255, "(8, 0)": 0.7365117073059082, "(8, 16)": 0.7365117073059082, "(10, 0)": 0.7170429825782776, "(10, 16)": 0.7365117073059082, "(12, 0)": 0.7365117073059082, "(12, 16)": 0.8099271059036255, "(14, 0)": 0.7365117073059082, "(14, 16)": 0.8114590644836426, "(16, 0)": 0.7743644714355469, "(16, 16)": 0.7365117073059082, "(18, 0)": 0.7365117073059082, "(18, 16)": 0.8099271059036255, "(20, 0)": 0.8099271059036255, "(20, 16)": 0.7365117073059082, "(22, 0)": 0.7365117073059082, "(22, 16)": 0.8099271059036255, "(24, 0)": 0.7170429825782776, "(24, 16)": 0.7170429825782776, "(26, 0)": 0.7170429825782776, "(26, 16)": 0.8099271059036255, "(28, 0)": 0.7170429825782776, "(28, 16)": 0.7365117073059082, "(30, 0)": 0.7170429825782776, "(30, 16)": 0.7170429825782776}, "r_span": [1150, 1276], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012930035591125488}}, {"prompt_attention_score": {"(0, 0)": 0.6571890115737915, "(0, 16)": 0.6571890115737915, "(2, 0)": 0.6571890115737915, "(2, 16)": 0.6571890115737915, "(4, 0)": 0.6571890115737915, "(4, 16)": 0.6571890115737915, "(6, 0)": 0.6571890115737915, "(6, 16)": 0.5904552340507507, "(8, 0)": 0.6219706535339355, "(8, 16)": 0.6571890115737915, "(10, 0)": 0.5934454798698425, "(10, 16)": 0.6571890115737915, "(12, 0)": 0.6571890115737915, "(12, 16)": 0.5904552340507507, "(14, 0)": 0.6571890115737915, "(14, 16)": 0.6087698340415955, "(16, 0)": 0.6087698340415955, "(16, 16)": 0.6571890115737915, "(18, 0)": 0.6571890115737915, "(18, 16)": 0.6087698340415955, "(20, 0)": 0.6087698340415955, "(20, 16)": 0.6571890115737915, "(22, 0)": 0.5594812631607056, "(22, 16)": 0.6219706535339355, "(24, 0)": 0.6571890115737915, "(24, 16)": 0.6087698340415955, "(26, 0)": 0.5594812631607056, "(26, 16)": 0.5904552340507507, "(28, 0)": 0.5594812631607056, "(28, 16)": 0.5594812631607056, "(30, 0)": 0.5594812631607056, "(30, 16)": 0.5594812631607056}, "r_span": [1273, 1323], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006172657012939453}}]}, {"id": "657", "source_id": "15702", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 600, "end": 631, "text": "Jordan is an experienced sailor", "meta": "EVIDENT CONFLICT\nOriginal: \"... he had worried about his son (Louis Jordan), who is an inexperienced sailor...\"\nGenerative: \"Jordan is an experienced sailor...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 633, "end": 675, "text": "but this was his first time sailing alone.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention that this was the first time Louis Jordan sailing alone\nGenerative: \"...but this was his first time sailing alone.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "A man named Louis Jordan has been rescued after being stranded at sea for 66 days. Jordan, 37, set out to fish in the ocean from his 35-foot sailboat but was caught in a storm that capsized his boat and broke his mast. Despite being injured and unable to repair the boat, Jordan managed to rig a makeshift mast and sail, but made little progress against the currents. He was eventually rescued by the crew of a 1,000-foot container ship after signaling for help. Jordan's father, Frank, reported his son missing on January 29th, and the Coast Guard has found no reason to doubt his incredible story. Jordan is an experienced sailor, but this was his first time sailing alone. He had been living on his boat at a marina in Conway, South Carolina, and had been experiencing difficulties catching food. Despite the challenges he faced, Jordan remained positive and was able to survive against all odds.", "response_spans": [[0, 511], [496, 899]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7243508100509644, "(0, 16)": 0.7243508100509644, "(2, 0)": 0.7243508100509644, "(2, 16)": 0.7243508100509644, "(4, 0)": 0.7243508100509644, "(4, 16)": 0.7243508100509644, "(6, 0)": 0.7243508100509644, "(6, 16)": 0.8531239032745361, "(8, 0)": 0.6488288640975952, "(8, 16)": 0.6488288640975952, "(10, 0)": 0.6488288640975952, "(10, 16)": 0.6488288640975952, "(12, 0)": 0.6488288640975952, "(12, 16)": 0.8531239032745361, "(14, 0)": 0.6488288640975952, "(14, 16)": 0.8531239032745361, "(16, 0)": 0.7375909090042114, "(16, 16)": 0.5977786183357239, "(18, 0)": 0.6488288640975952, "(18, 16)": 0.8531239032745361, "(20, 0)": 0.8531239032745361, "(20, 16)": 0.6488288640975952, "(22, 0)": 0.6488288640975952, "(22, 16)": 0.8531239032745361, "(24, 0)": 0.6488288640975952, "(24, 16)": 0.8531239032745361, "(26, 0)": 0.5977786183357239, "(26, 16)": 0.7572492957115173, "(28, 0)": 0.5977786183357239, "(28, 16)": 0.6488288640975952, "(30, 0)": 0.5977786183357239, "(30, 16)": 0.5977786183357239}, "r_span": [1343, 1476], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016183853149414062}}, {"prompt_attention_score": {"(0, 0)": 0.7280241250991821, "(0, 16)": 0.7280241250991821, "(2, 0)": 0.7280241250991821, "(2, 16)": 0.731956958770752, "(4, 0)": 0.7280241250991821, "(4, 16)": 0.7280241250991821, "(6, 0)": 0.731956958770752, "(6, 16)": 0.7546327710151672, "(8, 0)": 0.7280241250991821, "(8, 16)": 0.68766188621521, "(10, 0)": 0.7553374767303467, "(10, 16)": 0.731956958770752, "(12, 0)": 0.68766188621521, "(12, 16)": 0.7553374767303467, "(14, 0)": 0.68766188621521, "(14, 16)": 0.7553374767303467, "(16, 0)": 0.7546327710151672, "(16, 16)": 0.591133713722229, "(18, 0)": 0.731956958770752, "(18, 16)": 0.7553374767303467, "(20, 0)": 0.7553374767303467, "(20, 16)": 0.68766188621521, "(22, 0)": 0.68766188621521, "(22, 16)": 0.7553374767303467, "(24, 0)": 0.68766188621521, "(24, 16)": 0.7553374767303467, "(26, 0)": 0.591133713722229, "(26, 16)": 0.731956958770752, "(28, 0)": 0.591133713722229, "(28, 16)": 0.68766188621521, "(30, 0)": 0.731956958770752, "(30, 16)": 0.591133713722229}, "r_span": [1474, 1564], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010949373245239258}}]}, {"id": "693", "source_id": "15708", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On Wednesday, the lead investigator in the crash of Germanwings Flight 9525 denied any knowledge of a video allegedly showing the final moments of the doomed flight. Prosecutor Brice Robin stated that no such video had been provided to the investigation team. Two publications, Bild and Paris Match, claimed to have obtained a cell phone video taken by a passenger showing the plane's descent into the Alps, but neither publication has released the footage. Meanwhile, German airline Lufthansa confirmed that co-pilot Andreas Lubitz had battled depression in the past, leading some to speculate that his mental state may have played a role in the crash. Investigators are still trying to determine the cause of the crash and Lubitz's possible motive.", "response_spans": [[0, 508], [494, 750]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6630116701126099, "(0, 16)": 0.7080879211425781, "(2, 0)": 0.6630116701126099, "(2, 16)": 0.6630116701126099, "(4, 0)": 0.6630116701126099, "(4, 16)": 0.6630116701126099, "(6, 0)": 0.6630116701126099, "(6, 16)": 0.8886281847953796, "(8, 0)": 0.6630116701126099, "(8, 16)": 0.6630116701126099, "(10, 0)": 0.6630116701126099, "(10, 16)": 0.6630116701126099, "(12, 0)": 0.6630116701126099, "(12, 16)": 0.8886281847953796, "(14, 0)": 0.6630116701126099, "(14, 16)": 0.6630116701126099, "(16, 0)": 0.6630116701126099, "(16, 16)": 0.6630116701126099, "(18, 0)": 0.6630116701126099, "(18, 16)": 0.8886281847953796, "(20, 0)": 0.8886281847953796, "(20, 16)": 0.6630116701126099, "(22, 0)": 0.6630116701126099, "(22, 16)": 0.8886281847953796, "(24, 0)": 0.6630116701126099, "(24, 16)": 0.8886281847953796, "(26, 0)": 0.6630116701126099, "(26, 16)": 0.6630116701126099, "(28, 0)": 0.6630116701126099, "(28, 16)": 0.6630116701126099, "(30, 0)": 0.6630116701126099, "(30, 16)": 0.6630116701126099}, "r_span": [1433, 1545], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017102956771850586}}, {"prompt_attention_score": {"(0, 0)": 0.8473548889160156, "(0, 16)": 0.8473548889160156, "(2, 0)": 0.7053744196891785, "(2, 16)": 0.7053744196891785, "(4, 0)": 0.7053744196891785, "(4, 16)": 0.7053744196891785, "(6, 0)": 0.7053744196891785, "(6, 16)": 0.8695969581604004, "(8, 0)": 0.7053744196891785, "(8, 16)": 0.7053744196891785, "(10, 0)": 0.8473548889160156, "(10, 16)": 0.7053744196891785, "(12, 0)": 0.7053744196891785, "(12, 16)": 0.8695969581604004, "(14, 0)": 0.7053744196891785, "(14, 16)": 0.7053744196891785, "(16, 0)": 0.7053744196891785, "(16, 16)": 0.7053744196891785, "(18, 0)": 0.7053744196891785, "(18, 16)": 0.8695969581604004, "(20, 0)": 0.8695969581604004, "(20, 16)": 0.8473548889160156, "(22, 0)": 0.7053744196891785, "(22, 16)": 0.8695969581604004, "(24, 0)": 0.7053744196891785, "(24, 16)": 0.8695969581604004, "(26, 0)": 0.7053744196891785, "(26, 16)": 0.8473548889160156, "(28, 0)": 0.8473548889160156, "(28, 16)": 0.8473548889160156, "(30, 0)": 0.8473548889160156, "(30, 16)": 0.7053744196891785}, "r_span": [1544, 1601], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0017969608306884766}}]}, {"id": "723", "source_id": "15713", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 68 words or less:\n\nRobert Lewis Burns Jr., original drummer of Lynyrd Skynyrd, died in a car crash at age 64. Burns was part of the band's original lineup and left before their third album. He was not involved in the 1977 plane crash that killed three members. The band has continued to tour with Gary Rossington, the only remaining original member.", "response_spans": [[0, 385]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7989046573638916, "(0, 16)": 0.7989046573638916, "(2, 0)": 0.7989046573638916, "(2, 16)": 0.7989046573638916, "(4, 0)": 0.7989046573638916, "(4, 16)": 0.7989046573638916, "(6, 0)": 0.7989046573638916, "(6, 16)": 0.901278018951416, "(8, 0)": 0.6936206817626953, "(8, 16)": 0.7989046573638916, "(10, 0)": 0.7989046573638916, "(10, 16)": 0.7989046573638916, "(12, 0)": 0.7989046573638916, "(12, 16)": 0.7989046573638916, "(14, 0)": 0.901278018951416, "(14, 16)": 0.901278018951416, "(16, 0)": 0.901278018951416, "(16, 16)": 0.901278018951416, "(18, 0)": 0.901278018951416, "(18, 16)": 0.901278018951416, "(20, 0)": 0.901278018951416, "(20, 16)": 0.901278018951416, "(22, 0)": 0.901278018951416, "(22, 16)": 0.7989046573638916, "(24, 0)": 0.901278018951416, "(24, 16)": 0.901278018951416, "(26, 0)": 0.901278018951416, "(26, 16)": 0.901278018951416, "(28, 0)": 0.901278018951416, "(28, 16)": 0.6936206817626953, "(30, 0)": 0.901278018951416, "(30, 16)": 0.901278018951416}, "r_span": [474, 575], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016258955001831055}}]}, {"id": "729", "source_id": "15714", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 157, "end": 191, "text": "and the fire has been extinguished", "meta": "HIGH INTRO OF NEW INFO\nNo mention of the fire being extinguished. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "A nuclear submarine caught fire during repairs at a Russian shipyard, with no ammunition on board. Insulation caught fire while welding work was being done, and the fire has been extinguished without any injuries.", "response_spans": [[0, 213]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8070303201675415, "(0, 16)": 0.8070303201675415, "(2, 0)": 0.8070303201675415, "(2, 16)": 0.8070303201675415, "(4, 0)": 0.8070303201675415, "(4, 16)": 0.8070303201675415, "(6, 0)": 0.8070303201675415, "(6, 16)": 0.8772386908531189, "(8, 0)": 0.8070303201675415, "(8, 16)": 0.8772386908531189, "(10, 0)": 0.8070303201675415, "(10, 16)": 0.8070303201675415, "(12, 0)": 0.8772386908531189, "(12, 16)": 0.8772386908531189, "(14, 0)": 0.8070303201675415, "(14, 16)": 0.8772386908531189, "(16, 0)": 0.8772386908531189, "(16, 16)": 0.8772386908531189, "(18, 0)": 0.8772386908531189, "(18, 16)": 0.8772386908531189, "(20, 0)": 0.8772386908531189, "(20, 16)": 0.8070303201675415, "(22, 0)": 0.8772386908531189, "(22, 16)": 0.8772386908531189, "(24, 0)": 0.8772386908531189, "(24, 16)": 0.8772386908531189, "(26, 0)": 0.8772386908531189, "(26, 16)": 0.8772386908531189, "(28, 0)": 0.8772386908531189, "(28, 16)": 0.8772386908531189, "(30, 0)": 0.8772386908531189, "(30, 16)": 0.8772386908531189}, "r_span": [323, 373], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -3.0100345611572266e-05}}]}, {"id": "777", "source_id": "15722", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 91 words:\n\nThe California Public Utilities Commission ordered Pacific Gas & Electric Co. to pay a record $1.6 billion penalty for unsafe operation of its gas transmission system, including the 2010 pipeline rupture in San Bruno that killed eight people. The majority of the penalty will fund pipeline safety improvements, with $850 million going towards upgrades and $50 million for other safety measures. PG&E's CEO apologized for the tragedy and promised to become the safest energy company in the US.", "response_spans": [[0, 45], [47, 539]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5384346842765808, "(0, 16)": 0.5384346842765808, "(2, 0)": 0.5384346842765808, "(2, 16)": 0.5384346842765808, "(4, 0)": 0.5384346842765808, "(4, 16)": 0.5384346842765808, "(6, 0)": 0.5275042653083801, "(6, 16)": 0.8179137706756592, "(8, 0)": 0.508563220500946, "(8, 16)": 0.5911614894866943, "(10, 0)": 0.8179137706756592, "(10, 16)": 0.5911614894866943, "(12, 0)": 0.5911614894866943, "(12, 16)": 0.8179137706756592, "(14, 0)": 0.508563220500946, "(14, 16)": 0.8179137706756592, "(16, 0)": 0.8179137706756592, "(16, 16)": 0.508563220500946, "(18, 0)": 0.5911614894866943, "(18, 16)": 0.8179137706756592, "(20, 0)": 0.8179137706756592, "(20, 16)": 0.508563220500946, "(22, 0)": 0.508563220500946, "(22, 16)": 0.508563220500946, "(24, 0)": 0.508563220500946, "(24, 16)": 0.508563220500946, "(26, 0)": 0.508563220500946, "(26, 16)": 0.508563220500946, "(28, 0)": 0.508563220500946, "(28, 16)": 0.5384346842765808, "(30, 0)": 0.508563220500946, "(30, 16)": 0.508563220500946}, "r_span": [565, 578], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 6.449222564697266e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7947772145271301, "(0, 16)": 0.7947772145271301, "(2, 0)": 0.7947772145271301, "(2, 16)": 0.7947772145271301, "(4, 0)": 0.7947772145271301, "(4, 16)": 0.7947772145271301, "(6, 0)": 0.7947772145271301, "(6, 16)": 0.9569084644317627, "(8, 0)": 0.7947772145271301, "(8, 16)": 0.7947772145271301, "(10, 0)": 0.7940354347229004, "(10, 16)": 0.9569084644317627, "(12, 0)": 0.9569084644317627, "(12, 16)": 0.9569084644317627, "(14, 0)": 0.9569084644317627, "(14, 16)": 0.9569084644317627, "(16, 0)": 0.9569084644317627, "(16, 16)": 0.9569084644317627, "(18, 0)": 0.9569084644317627, "(18, 16)": 0.9569084644317627, "(20, 0)": 0.9569084644317627, "(20, 16)": 0.9569084644317627, "(22, 0)": 0.9569084644317627, "(22, 16)": 0.9569084644317627, "(24, 0)": 0.9569084644317627, "(24, 16)": 0.9569084644317627, "(26, 0)": 0.9569084644317627, "(26, 16)": 0.9569084644317627, "(28, 0)": 0.9569084644317627, "(28, 16)": 0.9569084644317627, "(30, 0)": 0.9569084644317627, "(30, 16)": 0.9569084644317627}, "r_span": [580, 691], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00014418363571166992}}]}, {"id": "837", "source_id": "15732", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the news in 65 words or less:\n\nNelly, a 40-year-old hip-hop star, was arrested on drug charges in Tennessee after a state trooper pulled over his private bus on I-40. Police found methamphetamine, marijuana, and other drug paraphernalia, as well as several handguns, including a gold-plated Desert Eagle pistol. Nelly was taken to jail but later posted bond and was released.", "response_spans": [[0, 401]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7765846848487854, "(0, 16)": 0.7765846848487854, "(2, 0)": 0.7765846848487854, "(2, 16)": 0.7765846848487854, "(4, 0)": 0.7765846848487854, "(4, 16)": 0.7765846848487854, "(6, 0)": 0.7765846848487854, "(6, 16)": 0.9040274620056152, "(8, 0)": 0.6795818209648132, "(8, 16)": 0.7765846848487854, "(10, 0)": 0.7765846848487854, "(10, 16)": 0.7765846848487854, "(12, 0)": 0.9040274620056152, "(12, 16)": 0.7765846848487854, "(14, 0)": 0.9040274620056152, "(14, 16)": 0.9040274620056152, "(16, 0)": 0.9040274620056152, "(16, 16)": 0.9040274620056152, "(18, 0)": 0.9040274620056152, "(18, 16)": 0.9040274620056152, "(20, 0)": 0.9040274620056152, "(20, 16)": 0.9040274620056152, "(22, 0)": 0.9040274620056152, "(22, 16)": 0.9040274620056152, "(24, 0)": 0.9040274620056152, "(24, 16)": 0.9040274620056152, "(26, 0)": 0.9040274620056152, "(26, 16)": 0.9040274620056152, "(28, 0)": 0.9040274620056152, "(28, 16)": 0.9040274620056152, "(30, 0)": 0.9040274620056152, "(30, 16)": 0.9040274620056152}, "r_span": [460, 579], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017497539520263672}}]}, {"id": "843", "source_id": "15733", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 313, "end": 380, "text": "and hasn't experienced any of the abuse alleged in the documentary.", "meta": "HIGH INTRO OF NEW INFO\nNo explicit mention of abuse, source content only states \"hearsay.\" ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 64 words:\n\nJohn Travolta has dismissed HBO's documentary \"Going Clear: Scientology and the Prison of Belief\" as negative and untrue, despite being one of the Church of Scientology's most high-profile members. He claims he's had a positive experience with the organization and hasn't experienced any of the abuse alleged in the documentary.", "response_spans": [[0, 380]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6725521087646484, "(0, 16)": 0.6725521087646484, "(2, 0)": 0.6725521087646484, "(2, 16)": 0.6725521087646484, "(4, 0)": 0.6725521087646484, "(4, 16)": 0.6725521087646484, "(6, 0)": 0.6725521087646484, "(6, 16)": 0.8911204934120178, "(8, 0)": 0.6725521087646484, "(8, 16)": 0.6725521087646484, "(10, 0)": 0.8911204934120178, "(10, 16)": 0.6725521087646484, "(12, 0)": 0.6725521087646484, "(12, 16)": 0.8911204934120178, "(14, 0)": 0.8911204934120178, "(14, 16)": 0.8911204934120178, "(16, 0)": 0.8911204934120178, "(16, 16)": 0.8911204934120178, "(18, 0)": 0.8911204934120178, "(18, 16)": 0.8911204934120178, "(20, 0)": 0.8911204934120178, "(20, 16)": 0.8911204934120178, "(22, 0)": 0.8911204934120178, "(22, 16)": 0.8911204934120178, "(24, 0)": 0.8911204934120178, "(24, 16)": 0.8911204934120178, "(26, 0)": 0.8911204934120178, "(26, 16)": 0.8911204934120178, "(28, 0)": 0.8911204934120178, "(28, 16)": 0.8911204934120178, "(30, 0)": 0.8911204934120178, "(30, 16)": 0.8911204934120178}, "r_span": [452, 551], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0004126429557800293}}]}, {"id": "855", "source_id": "15735", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "A fatal car crash occurred at Walt Disney World Speedway during an exotic driving experience, where a Lamborghini crashed into a guardrail and the passenger, Gary Terry, died at the scene. The driver, Tavon Watson, sustained minor injuries.", "response_spans": [[0, 240]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8992549777030945, "(0, 16)": 0.7391844987869263, "(2, 0)": 0.7391844987869263, "(2, 16)": 0.7391844987869263, "(4, 0)": 0.7391844987869263, "(4, 16)": 0.8992549777030945, "(6, 0)": 0.7391844987869263, "(6, 16)": 0.8992549777030945, "(8, 0)": 0.8992549777030945, "(8, 16)": 0.8992549777030945, "(10, 0)": 0.7391844987869263, "(10, 16)": 0.8992549777030945, "(12, 0)": 0.8992549777030945, "(12, 16)": 0.8992549777030945, "(14, 0)": 0.8992549777030945, "(14, 16)": 0.8992549777030945, "(16, 0)": 0.8992549777030945, "(16, 16)": 0.8992549777030945, "(18, 0)": 0.8992549777030945, "(18, 16)": 0.8992549777030945, "(20, 0)": 0.8992549777030945, "(20, 16)": 0.8992549777030945, "(22, 0)": 0.8992549777030945, "(22, 16)": 0.8992549777030945, "(24, 0)": 0.8992549777030945, "(24, 16)": 0.8992549777030945, "(26, 0)": 0.8992549777030945, "(26, 16)": 0.8992549777030945, "(28, 0)": 0.8992549777030945, "(28, 16)": 0.8992549777030945, "(30, 0)": 0.8992549777030945, "(30, 16)": 0.8992549777030945}, "r_span": [335, 393], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008567571640014648}}]}, {"id": "879", "source_id": "15739", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 42 words or less:\n\nGastrointestinal illness affects 100 passengers and 5 crew on a cruise ship off the coast of California, with the CDC investigating the cause.", "response_spans": [[0, 197]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7136160135269165, "(0, 16)": 0.7136160135269165, "(2, 0)": 0.7136160135269165, "(2, 16)": 0.7136160135269165, "(4, 0)": 0.7136160135269165, "(4, 16)": 0.8655331134796143, "(6, 0)": 0.7136160135269165, "(6, 16)": 0.8655331134796143, "(8, 0)": 0.8655331134796143, "(8, 16)": 0.8655331134796143, "(10, 0)": 0.8655331134796143, "(10, 16)": 0.8655331134796143, "(12, 0)": 0.8655331134796143, "(12, 16)": 0.8655331134796143, "(14, 0)": 0.8655331134796143, "(14, 16)": 0.8655331134796143, "(16, 0)": 0.8655331134796143, "(16, 16)": 0.8655331134796143, "(18, 0)": 0.8655331134796143, "(18, 16)": 0.8655331134796143, "(20, 0)": 0.8655331134796143, "(20, 16)": 0.8655331134796143, "(22, 0)": 0.8655331134796143, "(22, 16)": 0.8655331134796143, "(24, 0)": 0.8655331134796143, "(24, 16)": 0.8655331134796143, "(26, 0)": 0.8655331134796143, "(26, 16)": 0.8655331134796143, "(28, 0)": 0.8655331134796143, "(28, 16)": 0.8655331134796143, "(30, 0)": 0.8655331134796143, "(30, 16)": 0.8655331134796143}, "r_span": [343, 398], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00030869245529174805}}]}, {"id": "885", "source_id": "15740", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 445, "end": 492, "text": "it is hidden beneath layers of earth and debris", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the graffiti is hidden beneath layers of earth and debris, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 121 words:\n\nGraffiti left behind by World War I soldiers has been discovered in a French chalk quarry, including the names and ranks of nearly 2,000 soldiers. The inscriptions date back to 1916 and provide a personal glimpse into the lives of the soldiers. Many of the inscriptions are from Australian and British soldiers, with a smaller number from the US. The graffiti is fragile and difficult to find, as it is hidden beneath layers of earth and debris. The discoveries have been documented by photographer Jeff Gusky, who has been working to preserve the history of the area. The graffiti serves as a poignant reminder of the human cost of war.", "response_spans": [[0, 46], [48, 558], [547, 685]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5019809007644653, "(0, 16)": 0.5019809007644653, "(2, 0)": 0.5805803537368774, "(2, 16)": 0.5019809007644653, "(4, 0)": 0.5805803537368774, "(4, 16)": 0.5805803537368774, "(6, 0)": 0.5019809007644653, "(6, 16)": 0.8187721967697144, "(8, 0)": 0.5156213045120239, "(8, 16)": 0.5019809007644653, "(10, 0)": 0.8187721967697144, "(10, 16)": 0.5811550617218018, "(12, 0)": 0.5811550617218018, "(12, 16)": 0.8187721967697144, "(14, 0)": 0.5019809007644653, "(14, 16)": 0.8187721967697144, "(16, 0)": 0.8187721967697144, "(16, 16)": 0.5019809007644653, "(18, 0)": 0.5811550617218018, "(18, 16)": 0.8187721967697144, "(20, 0)": 0.8187721967697144, "(20, 16)": 0.5019809007644653, "(22, 0)": 0.5156213045120239, "(22, 16)": 0.5156213045120239, "(24, 0)": 0.5019809007644653, "(24, 16)": 0.5156213045120239, "(26, 0)": 0.5156213045120239, "(26, 16)": 0.5156213045120239, "(28, 0)": 0.5156213045120239, "(28, 16)": 0.567626416683197, "(30, 0)": 0.5156213045120239, "(30, 16)": 0.5156213045120239}, "r_span": [812, 826], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00010251998901367188}}, {"prompt_attention_score": {"(0, 0)": 0.7536920309066772, "(0, 16)": 0.7536920309066772, "(2, 0)": 0.6320191621780396, "(2, 16)": 0.6320191621780396, "(4, 0)": 0.6320191621780396, "(4, 16)": 0.6320191621780396, "(6, 0)": 0.6320191621780396, "(6, 16)": 0.8117097616195679, "(8, 0)": 0.8117097616195679, "(8, 16)": 0.6320191621780396, "(10, 0)": 0.6320191621780396, "(10, 16)": 0.6320191621780396, "(12, 0)": 0.6320191621780396, "(12, 16)": 0.7536920309066772, "(14, 0)": 0.6320191621780396, "(14, 16)": 0.8117097616195679, "(16, 0)": 0.8117097616195679, "(16, 16)": 0.6320191621780396, "(18, 0)": 0.6320191621780396, "(18, 16)": 0.8117097616195679, "(20, 0)": 0.8117097616195679, "(20, 16)": 0.6320191621780396, "(22, 0)": 0.8117097616195679, "(22, 16)": 0.8117097616195679, "(24, 0)": 0.6286181211471558, "(24, 16)": 0.8117097616195679, "(26, 0)": 0.8117097616195679, "(26, 16)": 0.8117097616195679, "(28, 0)": 0.8117097616195679, "(28, 16)": 0.6320191621780396, "(30, 0)": 0.8117097616195679, "(30, 16)": 0.8117097616195679}, "r_span": [828, 951], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.002892732620239258}}, {"prompt_attention_score": {"(0, 0)": 0.727226197719574, "(0, 16)": 0.727226197719574, "(2, 0)": 0.5830501317977905, "(2, 16)": 0.5830501317977905, "(4, 0)": 0.5830501317977905, "(4, 16)": 0.5830501317977905, "(6, 0)": 0.5830501317977905, "(6, 16)": 0.6088918447494507, "(8, 0)": 0.6821695566177368, "(8, 16)": 0.5830501317977905, "(10, 0)": 0.5830501317977905, "(10, 16)": 0.5830501317977905, "(12, 0)": 0.5830501317977905, "(12, 16)": 0.6088918447494507, "(14, 0)": 0.5830501317977905, "(14, 16)": 0.5830501317977905, "(16, 0)": 0.5830501317977905, "(16, 16)": 0.5830501317977905, "(18, 0)": 0.5830501317977905, "(18, 16)": 0.6088918447494507, "(20, 0)": 0.727226197719574, "(20, 16)": 0.5830501317977905, "(22, 0)": 0.5830501317977905, "(22, 16)": 0.727226197719574, "(24, 0)": 0.5830501317977905, "(24, 16)": 0.6416875123977661, "(26, 0)": 0.6821695566177368, "(26, 16)": 0.6821695566177368, "(28, 0)": 0.6821695566177368, "(28, 16)": 0.5830501317977905, "(30, 0)": 0.6821695566177368, "(30, 16)": 0.6821695566177368}, "r_span": [947, 982], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0010644197463989258}}]}, {"id": "909", "source_id": "15744", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 130, "end": 299, "text": "The article had sparked a national conversation about sexual assault on college campuses, but it was widely criticized for its flawed reporting and lack of fact-checking", "meta": "HIGH INTRO OF NEW INFO\nIt is not mentioned in the original source that the article was widely criticized for its flawed reporting and lack of fact-checking.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 715, "end": 1106, "text": "The retraction has raised concerns about whether survivors will come forward, fearing they will be accused of lying. The university has implemented a zero-tolerance policy on sexual assault, but it remains to be seen how effective this policy will be. The incident has sparked a wider debate about the need for better reporting and handling of sexual assault allegations on college campuses.", "meta": "HIGH INTRO OF NEW INFO\n\"The retraction has raised concerns...  allegations on college campuses.\" is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "On Sunday night, Rolling Stone retracted a controversial article about a purported gang rape at the University of Virginia (UVA). The article had sparked a national conversation about sexual assault on college campuses, but it was widely criticized for its flawed reporting and lack of fact-checking. According to the article, UVA has never expelled a student for sexual assault, despite numerous allegations. However, an investigation by the law firm of O'Melveny & Myers found that the university failed to handle these allegations properly. The article also highlighted a culture on campus where sexual assault is normalized, with students using a euphemism for rape and judging victims based on their clothing. The retraction has raised concerns about whether survivors will come forward, fearing they will be accused of lying. The university has implemented a zero-tolerance policy on sexual assault, but it remains to be seen how effective this policy will be. The incident has sparked a wider debate about the need for better reporting and handling of sexual assault allegations on college campuses.", "response_spans": [[0, 508], [499, 1006], [992, 1106]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6371420621871948, "(0, 16)": 0.6371420621871948, "(2, 0)": 0.6134335994720459, "(2, 16)": 0.6134335994720459, "(4, 0)": 0.6134335994720459, "(4, 16)": 0.6134335994720459, "(6, 0)": 0.6134335994720459, "(6, 16)": 0.9058191776275635, "(8, 0)": 0.6134335994720459, "(8, 16)": 0.6134335994720459, "(10, 0)": 0.6134335994720459, "(10, 16)": 0.6134335994720459, "(12, 0)": 0.6134335994720459, "(12, 16)": 0.9058191776275635, "(14, 0)": 0.6134335994720459, "(14, 16)": 0.6134335994720459, "(16, 0)": 0.6134335994720459, "(16, 16)": 0.6134335994720459, "(18, 0)": 0.6134335994720459, "(18, 16)": 0.9058191776275635, "(20, 0)": 0.9058191776275635, "(20, 16)": 0.6371420621871948, "(22, 0)": 0.6134335994720459, "(22, 16)": 0.9058191776275635, "(24, 0)": 0.6371420621871948, "(24, 16)": 0.9058191776275635, "(26, 0)": 0.6134335994720459, "(26, 16)": 0.6134335994720459, "(28, 0)": 0.6134335994720459, "(28, 16)": 0.6134335994720459, "(30, 0)": 0.6134335994720459, "(30, 16)": 0.6134335994720459}, "r_span": [1459, 1571], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012332797050476074}}, {"prompt_attention_score": {"(0, 0)": 0.6990853548049927, "(0, 16)": 0.6990853548049927, "(2, 0)": 0.6990853548049927, "(2, 16)": 0.6990853548049927, "(4, 0)": 0.6990853548049927, "(4, 16)": 0.5785055160522461, "(6, 0)": 0.5785055160522461, "(6, 16)": 0.7418818473815918, "(8, 0)": 0.6990853548049927, "(8, 16)": 0.6990853548049927, "(10, 0)": 0.5785055160522461, "(10, 16)": 0.5785055160522461, "(12, 0)": 0.5785055160522461, "(12, 16)": 0.7418818473815918, "(14, 0)": 0.6990853548049927, "(14, 16)": 0.5785055160522461, "(16, 0)": 0.5785055160522461, "(16, 16)": 0.6990853548049927, "(18, 0)": 0.5785055160522461, "(18, 16)": 0.7418818473815918, "(20, 0)": 0.6990853548049927, "(20, 16)": 0.6990853548049927, "(22, 0)": 0.6990853548049927, "(22, 16)": 0.6990853548049927, "(24, 0)": 0.6990853548049927, "(24, 16)": 0.7239893674850464, "(26, 0)": 0.7342573404312134, "(26, 16)": 0.5785055160522461, "(28, 0)": 0.5785055160522461, "(28, 16)": 0.6990853548049927, "(30, 0)": 0.7342573404312134, "(30, 16)": 0.7342573404312134}, "r_span": [1570, 1675], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0017367005348205566}}, {"prompt_attention_score": {"(0, 0)": 0.6190465688705444, "(0, 16)": 0.6190465688705444, "(2, 0)": 0.6190465688705444, "(2, 16)": 0.7373178005218506, "(4, 0)": 0.5834406614303589, "(4, 16)": 0.5834406614303589, "(6, 0)": 0.5834406614303589, "(6, 16)": 0.6923804879188538, "(8, 0)": 0.6190465688705444, "(8, 16)": 0.6190465688705444, "(10, 0)": 0.5834406614303589, "(10, 16)": 0.5834406614303589, "(12, 0)": 0.5834406614303589, "(12, 16)": 0.7373178005218506, "(14, 0)": 0.6190465688705444, "(14, 16)": 0.5834406614303589, "(16, 0)": 0.5834406614303589, "(16, 16)": 0.5834406614303589, "(18, 0)": 0.7023550271987915, "(18, 16)": 0.6190465688705444, "(20, 0)": 0.7373178005218506, "(20, 16)": 0.6190465688705444, "(22, 0)": 0.6190465688705444, "(22, 16)": 0.6190465688705444, "(24, 0)": 0.6190465688705444, "(24, 16)": 0.7373178005218506, "(26, 0)": 0.6853132843971252, "(26, 16)": 0.5834406614303589, "(28, 0)": 0.5834406614303589, "(28, 16)": 0.6190465688705444, "(30, 0)": 0.6853132843971252, "(30, 16)": 0.6853132843971252}, "r_span": [1673, 1693], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00016319751739501953}}]}, {"id": "927", "source_id": "15747", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 705, "end": 858, "text": "Additionally, Jiang shares insights on the impact of sleep deprivation on IQ, the benefits of doing nothing, and the habits of highly ineffective people.", "meta": "EVIDENT CONFLICT\nOriginal: The information were not shared by Jia Jiang.\nGenerative: \"Jiang shares insights on the impact of sleep... habits of highly ineffective people.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Jia Jiang, a Chinese-born entrepreneur, faced rejection when he quit his comfortable job to pursue his dreams of becoming an entrepreneur. To overcome his fear of rejection, he started the \"100 Days of Rejection\" project, where he asked strangers for $100 or an apple without explanation. His project gained attention after he shared his experiences on social media, and he wrote a book called \"Rejection Proof\" based on his journey. Jiang's tips for dealing with rejection include embracing the fear, viewing rejection as a numbers game, and asking why to find solutions. He also suggests setting a limit on the number of nos one can tolerate and standing tall, remembering that rejection is an opinion. Additionally, Jiang shares insights on the impact of sleep deprivation on IQ, the benefits of doing nothing, and the habits of highly ineffective people.", "response_spans": [[0, 509], [492, 858]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.702005922794342, "(0, 16)": 0.5932507514953613, "(2, 0)": 0.5932507514953613, "(2, 16)": 0.5932507514953613, "(4, 0)": 0.5932507514953613, "(4, 16)": 0.5932507514953613, "(6, 0)": 0.5932507514953613, "(6, 16)": 0.8421177864074707, "(8, 0)": 0.5932507514953613, "(8, 16)": 0.702005922794342, "(10, 0)": 0.7590532302856445, "(10, 16)": 0.6376376152038574, "(12, 0)": 0.702005922794342, "(12, 16)": 0.8421177864074707, "(14, 0)": 0.702005922794342, "(14, 16)": 0.8421177864074707, "(16, 0)": 0.8421177864074707, "(16, 16)": 0.702005922794342, "(18, 0)": 0.5932507514953613, "(18, 16)": 0.8421177864074707, "(20, 0)": 0.8421177864074707, "(20, 16)": 0.702005922794342, "(22, 0)": 0.702005922794342, "(22, 16)": 0.6789590120315552, "(24, 0)": 0.702005922794342, "(24, 16)": 0.8421177864074707, "(26, 0)": 0.8421177864074707, "(26, 16)": 0.8421177864074707, "(28, 0)": 0.8421177864074707, "(28, 16)": 0.702005922794342, "(30, 0)": 0.702005922794342, "(30, 16)": 0.8421177864074707}, "r_span": [1117, 1238], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004905462265014648}}, {"prompt_attention_score": {"(0, 0)": 0.749302327632904, "(0, 16)": 0.749302327632904, "(2, 0)": 0.7520720958709717, "(2, 16)": 0.7520720958709717, "(4, 0)": 0.7520720958709717, "(4, 16)": 0.7520720958709717, "(6, 0)": 0.7520720958709717, "(6, 16)": 0.7081177830696106, "(8, 0)": 0.7520720958709717, "(8, 16)": 0.7520720958709717, "(10, 0)": 0.7520720958709717, "(10, 16)": 0.7520720958709717, "(12, 0)": 0.7520720958709717, "(12, 16)": 0.7520720958709717, "(14, 0)": 0.749302327632904, "(14, 16)": 0.7520720958709717, "(16, 0)": 0.7520720958709717, "(16, 16)": 0.7520720958709717, "(18, 0)": 0.749302327632904, "(18, 16)": 0.7520720958709717, "(20, 0)": 0.7520720958709717, "(20, 16)": 0.749302327632904, "(22, 0)": 0.749302327632904, "(22, 16)": 0.7520720958709717, "(24, 0)": 0.749302327632904, "(24, 16)": 0.7520720958709717, "(26, 0)": 0.6186110377311707, "(26, 16)": 0.7520720958709717, "(28, 0)": 0.6186110377311707, "(28, 16)": 0.749302327632904, "(30, 0)": 0.6186110377311707, "(30, 16)": 0.6186110377311707}, "r_span": [1234, 1316], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.000922858715057373}}]}, {"id": "963", "source_id": "15753", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 354, "end": 430, "text": "Many survivors and responders have been affected emotionally and physically.", "meta": "HIGH INTRO OF NEW INFO\nIt mentioned that many survivors and responders have been affected emotionally and physically, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 67 words or less:\n\nMore than 25,000 people have fought Ebola infections in the past year, with over 10,000 dying. Although the number of new cases has decreased, there are still dozens infected each week. Surveillance improvements suggest unknown chains of transmission may lead to new infections in the coming weeks. Many survivors and responders have been affected emotionally and physically.", "response_spans": [[0, 430]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7659566402435303, "(0, 16)": 0.7659566402435303, "(2, 0)": 0.7659566402435303, "(2, 16)": 0.7659566402435303, "(4, 0)": 0.7659566402435303, "(4, 16)": 0.7659566402435303, "(6, 0)": 0.7659566402435303, "(6, 16)": 0.7511526346206665, "(8, 0)": 0.7511526346206665, "(8, 16)": 0.7659566402435303, "(10, 0)": 0.7511526346206665, "(10, 16)": 0.7511526346206665, "(12, 0)": 0.7511526346206665, "(12, 16)": 0.7511526346206665, "(14, 0)": 0.7659566402435303, "(14, 16)": 0.7511526346206665, "(16, 0)": 0.7511526346206665, "(16, 16)": 0.7511526346206665, "(18, 0)": 0.7511526346206665, "(18, 16)": 0.7511526346206665, "(20, 0)": 0.7511526346206665, "(20, 16)": 0.7659566402435303, "(22, 0)": 0.7511526346206665, "(22, 16)": 0.7511526346206665, "(24, 0)": 0.7659566402435303, "(24, 16)": 0.7511526346206665, "(26, 0)": 0.7511526346206665, "(26, 16)": 0.7511526346206665, "(28, 0)": 0.7511526346206665, "(28, 16)": 0.7659566402435303, "(30, 0)": 0.7511526346206665, "(30, 16)": 0.7511526346206665}, "r_span": [424, 536], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009108781814575195}}]}, {"id": "999", "source_id": "15759", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "The article discusses the recent killing of Walter Scott by North Charleston police officer Michael Slager, and the role that body cameras could have played in preventing the tragedy. The author argues that while body cameras can help ensure that justice is served and improve relations between police and the community, they are only a temporary solution to the larger issue of racial bias in the criminal justice system. The author suggests that deeper changes are needed, such as tougher employment screening standards, more training for officers, and broader social changes to address income, education, and opportunity disparities between races. The article concludes that while body cameras cannot eradicate racial bias, they can help bring it to light and prevent similar tragedies from occurring in the future.", "response_spans": [[0, 511], [502, 818]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7619974613189697, "(0, 16)": 0.7619974613189697, "(2, 0)": 0.6801474094390869, "(2, 16)": 0.7619974613189697, "(4, 0)": 0.7619974613189697, "(4, 16)": 0.7619974613189697, "(6, 0)": 0.7619974613189697, "(6, 16)": 0.7500669956207275, "(8, 0)": 0.7619974613189697, "(8, 16)": 0.7619974613189697, "(10, 0)": 0.7619974613189697, "(10, 16)": 0.7619974613189697, "(12, 0)": 0.7619974613189697, "(12, 16)": 0.7727525234222412, "(14, 0)": 0.7619974613189697, "(14, 16)": 0.7557689547538757, "(16, 0)": 0.7557689547538757, "(16, 16)": 0.7619974613189697, "(18, 0)": 0.7619974613189697, "(18, 16)": 0.7727525234222412, "(20, 0)": 0.7727525234222412, "(20, 16)": 0.7389855980873108, "(22, 0)": 0.7557689547538757, "(22, 16)": 0.7557689547538757, "(24, 0)": 0.7389855980873108, "(24, 16)": 0.7557689547538757, "(26, 0)": 0.7557689547538757, "(26, 16)": 0.7557689547538757, "(28, 0)": 0.7557689547538757, "(28, 16)": 0.7389855980873108, "(30, 0)": 0.7557689547538757, "(30, 16)": 0.7557689547538757}, "r_span": [1044, 1146], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002224445343017578}}, {"prompt_attention_score": {"(0, 0)": 0.7754313945770264, "(0, 16)": 0.8812716007232666, "(2, 0)": 0.8812716007232666, "(2, 16)": 0.8812716007232666, "(4, 0)": 0.8812716007232666, "(4, 16)": 0.8812716007232666, "(6, 0)": 0.8812716007232666, "(6, 16)": 0.690682590007782, "(8, 0)": 0.8812716007232666, "(8, 16)": 0.8812716007232666, "(10, 0)": 0.8812716007232666, "(10, 16)": 0.8812716007232666, "(12, 0)": 0.8812716007232666, "(12, 16)": 0.7754313945770264, "(14, 0)": 0.8812716007232666, "(14, 16)": 0.8812716007232666, "(16, 0)": 0.8812716007232666, "(16, 16)": 0.8812716007232666, "(18, 0)": 0.7080956697463989, "(18, 16)": 0.7754313945770264, "(20, 0)": 0.8812716007232666, "(20, 16)": 0.8812716007232666, "(22, 0)": 0.579298734664917, "(22, 16)": 0.8812716007232666, "(24, 0)": 0.7080956697463989, "(24, 16)": 0.8812716007232666, "(26, 0)": 0.579298734664917, "(26, 16)": 0.8812716007232666, "(28, 0)": 0.579298734664917, "(28, 16)": 0.8812716007232666, "(30, 0)": 0.7080956697463989, "(30, 16)": 0.579298734664917}, "r_span": [1145, 1208], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009717345237731934}}]}, {"id": "1053", "source_id": "15769", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 99 words:\n\nTomasz Lazar, a Polish photographer, has been interviewing and photographing adults who were forced to live in Siberia as children during World War II. He has located over 30 survivors, now in their 80s, who share their traumatic experiences of being deported and separated from their families. Despite their painful memories, the survivors have welcomed Lazar with open arms and shared their stories to ensure their legacy is remembered. Lazar's work aims to remind future generations of the importance of human rights and avoiding similar mistakes in the past.", "response_spans": [[0, 45], [47, 553], [536, 609]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5372279286384583, "(0, 16)": 0.5372279286384583, "(2, 0)": 0.5372279286384583, "(2, 16)": 0.5372279286384583, "(4, 0)": 0.5540962219238281, "(4, 16)": 0.5372279286384583, "(6, 0)": 0.5540962219238281, "(6, 16)": 0.8314668536186218, "(8, 0)": 0.5372279286384583, "(8, 16)": 0.5372279286384583, "(10, 0)": 0.8314668536186218, "(10, 16)": 0.5891498327255249, "(12, 0)": 0.5891498327255249, "(12, 16)": 0.8314668536186218, "(14, 0)": 0.5499909520149231, "(14, 16)": 0.8314668536186218, "(16, 0)": 0.8314668536186218, "(16, 16)": 0.5499909520149231, "(18, 0)": 0.5891498327255249, "(18, 16)": 0.8314668536186218, "(20, 0)": 0.8314668536186218, "(20, 16)": 0.5499909520149231, "(22, 0)": 0.5499909520149231, "(22, 16)": 0.5499909520149231, "(24, 0)": 0.5499909520149231, "(24, 16)": 0.5499909520149231, "(26, 0)": 0.5499909520149231, "(26, 16)": 0.5499909520149231, "(28, 0)": 0.5891498327255249, "(28, 16)": 0.5499909520149231, "(30, 0)": 0.5499909520149231, "(30, 16)": 0.5499909520149231}, "r_span": [638, 651], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011140108108520508}}, {"prompt_attention_score": {"(0, 0)": 0.8058150410652161, "(0, 16)": 0.8058150410652161, "(2, 0)": 0.8058150410652161, "(2, 16)": 0.8058150410652161, "(4, 0)": 0.8058150410652161, "(4, 16)": 0.8058150410652161, "(6, 0)": 0.8058150410652161, "(6, 16)": 0.850430965423584, "(8, 0)": 0.8058150410652161, "(8, 16)": 0.8058150410652161, "(10, 0)": 0.8058150410652161, "(10, 16)": 0.8058150410652161, "(12, 0)": 0.8058150410652161, "(12, 16)": 0.850430965423584, "(14, 0)": 0.850430965423584, "(14, 16)": 0.8058150410652161, "(16, 0)": 0.850430965423584, "(16, 16)": 0.850430965423584, "(18, 0)": 0.8058150410652161, "(18, 16)": 0.850430965423584, "(20, 0)": 0.850430965423584, "(20, 16)": 0.850430965423584, "(22, 0)": 0.850430965423584, "(22, 16)": 0.850430965423584, "(24, 0)": 0.7163720726966858, "(24, 16)": 0.850430965423584, "(26, 0)": 0.850430965423584, "(26, 16)": 0.850430965423584, "(28, 0)": 0.850430965423584, "(28, 16)": 0.850430965423584, "(30, 0)": 0.850430965423584, "(30, 16)": 0.850430965423584}, "r_span": [653, 772], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 1.9371509552001953e-05}}, {"prompt_attention_score": {"(0, 0)": 0.5274873971939087, "(0, 16)": 0.5274873971939087, "(2, 0)": 0.5274873971939087, "(2, 16)": 0.5274873971939087, "(4, 0)": 0.5274873971939087, "(4, 16)": 0.5274873971939087, "(6, 0)": 0.5030208826065063, "(6, 16)": 0.531761109828949, "(8, 0)": 0.5274873971939087, "(8, 16)": 0.5274873971939087, "(10, 0)": 0.5274873971939087, "(10, 16)": 0.5274873971939087, "(12, 0)": 0.5274873971939087, "(12, 16)": 0.5274873971939087, "(14, 0)": 0.531761109828949, "(14, 16)": 0.5274873971939087, "(16, 0)": 0.5274873971939087, "(16, 16)": 0.5274873971939087, "(18, 0)": 0.49502184987068176, "(18, 16)": 0.5274873971939087, "(20, 0)": 0.5274873971939087, "(20, 16)": 0.49502184987068176, "(22, 0)": 0.531761109828949, "(22, 16)": 0.5274873971939087, "(24, 0)": 0.4946443438529968, "(24, 16)": 0.5274873971939087, "(26, 0)": 0.531761109828949, "(26, 16)": 0.531761109828949, "(28, 0)": 0.531761109828949, "(28, 16)": 0.49502184987068176, "(30, 0)": 0.531761109828949, "(30, 16)": 0.531761109828949}, "r_span": [770, 783], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002808570861816406}}]}, {"id": "1107", "source_id": "15778", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 10, "end": 36, "text": "including a pregnant woman", "meta": "SUBTLE CONFLICT:\nAIGC:including a pregnant woman\nOriginal: ‚Ä¶their three children‚Ä¶\n..breast feeding‚Ä¶ (implies she just gave birth, there was no mention that she was pregnant) \n", "label_type": "Subtle Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "A family, including a pregnant woman and three young children, managed to escape from a Yazidi refugee camp in Duhok, Iraqi Kurdistan, after being held captive by ISIS for eight months. The family, along with hundreds of others, were taken from their homes in Sinjar and brought to the camp, located near the front lines with ISIS. Many of the camp's inhabitants are Yazidis who were captured and enslaved by ISIS, with reports of widespread rape and abuse. The family's story is one of horror and resilience, as they recount the brutality they faced at the hands of their captors, including the separation of women and children, and the sale of young girls as sex slaves. Despite the hardship, the family is grateful to be alive and are hoping for international support to help free the remaining captives and rebuild their community.", "response_spans": [[0, 512], [494, 835]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7270932197570801, "(0, 16)": 0.7270932197570801, "(2, 0)": 0.5975250601768494, "(2, 16)": 0.5975250601768494, "(4, 0)": 0.5975250601768494, "(4, 16)": 0.5975250601768494, "(6, 0)": 0.7270932197570801, "(6, 16)": 0.7889766693115234, "(8, 0)": 0.5975250601768494, "(8, 16)": 0.5975250601768494, "(10, 0)": 0.5975250601768494, "(10, 16)": 0.5975250601768494, "(12, 0)": 0.5975250601768494, "(12, 16)": 0.7889766693115234, "(14, 0)": 0.5975250601768494, "(14, 16)": 0.5975250601768494, "(16, 0)": 0.5975250601768494, "(16, 16)": 0.5975250601768494, "(18, 0)": 0.5975250601768494, "(18, 16)": 0.7889766693115234, "(20, 0)": 0.7889766693115234, "(20, 16)": 0.7270932197570801, "(22, 0)": 0.5975250601768494, "(22, 16)": 0.7889766693115234, "(24, 0)": 0.5975250601768494, "(24, 16)": 0.7587587833404541, "(26, 0)": 0.7889766693115234, "(26, 16)": 0.5975250601768494, "(28, 0)": 0.5975250601768494, "(28, 16)": 0.5975250601768494, "(30, 0)": 0.7889766693115234, "(30, 16)": 0.7889766693115234}, "r_span": [1584, 1715], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0002447962760925293}}, {"prompt_attention_score": {"(0, 0)": 0.7024393081665039, "(0, 16)": 0.7024393081665039, "(2, 0)": 0.7024393081665039, "(2, 16)": 0.7024393081665039, "(4, 0)": 0.7024393081665039, "(4, 16)": 0.7024393081665039, "(6, 0)": 0.7024393081665039, "(6, 16)": 0.641259491443634, "(8, 0)": 0.7024393081665039, "(8, 16)": 0.7024393081665039, "(10, 0)": 0.7024393081665039, "(10, 16)": 0.7024393081665039, "(12, 0)": 0.7024393081665039, "(12, 16)": 0.641259491443634, "(14, 0)": 0.7024393081665039, "(14, 16)": 0.6062679290771484, "(16, 0)": 0.7024393081665039, "(16, 16)": 0.7024393081665039, "(18, 0)": 0.7024393081665039, "(18, 16)": 0.641259491443634, "(20, 0)": 0.6396003365516663, "(20, 16)": 0.5301516056060791, "(22, 0)": 0.7024393081665039, "(22, 16)": 0.641259491443634, "(24, 0)": 0.5301516056060791, "(24, 16)": 0.641259491443634, "(26, 0)": 0.5118230581283569, "(26, 16)": 0.7024393081665039, "(28, 0)": 0.6062679290771484, "(28, 16)": 0.5118230581283569, "(30, 0)": 0.5118230581283569, "(30, 16)": 0.5118230581283569}, "r_span": [1710, 1780], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0022666454315185547}}]}, {"id": "1113", "source_id": "15779", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "An American citizen, Debra Lobo, was shot in Karachi, Pakistan while driving from work, with pamphlets found in her car calling for America to be burned. The 55-year-old is expected to survive, but is unconscious. The US Embassy is in contact with Pakistani authorities and is investigating the incident.", "response_spans": [[0, 304]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.703548789024353, "(0, 16)": 0.703548789024353, "(2, 0)": 0.703548789024353, "(2, 16)": 0.703548789024353, "(4, 0)": 0.703548789024353, "(4, 16)": 0.8838233351707458, "(6, 0)": 0.703548789024353, "(6, 16)": 0.8838233351707458, "(8, 0)": 0.8838233351707458, "(8, 16)": 0.8838233351707458, "(10, 0)": 0.8838233351707458, "(10, 16)": 0.8838233351707458, "(12, 0)": 0.8838233351707458, "(12, 16)": 0.8838233351707458, "(14, 0)": 0.8838233351707458, "(14, 16)": 0.8838233351707458, "(16, 0)": 0.8838233351707458, "(16, 16)": 0.8838233351707458, "(18, 0)": 0.8838233351707458, "(18, 16)": 0.8838233351707458, "(20, 0)": 0.8838233351707458, "(20, 16)": 0.8838233351707458, "(22, 0)": 0.8838233351707458, "(22, 16)": 0.8838233351707458, "(24, 0)": 0.8838233351707458, "(24, 16)": 0.8838233351707458, "(26, 0)": 0.8838233351707458, "(26, 16)": 0.8838233351707458, "(28, 0)": 0.8838233351707458, "(28, 16)": 0.8838233351707458, "(30, 0)": 0.8838233351707458, "(30, 16)": 0.8838233351707458}, "r_span": [320, 398], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009379982948303223}}]}, {"id": "1155", "source_id": "15786", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 659, "end": 756, "text": "The boys, aged 16 and 14, and their mother were transported to hospitals in the US for treatment,", "meta": "SUBTLE CONFLICT\nAll of them are transported to hospitals in US.\noriginal:  The family was airlifted to hospitals in the United States", "label_type": "Subtle Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Two Delaware boys are in a coma and their father remains unable to talk or move two weeks after falling ill during a trip to the US Virgin Islands. The family was renting a villa at the Sirenusa resort when they became ill, and initial tests reveal that a pesticide may have caused their illnesses. The US Environmental Protection Agency (EPA) is investigating whether the family was exposed to the pesticide during a fumigation at the resort on March 18. The family's lawyer declined to comment on the investigation, but the EPA confirmed that it is working with local government agencies to determine if any environmental regulations or laws were violated. The boys, aged 16 and 14, and their mother were transported to hospitals in the US for treatment, while the father remains hospitalized.", "response_spans": [[0, 502], [485, 795]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6139920949935913, "(0, 16)": 0.6139920949935913, "(2, 0)": 0.6139920949935913, "(2, 16)": 0.6139920949935913, "(4, 0)": 0.6139920949935913, "(4, 16)": 0.6735965609550476, "(6, 0)": 0.6032153964042664, "(6, 16)": 0.9026466012001038, "(8, 0)": 0.6032153964042664, "(8, 16)": 0.6032153964042664, "(10, 0)": 0.8275834918022156, "(10, 16)": 0.6032153964042664, "(12, 0)": 0.6975753307342529, "(12, 16)": 0.9026466012001038, "(14, 0)": 0.6032153964042664, "(14, 16)": 0.6975753307342529, "(16, 0)": 0.9026466012001038, "(16, 16)": 0.6975753307342529, "(18, 0)": 0.6975753307342529, "(18, 16)": 0.9026466012001038, "(20, 0)": 0.9026466012001038, "(20, 16)": 0.6032153964042664, "(22, 0)": 0.6032153964042664, "(22, 16)": 0.9026466012001038, "(24, 0)": 0.8275834918022156, "(24, 16)": 0.9026466012001038, "(26, 0)": 0.6975753307342529, "(26, 16)": 0.6975753307342529, "(28, 0)": 0.6975753307342529, "(28, 16)": 0.6032153964042664, "(30, 0)": 0.6975753307342529, "(30, 16)": 0.6975753307342529}, "r_span": [941, 1059], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005841851234436035}}, {"prompt_attention_score": {"(0, 0)": 0.5764971375465393, "(0, 16)": 0.5764971375465393, "(2, 0)": 0.615027666091919, "(2, 16)": 0.615027666091919, "(4, 0)": 0.615027666091919, "(4, 16)": 0.615027666091919, "(6, 0)": 0.5764971375465393, "(6, 16)": 0.6800597906112671, "(8, 0)": 0.615027666091919, "(8, 16)": 0.615027666091919, "(10, 0)": 0.757699728012085, "(10, 16)": 0.5764971375465393, "(12, 0)": 0.615027666091919, "(12, 16)": 0.6800597906112671, "(14, 0)": 0.615027666091919, "(14, 16)": 0.6800597906112671, "(16, 0)": 0.7234618663787842, "(16, 16)": 0.615027666091919, "(18, 0)": 0.615027666091919, "(18, 16)": 0.6800597906112671, "(20, 0)": 0.6800597906112671, "(20, 16)": 0.615027666091919, "(22, 0)": 0.7566143274307251, "(22, 16)": 0.7234618663787842, "(24, 0)": 0.615027666091919, "(24, 16)": 0.6800597906112671, "(26, 0)": 0.7566143274307251, "(26, 16)": 0.7566143274307251, "(28, 0)": 0.7566143274307251, "(28, 16)": 0.615027666091919, "(30, 0)": 0.7566143274307251, "(30, 16)": 0.7566143274307251}, "r_span": [1056, 1123], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.001403510570526123}}]}, {"id": "1173", "source_id": "15789", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 143, "end": 305, "text": "APhA opposes the use of drugs for lethal injection due to the risk of botched executions, citing instances where inmates have writhed in pain for extended periods", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nThis was not mentioned in the source content", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "The American Pharmacists Association (APhA) has adopted a policy banning its members from participating in executions due to ethical concerns. APhA opposes the use of drugs for lethal injection due to the risk of botched executions, citing instances where inmates have writhed in pain for extended periods. Thirty-two states allow capital punishment, with lethal injection being the most common method, but shortages of execution drugs have led some states to consider alternative methods like firing squads. APhA joins other medical organizations in advocating against pharmacist involvement in executions, emphasizing that pharmacists should not be involved in harmful or unethical practices.", "response_spans": [[0, 508], [489, 694]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7552098035812378, "(0, 16)": 0.7552098035812378, "(2, 0)": 0.7552098035812378, "(2, 16)": 0.7552098035812378, "(4, 0)": 0.7552098035812378, "(4, 16)": 0.7086820602416992, "(6, 0)": 0.7086820602416992, "(6, 16)": 0.8414323329925537, "(8, 0)": 0.7552098035812378, "(8, 16)": 0.7552098035812378, "(10, 0)": 0.8414323329925537, "(10, 16)": 0.7552098035812378, "(12, 0)": 0.7552098035812378, "(12, 16)": 0.7523381114006042, "(14, 0)": 0.7086820602416992, "(14, 16)": 0.8414323329925537, "(16, 0)": 0.8414323329925537, "(16, 16)": 0.8414323329925537, "(18, 0)": 0.8414323329925537, "(18, 16)": 0.8414323329925537, "(20, 0)": 0.8414323329925537, "(20, 16)": 0.7086820602416992, "(22, 0)": 0.8414323329925537, "(22, 16)": 0.8414323329925537, "(24, 0)": 0.7086820602416992, "(24, 16)": 0.8414323329925537, "(26, 0)": 0.8414323329925537, "(26, 16)": 0.8414323329925537, "(28, 0)": 0.8414323329925537, "(28, 16)": 0.7086820602416992, "(30, 0)": 0.8414323329925537, "(30, 16)": 0.8414323329925537}, "r_span": [596, 711], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00028568506240844727}}, {"prompt_attention_score": {"(0, 0)": 0.5303289890289307, "(0, 16)": 0.787674069404602, "(2, 0)": 0.787674069404602, "(2, 16)": 0.787674069404602, "(4, 0)": 0.787674069404602, "(4, 16)": 0.787674069404602, "(6, 0)": 0.787674069404602, "(6, 16)": 0.747550368309021, "(8, 0)": 0.787674069404602, "(8, 16)": 0.787674069404602, "(10, 0)": 0.787674069404602, "(10, 16)": 0.787674069404602, "(12, 0)": 0.787674069404602, "(12, 16)": 0.787674069404602, "(14, 0)": 0.747550368309021, "(14, 16)": 0.787674069404602, "(16, 0)": 0.787674069404602, "(16, 16)": 0.787674069404602, "(18, 0)": 0.747550368309021, "(18, 16)": 0.787674069404602, "(20, 0)": 0.747550368309021, "(20, 16)": 0.5303289890289307, "(22, 0)": 0.747550368309021, "(22, 16)": 0.787674069404602, "(24, 0)": 0.5303289890289307, "(24, 16)": 0.747550368309021, "(26, 0)": 0.747550368309021, "(26, 16)": 0.747550368309021, "(28, 0)": 0.747550368309021, "(28, 16)": 0.5303289890289307, "(30, 0)": 0.747550368309021, "(30, 16)": 0.747550368309021}, "r_span": [707, 752], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000934600830078125}}]}, {"id": "1185", "source_id": "15791", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 740, "end": 778, "text": "citing his father's battle with asthma", "meta": "EVIDENT CONFLICT:\nAIGC: citing his father's battle with asthma\nOriginal: favorite uncle died from a severe asthma attack \n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 1067, "end": 1318, "text": "According to the Environmental Protection Agency (EPA), climate change will lead to increased heat exposure, malnutrition, and the spread of disease-carrying insects, and is expected to cause an additional 250,000 deaths per year between 2030 and 2050", "meta": "EVIDENT CONFLICT:\nAIGC: According to the Environmental Protection Agency (EPA), climate change.....per year between 2030 and 2050.\nOriginal: It was the World Health Organization who stated that the climate change will cause an additional 250,000 deaths per year between 2030 and 2050 and WHO's director on public health and environment department, Dr. Maria Neira about heat exposure, malnutrition, and the spread of disease-carrying insects.\n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "On Tuesday, President Barack Obama joined other officials to discuss the link between climate change and public health. The event occurred during National Public Health Week and featured U.S. Surgeon General Dr. Vivek Murthy and EPA Administrator Gina McCarthy. The discussion focused on how climate change affects people's health and the steps being taken to address the issue. Obama shared his personal experience with air quality in Los Angeles, stating that it was bad enough in the 1970s that he couldn't go outside during smog alerts. He highlighted the progress made since then due to the Clean Air Act and stressed the importance of taking action to improve air quality. Murphy discussed the impact of climate change on his family, citing his father's battle with asthma, and emphasized the need for communities to prepare for and respond to the health effects of climate change. The event also featured a roundtable discussion with doctors and nurses who are working to raise awareness and develop strategies to address the health effects of climate change. According to the Environmental Protection Agency (EPA), climate change will lead to increased heat exposure, malnutrition, and the spread of disease-carrying insects, and is expected to cause an additional 250,000 deaths per year between 2030 and 2050. Despite this, there remains a sizable group of people who deny that climate change is occurring.", "response_spans": [[0, 512], [493, 998], [979, 1416]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6061538457870483, "(0, 16)": 0.6021311283111572, "(2, 0)": 0.6061538457870483, "(2, 16)": 0.6061538457870483, "(4, 0)": 0.6061538457870483, "(4, 16)": 0.6061538457870483, "(6, 0)": 0.6061538457870483, "(6, 16)": 0.8668467998504639, "(8, 0)": 0.6061538457870483, "(8, 16)": 0.6061538457870483, "(10, 0)": 0.6061538457870483, "(10, 16)": 0.6061538457870483, "(12, 0)": 0.6061538457870483, "(12, 16)": 0.8668467998504639, "(14, 0)": 0.6061538457870483, "(14, 16)": 0.6061538457870483, "(16, 0)": 0.6061538457870483, "(16, 16)": 0.6061538457870483, "(18, 0)": 0.6061538457870483, "(18, 16)": 0.8668467998504639, "(20, 0)": 0.8668467998504639, "(20, 16)": 0.6061538457870483, "(22, 0)": 0.6061538457870483, "(22, 16)": 0.6797446608543396, "(24, 0)": 0.6061538457870483, "(24, 16)": 0.8668467998504639, "(26, 0)": 0.6061538457870483, "(26, 16)": 0.6061538457870483, "(28, 0)": 0.6061538457870483, "(28, 16)": 0.6061538457870483, "(30, 0)": 0.6061538457870483, "(30, 16)": 0.6061538457870483}, "r_span": [1414, 1529], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015256404876708984}}, {"prompt_attention_score": {"(0, 0)": 0.7359839081764221, "(0, 16)": 0.6165552139282227, "(2, 0)": 0.7359839081764221, "(2, 16)": 0.7359839081764221, "(4, 0)": 0.7359839081764221, "(4, 16)": 0.7359839081764221, "(6, 0)": 0.7359839081764221, "(6, 16)": 0.5809534788131714, "(8, 0)": 0.7359839081764221, "(8, 16)": 0.7359839081764221, "(10, 0)": 0.7359839081764221, "(10, 16)": 0.7359839081764221, "(12, 0)": 0.7359839081764221, "(12, 16)": 0.7217113971710205, "(14, 0)": 0.7359839081764221, "(14, 16)": 0.7359839081764221, "(16, 0)": 0.7359839081764221, "(16, 16)": 0.7359839081764221, "(18, 0)": 0.7359839081764221, "(18, 16)": 0.7542380094528198, "(20, 0)": 0.7217113971710205, "(20, 16)": 0.6165552139282227, "(22, 0)": 0.6165552139282227, "(22, 16)": 0.7217113971710205, "(24, 0)": 0.7359839081764221, "(24, 16)": 0.7217113971710205, "(26, 0)": 0.6165552139282227, "(26, 16)": 0.7359839081764221, "(28, 0)": 0.7359839081764221, "(28, 16)": 0.6165552139282227, "(30, 0)": 0.7359839081764221, "(30, 16)": 0.7359839081764221}, "r_span": [1524, 1632], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0007800459861755371}}, {"prompt_attention_score": {"(0, 0)": 0.5500604510307312, "(0, 16)": 0.5500604510307312, "(2, 0)": 0.5500604510307312, "(2, 16)": 0.5500604510307312, "(4, 0)": 0.5500604510307312, "(4, 16)": 0.5500604510307312, "(6, 0)": 0.5500604510307312, "(6, 16)": 0.835747241973877, "(8, 0)": 0.5500604510307312, "(8, 16)": 0.5500604510307312, "(10, 0)": 0.5500604510307312, "(10, 16)": 0.5500604510307312, "(12, 0)": 0.5500604510307312, "(12, 16)": 0.835747241973877, "(14, 0)": 0.5500604510307312, "(14, 16)": 0.5500604510307312, "(16, 0)": 0.5500604510307312, "(16, 16)": 0.5500604510307312, "(18, 0)": 0.5500604510307312, "(18, 16)": 0.6410887837409973, "(20, 0)": 0.835747241973877, "(20, 16)": 0.6410887837409973, "(22, 0)": 0.5500604510307312, "(22, 16)": 0.6410887837409973, "(24, 0)": 0.5500604510307312, "(24, 16)": 0.6410887837409973, "(26, 0)": 0.5500604510307312, "(26, 16)": 0.5500604510307312, "(28, 0)": 0.5500604510307312, "(28, 16)": 0.5500604510307312, "(30, 0)": 0.5500604510307312, "(30, 16)": 0.5500604510307312}, "r_span": [1628, 1736], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007236599922180176}}]}, {"id": "1239", "source_id": "15800", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 166, "end": 215, "text": "the bike was recovered by police just days later,", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of how many hours or days the police retrieve the bike\nGenerative: \"...the bike was recovered by police just days later...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Cyclist Wang Pingan's epic 460-day trip across China came to an abrupt halt when his beloved bike was stolen in the city of Shenzhen. However, in a surprising twist, the bike was recovered by police just days later, thanks to surveillance footage. Wang had refused to replace the bike, which held sentimental value after accompanying him on a two-wheel trek through every major province in China. Despite the setback, Wang is determined to complete his journey, which includes reaching the final destination of Hainan Island.", "response_spans": [[0, 510], [496, 525]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7086743712425232, "(0, 16)": 0.7086743712425232, "(2, 0)": 0.7086743712425232, "(2, 16)": 0.7086743712425232, "(4, 0)": 0.7086743712425232, "(4, 16)": 0.7086743712425232, "(6, 0)": 0.7086743712425232, "(6, 16)": 0.8938829302787781, "(8, 0)": 0.6577814817428589, "(8, 16)": 0.7086743712425232, "(10, 0)": 0.7086743712425232, "(10, 16)": 0.7086743712425232, "(12, 0)": 0.7086743712425232, "(12, 16)": 0.8938829302787781, "(14, 0)": 0.7086743712425232, "(14, 16)": 0.8938829302787781, "(16, 0)": 0.8938829302787781, "(16, 16)": 0.7086743712425232, "(18, 0)": 0.7086743712425232, "(18, 16)": 0.7926270961761475, "(20, 0)": 0.8938829302787781, "(20, 16)": 0.7086743712425232, "(22, 0)": 0.8938829302787781, "(22, 16)": 0.8938829302787781, "(24, 0)": 0.6577814817428589, "(24, 16)": 0.6577814817428589, "(26, 0)": 0.8938829302787781, "(26, 16)": 0.8938829302787781, "(28, 0)": 0.8938829302787781, "(28, 16)": 0.6577814817428589, "(30, 0)": 0.8938829302787781, "(30, 16)": 0.8938829302787781}, "r_span": [694, 818], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.002452671527862549}}, {"prompt_attention_score": {"(0, 0)": 0.4767606258392334, "(0, 16)": 0.4767606258392334, "(2, 0)": 0.4767606258392334, "(2, 16)": 0.4767606258392334, "(4, 0)": 0.4767606258392334, "(4, 16)": 0.5429791212081909, "(6, 0)": 0.5429791212081909, "(6, 16)": 0.6877632737159729, "(8, 0)": 0.5429791212081909, "(8, 16)": 0.4767606258392334, "(10, 0)": 0.5429791212081909, "(10, 16)": 0.5429791212081909, "(12, 0)": 0.551577091217041, "(12, 16)": 0.6877632737159729, "(14, 0)": 0.5429791212081909, "(14, 16)": 0.5429791212081909, "(16, 0)": 0.6877632737159729, "(16, 16)": 0.4767606258392334, "(18, 0)": 0.4767606258392334, "(18, 16)": 0.6877632737159729, "(20, 0)": 0.6877632737159729, "(20, 16)": 0.4767606258392334, "(22, 0)": 0.551577091217041, "(22, 16)": 0.5429791212081909, "(24, 0)": 0.5429791212081909, "(24, 16)": 0.5429791212081909, "(26, 0)": 0.551577091217041, "(26, 16)": 0.5429791212081909, "(28, 0)": 0.551577091217041, "(28, 16)": 0.5429791212081909, "(30, 0)": 0.551577091217041, "(30, 16)": 0.551577091217041}, "r_span": [817, 823], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00015735626220703125}}]}, {"id": "1341", "source_id": "15817", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 200 words or less:\n\nMigrants from various countries, including Eritrea, Syria, and Somalia, are attempting to reach Europe through Libya due to a combination of push and pull factors. The \"horn of Africa to the Atlantic\" migration route is well-established, with smugglers charging between $200 and $300 for passage. However, the journey is fraught with danger, including kidnapping, robbery, and capsizing of boats. Despite these risks, many migrants see it as their only option for a better life in Europe. The International Organization for Migration (IOM) has tracked the migration flows through North Africa for years and notes that the \"push factor\" of instability and poverty in Africa and the Middle East is greater than the \"pull factor\" of Europe. The recent murder of Egyptian and Ethiopian Christians by ISIS's Libyan affiliate may have hastened the departure of some migrants.", "response_spans": [[0, 54], [56, 562], [545, 925]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4966922402381897, "(0, 16)": 0.4966922402381897, "(2, 0)": 0.4852905869483948, "(2, 16)": 0.4852905869483948, "(4, 0)": 0.4852905869483948, "(4, 16)": 0.4852905869483948, "(6, 0)": 0.4852905869483948, "(6, 16)": 0.8147764801979065, "(8, 0)": 0.4852905869483948, "(8, 16)": 0.4852905869483948, "(10, 0)": 0.4852905869483948, "(10, 16)": 0.4852905869483948, "(12, 0)": 0.4852905869483948, "(12, 16)": 0.8147764801979065, "(14, 0)": 0.4852905869483948, "(14, 16)": 0.4852905869483948, "(16, 0)": 0.4852905869483948, "(16, 16)": 0.4852905869483948, "(18, 0)": 0.4852905869483948, "(18, 16)": 0.8147764801979065, "(20, 0)": 0.8147764801979065, "(20, 16)": 0.4852905869483948, "(22, 0)": 0.4852905869483948, "(22, 16)": 0.522154688835144, "(24, 0)": 0.4852905869483948, "(24, 16)": 0.522154688835144, "(26, 0)": 0.4852905869483948, "(26, 16)": 0.4852905869483948, "(28, 0)": 0.4852905869483948, "(28, 16)": 0.4852905869483948, "(30, 0)": 0.4852905869483948, "(30, 16)": 0.4852905869483948}, "r_span": [1490, 1506], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006059408187866211}}, {"prompt_attention_score": {"(0, 0)": 0.7359482645988464, "(0, 16)": 0.7359482645988464, "(2, 0)": 0.7359482645988464, "(2, 16)": 0.7359482645988464, "(4, 0)": 0.7359482645988464, "(4, 16)": 0.7359482645988464, "(6, 0)": 0.7359482645988464, "(6, 16)": 0.8228364586830139, "(8, 0)": 0.7359482645988464, "(8, 16)": 0.7359482645988464, "(10, 0)": 0.7359482645988464, "(10, 16)": 0.7359482645988464, "(12, 0)": 0.7359482645988464, "(12, 16)": 0.8228364586830139, "(14, 0)": 0.7359482645988464, "(14, 16)": 0.7359482645988464, "(16, 0)": 0.7359482645988464, "(16, 16)": 0.7359482645988464, "(18, 0)": 0.7359482645988464, "(18, 16)": 0.8228364586830139, "(20, 0)": 0.8228364586830139, "(20, 16)": 0.7359482645988464, "(22, 0)": 0.7359482645988464, "(22, 16)": 0.8228364586830139, "(24, 0)": 0.7359482645988464, "(24, 16)": 0.7955502271652222, "(26, 0)": 0.7359482645988464, "(26, 16)": 0.7359482645988464, "(28, 0)": 0.7359482645988464, "(28, 16)": 0.7359482645988464, "(30, 0)": 0.7359482645988464, "(30, 16)": 0.7359482645988464}, "r_span": [1508, 1632], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -7.838010787963867e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7953146696090698, "(0, 16)": 0.7003817558288574, "(2, 0)": 0.7953146696090698, "(2, 16)": 0.7953146696090698, "(4, 0)": 0.7953146696090698, "(4, 16)": 0.7953146696090698, "(6, 0)": 0.7953146696090698, "(6, 16)": 0.7764638662338257, "(8, 0)": 0.7953146696090698, "(8, 16)": 0.7953146696090698, "(10, 0)": 0.7003817558288574, "(10, 16)": 0.7953146696090698, "(12, 0)": 0.7953146696090698, "(12, 16)": 0.7919987440109253, "(14, 0)": 0.7953146696090698, "(14, 16)": 0.7953146696090698, "(16, 0)": 0.7953146696090698, "(16, 16)": 0.7953146696090698, "(18, 0)": 0.7953146696090698, "(18, 16)": 0.7953146696090698, "(20, 0)": 0.7919987440109253, "(20, 16)": 0.7003817558288574, "(22, 0)": 0.7953146696090698, "(22, 16)": 0.7919987440109253, "(24, 0)": 0.7953146696090698, "(24, 16)": 0.7365527749061584, "(26, 0)": 0.7003817558288574, "(26, 16)": 0.7953146696090698, "(28, 0)": 0.7003817558288574, "(28, 16)": 0.7953146696090698, "(30, 0)": 0.7953146696090698, "(30, 16)": 0.7953146696090698}, "r_span": [1631, 1714], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003688931465148926}}]}, {"id": "1353", "source_id": "15819", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "The Obama administration's Clean Power Plan has been criticized for neglecting nuclear energy, despite it being the largest source of carbon-free energy in the US. Former NASA scientist James Hansen has warned that continued opposition to nuclear power could threaten efforts to avoid dangerous climate change. However, the administration's energy policy plan appears to be biased against nuclear energy, as demonstrated by its modeled emissions reductions scenarios, which assume no new nuclear construction and the retirement of nearly all operating plants by 2050. This is despite the fact that nuclear power is carbon-free and could play a crucial role in meeting aggressive carbon reduction targets. The administration's recent executive order on federal sustainability does not provide enough credit for emission reductions from nuclear energy, and its modeling seems to encourage the shutdown of existing nuclear plants in favor of natural gas combined cycle plants. Critics argue that this reflects a broader anti-nuclear bias in the administration's policies, despite its claims to support an all-of-the-above energy strategy and addressing climate change.", "response_spans": [[0, 512], [496, 1006], [988, 1165]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.763788640499115, "(0, 16)": 0.763788640499115, "(2, 0)": 0.763788640499115, "(2, 16)": 0.763788640499115, "(4, 0)": 0.763788640499115, "(4, 16)": 0.763788640499115, "(6, 0)": 0.763788640499115, "(6, 16)": 0.8315096497535706, "(8, 0)": 0.763788640499115, "(8, 16)": 0.763788640499115, "(10, 0)": 0.8315096497535706, "(10, 16)": 0.763788640499115, "(12, 0)": 0.763788640499115, "(12, 16)": 0.8315096497535706, "(14, 0)": 0.763788640499115, "(14, 16)": 0.8559784293174744, "(16, 0)": 0.8559784293174744, "(16, 16)": 0.763788640499115, "(18, 0)": 0.763788640499115, "(18, 16)": 0.8315096497535706, "(20, 0)": 0.8559784293174744, "(20, 16)": 0.763788640499115, "(22, 0)": 0.8340470790863037, "(22, 16)": 0.8315096497535706, "(24, 0)": 0.8340470790863037, "(24, 16)": 0.8315096497535706, "(26, 0)": 0.8559784293174744, "(26, 16)": 0.7363291382789612, "(28, 0)": 0.8559784293174744, "(28, 16)": 0.763788640499115, "(30, 0)": 0.8559784293174744, "(30, 16)": 0.8559784293174744}, "r_span": [1180, 1278], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0021382570266723633}}, {"prompt_attention_score": {"(0, 0)": 0.7514649033546448, "(0, 16)": 0.7514649033546448, "(2, 0)": 0.7514649033546448, "(2, 16)": 0.7514649033546448, "(4, 0)": 0.7514649033546448, "(4, 16)": 0.7514649033546448, "(6, 0)": 0.7514649033546448, "(6, 16)": 0.718113124370575, "(8, 0)": 0.7514649033546448, "(8, 16)": 0.7514649033546448, "(10, 0)": 0.7514649033546448, "(10, 16)": 0.7514649033546448, "(12, 0)": 0.7514649033546448, "(12, 16)": 0.8494102954864502, "(14, 0)": 0.7514649033546448, "(14, 16)": 0.7514649033546448, "(16, 0)": 0.7514649033546448, "(16, 16)": 0.7514649033546448, "(18, 0)": 0.8494102954864502, "(18, 16)": 0.8494102954864502, "(20, 0)": 0.8494102954864502, "(20, 16)": 0.7514649033546448, "(22, 0)": 0.8494102954864502, "(22, 16)": 0.8494102954864502, "(24, 0)": 0.7514649033546448, "(24, 16)": 0.8494102954864502, "(26, 0)": 0.7742058038711548, "(26, 16)": 0.7514649033546448, "(28, 0)": 0.7742058038711548, "(28, 16)": 0.7514649033546448, "(30, 0)": 0.8494102954864502, "(30, 16)": 0.7742058038711548}, "r_span": [1277, 1377], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0013781189918518066}}, {"prompt_attention_score": {"(0, 0)": 0.699159562587738, "(0, 16)": 0.699159562587738, "(2, 0)": 0.699159562587738, "(2, 16)": 0.6972690224647522, "(4, 0)": 0.699159562587738, "(4, 16)": 0.699159562587738, "(6, 0)": 0.699159562587738, "(6, 16)": 0.699159562587738, "(8, 0)": 0.699159562587738, "(8, 16)": 0.699159562587738, "(10, 0)": 0.699159562587738, "(10, 16)": 0.699159562587738, "(12, 0)": 0.699159562587738, "(12, 16)": 0.699159562587738, "(14, 0)": 0.6972690224647522, "(14, 16)": 0.699159562587738, "(16, 0)": 0.699159562587738, "(16, 16)": 0.6972690224647522, "(18, 0)": 0.6972690224647522, "(18, 16)": 0.699159562587738, "(20, 0)": 0.699159562587738, "(20, 16)": 0.699159562587738, "(22, 0)": 0.6398385763168335, "(22, 16)": 0.699159562587738, "(24, 0)": 0.699159562587738, "(24, 16)": 0.699159562587738, "(26, 0)": 0.6398385763168335, "(26, 16)": 0.699159562587738, "(28, 0)": 0.6398385763168335, "(28, 16)": 0.699159562587738, "(30, 0)": 0.6972690224647522, "(30, 16)": 0.6398385763168335}, "r_span": [1374, 1414], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000946342945098877}}]}, {"id": "1455", "source_id": "15836", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On the 100th anniversary of the massacre of Armenians under the Ottoman Empire, Turkey remains steadfast in its refusal to acknowledge the event as genocide. Despite pressure from scholars, world leaders, and the Armenian government, the Turkish government continues to deny that a genocide took place, insisting that the deaths were part of broader intercommunal violence during World War I. The issue is highly politicized, with the ruling party avoiding the term genocide due to fears of damaging relations with neighboring countries and staining the legacy of the country's founders. Meanwhile, many Turks remain unaware or uncomfortable with the topic, and the issue continues to divide opinions both within Turkey and internationally.", "response_spans": [[0, 509], [491, 740]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.715978741645813, "(0, 16)": 0.6135420799255371, "(2, 0)": 0.715978741645813, "(2, 16)": 0.715978741645813, "(4, 0)": 0.715978741645813, "(4, 16)": 0.715978741645813, "(6, 0)": 0.715978741645813, "(6, 16)": 0.8218894600868225, "(8, 0)": 0.715978741645813, "(8, 16)": 0.715978741645813, "(10, 0)": 0.715978741645813, "(10, 16)": 0.715978741645813, "(12, 0)": 0.715978741645813, "(12, 16)": 0.8218894600868225, "(14, 0)": 0.715978741645813, "(14, 16)": 0.715978741645813, "(16, 0)": 0.715978741645813, "(16, 16)": 0.715978741645813, "(18, 0)": 0.715978741645813, "(18, 16)": 0.8218894600868225, "(20, 0)": 0.8218894600868225, "(20, 16)": 0.715978741645813, "(22, 0)": 0.715978741645813, "(22, 16)": 0.715978741645813, "(24, 0)": 0.715978741645813, "(24, 16)": 0.8218894600868225, "(26, 0)": 0.715978741645813, "(26, 16)": 0.715978741645813, "(28, 0)": 0.715978741645813, "(28, 16)": 0.715978741645813, "(30, 0)": 0.715978741645813, "(30, 16)": 0.715978741645813}, "r_span": [1468, 1588], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00010287761688232422}}, {"prompt_attention_score": {"(0, 0)": 0.6899155378341675, "(0, 16)": 0.6899155378341675, "(2, 0)": 0.7235047817230225, "(2, 16)": 0.7235047817230225, "(4, 0)": 0.7235047817230225, "(4, 16)": 0.7235047817230225, "(6, 0)": 0.7235047817230225, "(6, 16)": 0.6591942310333252, "(8, 0)": 0.7235047817230225, "(8, 16)": 0.7235047817230225, "(10, 0)": 0.6899155378341675, "(10, 16)": 0.6899155378341675, "(12, 0)": 0.7235047817230225, "(12, 16)": 0.7073301076889038, "(14, 0)": 0.7235047817230225, "(14, 16)": 0.6899155378341675, "(16, 0)": 0.6899155378341675, "(16, 16)": 0.7235047817230225, "(18, 0)": 0.7235047817230225, "(18, 16)": 0.6469216346740723, "(20, 0)": 0.7073301076889038, "(20, 16)": 0.6899155378341675, "(22, 0)": 0.6899155378341675, "(22, 16)": 0.7073301076889038, "(24, 0)": 0.7235047817230225, "(24, 16)": 0.7073301076889038, "(26, 0)": 0.6899155378341675, "(26, 16)": 0.6899155378341675, "(28, 0)": 0.6899155378341675, "(28, 16)": 0.7235047817230225, "(30, 0)": 0.6899155378341675, "(30, 16)": 0.7235047817230225}, "r_span": [1586, 1637], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0017229914665222168}}]}, {"id": "1479", "source_id": "11317", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Walmart, one of the largest employers in the United States, has emerged as a key player in the national debate on religious freedom laws and LGBTQ rights. The company has come out strongly against a religious freedom law passed in Arkansas, arguing that it could lead to discrimination against gay and lesbian customers. This stance has drawn attention to the growing support among businesses for LGBTQ equality, with many CEOs speaking out against discrimination and advocating for inclusive workplace policies. The backlash over Indiana's similar law has led some Republicans to reconsider their stance, with some calling for a more balanced approach to protecting religious liberties while also promoting equality. The debate has reached the highest levels of politics, with likely GOP presidential candidates like Jeb Bush and Ted Cruz taking opposite positions on the issue. The controversy highlights the evolving attitudes towards LGBTQ rights in the US, with many businesses recognizing the importance of supporting their LGBTQ employees and customers.", "response_spans": [[0, 512], [493, 998], [983, 1060]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6789059042930603, "(0, 16)": 0.7710491418838501, "(2, 0)": 0.6789059042930603, "(2, 16)": 0.6789059042930603, "(4, 0)": 0.6789059042930603, "(4, 16)": 0.6789059042930603, "(6, 0)": 0.6789059042930603, "(6, 16)": 0.8422212600708008, "(8, 0)": 0.6789059042930603, "(8, 16)": 0.6789059042930603, "(10, 0)": 0.6789059042930603, "(10, 16)": 0.6789059042930603, "(12, 0)": 0.6789059042930603, "(12, 16)": 0.7922406792640686, "(14, 0)": 0.6789059042930603, "(14, 16)": 0.6789059042930603, "(16, 0)": 0.6789059042930603, "(16, 16)": 0.6789059042930603, "(18, 0)": 0.6789059042930603, "(18, 16)": 0.8422212600708008, "(20, 0)": 0.8422212600708008, "(20, 16)": 0.7710491418838501, "(22, 0)": 0.6789059042930603, "(22, 16)": 0.8422212600708008, "(24, 0)": 0.6789059042930603, "(24, 16)": 0.8422212600708008, "(26, 0)": 0.6789059042930603, "(26, 16)": 0.6789059042930603, "(28, 0)": 0.6789059042930603, "(28, 16)": 0.6789059042930603, "(30, 0)": 0.6789059042930603, "(30, 16)": 0.6789059042930603}, "r_span": [1440, 1550], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007462501525878906}}, {"prompt_attention_score": {"(0, 0)": 0.6875909566879272, "(0, 16)": 0.6875909566879272, "(2, 0)": 0.384212464094162, "(2, 16)": 0.384212464094162, "(4, 0)": 0.384212464094162, "(4, 16)": 0.6875909566879272, "(6, 0)": 0.6875909566879272, "(6, 16)": 0.8117127418518066, "(8, 0)": 0.6875909566879272, "(8, 16)": 0.384212464094162, "(10, 0)": 0.6875909566879272, "(10, 16)": 0.6875909566879272, "(12, 0)": 0.6875909566879272, "(12, 16)": 0.8428916931152344, "(14, 0)": 0.384212464094162, "(14, 16)": 0.6875909566879272, "(16, 0)": 0.6875909566879272, "(16, 16)": 0.384212464094162, "(18, 0)": 0.6875909566879272, "(18, 16)": 0.8428916931152344, "(20, 0)": 0.8428916931152344, "(20, 16)": 0.384212464094162, "(22, 0)": 0.384212464094162, "(22, 16)": 0.8428916931152344, "(24, 0)": 0.384212464094162, "(24, 16)": 0.8428916931152344, "(26, 0)": 0.6875909566879272, "(26, 16)": 0.6875909566879272, "(28, 0)": 0.6875909566879272, "(28, 16)": 0.384212464094162, "(30, 0)": 0.8428916931152344, "(30, 16)": 0.690828800201416}, "r_span": [1547, 1652], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004729032516479492}}, {"prompt_attention_score": {"(0, 0)": 0.6203934550285339, "(0, 16)": 0.6203934550285339, "(2, 0)": 0.6203934550285339, "(2, 16)": 0.6203934550285339, "(4, 0)": 0.6203934550285339, "(4, 16)": 0.6203934550285339, "(6, 0)": 0.6203934550285339, "(6, 16)": 0.5705420970916748, "(8, 0)": 0.6203934550285339, "(8, 16)": 0.6203934550285339, "(10, 0)": 0.6203934550285339, "(10, 16)": 0.6203934550285339, "(12, 0)": 0.6203934550285339, "(12, 16)": 0.6203934550285339, "(14, 0)": 0.5132163166999817, "(14, 16)": 0.6203934550285339, "(16, 0)": 0.6203934550285339, "(16, 16)": 0.6203934550285339, "(18, 0)": 0.6203934550285339, "(18, 16)": 0.6648476123809814, "(20, 0)": 0.6648476123809814, "(20, 16)": 0.5132163166999817, "(22, 0)": 0.5132163166999817, "(22, 16)": 0.5705420970916748, "(24, 0)": 0.5576106309890747, "(24, 16)": 0.6648476123809814, "(26, 0)": 0.6203934550285339, "(26, 16)": 0.6203934550285339, "(28, 0)": 0.6203934550285339, "(28, 16)": 0.5132163166999817, "(30, 0)": 0.5132163166999817, "(30, 16)": 0.5842857360839844}, "r_span": [1650, 1664], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000125885009765625}}]}, {"id": "1515", "source_id": "11323", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Easter is a significant religious event in the Christian faith, commemorating the resurrection of Jesus Christ. However, it has also adopted various secular traditions, such as the Easter bunny and colored eggs. The date of Easter varies due to a combination of solar and lunar cycles, with Western and Eastern Christianity having different calendars. The timing of Easter is linked to the Jewish holiday of Passover, as Jesus' crucifixion occurred around the same time. According to some sources, the Easter bunny and egg tradition originated in medieval Europe, while others attribute it to ancient pagan cultures. Additionally, some Christian denominations observe their own unique traditions during the Holy Week leading up to Easter.", "response_spans": [[0, 508], [489, 738]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.592960000038147, "(0, 16)": 0.6718711853027344, "(2, 0)": 0.592960000038147, "(2, 16)": 0.592960000038147, "(4, 0)": 0.592960000038147, "(4, 16)": 0.592960000038147, "(6, 0)": 0.592960000038147, "(6, 16)": 0.8530857563018799, "(8, 0)": 0.592960000038147, "(8, 16)": 0.592960000038147, "(10, 0)": 0.592960000038147, "(10, 16)": 0.592960000038147, "(12, 0)": 0.592960000038147, "(12, 16)": 0.8238867521286011, "(14, 0)": 0.592960000038147, "(14, 16)": 0.592960000038147, "(16, 0)": 0.592960000038147, "(16, 16)": 0.592960000038147, "(18, 0)": 0.592960000038147, "(18, 16)": 0.8530857563018799, "(20, 0)": 0.8530857563018799, "(20, 16)": 0.6718711853027344, "(22, 0)": 0.592960000038147, "(22, 16)": 0.8530857563018799, "(24, 0)": 0.592960000038147, "(24, 16)": 0.8530857563018799, "(26, 0)": 0.592960000038147, "(26, 16)": 0.592960000038147, "(28, 0)": 0.592960000038147, "(28, 16)": 0.592960000038147, "(30, 0)": 0.592960000038147, "(30, 16)": 0.592960000038147}, "r_span": [1493, 1608], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008872151374816895}}, {"prompt_attention_score": {"(0, 0)": 0.5793486833572388, "(0, 16)": 0.5793486833572388, "(2, 0)": 0.5793486833572388, "(2, 16)": 0.5793486833572388, "(4, 0)": 0.7333202362060547, "(4, 16)": 0.5793486833572388, "(6, 0)": 0.5793486833572388, "(6, 16)": 0.7690654397010803, "(8, 0)": 0.5793486833572388, "(8, 16)": 0.7333202362060547, "(10, 0)": 0.5793486833572388, "(10, 16)": 0.5793486833572388, "(12, 0)": 0.5793486833572388, "(12, 16)": 0.8007805347442627, "(14, 0)": 0.7333202362060547, "(14, 16)": 0.5793486833572388, "(16, 0)": 0.5793486833572388, "(16, 16)": 0.5793486833572388, "(18, 0)": 0.5793486833572388, "(18, 16)": 0.8007805347442627, "(20, 0)": 0.8007805347442627, "(20, 16)": 0.7333202362060547, "(22, 0)": 0.5793486833572388, "(22, 16)": 0.7269403338432312, "(24, 0)": 0.7333202362060547, "(24, 16)": 0.7269403338432312, "(26, 0)": 0.5793486833572388, "(26, 16)": 0.5793486833572388, "(28, 0)": 0.5793486833572388, "(28, 16)": 0.7333202362060547, "(30, 0)": 0.5793486833572388, "(30, 16)": 0.7390706539154053}, "r_span": [1604, 1653], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0022770166397094727}}]}, {"id": "1521", "source_id": "11332", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 114 words:\n\nJapan's Defense Minister, Gen Nakatani, has revealed that the country's Air Self Defense Force (ASDF) has never detected any extraterrestrial objects despite flamboyant former wrestler-turned-lawmaker Antonio Inoki's inquiry. Nakatani stated that ASDF jets are deployed when there are indications of an unidentified flying object that could violate Japanese airspace, but no such incidents have been reported. Inoki, who has claimed to have seen a UFO himself, has sparked conversations about the legal implications of defending against an alien invasion under Japan's pacifist constitution.", "response_spans": [[0, 46], [48, 550], [535, 639]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5139499306678772, "(0, 16)": 0.5139499306678772, "(2, 0)": 0.5139499306678772, "(2, 16)": 0.5139499306678772, "(4, 0)": 0.5139499306678772, "(4, 16)": 0.5139499306678772, "(6, 0)": 0.5139499306678772, "(6, 16)": 0.8094407320022583, "(8, 0)": 0.5139499306678772, "(8, 16)": 0.5915871858596802, "(10, 0)": 0.8094407320022583, "(10, 16)": 0.5139499306678772, "(12, 0)": 0.5915871858596802, "(12, 16)": 0.8094407320022583, "(14, 0)": 0.5139499306678772, "(14, 16)": 0.8094407320022583, "(16, 0)": 0.48153287172317505, "(16, 16)": 0.48153287172317505, "(18, 0)": 0.5915871858596802, "(18, 16)": 0.8094407320022583, "(20, 0)": 0.8094407320022583, "(20, 16)": 0.5088071823120117, "(22, 0)": 0.48153287172317505, "(22, 16)": 0.48153287172317505, "(24, 0)": 0.5088071823120117, "(24, 16)": 0.48153287172317505, "(26, 0)": 0.48153287172317505, "(26, 16)": 0.48153287172317505, "(28, 0)": 0.48153287172317505, "(28, 16)": 0.5088071823120117, "(30, 0)": 0.48153287172317505, "(30, 16)": 0.48153287172317505}, "r_span": [750, 764], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00010001659393310547}}, {"prompt_attention_score": {"(0, 0)": 0.7787994742393494, "(0, 16)": 0.7787994742393494, "(2, 0)": 0.7787994742393494, "(2, 16)": 0.7787994742393494, "(4, 0)": 0.7787994742393494, "(4, 16)": 0.7787994742393494, "(6, 0)": 0.7787994742393494, "(6, 16)": 0.9097303152084351, "(8, 0)": 0.7787994742393494, "(8, 16)": 0.7787994742393494, "(10, 0)": 0.7787994742393494, "(10, 16)": 0.7787994742393494, "(12, 0)": 0.7787994742393494, "(12, 16)": 0.9097303152084351, "(14, 0)": 0.7303214073181152, "(14, 16)": 0.7787994742393494, "(16, 0)": 0.7303214073181152, "(16, 16)": 0.7787994742393494, "(18, 0)": 0.7787994742393494, "(18, 16)": 0.9097303152084351, "(20, 0)": 0.9097303152084351, "(20, 16)": 0.7303214073181152, "(22, 0)": 0.7862181663513184, "(22, 16)": 0.9097303152084351, "(24, 0)": 0.7303214073181152, "(24, 16)": 0.9097303152084351, "(26, 0)": 0.7862181663513184, "(26, 16)": 0.7862181663513184, "(28, 0)": 0.7862181663513184, "(28, 16)": 0.7303214073181152, "(30, 0)": 0.7862181663513184, "(30, 16)": 0.7862181663513184}, "r_span": [766, 888], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.003452003002166748}}, {"prompt_attention_score": {"(0, 0)": 0.8064075112342834, "(0, 16)": 0.8064075112342834, "(2, 0)": 0.8064075112342834, "(2, 16)": 0.8064075112342834, "(4, 0)": 0.8064075112342834, "(4, 16)": 0.8064075112342834, "(6, 0)": 0.8064075112342834, "(6, 16)": 0.6837670803070068, "(8, 0)": 0.8064075112342834, "(8, 16)": 0.8064075112342834, "(10, 0)": 0.8064075112342834, "(10, 16)": 0.8064075112342834, "(12, 0)": 0.8064075112342834, "(12, 16)": 0.8064075112342834, "(14, 0)": 0.5764044523239136, "(14, 16)": 0.8064075112342834, "(16, 0)": 0.8064075112342834, "(16, 16)": 0.8064075112342834, "(18, 0)": 0.6837670803070068, "(18, 16)": 0.8064075112342834, "(20, 0)": 0.8064075112342834, "(20, 16)": 0.5764044523239136, "(22, 0)": 0.6837670803070068, "(22, 16)": 0.8064075112342834, "(24, 0)": 0.5764044523239136, "(24, 16)": 0.8064075112342834, "(26, 0)": 0.6837670803070068, "(26, 16)": 0.8064075112342834, "(28, 0)": 0.6837670803070068, "(28, 16)": 0.5764044523239136, "(30, 0)": 0.6837670803070068, "(30, 16)": 0.6837670803070068}, "r_span": [886, 907], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007987022399902344}}]}, {"id": "1569", "source_id": "11349", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Lauren Hill, a 19-year-old college basketball player who fought brain cancer and inspired millions, has passed away. Hill was diagnosed with diffuse intrinsic pontine glioma in 2013 but continued to play basketball, even during chemotherapy treatments. Mount St. Joseph University successfully petitioned the NCAA to move up the opening game of its schedule so Hill could play, and she scored the first two points and the final layup of the game. Despite her illness, Hill remained positive and encouraged others to cherish every moment and never give up on their dreams. She raised over $1.4 million for pediatric cancer research and leaves behind a legacy of strength, courage, and inspiration. Hill's passing has been met with tributes from NBA great LeBron James and NCAA President Mark Emmert, who praised her enthusiasm and spirit.", "response_spans": [[0, 512], [495, 837]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7794114351272583, "(0, 16)": 0.7794114351272583, "(2, 0)": 0.7794114351272583, "(2, 16)": 0.7794114351272583, "(4, 0)": 0.7794114351272583, "(4, 16)": 0.7794114351272583, "(6, 0)": 0.7794114351272583, "(6, 16)": 0.9199726581573486, "(8, 0)": 0.7794114351272583, "(8, 16)": 0.7794114351272583, "(10, 0)": 0.7794114351272583, "(10, 16)": 0.7794114351272583, "(12, 0)": 0.7794114351272583, "(12, 16)": 0.9199726581573486, "(14, 0)": 0.7794114351272583, "(14, 16)": 0.9199726581573486, "(16, 0)": 0.7794114351272583, "(16, 16)": 0.7794114351272583, "(18, 0)": 0.7794114351272583, "(18, 16)": 0.9199726581573486, "(20, 0)": 0.9199726581573486, "(20, 16)": 0.7794114351272583, "(22, 0)": 0.5780164003372192, "(22, 16)": 0.9199726581573486, "(24, 0)": 0.5780164003372192, "(24, 16)": 0.9199726581573486, "(26, 0)": 0.5780164003372192, "(26, 16)": 0.7794114351272583, "(28, 0)": 0.9199726581573486, "(28, 16)": 0.7794114351272583, "(30, 0)": 0.5780164003372192, "(30, 16)": 0.9199726581573486}, "r_span": [1013, 1126], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008447766304016113}}, {"prompt_attention_score": {"(0, 0)": 0.6944187879562378, "(0, 16)": 0.6944187879562378, "(2, 0)": 0.6944187879562378, "(2, 16)": 0.6476492881774902, "(4, 0)": 0.6944187879562378, "(4, 16)": 0.6944187879562378, "(6, 0)": 0.7090434432029724, "(6, 16)": 0.6717252731323242, "(8, 0)": 0.6944187879562378, "(8, 16)": 0.6476492881774902, "(10, 0)": 0.6944187879562378, "(10, 16)": 0.6944187879562378, "(12, 0)": 0.6476492881774902, "(12, 16)": 0.7891286611557007, "(14, 0)": 0.6476492881774902, "(14, 16)": 0.6944187879562378, "(16, 0)": 0.6717252731323242, "(16, 16)": 0.6476492881774902, "(18, 0)": 0.6476492881774902, "(18, 16)": 0.7891286611557007, "(20, 0)": 0.7891286611557007, "(20, 16)": 0.6476492881774902, "(22, 0)": 0.6476492881774902, "(22, 16)": 0.6900959610939026, "(24, 0)": 0.6476492881774902, "(24, 16)": 0.7891286611557007, "(26, 0)": 0.7379133105278015, "(26, 16)": 0.7891286611557007, "(28, 0)": 0.7379133105278015, "(28, 16)": 0.6476492881774902, "(30, 0)": 0.6476492881774902, "(30, 16)": 0.7379133105278015}, "r_span": [1124, 1203], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002453923225402832}}]}, {"id": "1587", "source_id": "11353", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "A piece of a fiberglass boat believed to have originated from the 2011 Japan earthquake and tsunami was found off the Oregon coast and towed to shore. Inside, biologists found over 4,000 miles later, yellowtail jack fish typically found in Japanese waters. The fish will be taken to the Oregon Coast Aquarium.", "response_spans": [[0, 309]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8498052358627319, "(0, 16)": 0.8498052358627319, "(2, 0)": 0.8498052358627319, "(2, 16)": 0.8498052358627319, "(4, 0)": 0.8498052358627319, "(4, 16)": 0.8282487392425537, "(6, 0)": 0.8498052358627319, "(6, 16)": 0.8282487392425537, "(8, 0)": 0.8282487392425537, "(8, 16)": 0.8282487392425537, "(10, 0)": 0.8498052358627319, "(10, 16)": 0.8498052358627319, "(12, 0)": 0.8498052358627319, "(12, 16)": 0.8282487392425537, "(14, 0)": 0.8282487392425537, "(14, 16)": 0.8282487392425537, "(16, 0)": 0.8282487392425537, "(16, 16)": 0.8282487392425537, "(18, 0)": 0.8282487392425537, "(18, 16)": 0.8282487392425537, "(20, 0)": 0.8282487392425537, "(20, 16)": 0.8282487392425537, "(22, 0)": 0.8282487392425537, "(22, 16)": 0.8282487392425537, "(24, 0)": 0.8282487392425537, "(24, 16)": 0.8282487392425537, "(26, 0)": 0.8282487392425537, "(26, 16)": 0.8282487392425537, "(28, 0)": 0.8282487392425537, "(28, 16)": 0.8282487392425537, "(30, 0)": 0.8282487392425537, "(30, 16)": 0.8282487392425537}, "r_span": [313, 391], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0020666122436523438}}]}, {"id": "1599", "source_id": "11355", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Former Australian cricket captain and legendary broadcaster Richie Benaud has passed away at the age of 84. Benaud was widely regarded as the greatest commentator in cricket history, with a career spanning over four decades with the BBC. He was known for his witty one-liners and insightful analysis, and was inducted into the Sport Australia Hall of Fame in 1985. Benaud was a pioneering figure in Australian cricket, leading the team as captain from 1958 to 1964 and setting an incredibly high standard on and off the field. His passing has drawn tributes from around the world, including from Australian Prime Minister Tony Abbott, who described Benaud as \"cricket personified\". Current Australian captain Michael Clarke and former Pakistani captain Imran Khan are among those who have paid their respects, while British Prime Minister David Cameron has also expressed his sadness at Benaud's passing.", "response_spans": [[0, 511], [496, 904]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7582443952560425, "(0, 16)": 0.7582443952560425, "(2, 0)": 0.7582443952560425, "(2, 16)": 0.7582443952560425, "(4, 0)": 0.7582443952560425, "(4, 16)": 0.7582443952560425, "(6, 0)": 0.7582443952560425, "(6, 16)": 0.9057972431182861, "(8, 0)": 0.7510875463485718, "(8, 16)": 0.7582443952560425, "(10, 0)": 0.7582443952560425, "(10, 16)": 0.7582443952560425, "(12, 0)": 0.7582443952560425, "(12, 16)": 0.9057972431182861, "(14, 0)": 0.7582443952560425, "(14, 16)": 0.9057972431182861, "(16, 0)": 0.9057972431182861, "(16, 16)": 0.7582443952560425, "(18, 0)": 0.7582443952560425, "(18, 16)": 0.9057972431182861, "(20, 0)": 0.9057972431182861, "(20, 16)": 0.7582443952560425, "(22, 0)": 0.7582443952560425, "(22, 16)": 0.9057972431182861, "(24, 0)": 0.7582443952560425, "(24, 16)": 0.9057972431182861, "(26, 0)": 0.9057972431182861, "(26, 16)": 0.7582443952560425, "(28, 0)": 0.9057972431182861, "(28, 16)": 0.7582443952560425, "(30, 0)": 0.7582443952560425, "(30, 16)": 0.9057972431182861}, "r_span": [1500, 1631], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00107496976852417}}, {"prompt_attention_score": {"(0, 0)": 0.8162097930908203, "(0, 16)": 0.8162097930908203, "(2, 0)": 0.8162097930908203, "(2, 16)": 0.7693947553634644, "(4, 0)": 0.8162097930908203, "(4, 16)": 0.8162097930908203, "(6, 0)": 0.8162097930908203, "(6, 16)": 0.7706667184829712, "(8, 0)": 0.8162097930908203, "(8, 16)": 0.8162097930908203, "(10, 0)": 0.8162097930908203, "(10, 16)": 0.8162097930908203, "(12, 0)": 0.8162097930908203, "(12, 16)": 0.8162097930908203, "(14, 0)": 0.8162097930908203, "(14, 16)": 0.8162097930908203, "(16, 0)": 0.8162097930908203, "(16, 16)": 0.8162097930908203, "(18, 0)": 0.8162097930908203, "(18, 16)": 0.8162097930908203, "(20, 0)": 0.8162097930908203, "(20, 16)": 0.8162097930908203, "(22, 0)": 0.6811015605926514, "(22, 16)": 0.8162097930908203, "(24, 0)": 0.8162097930908203, "(24, 16)": 0.7637757062911987, "(26, 0)": 0.7410387992858887, "(26, 16)": 0.8162097930908203, "(28, 0)": 0.7410387992858887, "(28, 16)": 0.8162097930908203, "(30, 0)": 0.6811015605926514, "(30, 16)": 0.7410387992858887}, "r_span": [1629, 1713], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013256669044494629}}]}, {"id": "1605", "source_id": "11356", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Malala Yousafzai, Nobel laureate and education advocate, has been given an asteroid named after her by NASA astrophysicist Amy Mainzer. The asteroid, 316201 Malala, orbits the sun between Mars and Jupiter every five and a half years and is approximately 4 kilometers in diameter. Mainzer chose to honor Malala for her work in promoting girls' education, which she believes is crucial for increasing human potential and solving global problems.", "response_spans": [[0, 443]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8490069508552551, "(0, 16)": 0.8490069508552551, "(2, 0)": 0.8490069508552551, "(2, 16)": 0.8490069508552551, "(4, 0)": 0.8490069508552551, "(4, 16)": 0.8490069508552551, "(6, 0)": 0.8490069508552551, "(6, 16)": 0.8368948698043823, "(8, 0)": 0.8490069508552551, "(8, 16)": 0.8490069508552551, "(10, 0)": 0.8490069508552551, "(10, 16)": 0.8490069508552551, "(12, 0)": 0.8490069508552551, "(12, 16)": 0.8490069508552551, "(14, 0)": 0.8490069508552551, "(14, 16)": 0.8368948698043823, "(16, 0)": 0.8368948698043823, "(16, 16)": 0.8368948698043823, "(18, 0)": 0.8368948698043823, "(18, 16)": 0.8368948698043823, "(20, 0)": 0.8490069508552551, "(20, 16)": 0.8490069508552551, "(22, 0)": 0.8368948698043823, "(22, 16)": 0.8368948698043823, "(24, 0)": 0.8368948698043823, "(24, 16)": 0.8368948698043823, "(26, 0)": 0.8368948698043823, "(26, 16)": 0.8368948698043823, "(28, 0)": 0.8368948698043823, "(28, 16)": 0.8490069508552551, "(30, 0)": 0.8368948698043823, "(30, 16)": 0.8368948698043823}, "r_span": [480, 589], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014189481735229492}}]}, {"id": "1623", "source_id": "11366", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 89 words:\n\nAt least five people were killed and over a dozen injured in an explosion outside a bus station in Gombe, Nigeria. A woman left her explosives-laden handbag near a bus filled with passengers, setting it on fire. Boko Haram is believed to be responsible, despite recent offensives against the group. This is the first attack since Nigeria's presidential election, which was won by opposition candidate Muhammadu Buhari, who vowed to end Boko Haram's reign of terror.", "response_spans": [[0, 512]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7647152543067932, "(0, 16)": 0.7647152543067932, "(2, 0)": 0.7647152543067932, "(2, 16)": 0.7647152543067932, "(4, 0)": 0.7647152543067932, "(4, 16)": 0.7647152543067932, "(6, 0)": 0.7647152543067932, "(6, 16)": 0.8326526880264282, "(8, 0)": 0.7647152543067932, "(8, 16)": 0.7647152543067932, "(10, 0)": 0.7647152543067932, "(10, 16)": 0.7647152543067932, "(12, 0)": 0.7647152543067932, "(12, 16)": 0.8326526880264282, "(14, 0)": 0.7647152543067932, "(14, 16)": 0.7647152543067932, "(16, 0)": 0.8326526880264282, "(16, 16)": 0.7647152543067932, "(18, 0)": 0.7647152543067932, "(18, 16)": 0.7647152543067932, "(20, 0)": 0.8326526880264282, "(20, 16)": 0.7647152543067932, "(22, 0)": 0.7647152543067932, "(22, 16)": 0.7647152543067932, "(24, 0)": 0.7647152543067932, "(24, 16)": 0.8326526880264282, "(26, 0)": 0.7647152543067932, "(26, 16)": 0.7647152543067932, "(28, 0)": 0.7647152543067932, "(28, 16)": 0.7647152543067932, "(30, 0)": 0.7647152543067932, "(30, 16)": 0.8326526880264282}, "r_span": [562, 688], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0023685693740844727}}]}, {"id": "1647", "source_id": "11370", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "At the Summit of the Americas in Panama, President Barack Obama is seeking to improve US relations with Latin American and Caribbean countries, which have declined in recent years due to a perceived lack of US interest and influence in the region. However, past summits have ended in diplomatic and public relations disasters for the US, including incidents of US Secret Service agents hiring prostitutes and a confrontation between Obama and Venezuelan President Hugo Chavez. Obama has a chance to turn things around with his new Cuba policy, but risks handing a propaganda victory to Venezuelan President Nicol√°s Maduro by imposing sanctions on his regime. The US has lost influence in the region to China, Russia, and Iran, and faces challenges such as oppression of opposition leaders, suppression of press freedom, and corruption. If Obama can articulate a clear vision and demonstrate support for democracy, human rights, and the rule of law in the region, he may be able to rebuild US relationships and improve the lives of millions of people living in poverty.", "response_spans": [[0, 510], [496, 1005], [989, 1068]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6929459571838379, "(0, 16)": 0.6929459571838379, "(2, 0)": 0.6929459571838379, "(2, 16)": 0.6929459571838379, "(4, 0)": 0.6929459571838379, "(4, 16)": 0.6929459571838379, "(6, 0)": 0.6929459571838379, "(6, 16)": 0.7532005310058594, "(8, 0)": 0.6929459571838379, "(8, 16)": 0.6929459571838379, "(10, 0)": 0.736282467842102, "(10, 16)": 0.6929459571838379, "(12, 0)": 0.6929459571838379, "(12, 16)": 0.8174054622650146, "(14, 0)": 0.7364411950111389, "(14, 16)": 0.7999023199081421, "(16, 0)": 0.7999023199081421, "(16, 16)": 0.7364411950111389, "(18, 0)": 0.7364411950111389, "(18, 16)": 0.8174054622650146, "(20, 0)": 0.7239896059036255, "(20, 16)": 0.7364411950111389, "(22, 0)": 0.7364411950111389, "(22, 16)": 0.6609610319137573, "(24, 0)": 0.7364411950111389, "(24, 16)": 0.8174054622650146, "(26, 0)": 0.7999023199081421, "(26, 16)": 0.736282467842102, "(28, 0)": 0.7999023199081421, "(28, 16)": 0.7364411950111389, "(30, 0)": 0.7999023199081421, "(30, 16)": 0.7999023199081421}, "r_span": [1422, 1534], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017426013946533203}}, {"prompt_attention_score": {"(0, 0)": 0.766665518283844, "(0, 16)": 0.766665518283844, "(2, 0)": 0.766665518283844, "(2, 16)": 0.766665518283844, "(4, 0)": 0.766665518283844, "(4, 16)": 0.766665518283844, "(6, 0)": 0.766665518283844, "(6, 16)": 0.7121517062187195, "(8, 0)": 0.766665518283844, "(8, 16)": 0.7675994634628296, "(10, 0)": 0.7747868299484253, "(10, 16)": 0.766665518283844, "(12, 0)": 0.7675994634628296, "(12, 16)": 0.7747868299484253, "(14, 0)": 0.7675994634628296, "(14, 16)": 0.766665518283844, "(16, 0)": 0.7675994634628296, "(16, 16)": 0.766665518283844, "(18, 0)": 0.7675994634628296, "(18, 16)": 0.7675994634628296, "(20, 0)": 0.7675994634628296, "(20, 16)": 0.7675994634628296, "(22, 0)": 0.7675994634628296, "(22, 16)": 0.7675994634628296, "(24, 0)": 0.7675994634628296, "(24, 16)": 0.7675994634628296, "(26, 0)": 0.7036072015762329, "(26, 16)": 0.7675994634628296, "(28, 0)": 0.7036072015762329, "(28, 16)": 0.7675994634628296, "(30, 0)": 0.7036072015762329, "(30, 16)": 0.7036072015762329}, "r_span": [1532, 1644], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00034046173095703125}}, {"prompt_attention_score": {"(0, 0)": 0.6402357816696167, "(0, 16)": 0.6402357816696167, "(2, 0)": 0.6402357816696167, "(2, 16)": 0.5347251296043396, "(4, 0)": 0.6402357816696167, "(4, 16)": 0.5347251296043396, "(6, 0)": 0.6402357816696167, "(6, 16)": 0.5851413011550903, "(8, 0)": 0.6402357816696167, "(8, 16)": 0.5137310028076172, "(10, 0)": 0.6402357816696167, "(10, 16)": 0.6402357816696167, "(12, 0)": 0.5347251296043396, "(12, 16)": 0.6402357816696167, "(14, 0)": 0.5347251296043396, "(14, 16)": 0.6402357816696167, "(16, 0)": 0.6402357816696167, "(16, 16)": 0.5347251296043396, "(18, 0)": 0.5347251296043396, "(18, 16)": 0.6402357816696167, "(20, 0)": 0.6402357816696167, "(20, 16)": 0.5347251296043396, "(22, 0)": 0.5347251296043396, "(22, 16)": 0.6402357816696167, "(24, 0)": 0.5347251296043396, "(24, 16)": 0.6402357816696167, "(26, 0)": 0.5391534566879272, "(26, 16)": 0.5347251296043396, "(28, 0)": 0.5391534566879272, "(28, 16)": 0.5347251296043396, "(30, 0)": 0.5347251296043396, "(30, 16)": 0.5391534566879272}, "r_span": [1643, 1657], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001170039176940918}}]}, {"id": "1677", "source_id": "11383", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 106 words:\n\nUnicef delivered vital food and supplies to Yemen despite the ongoing conflict between Houthi rebels and Saudi-led coalition forces. The country's international airport is damaged and off-limits, so the aid organization had to rely on a desperate aid mission. Despite the danger, Unicef managed to unload huge amounts of emergency nutrition and medical equipment onto the tarmac. However, the situation remains dire, with over 100,000 Yemeni civilians displaced and 15.9 million people in need of assistance. The main terminal is under Houthi rebel control, making it difficult for aid workers to distribute supplies effectively.", "response_spans": [[0, 46], [48, 556], [537, 677]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5042811632156372, "(0, 16)": 0.5042811632156372, "(2, 0)": 0.5042811632156372, "(2, 16)": 0.5042811632156372, "(4, 0)": 0.5042811632156372, "(4, 16)": 0.5042811632156372, "(6, 0)": 0.5042811632156372, "(6, 16)": 0.8162092566490173, "(8, 0)": 0.5042811632156372, "(8, 16)": 0.5042811632156372, "(10, 0)": 0.8162092566490173, "(10, 16)": 0.5042811632156372, "(12, 0)": 0.6099863052368164, "(12, 16)": 0.8162092566490173, "(14, 0)": 0.5042811632156372, "(14, 16)": 0.8162092566490173, "(16, 0)": 0.8162092566490173, "(16, 16)": 0.49769753217697144, "(18, 0)": 0.6099863052368164, "(18, 16)": 0.8162092566490173, "(20, 0)": 0.8162092566490173, "(20, 16)": 0.5042811632156372, "(22, 0)": 0.49769753217697144, "(22, 16)": 0.49769753217697144, "(24, 0)": 0.5042811632156372, "(24, 16)": 0.49769753217697144, "(26, 0)": 0.49769753217697144, "(26, 16)": 0.49769753217697144, "(28, 0)": 0.6099863052368164, "(28, 16)": 0.5042811632156372, "(30, 0)": 0.49769753217697144, "(30, 16)": 0.49769753217697144}, "r_span": [681, 695], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007476806640625}}, {"prompt_attention_score": {"(0, 0)": 0.7625236511230469, "(0, 16)": 0.7625236511230469, "(2, 0)": 0.7625236511230469, "(2, 16)": 0.7625236511230469, "(4, 0)": 0.7625236511230469, "(4, 16)": 0.7625236511230469, "(6, 0)": 0.7625236511230469, "(6, 16)": 0.8183605670928955, "(8, 0)": 0.7625236511230469, "(8, 16)": 0.7625236511230469, "(10, 0)": 0.7625236511230469, "(10, 16)": 0.7625236511230469, "(12, 0)": 0.7625236511230469, "(12, 16)": 0.8183605670928955, "(14, 0)": 0.7625236511230469, "(14, 16)": 0.7565624117851257, "(16, 0)": 0.7565624117851257, "(16, 16)": 0.7625236511230469, "(18, 0)": 0.7625236511230469, "(18, 16)": 0.8183605670928955, "(20, 0)": 0.7389999628067017, "(20, 16)": 0.7625236511230469, "(22, 0)": 0.7625236511230469, "(22, 16)": 0.8183605670928955, "(24, 0)": 0.7625236511230469, "(24, 16)": 0.8183605670928955, "(26, 0)": 0.7565624117851257, "(26, 16)": 0.7565624117851257, "(28, 0)": 0.7565624117851257, "(28, 16)": 0.7625236511230469, "(30, 0)": 0.7565624117851257, "(30, 16)": 0.7565624117851257}, "r_span": [697, 824], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014731884002685547}}, {"prompt_attention_score": {"(0, 0)": 0.7176978588104248, "(0, 16)": 0.7176978588104248, "(2, 0)": 0.7176978588104248, "(2, 16)": 0.7176978588104248, "(4, 0)": 0.7176978588104248, "(4, 16)": 0.7176978588104248, "(6, 0)": 0.7176978588104248, "(6, 16)": 0.8366658091545105, "(8, 0)": 0.7176978588104248, "(8, 16)": 0.7176978588104248, "(10, 0)": 0.7176978588104248, "(10, 16)": 0.7176978588104248, "(12, 0)": 0.6629887223243713, "(12, 16)": 0.8366658091545105, "(14, 0)": 0.7176978588104248, "(14, 16)": 0.7176978588104248, "(16, 0)": 0.7176978588104248, "(16, 16)": 0.7176978588104248, "(18, 0)": 0.7176978588104248, "(18, 16)": 0.8366658091545105, "(20, 0)": 0.8366658091545105, "(20, 16)": 0.7176978588104248, "(22, 0)": 0.6629887223243713, "(22, 16)": 0.8366658091545105, "(24, 0)": 0.7176978588104248, "(24, 16)": 0.8366658091545105, "(26, 0)": 0.6629887223243713, "(26, 16)": 0.6629887223243713, "(28, 0)": 0.6629887223243713, "(28, 16)": 0.7176978588104248, "(30, 0)": 0.6629887223243713, "(30, 16)": 0.6629887223243713}, "r_span": [821, 848], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006746053695678711}}]}, {"id": "1683", "source_id": "11384", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 200 words:\n\nThe author reflects on their personal experience of sexual harassment on a local train in Mumbai when they were 13 years old and how it has impacted their life since then. They highlight a study that shows 80% of women in Mumbai have experienced street harassment, primarily in crowded areas like trains and railway platforms. The author notes that while most people consider sexual violence as rape, they also include other forms of harassment such as groping, stalking, and ogling, which are equally intimidating. They also acknowledge that many women choose to limit their activities or wear conservative clothing to avoid harassment. The author encourages women to speak up about their experiences and realizes that addressing sexual harassment requires a cultural shift. They cite recent cases of sexual harassment in India, such as the allegations against Rajendra Pachauri and Tarun Tejpal, and emphasize the importance of supporting women who come forward with their stories. The author argues that ignoring or accepting sexual harassment as part of daily life restricts women's full potential and hinders their ability to live full lives.", "response_spans": [[0, 46], [48, 549], [532, 1042], [1023, 1195]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5485450029373169, "(0, 16)": 0.5485450029373169, "(2, 0)": 0.5024439692497253, "(2, 16)": 0.5485450029373169, "(4, 0)": 0.5024439692497253, "(4, 16)": 0.5024439692497253, "(6, 0)": 0.5485450029373169, "(6, 16)": 0.8053804636001587, "(8, 0)": 0.5485450029373169, "(8, 16)": 0.5944266319274902, "(10, 0)": 0.8053804636001587, "(10, 16)": 0.5944266319274902, "(12, 0)": 0.5944266319274902, "(12, 16)": 0.8053804636001587, "(14, 0)": 0.5485450029373169, "(14, 16)": 0.5944266319274902, "(16, 0)": 0.5944266319274902, "(16, 16)": 0.5851659774780273, "(18, 0)": 0.5944266319274902, "(18, 16)": 0.8053804636001587, "(20, 0)": 0.8053804636001587, "(20, 16)": 0.6003957390785217, "(22, 0)": 0.5851659774780273, "(22, 16)": 0.5359381437301636, "(24, 0)": 0.6003957390785217, "(24, 16)": 0.5359381437301636, "(26, 0)": 0.5851659774780273, "(26, 16)": 0.5117296576499939, "(28, 0)": 0.5851659774780273, "(28, 16)": 0.5024439692497253, "(30, 0)": 0.5851659774780273, "(30, 16)": 0.5851659774780273}, "r_span": [1265, 1279], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002690553665161133}}, {"prompt_attention_score": {"(0, 0)": 0.636685848236084, "(0, 16)": 0.636685848236084, "(2, 0)": 0.636685848236084, "(2, 16)": 0.636685848236084, "(4, 0)": 0.636685848236084, "(4, 16)": 0.636685848236084, "(6, 0)": 0.636685848236084, "(6, 16)": 0.8547689318656921, "(8, 0)": 0.8045427799224854, "(8, 16)": 0.636685848236084, "(10, 0)": 0.8547689318656921, "(10, 16)": 0.636685848236084, "(12, 0)": 0.787675678730011, "(12, 16)": 0.8547689318656921, "(14, 0)": 0.8045427799224854, "(14, 16)": 0.8547689318656921, "(16, 0)": 0.8045427799224854, "(16, 16)": 0.8045427799224854, "(18, 0)": 0.636685848236084, "(18, 16)": 0.8547689318656921, "(20, 0)": 0.8547689318656921, "(20, 16)": 0.5212770700454712, "(22, 0)": 0.8045427799224854, "(22, 16)": 0.8547689318656921, "(24, 0)": 0.7188486456871033, "(24, 16)": 0.8547689318656921, "(26, 0)": 0.8045427799224854, "(26, 16)": 0.8547689318656921, "(28, 0)": 0.8045427799224854, "(28, 16)": 0.8045427799224854, "(30, 0)": 0.8045427799224854, "(30, 16)": 0.8045427799224854}, "r_span": [1281, 1395], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002784550189971924}}, {"prompt_attention_score": {"(0, 0)": 0.7328214049339294, "(0, 16)": 0.6602620482444763, "(2, 0)": 0.7328214049339294, "(2, 16)": 0.7328214049339294, "(4, 0)": 0.7328214049339294, "(4, 16)": 0.7328214049339294, "(6, 0)": 0.7328214049339294, "(6, 16)": 0.7310205101966858, "(8, 0)": 0.7328214049339294, "(8, 16)": 0.7328214049339294, "(10, 0)": 0.7814657092094421, "(10, 16)": 0.7328214049339294, "(12, 0)": 0.7328214049339294, "(12, 16)": 0.7379293441772461, "(14, 0)": 0.7066797614097595, "(14, 16)": 0.7328214049339294, "(16, 0)": 0.7310205101966858, "(16, 16)": 0.7066797614097595, "(18, 0)": 0.7814657092094421, "(18, 16)": 0.8324297666549683, "(20, 0)": 0.8324297666549683, "(20, 16)": 0.7814657092094421, "(22, 0)": 0.7066797614097595, "(22, 16)": 0.7310205101966858, "(24, 0)": 0.7814657092094421, "(24, 16)": 0.7310205101966858, "(26, 0)": 0.7066797614097595, "(26, 16)": 0.642784833908081, "(28, 0)": 0.7066797614097595, "(28, 16)": 0.7066797614097595, "(30, 0)": 0.7066797614097595, "(30, 16)": 0.7066797614097595}, "r_span": [1393, 1499], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0013900995254516602}}, {"prompt_attention_score": {"(0, 0)": 0.5570487380027771, "(0, 16)": 0.5570487380027771, "(2, 0)": 0.728138267993927, "(2, 16)": 0.5570487380027771, "(4, 0)": 0.728138267993927, "(4, 16)": 0.728138267993927, "(6, 0)": 0.728138267993927, "(6, 16)": 0.728138267993927, "(8, 0)": 0.728138267993927, "(8, 16)": 0.728138267993927, "(10, 0)": 0.728138267993927, "(10, 16)": 0.728138267993927, "(12, 0)": 0.728138267993927, "(12, 16)": 0.728138267993927, "(14, 0)": 0.6677147150039673, "(14, 16)": 0.728138267993927, "(16, 0)": 0.728138267993927, "(16, 16)": 0.6677147150039673, "(18, 0)": 0.7412844896316528, "(18, 16)": 0.728138267993927, "(20, 0)": 0.728138267993927, "(20, 16)": 0.48743441700935364, "(22, 0)": 0.6677147150039673, "(22, 16)": 0.728138267993927, "(24, 0)": 0.6916024684906006, "(24, 16)": 0.728138267993927, "(26, 0)": 0.6677147150039673, "(26, 16)": 0.7258074283599854, "(28, 0)": 0.6677147150039673, "(28, 16)": 0.6677147150039673, "(30, 0)": 0.6677147150039673, "(30, 16)": 0.6677147150039673}, "r_span": [1496, 1533], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00016945600509643555}}]}, {"id": "1701", "source_id": "11395", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Mountaineers have returned to Mount Everest this year after a deadly season last year when 16 Nepalis died in an avalanche while completing their morning prayers. This year, the route through the Khumbu Icefall has been changed to reduce risks, taking longer but expected to be safer. However, some climbing companies have decided to stop using the Nepal side due to increased danger, while others remain unsure. The local Nepalese committee that determines the path up Everest voted to return to the central route for safety reasons. Despite concerns, many Sherpas are still willing to risk their lives to reach the summit, as climbing is how they feed their families and send their children to school. Several mountaineers are also returning this year, including Jon Reiter, who survived last year's avalanche and is making his way to base camp again.", "response_spans": [[0, 508], [494, 853]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7531741857528687, "(0, 16)": 0.7531741857528687, "(2, 0)": 0.7531741857528687, "(2, 16)": 0.7531741857528687, "(4, 0)": 0.7531741857528687, "(4, 16)": 0.7531741857528687, "(6, 0)": 0.7531741857528687, "(6, 16)": 0.8423436880111694, "(8, 0)": 0.7595463991165161, "(8, 16)": 0.6696507334709167, "(10, 0)": 0.8097109794616699, "(10, 16)": 0.7595463991165161, "(12, 0)": 0.7595463991165161, "(12, 16)": 0.8423436880111694, "(14, 0)": 0.7595463991165161, "(14, 16)": 0.8423436880111694, "(16, 0)": 0.8423436880111694, "(16, 16)": 0.7531741857528687, "(18, 0)": 0.7531741857528687, "(18, 16)": 0.8213213682174683, "(20, 0)": 0.8423436880111694, "(20, 16)": 0.7595463991165161, "(22, 0)": 0.7595463991165161, "(22, 16)": 0.8423436880111694, "(24, 0)": 0.7595463991165161, "(24, 16)": 0.8423436880111694, "(26, 0)": 0.8423436880111694, "(26, 16)": 0.7901161313056946, "(28, 0)": 0.8423436880111694, "(28, 16)": 0.6696507334709167, "(30, 0)": 0.8423436880111694, "(30, 16)": 0.8423436880111694}, "r_span": [1322, 1435], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00215834379196167}}, {"prompt_attention_score": {"(0, 0)": 0.7942551374435425, "(0, 16)": 0.7942551374435425, "(2, 0)": 0.6627503633499146, "(2, 16)": 0.8263809680938721, "(4, 0)": 0.7942551374435425, "(4, 16)": 0.7942551374435425, "(6, 0)": 0.8263809680938721, "(6, 16)": 0.709592342376709, "(8, 0)": 0.7942551374435425, "(8, 16)": 0.6627503633499146, "(10, 0)": 0.7942551374435425, "(10, 16)": 0.8263809680938721, "(12, 0)": 0.8263809680938721, "(12, 16)": 0.8263809680938721, "(14, 0)": 0.8263809680938721, "(14, 16)": 0.709592342376709, "(16, 0)": 0.7942551374435425, "(16, 16)": 0.8263809680938721, "(18, 0)": 0.8263809680938721, "(18, 16)": 0.8263809680938721, "(20, 0)": 0.709592342376709, "(20, 16)": 0.6627503633499146, "(22, 0)": 0.8263809680938721, "(22, 16)": 0.7942551374435425, "(24, 0)": 0.8263809680938721, "(24, 16)": 0.8263809680938721, "(26, 0)": 0.7045921087265015, "(26, 16)": 0.8263809680938721, "(28, 0)": 0.7045921087265015, "(28, 16)": 0.6627503633499146, "(30, 0)": 0.8263809680938721, "(30, 16)": 0.7045921087265015}, "r_span": [1433, 1510], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00034606456756591797}}]}, {"id": "1731", "source_id": "11400", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "In recent years, there has been a trend towards \"National Get Tested Month,\" with influential figures such as Mark Cuban and Taylor Swift encouraging people to get tested for various medical conditions. However, some experts are warning that this trend could lead to a number of negative consequences, including unnecessary medical procedures and increased healthcare costs. With the rise of direct-to-consumer genetic testing, it has become possible for individuals to order their own lab tests without a doctor's order, leading to concerns about the accuracy and relevance of the results. Some have pointed to the example of South Korea, where thyroid cancer screenings have led to a 15-fold increase in diagnoses, raising questions about the potential harms of over-testing. While there have been advances in diagnostic testing, it is important to recognize that testing oneself does not necessarily lead to better health outcomes, and that education and regulation are needed to ensure that individuals are not misled by false or irrelevant test results.", "response_spans": [[0, 505], [486, 994], [980, 1058]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6610633134841919, "(0, 16)": 0.6610633134841919, "(2, 0)": 0.6610633134841919, "(2, 16)": 0.6610633134841919, "(4, 0)": 0.6610633134841919, "(4, 16)": 0.6610633134841919, "(6, 0)": 0.6610633134841919, "(6, 16)": 0.8125677704811096, "(8, 0)": 0.8125677704811096, "(8, 16)": 0.6610633134841919, "(10, 0)": 0.7045577764511108, "(10, 16)": 0.6520168781280518, "(12, 0)": 0.6610633134841919, "(12, 16)": 0.8125677704811096, "(14, 0)": 0.6610633134841919, "(14, 16)": 0.8125677704811096, "(16, 0)": 0.8125677704811096, "(16, 16)": 0.6610633134841919, "(18, 0)": 0.6610633134841919, "(18, 16)": 0.8125677704811096, "(20, 0)": 0.8125677704811096, "(20, 16)": 0.6610633134841919, "(22, 0)": 0.8125677704811096, "(22, 16)": 0.6203334331512451, "(24, 0)": 0.6610633134841919, "(24, 16)": 0.8125677704811096, "(26, 0)": 0.8125677704811096, "(26, 16)": 0.6520168781280518, "(28, 0)": 0.8125677704811096, "(28, 16)": 0.6610633134841919, "(30, 0)": 0.8125677704811096, "(30, 16)": 0.8125677704811096}, "r_span": [1220, 1319], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0027517080307006836}}, {"prompt_attention_score": {"(0, 0)": 0.706120491027832, "(0, 16)": 0.706120491027832, "(2, 0)": 0.706120491027832, "(2, 16)": 0.706120491027832, "(4, 0)": 0.706120491027832, "(4, 16)": 0.706120491027832, "(6, 0)": 0.706120491027832, "(6, 16)": 0.8149110078811646, "(8, 0)": 0.6866311430931091, "(8, 16)": 0.706120491027832, "(10, 0)": 0.6866311430931091, "(10, 16)": 0.706120491027832, "(12, 0)": 0.6866311430931091, "(12, 16)": 0.8149110078811646, "(14, 0)": 0.706120491027832, "(14, 16)": 0.8149110078811646, "(16, 0)": 0.6866311430931091, "(16, 16)": 0.706120491027832, "(18, 0)": 0.706120491027832, "(18, 16)": 0.706120491027832, "(20, 0)": 0.8149110078811646, "(20, 16)": 0.706120491027832, "(22, 0)": 0.6153892278671265, "(22, 16)": 0.8149110078811646, "(24, 0)": 0.706120491027832, "(24, 16)": 0.6866311430931091, "(26, 0)": 0.6153892278671265, "(26, 16)": 0.706120491027832, "(28, 0)": 0.6153892278671265, "(28, 16)": 0.706120491027832, "(30, 0)": 0.6153892278671265, "(30, 16)": 0.6153892278671265}, "r_span": [1316, 1420], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00021630525588989258}}, {"prompt_attention_score": {"(0, 0)": 0.6715972423553467, "(0, 16)": 0.6715972423553467, "(2, 0)": 0.5877801179885864, "(2, 16)": 0.5877801179885864, "(4, 0)": 0.6715972423553467, "(4, 16)": 0.6715972423553467, "(6, 0)": 0.5877801179885864, "(6, 16)": 0.6848114728927612, "(8, 0)": 0.6715972423553467, "(8, 16)": 0.5877801179885864, "(10, 0)": 0.5877801179885864, "(10, 16)": 0.6715972423553467, "(12, 0)": 0.5877801179885864, "(12, 16)": 0.6715972423553467, "(14, 0)": 0.5877801179885864, "(14, 16)": 0.6715972423553467, "(16, 0)": 0.6715972423553467, "(16, 16)": 0.6018900871276855, "(18, 0)": 0.6848114728927612, "(18, 16)": 0.6715972423553467, "(20, 0)": 0.6715972423553467, "(20, 16)": 0.6715972423553467, "(22, 0)": 0.6018900871276855, "(22, 16)": 0.6715972423553467, "(24, 0)": 0.6715972423553467, "(24, 16)": 0.6715972423553467, "(26, 0)": 0.6018900871276855, "(26, 16)": 0.6715972423553467, "(28, 0)": 0.6018900871276855, "(28, 16)": 0.6715972423553467, "(30, 0)": 0.6018900871276855, "(30, 16)": 0.6018900871276855}, "r_span": [1418, 1432], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00041806697845458984}}]}, {"id": "1749", "source_id": "11410", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 66 words:\n\nCanada's CF-18 Hornets have conducted their first airstrike against ISIS in Syria, hitting one of the extremist group's garrisons near Raqqa. The strike was successful, according to the Canadian Department of National Defence. This expansion of the airstrikes into Syria demonstrates Canada's determination to combat terrorism and promote regional security.", "response_spans": [[0, 404]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7811821699142456, "(0, 16)": 0.7811821699142456, "(2, 0)": 0.7811821699142456, "(2, 16)": 0.7811821699142456, "(4, 0)": 0.7811821699142456, "(4, 16)": 0.7811821699142456, "(6, 0)": 0.7811821699142456, "(6, 16)": 0.9279482960700989, "(8, 0)": 0.9279482960700989, "(8, 16)": 0.7811821699142456, "(10, 0)": 0.7763437032699585, "(10, 16)": 0.9279482960700989, "(12, 0)": 0.9279482960700989, "(12, 16)": 0.9279482960700989, "(14, 0)": 0.9279482960700989, "(14, 16)": 0.9279482960700989, "(16, 0)": 0.9279482960700989, "(16, 16)": 0.9279482960700989, "(18, 0)": 0.9279482960700989, "(18, 16)": 0.9279482960700989, "(20, 0)": 0.9279482960700989, "(20, 16)": 0.9279482960700989, "(22, 0)": 0.9279482960700989, "(22, 16)": 0.9279482960700989, "(24, 0)": 0.9279482960700989, "(24, 16)": 0.9279482960700989, "(26, 0)": 0.9279482960700989, "(26, 16)": 0.9279482960700989, "(28, 0)": 0.9279482960700989, "(28, 16)": 0.9279482960700989, "(30, 0)": 0.9279482960700989, "(30, 16)": 0.9279482960700989}, "r_span": [438, 537], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006297826766967773}}]}, {"id": "1827", "source_id": "11768", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 334, "end": 406, "text": "Both families kept their pregnancies a secret until the babies were born", "meta": "EVIDENT CONFLICT\nOriginal: \"The first set of female quintuplets... parents are blogging about their unique experience.\"\nGenerative: \"Both families kept their pregnancies a secret until the babies were born.\"\n(Only Sharon and Korey Rademacher decided to keep it a secret from family and friends.)", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 117, "end": 131, "text": "IVF treatment,", "meta": "SUBTLE CONFLICT\nOriginal: \"intrauterine insemination\"\nGenerative: \"IVF treatment\"\n\nDifferent procedure but same goal. Does not change any factual details.", "label_type": "Subtle Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here is a summary of the news in 77 words:\n\nThe Busby family welcomed five female quintuplets in Houston after IVF treatment, while the Rademacher family surprised everyone with the arrival of twin girls in Florida. The Busby girls are Ava, Hazel, Olivia, Parker, and Riley, while the Rademacher twins are Mary Ann and Brianna. Both families kept their pregnancies a secret until the babies were born.", "response_spans": [[0, 407]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7707329988479614, "(0, 16)": 0.7707329988479614, "(2, 0)": 0.7707329988479614, "(2, 16)": 0.7707329988479614, "(4, 0)": 0.7707329988479614, "(4, 16)": 0.7707329988479614, "(6, 0)": 0.7707329988479614, "(6, 16)": 0.8341387510299683, "(8, 0)": 0.7707329988479614, "(8, 16)": 0.7707329988479614, "(10, 0)": 0.7707329988479614, "(10, 16)": 0.7707329988479614, "(12, 0)": 0.7707329988479614, "(12, 16)": 0.8341387510299683, "(14, 0)": 0.7676649689674377, "(14, 16)": 0.8341387510299683, "(16, 0)": 0.8341387510299683, "(16, 16)": 0.8341387510299683, "(18, 0)": 0.8341387510299683, "(18, 16)": 0.8341387510299683, "(20, 0)": 0.8341387510299683, "(20, 16)": 0.7707329988479614, "(22, 0)": 0.8341387510299683, "(22, 16)": 0.8341387510299683, "(24, 0)": 0.8341387510299683, "(24, 16)": 0.8341387510299683, "(26, 0)": 0.8341387510299683, "(26, 16)": 0.8341387510299683, "(28, 0)": 0.8341387510299683, "(28, 16)": 0.8341387510299683, "(30, 0)": 0.8341387510299683, "(30, 16)": 0.8341387510299683}, "r_span": [501, 611], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.000726163387298584}}]}, {"id": "1893", "source_id": "11779", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "The US government has revised its policy regarding the no-fly list, providing affected individuals with more information about why they have been banned from commercial flights and allowing them to dispute their status. Under the new policy, those on the list will be notified of their status if they apply for redress, and will have the option to request additional information. The government will also provide a more detailed response to requests for information, identifying the specific criteria used to place them on the list. However, the American Civil Liberties Union (ACLU) is still challenging the policy, stating that it does not provide sufficient due process protections.", "response_spans": [[0, 508], [492, 685]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7936314344406128, "(0, 16)": 0.7936314344406128, "(2, 0)": 0.7936314344406128, "(2, 16)": 0.7936314344406128, "(4, 0)": 0.7936314344406128, "(4, 16)": 0.7936314344406128, "(6, 0)": 0.7936314344406128, "(6, 16)": 0.8429718017578125, "(8, 0)": 0.7936314344406128, "(8, 16)": 0.7936314344406128, "(10, 0)": 0.7587451934814453, "(10, 16)": 0.7587451934814453, "(12, 0)": 0.8083828687667847, "(12, 16)": 0.7936314344406128, "(14, 0)": 0.8083828687667847, "(14, 16)": 0.8429718017578125, "(16, 0)": 0.8429718017578125, "(16, 16)": 0.7936314344406128, "(18, 0)": 0.8429718017578125, "(18, 16)": 0.8429718017578125, "(20, 0)": 0.8429718017578125, "(20, 16)": 0.8083828687667847, "(22, 0)": 0.8429718017578125, "(22, 16)": 0.8429718017578125, "(24, 0)": 0.8083828687667847, "(24, 16)": 0.8429718017578125, "(26, 0)": 0.8429718017578125, "(26, 16)": 0.8429718017578125, "(28, 0)": 0.8429718017578125, "(28, 16)": 0.8429718017578125, "(30, 0)": 0.8429718017578125, "(30, 16)": 0.8429718017578125}, "r_span": [741, 835], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000507354736328125}}, {"prompt_attention_score": {"(0, 0)": 0.6244454383850098, "(0, 16)": 0.6244454383850098, "(2, 0)": 0.6244454383850098, "(2, 16)": 0.6244454383850098, "(4, 0)": 0.6244454383850098, "(4, 16)": 0.6244454383850098, "(6, 0)": 0.6244454383850098, "(6, 16)": 0.7290342450141907, "(8, 0)": 0.6244454383850098, "(8, 16)": 0.6244454383850098, "(10, 0)": 0.7290342450141907, "(10, 16)": 0.7290342450141907, "(12, 0)": 0.6244454383850098, "(12, 16)": 0.7290342450141907, "(14, 0)": 0.6874110102653503, "(14, 16)": 0.6874110102653503, "(16, 0)": 0.7290342450141907, "(16, 16)": 0.6874110102653503, "(18, 0)": 0.6874110102653503, "(18, 16)": 0.7199743986129761, "(20, 0)": 0.7199743986129761, "(20, 16)": 0.6874110102653503, "(22, 0)": 0.6874110102653503, "(22, 16)": 0.7199743986129761, "(24, 0)": 0.6106019020080566, "(24, 16)": 0.7199743986129761, "(26, 0)": 0.6874110102653503, "(26, 16)": 0.6874110102653503, "(28, 0)": 0.6874110102653503, "(28, 16)": 0.6874110102653503, "(30, 0)": 0.6874110102653503, "(30, 16)": 0.6874110102653503}, "r_span": [833, 873], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006554126739501953}}]}, {"id": "1965", "source_id": "11791", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 397, "end": 444, "text": ", was found dead in a field near Lindsey's home", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nIt was not mentioned in the source content that the cat was found dead in a fieldd near Lindsey's home.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "A Texas veterinarian, Dr. Kristen Lindsey, faces backlash after posting a photo of herself holding the lifeless body of a cat she killed with an arrow. The incident sparked outrage and calls for her to be charged with animal cruelty. Lindsey worked at the Washington Animal Clinic, which has since distanced itself from her actions and fired her. The cat, believed to be a pet of an elderly couple, was found dead in a field near Lindsey's home. An investigation is underway, and animal rights activists are pushing for charges.", "response_spans": [[0, 507], [494, 528]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7196371555328369, "(0, 16)": 0.7196371555328369, "(2, 0)": 0.7196371555328369, "(2, 16)": 0.7196371555328369, "(4, 0)": 0.7196371555328369, "(4, 16)": 0.7196371555328369, "(6, 0)": 0.7196371555328369, "(6, 16)": 0.7134277820587158, "(8, 0)": 0.7196371555328369, "(8, 16)": 0.7196371555328369, "(10, 0)": 0.7134277820587158, "(10, 16)": 0.7196371555328369, "(12, 0)": 0.7196371555328369, "(12, 16)": 0.8129676580429077, "(14, 0)": 0.7196371555328369, "(14, 16)": 0.8129676580429077, "(16, 0)": 0.8129676580429077, "(16, 16)": 0.7196371555328369, "(18, 0)": 0.7196371555328369, "(18, 16)": 0.8129676580429077, "(20, 0)": 0.8129676580429077, "(20, 16)": 0.7196371555328369, "(22, 0)": 0.7196371555328369, "(22, 16)": 0.8129676580429077, "(24, 0)": 0.7196371555328369, "(24, 16)": 0.8129676580429077, "(26, 0)": 0.8129676580429077, "(26, 16)": 0.8129676580429077, "(28, 0)": 0.8129676580429077, "(28, 16)": 0.7196371555328369, "(30, 0)": 0.8129676580429077, "(30, 16)": 0.8129676580429077}, "r_span": [785, 903], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005770325660705566}}, {"prompt_attention_score": {"(0, 0)": 0.5654283761978149, "(0, 16)": 0.5654283761978149, "(2, 0)": 0.5654283761978149, "(2, 16)": 0.5654283761978149, "(4, 0)": 0.5654283761978149, "(4, 16)": 0.5654283761978149, "(6, 0)": 0.5654283761978149, "(6, 16)": 0.7010284066200256, "(8, 0)": 0.5654283761978149, "(8, 16)": 0.5654283761978149, "(10, 0)": 0.5654283761978149, "(10, 16)": 0.5654283761978149, "(12, 0)": 0.5654283761978149, "(12, 16)": 0.7010284066200256, "(14, 0)": 0.5654283761978149, "(14, 16)": 0.5654283761978149, "(16, 0)": 0.5654283761978149, "(16, 16)": 0.5654283761978149, "(18, 0)": 0.5654283761978149, "(18, 16)": 0.7010284066200256, "(20, 0)": 0.7010284066200256, "(20, 16)": 0.5654283761978149, "(22, 0)": 0.5654283761978149, "(22, 16)": 0.7010284066200256, "(24, 0)": 0.5654283761978149, "(24, 16)": 0.7010284066200256, "(26, 0)": 0.42372560501098633, "(26, 16)": 0.5654283761978149, "(28, 0)": 0.42372560501098633, "(28, 16)": 0.5654283761978149, "(30, 0)": 0.42372560501098633, "(30, 16)": 0.42372560501098633}, "r_span": [901, 907], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003730654716491699}}]}, {"id": "1989", "source_id": "11795", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "A mother angry at her son's participation in the Baltimore riots can be seen in a viral video hitting him multiple times in the head and scolding him as he tries to walk away. The mother's identity was not revealed, but Police Commissioner Anthony Batts expressed gratitude towards her for taking charge of her child.", "response_spans": [[0, 317]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.799101710319519, "(0, 16)": 0.799101710319519, "(2, 0)": 0.814644455909729, "(2, 16)": 0.799101710319519, "(4, 0)": 0.814644455909729, "(4, 16)": 0.814644455909729, "(6, 0)": 0.799101710319519, "(6, 16)": 0.814644455909729, "(8, 0)": 0.799101710319519, "(8, 16)": 0.799101710319519, "(10, 0)": 0.799101710319519, "(10, 16)": 0.799101710319519, "(12, 0)": 0.799101710319519, "(12, 16)": 0.799101710319519, "(14, 0)": 0.799101710319519, "(14, 16)": 0.799101710319519, "(16, 0)": 0.799101710319519, "(16, 16)": 0.799101710319519, "(18, 0)": 0.799101710319519, "(18, 16)": 0.814644455909729, "(20, 0)": 0.814644455909729, "(20, 16)": 0.799101710319519, "(22, 0)": 0.799101710319519, "(22, 16)": 0.814644455909729, "(24, 0)": 0.799101710319519, "(24, 16)": 0.814644455909729, "(26, 0)": 0.799101710319519, "(26, 16)": 0.799101710319519, "(28, 0)": 0.799101710319519, "(28, 16)": 0.799101710319519, "(30, 0)": 0.799101710319519, "(30, 16)": 0.799101710319519}, "r_span": [300, 369], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0024466514587402344}}]}, {"id": "2067", "source_id": "11808", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 555, "end": 594, "text": "and the death toll is expected to rise.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No information about the death toll\nGenerative: \"... and the death toll is expected to rise.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 133, "end": 181, "text": "80 km northwest of the capital city of Kathmandu", "meta": "LOW INTRO OF NEW INFO\nOriginal: Upon checking, 80 km northwest is equivalent to 30 km east of Kathmandu, however, this is not explicitly stated in the source content.\nGenerative: \"...80 km northwest of the capital city of Kathmandu...\"", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "A powerful earthquake hit Nepal on Saturday, causing widespread destruction and loss of life. The epicenter of the quake was located 80 km northwest of the capital city of Kathmandu, and the affected areas include the Kavre district, which is about 30 km east of Kathmandu. The roads leading to the affected areas are in poor condition, making it difficult for rescue teams to reach the sites. The villagers are facing immense challenges, with 90% of the houses in one village being declared uninhabitable. Many people are still trapped under the rubble, and the death toll is expected to rise. The villagers are also facing a severe shortage of food, water, and medical supplies. The situation is particularly dire in remote areas that are difficult to reach, where aid has yet to arrive. The government and relief organizations are working to provide assistance to the affected areas, but the scale of the disaster is enormous, and the task ahead is daunting.", "response_spans": [[0, 511], [492, 961]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7061891555786133, "(0, 16)": 0.7061891555786133, "(2, 0)": 0.7061891555786133, "(2, 16)": 0.7061891555786133, "(4, 0)": 0.7061891555786133, "(4, 16)": 0.7061891555786133, "(6, 0)": 0.7061891555786133, "(6, 16)": 0.7399618625640869, "(8, 0)": 0.5744620561599731, "(8, 16)": 0.7061891555786133, "(10, 0)": 0.7033888697624207, "(10, 16)": 0.7033888697624207, "(12, 0)": 0.5744620561599731, "(12, 16)": 0.7399618625640869, "(14, 0)": 0.5744620561599731, "(14, 16)": 0.7838295102119446, "(16, 0)": 0.7838295102119446, "(16, 16)": 0.5744620561599731, "(18, 0)": 0.5744620561599731, "(18, 16)": 0.7838295102119446, "(20, 0)": 0.699142336845398, "(20, 16)": 0.5744620561599731, "(22, 0)": 0.5744620561599731, "(22, 16)": 0.7838295102119446, "(24, 0)": 0.5744620561599731, "(24, 16)": 0.7838295102119446, "(26, 0)": 0.7838295102119446, "(26, 16)": 0.7033888697624207, "(28, 0)": 0.7838295102119446, "(28, 16)": 0.5744620561599731, "(30, 0)": 0.7838295102119446, "(30, 16)": 0.7838295102119446}, "r_span": [1367, 1491], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0023044943809509277}}, {"prompt_attention_score": {"(0, 0)": 0.703215479850769, "(0, 16)": 0.703215479850769, "(2, 0)": 0.7408251762390137, "(2, 16)": 0.7408251762390137, "(4, 0)": 0.703215479850769, "(4, 16)": 0.703215479850769, "(6, 0)": 0.7340043783187866, "(6, 16)": 0.7554266452789307, "(8, 0)": 0.7340043783187866, "(8, 16)": 0.7340043783187866, "(10, 0)": 0.7408251762390137, "(10, 16)": 0.7340043783187866, "(12, 0)": 0.7340043783187866, "(12, 16)": 0.7408251762390137, "(14, 0)": 0.7340043783187866, "(14, 16)": 0.7408251762390137, "(16, 0)": 0.703215479850769, "(16, 16)": 0.7340043783187866, "(18, 0)": 0.7340043783187866, "(18, 16)": 0.7408251762390137, "(20, 0)": 0.703215479850769, "(20, 16)": 0.7340043783187866, "(22, 0)": 0.7340043783187866, "(22, 16)": 0.7340043783187866, "(24, 0)": 0.7340043783187866, "(24, 16)": 0.6980733871459961, "(26, 0)": 0.6412346363067627, "(26, 16)": 0.703215479850769, "(28, 0)": 0.6412346363067627, "(28, 16)": 0.6412346363067627, "(30, 0)": 0.7340043783187866, "(30, 16)": 0.6412346363067627}, "r_span": [1486, 1586], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0034087300300598145}}]}, {"id": "2121", "source_id": "11817", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 232, "end": 286, "text": "who also made a cameo appearance in their performance.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned* \nGenerative: \" who also made a cameo appearance in their performance.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 42 words:\n\nHawkeye from Marvel Comics surprised fans with his hidden talent for singing Ed Sheeran parodies on \"The Tonight Show.\" He showed off his vocal skills alongside host Jimmy Fallon, who also made a cameo appearance in their performance.", "response_spans": [[0, 286]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5867304801940918, "(0, 16)": 0.5867304801940918, "(2, 0)": 0.5867304801940918, "(2, 16)": 0.5867304801940918, "(4, 0)": 0.5867304801940918, "(4, 16)": 0.5867304801940918, "(6, 0)": 0.5867304801940918, "(6, 16)": 0.8461123704910278, "(8, 0)": 0.8461123704910278, "(8, 16)": 0.5867304801940918, "(10, 0)": 0.8461123704910278, "(10, 16)": 0.8461123704910278, "(12, 0)": 0.8461123704910278, "(12, 16)": 0.8461123704910278, "(14, 0)": 0.5867304801940918, "(14, 16)": 0.8461123704910278, "(16, 0)": 0.8461123704910278, "(16, 16)": 0.8461123704910278, "(18, 0)": 0.8461123704910278, "(18, 16)": 0.8461123704910278, "(20, 0)": 0.8461123704910278, "(20, 16)": 0.8461123704910278, "(22, 0)": 0.8461123704910278, "(22, 16)": 0.8461123704910278, "(24, 0)": 0.8461123704910278, "(24, 16)": 0.8461123704910278, "(26, 0)": 0.8461123704910278, "(26, 16)": 0.8461123704910278, "(28, 0)": 0.8461123704910278, "(28, 16)": 0.8461123704910278, "(30, 0)": 0.8461123704910278, "(30, 16)": 0.8461123704910278}, "r_span": [339, 410], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0009355545043945312}}]}, {"id": "2139", "source_id": "11821", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 53 words or less:\n\nOlivia Munn has been cast as Psylocke in \"X-Men: Apocalypse,\" joining James McAvoy, Michael Fassbender, and Jennifer Lawrence in the sequel. The character was created by Chris Claremont and Herb Trimpe and has appeared in various comic book series since the 1970s.", "response_spans": [[0, 319]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6706241965293884, "(0, 16)": 0.6706241965293884, "(2, 0)": 0.7335255146026611, "(2, 16)": 0.7335255146026611, "(4, 0)": 0.7335255146026611, "(4, 16)": 0.7335255146026611, "(6, 0)": 0.7335255146026611, "(6, 16)": 0.7861752510070801, "(8, 0)": 0.6706241965293884, "(8, 16)": 0.7335255146026611, "(10, 0)": 0.7335255146026611, "(10, 16)": 0.7335255146026611, "(12, 0)": 0.7861752510070801, "(12, 16)": 0.6706241965293884, "(14, 0)": 0.7861752510070801, "(14, 16)": 0.7861752510070801, "(16, 0)": 0.7861752510070801, "(16, 16)": 0.7861752510070801, "(18, 0)": 0.7861752510070801, "(18, 16)": 0.6706241965293884, "(20, 0)": 0.7861752510070801, "(20, 16)": 0.7861752510070801, "(22, 0)": 0.7861752510070801, "(22, 16)": 0.7861752510070801, "(24, 0)": 0.7861752510070801, "(24, 16)": 0.7861752510070801, "(26, 0)": 0.7861752510070801, "(26, 16)": 0.7861752510070801, "(28, 0)": 0.7861752510070801, "(28, 16)": 0.7861752510070801, "(30, 0)": 0.7861752510070801, "(30, 16)": 0.7861752510070801}, "r_span": [442, 537], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009163022041320801}}]}, {"id": "2169", "source_id": "11826", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 79 words:\n\nStephen Hawking teamed up with Monty Python to release a new version of the group's classic song \"Galaxy Song\" to celebrate Record Store Day. The song features Hawking's signature computerized voice and incorporates scientific facts about the universe. The collaboration marks Hawking's latest venture into music after appearing on the Pink Floyd track \"Talkin' Hawkin'\".", "response_spans": [[0, 418]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.49610233306884766, "(0, 16)": 0.7292816042900085, "(2, 0)": 0.7292816042900085, "(2, 16)": 0.49610233306884766, "(4, 0)": 0.7292816042900085, "(4, 16)": 0.7292816042900085, "(6, 0)": 0.7292816042900085, "(6, 16)": 0.8457685708999634, "(8, 0)": 0.49610233306884766, "(8, 16)": 0.7292816042900085, "(10, 0)": 0.8457685708999634, "(10, 16)": 0.7292816042900085, "(12, 0)": 0.7292816042900085, "(12, 16)": 0.7292816042900085, "(14, 0)": 0.7292816042900085, "(14, 16)": 0.7292816042900085, "(16, 0)": 0.8457685708999634, "(16, 16)": 0.8457685708999634, "(18, 0)": 0.7292816042900085, "(18, 16)": 0.8457685708999634, "(20, 0)": 0.8457685708999634, "(20, 16)": 0.7292816042900085, "(22, 0)": 0.8457685708999634, "(22, 16)": 0.8457685708999634, "(24, 0)": 0.7292816042900085, "(24, 16)": 0.8457685708999634, "(26, 0)": 0.8457685708999634, "(26, 16)": 0.8457685708999634, "(28, 0)": 0.8457685708999634, "(28, 16)": 0.7292816042900085, "(30, 0)": 0.8457685708999634, "(30, 16)": 0.8457685708999634}, "r_span": [534, 635], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00033211708068847656}}]}, {"id": "2241", "source_id": "11838", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On the 35th anniversary of the Miami riots, the author reflects on the similarities between past and recent events. In 1980, the acquittal of police officers involved in the beating death of Arthur McDuffie led to widespread protests and violence in Miami. Similar incidents, such as the death of Freddie Gray in police custody in Baltimore, have led to riots and protests in recent years. The author notes that while riots may seem senseless and destructive, they can also be a powerful tool for bringing about change. She highlights the importance of nonviolent civil disobedience and legislative channels in advancing the civil rights agenda. The author also emphasizes the need for government officials to take action to address the underlying issues that lead to riots, such as poverty, joblessness, and racial bias in the criminal justice system. By examining the root causes of these conflicts, the author suggests, we can work towards creating a more just and equitable society.", "response_spans": [[0, 511], [493, 986]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.603702962398529, "(0, 16)": 0.603702962398529, "(2, 0)": 0.603702962398529, "(2, 16)": 0.603702962398529, "(4, 0)": 0.603702962398529, "(4, 16)": 0.603702962398529, "(6, 0)": 0.603702962398529, "(6, 16)": 0.844086766242981, "(8, 0)": 0.603702962398529, "(8, 16)": 0.603702962398529, "(10, 0)": 0.603702962398529, "(10, 16)": 0.603702962398529, "(12, 0)": 0.603702962398529, "(12, 16)": 0.844086766242981, "(14, 0)": 0.603702962398529, "(14, 16)": 0.603702962398529, "(16, 0)": 0.603702962398529, "(16, 16)": 0.603702962398529, "(18, 0)": 0.603702962398529, "(18, 16)": 0.844086766242981, "(20, 0)": 0.844086766242981, "(20, 16)": 0.603702962398529, "(22, 0)": 0.603702962398529, "(22, 16)": 0.603702962398529, "(24, 0)": 0.603702962398529, "(24, 16)": 0.7600135803222656, "(26, 0)": 0.603702962398529, "(26, 16)": 0.603702962398529, "(28, 0)": 0.603702962398529, "(28, 16)": 0.603702962398529, "(30, 0)": 0.603702962398529, "(30, 16)": 0.603702962398529}, "r_span": [1461, 1584], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.005572676658630371}}, {"prompt_attention_score": {"(0, 0)": 0.6640978455543518, "(0, 16)": 0.644651472568512, "(2, 0)": 0.6640978455543518, "(2, 16)": 0.6640978455543518, "(4, 0)": 0.6640978455543518, "(4, 16)": 0.6640978455543518, "(6, 0)": 0.6640978455543518, "(6, 16)": 0.7027135491371155, "(8, 0)": 0.6640978455543518, "(8, 16)": 0.6640978455543518, "(10, 0)": 0.644651472568512, "(10, 16)": 0.6640978455543518, "(12, 0)": 0.6640978455543518, "(12, 16)": 0.6572421193122864, "(14, 0)": 0.6640978455543518, "(14, 16)": 0.6640978455543518, "(16, 0)": 0.6640978455543518, "(16, 16)": 0.6640978455543518, "(18, 0)": 0.6640978455543518, "(18, 16)": 0.7484055757522583, "(20, 0)": 0.7202330827713013, "(20, 16)": 0.644651472568512, "(22, 0)": 0.6640978455543518, "(22, 16)": 0.7264031767845154, "(24, 0)": 0.6640978455543518, "(24, 16)": 0.7202330827713013, "(26, 0)": 0.644651472568512, "(26, 16)": 0.6640978455543518, "(28, 0)": 0.644651472568512, "(28, 16)": 0.644651472568512, "(30, 0)": 0.6640978455543518, "(30, 16)": 0.6640978455543518}, "r_span": [1582, 1684], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008481144905090332}}]}, {"id": "2247", "source_id": "11839", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 169, "end": 203, "text": "Four alleged attackers were killed", "meta": "EVIDENT CONFLICT\nAIGC: Four alleged attackers were killed\nOriginal: Three of the alleged attackers were killed,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the news in 38 words:\n\nIsraeli jets struck targets in the occupied Golan Heights after militants attempted to plant a bomb near the Israeli border. Four alleged attackers were killed, but their affiliation remains unclear.", "response_spans": [[0, 243]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7644894123077393, "(0, 16)": 0.7644894123077393, "(2, 0)": 0.7644894123077393, "(2, 16)": 0.7644894123077393, "(4, 0)": 0.7644894123077393, "(4, 16)": 0.7644894123077393, "(6, 0)": 0.7644894123077393, "(6, 16)": 0.8139687776565552, "(8, 0)": 0.7644894123077393, "(8, 16)": 0.7644894123077393, "(10, 0)": 0.7644894123077393, "(10, 16)": 0.7644894123077393, "(12, 0)": 0.7644894123077393, "(12, 16)": 0.8139687776565552, "(14, 0)": 0.7644894123077393, "(14, 16)": 0.7644894123077393, "(16, 0)": 0.8139687776565552, "(16, 16)": 0.7644894123077393, "(18, 0)": 0.7644894123077393, "(18, 16)": 0.8139687776565552, "(20, 0)": 0.8139687776565552, "(20, 16)": 0.7644894123077393, "(22, 0)": 0.7644894123077393, "(22, 16)": 0.8139687776565552, "(24, 0)": 0.7644894123077393, "(24, 16)": 0.8139687776565552, "(26, 0)": 0.7644894123077393, "(26, 16)": 0.8139687776565552, "(28, 0)": 0.7644894123077393, "(28, 16)": 0.7644894123077393, "(30, 0)": 0.7644894123077393, "(30, 16)": 0.7644894123077393}, "r_span": [280, 338], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0021589994430541992}}]}, {"id": "2253", "source_id": "11840", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 0, "end": 104, "text": "Cheryl, a Singapore high school student, has created a math problem that has gone viral on the internet.", "meta": "EVIDENT CONFLICT\nAIGC: Cheryl, a Singapore high school student, has created a math problem..\nOriginal: ‚ÄúCheryl's birthday‚Äù is the Singapore logic problem, not a literal highschool girl.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Cheryl, a Singapore high school student, has created a math problem that has gone viral on the internet. The problem involves finding her birthday by given a list of 10 possible dates. After eliminating nine of the dates through a conversation between two friends, the remaining date reveals Cheryl's birthday.", "response_spans": [[0, 310]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7797532081604004, "(0, 16)": 0.7797532081604004, "(2, 0)": 0.7975535988807678, "(2, 16)": 0.7975535988807678, "(4, 0)": 0.7797532081604004, "(4, 16)": 0.7975535988807678, "(6, 0)": 0.7975535988807678, "(6, 16)": 0.802458643913269, "(8, 0)": 0.7797532081604004, "(8, 16)": 0.7975535988807678, "(10, 0)": 0.7975535988807678, "(10, 16)": 0.7975535988807678, "(12, 0)": 0.7975535988807678, "(12, 16)": 0.7797532081604004, "(14, 0)": 0.7975535988807678, "(14, 16)": 0.7975535988807678, "(16, 0)": 0.802458643913269, "(16, 16)": 0.802458643913269, "(18, 0)": 0.802458643913269, "(18, 16)": 0.802458643913269, "(20, 0)": 0.7797532081604004, "(20, 16)": 0.7975535988807678, "(22, 0)": 0.802458643913269, "(22, 16)": 0.802458643913269, "(24, 0)": 0.802458643913269, "(24, 16)": 0.802458643913269, "(26, 0)": 0.802458643913269, "(26, 16)": 0.802458643913269, "(28, 0)": 0.802458643913269, "(28, 16)": 0.802458643913269, "(30, 0)": 0.802458643913269, "(30, 16)": 0.802458643913269}, "r_span": [387, 456], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00014221668243408203}}]}, {"id": "2361", "source_id": "11858", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 698, "end": 744, "text": "HIV infections in the US has increased by 150%", "meta": "EVIDENT CONFLICT\nAIGC: HIV infections in the US has increased by 150%\nOriginal: there has been a 150% increase in hepatitis C", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "There has been a severe outbreak of HIV infections in rural Indiana, with 142 people testing positive for the virus, including 136 confirmed cases and six more with preliminary positive test results. The outbreak is linked to the use of Opana, a prescription opioid, and has spread rapidly among users in Scott and Jackson counties. The Centers for Disease Control and Prevention (CDC) and state health leaders are working to contain the outbreak, including by providing education and access to testing and treatment. The state has declared a public health emergency in the affected area and has sent health volunteers to provide care and testing. The CDC has also announced that the number of new HIV infections in the US has increased by 150% between 2010 and 2013, primarily due to injection drug use. The outbreak in Indiana serves as a warning to remaining vigilant against the spread of HIV and other infectious diseases.", "response_spans": [[0, 506], [492, 927]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6919932961463928, "(0, 16)": 0.6919932961463928, "(2, 0)": 0.6919932961463928, "(2, 16)": 0.6919932961463928, "(4, 0)": 0.6919932961463928, "(4, 16)": 0.8057575225830078, "(6, 0)": 0.6919932961463928, "(6, 16)": 0.9619739055633545, "(8, 0)": 0.7357760667800903, "(8, 16)": 0.6919932961463928, "(10, 0)": 0.6812969446182251, "(10, 16)": 0.8057575225830078, "(12, 0)": 0.7212637662887573, "(12, 16)": 0.9619739055633545, "(14, 0)": 0.7212637662887573, "(14, 16)": 0.9619739055633545, "(16, 0)": 0.9619739055633545, "(16, 16)": 0.6919932961463928, "(18, 0)": 0.9619739055633545, "(18, 16)": 0.9619739055633545, "(20, 0)": 0.9619739055633545, "(20, 16)": 0.7212637662887573, "(22, 0)": 0.7212637662887573, "(22, 16)": 0.9619739055633545, "(24, 0)": 0.7212637662887573, "(24, 16)": 0.9619739055633545, "(26, 0)": 0.9619739055633545, "(26, 16)": 0.9619739055633545, "(28, 0)": 0.9619739055633545, "(28, 16)": 0.7212637662887573, "(30, 0)": 0.9619739055633545, "(30, 16)": 0.9619739055633545}, "r_span": [1055, 1170], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000755012035369873}}, {"prompt_attention_score": {"(0, 0)": 0.7349615693092346, "(0, 16)": 0.7349615693092346, "(2, 0)": 0.8553918600082397, "(2, 16)": 0.8553918600082397, "(4, 0)": 0.8553918600082397, "(4, 16)": 0.8553918600082397, "(6, 0)": 0.7349615693092346, "(6, 16)": 0.8834462761878967, "(8, 0)": 0.6341143846511841, "(8, 16)": 0.6341143846511841, "(10, 0)": 0.8553918600082397, "(10, 16)": 0.8553918600082397, "(12, 0)": 0.8553918600082397, "(12, 16)": 0.8553918600082397, "(14, 0)": 0.6341143846511841, "(14, 16)": 0.7349615693092346, "(16, 0)": 0.8553918600082397, "(16, 16)": 0.8315794467926025, "(18, 0)": 0.6341143846511841, "(18, 16)": 0.8553918600082397, "(20, 0)": 0.8834462761878967, "(20, 16)": 0.6341143846511841, "(22, 0)": 0.6341143846511841, "(22, 16)": 0.8834462761878967, "(24, 0)": 0.6341143846511841, "(24, 16)": 0.7011013031005859, "(26, 0)": 0.8315794467926025, "(26, 16)": 0.6341143846511841, "(28, 0)": 0.8315794467926025, "(28, 16)": 0.8315794467926025, "(30, 0)": 0.8315794467926025, "(30, 16)": 0.8315794467926025}, "r_span": [1168, 1272], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -5.650520324707031e-05}}]}, {"id": "2373", "source_id": "11860", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Longtime friend Leslie Morris has filed a legal petition to become Joni Mitchell's conservator after the singer was found unconscious in her home and hospitalized. While Morris' petition states Mitchell remains unconscious, her website claims she is alert and expected to make a full recovery. A doctor's declaration indicates Mitchell may be unable to attend court hearings for the next four to six months. Fans have created a tribute website to show support for the folk and jazz singer.", "response_spans": [[0, 489]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6939056515693665, "(0, 16)": 0.6939056515693665, "(2, 0)": 0.6939056515693665, "(2, 16)": 0.6939056515693665, "(4, 0)": 0.6939056515693665, "(4, 16)": 0.7213096022605896, "(6, 0)": 0.6939056515693665, "(6, 16)": 0.9104641079902649, "(8, 0)": 0.6939056515693665, "(8, 16)": 0.6939056515693665, "(10, 0)": 0.6939056515693665, "(10, 16)": 0.6939056515693665, "(12, 0)": 0.9104641079902649, "(12, 16)": 0.9104641079902649, "(14, 0)": 0.9104641079902649, "(14, 16)": 0.9104641079902649, "(16, 0)": 0.9104641079902649, "(16, 16)": 0.9104641079902649, "(18, 0)": 0.9104641079902649, "(18, 16)": 0.9104641079902649, "(20, 0)": 0.9104641079902649, "(20, 16)": 0.9104641079902649, "(22, 0)": 0.9104641079902649, "(22, 16)": 0.9104641079902649, "(24, 0)": 0.9104641079902649, "(24, 16)": 0.9104641079902649, "(26, 0)": 0.9104641079902649, "(26, 16)": 0.9104641079902649, "(28, 0)": 0.9104641079902649, "(28, 16)": 0.9104641079902649, "(30, 0)": 0.9104641079902649, "(30, 16)": 0.9104641079902649}, "r_span": [464, 568], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00326460599899292}}]}, {"id": "2427", "source_id": "11870", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Hillary Clinton's presidential campaign is facing scrutiny over conflicts of interest regarding donations to charities run by the Clinton family. A new book, \"Clinton Cash: The Untold Story of How and Why Foreign Governments and Businesses Helped Make Bill and Hillary Rich,\" by Peter Schweizer, raises questions about whether donations from foreign governments and companies influenced decisions made by Hillary Clinton when she was Secretary of State. The book also highlights the Clintons' charities' poor management and lack of transparency. While some have criticized the book as a distraction, Hillary Clinton seems unconcerned, suggesting that voters will focus on more pressing issues such as the economy and jobs.", "response_spans": [[0, 508], [493, 722]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6254395842552185, "(0, 16)": 0.6254395842552185, "(2, 0)": 0.6254395842552185, "(2, 16)": 0.6254395842552185, "(4, 0)": 0.6254395842552185, "(4, 16)": 0.6254395842552185, "(6, 0)": 0.6254395842552185, "(6, 16)": 0.8928176760673523, "(8, 0)": 0.6254395842552185, "(8, 16)": 0.6254395842552185, "(10, 0)": 0.6254395842552185, "(10, 16)": 0.6254395842552185, "(12, 0)": 0.6254395842552185, "(12, 16)": 0.8928176760673523, "(14, 0)": 0.6254395842552185, "(14, 16)": 0.8928176760673523, "(16, 0)": 0.8928176760673523, "(16, 16)": 0.6254395842552185, "(18, 0)": 0.6254395842552185, "(18, 16)": 0.8928176760673523, "(20, 0)": 0.8928176760673523, "(20, 16)": 0.7454760670661926, "(22, 0)": 0.7166962027549744, "(22, 16)": 0.8928176760673523, "(24, 0)": 0.7454760670661926, "(24, 16)": 0.8928176760673523, "(26, 0)": 0.7166962027549744, "(26, 16)": 0.7454760670661926, "(28, 0)": 0.7166962027549744, "(28, 16)": 0.7166962027549744, "(30, 0)": 0.7166962027549744, "(30, 16)": 0.7166962027549744}, "r_span": [1208, 1321], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009050965309143066}}, {"prompt_attention_score": {"(0, 0)": 0.7367436289787292, "(0, 16)": 0.7367436289787292, "(2, 0)": 0.7367436289787292, "(2, 16)": 0.7367436289787292, "(4, 0)": 0.7367436289787292, "(4, 16)": 0.7367436289787292, "(6, 0)": 0.7367436289787292, "(6, 16)": 0.6408586502075195, "(8, 0)": 0.7367436289787292, "(8, 16)": 0.7367436289787292, "(10, 0)": 0.7367436289787292, "(10, 16)": 0.7367436289787292, "(12, 0)": 0.7727888822555542, "(12, 16)": 0.7367436289787292, "(14, 0)": 0.7727888822555542, "(14, 16)": 0.7367436289787292, "(16, 0)": 0.7367436289787292, "(16, 16)": 0.7727888822555542, "(18, 0)": 0.7367436289787292, "(18, 16)": 0.7367436289787292, "(20, 0)": 0.7367436289787292, "(20, 16)": 0.7727888822555542, "(22, 0)": 0.6981950998306274, "(22, 16)": 0.7367436289787292, "(24, 0)": 0.7727888822555542, "(24, 16)": 0.7367436289787292, "(26, 0)": 0.6981950998306274, "(26, 16)": 0.7367436289787292, "(28, 0)": 0.6981950998306274, "(28, 16)": 0.6981950998306274, "(30, 0)": 0.6981950998306274, "(30, 16)": 0.6981950998306274}, "r_span": [1318, 1369], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.003399491310119629}}]}, {"id": "2445", "source_id": "11873", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Michelle Keegan named sexiest woman in the world by FHM, beating Kendall Jenner, Jennifer Lawrence, Kate Upton, and Caroline Flack.", "response_spans": [[0, 131]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7370109558105469, "(0, 16)": 0.7504608035087585, "(2, 0)": 0.7370109558105469, "(2, 16)": 0.7504608035087585, "(4, 0)": 0.7504608035087585, "(4, 16)": 0.7504608035087585, "(6, 0)": 0.7370109558105469, "(6, 16)": 0.7504608035087585, "(8, 0)": 0.7370109558105469, "(8, 16)": 0.7504608035087585, "(10, 0)": 0.7370109558105469, "(10, 16)": 0.7370109558105469, "(12, 0)": 0.7504608035087585, "(12, 16)": 0.7504608035087585, "(14, 0)": 0.7504608035087585, "(14, 16)": 0.7504608035087585, "(16, 0)": 0.7504608035087585, "(16, 16)": 0.7504608035087585, "(18, 0)": 0.7504608035087585, "(18, 16)": 0.7504608035087585, "(20, 0)": 0.7504608035087585, "(20, 16)": 0.7504608035087585, "(22, 0)": 0.7504608035087585, "(22, 16)": 0.7504608035087585, "(24, 0)": 0.7504608035087585, "(24, 16)": 0.7504608035087585, "(26, 0)": 0.7504608035087585, "(26, 16)": 0.7504608035087585, "(28, 0)": 0.7504608035087585, "(28, 16)": 0.7504608035087585, "(30, 0)": 0.7504608035087585, "(30, 16)": 0.7504608035087585}, "r_span": [271, 310], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 8.875131607055664e-05}}]}, {"id": "2457", "source_id": "11875", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 118 words:\n\nAndrew Lesnie, an Oscar-winning cinematographer who worked with director Peter Jackson on several films including the Lord of the Rings and Hobbit trilogies, has died at the age of 59. Leslie was known for his ability to balance technology and artistic considerations and worked on numerous other films including Rise of the Planet of the Apes and The Water Diviner. His death has been confirmed by the Australian Cinematographers Society, and he will be remembered for his contributions to the film industry.", "response_spans": [[0, 46], [48, 557]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5368217825889587, "(0, 16)": 0.5368217825889587, "(2, 0)": 0.4267271161079407, "(2, 16)": 0.5368217825889587, "(4, 0)": 0.4267271161079407, "(4, 16)": 0.5368217825889587, "(6, 0)": 0.5368217825889587, "(6, 16)": 0.8290968537330627, "(8, 0)": 0.5368217825889587, "(8, 16)": 0.5368217825889587, "(10, 0)": 0.8290968537330627, "(10, 16)": 0.5368217825889587, "(12, 0)": 0.5849413871765137, "(12, 16)": 0.8290968537330627, "(14, 0)": 0.5368217825889587, "(14, 16)": 0.8290968537330627, "(16, 0)": 0.5849413871765137, "(16, 16)": 0.4492197334766388, "(18, 0)": 0.5849413871765137, "(18, 16)": 0.8290968537330627, "(20, 0)": 0.8290968537330627, "(20, 16)": 0.5368217825889587, "(22, 0)": 0.4492197334766388, "(22, 16)": 0.4492197334766388, "(24, 0)": 0.5368217825889587, "(24, 16)": 0.4492197334766388, "(26, 0)": 0.5368217825889587, "(26, 16)": 0.4492197334766388, "(28, 0)": 0.4492197334766388, "(28, 16)": 0.5368217825889587, "(30, 0)": 0.4492197334766388, "(30, 16)": 0.4492197334766388}, "r_span": [821, 835], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004583597183227539}}, {"prompt_attention_score": {"(0, 0)": 0.5643943548202515, "(0, 16)": 0.5643943548202515, "(2, 0)": 0.5643943548202515, "(2, 16)": 0.5643943548202515, "(4, 0)": 0.5643943548202515, "(4, 16)": 0.5643943548202515, "(6, 0)": 0.5643943548202515, "(6, 16)": 0.8937371969223022, "(8, 0)": 0.5643943548202515, "(8, 16)": 0.5643943548202515, "(10, 0)": 0.5643943548202515, "(10, 16)": 0.5643943548202515, "(12, 0)": 0.8937371969223022, "(12, 16)": 0.8937371969223022, "(14, 0)": 0.5643943548202515, "(14, 16)": 0.8937371969223022, "(16, 0)": 0.8937371969223022, "(16, 16)": 0.5643943548202515, "(18, 0)": 0.5643943548202515, "(18, 16)": 0.6879094243049622, "(20, 0)": 0.8937371969223022, "(20, 16)": 0.5643943548202515, "(22, 0)": 0.5643943548202515, "(22, 16)": 0.8937371969223022, "(24, 0)": 0.5643943548202515, "(24, 16)": 0.8937371969223022, "(26, 0)": 0.8937371969223022, "(26, 16)": 0.8937371969223022, "(28, 0)": 0.8937371969223022, "(28, 16)": 0.5643943548202515, "(30, 0)": 0.8937371969223022, "(30, 16)": 0.8937371969223022}, "r_span": [837, 947], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001781463623046875}}]}, {"id": "2469", "source_id": "11877", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 175 words:\n\nGoogle's popular app Waze allows users to locate police officers in real-time, raising concerns about the safety of law enforcement officials. Despite being the top cause of felonious deaths for police officers, Google has refused to address these concerns with organizations representing law enforcement. The \"traffic cop\" feature on Waze allows users to identify the location of police officers and indicate whether they are visible or invisible. This poses an enormous risk to police officers and deputies who are trying to keep communities safe. The app also has other concerning uses, such as helping drunk drivers evade checkpoints and giving speeders assistance in evading speed limits. Google's refusal to address these concerns with law enforcement organizations raises questions about their commitment to the \"common good\" and their responsibility as a corporate neighbor.", "response_spans": [[0, 46], [48, 556], [544, 930]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6004912853240967, "(0, 16)": 0.6004912853240967, "(2, 0)": 0.5196906924247742, "(2, 16)": 0.6004912853240967, "(4, 0)": 0.5196906924247742, "(4, 16)": 0.6004912853240967, "(6, 0)": 0.6004912853240967, "(6, 16)": 0.8209180235862732, "(8, 0)": 0.6004912853240967, "(8, 16)": 0.6004912853240967, "(10, 0)": 0.8209180235862732, "(10, 16)": 0.5844536423683167, "(12, 0)": 0.5844536423683167, "(12, 16)": 0.8209180235862732, "(14, 0)": 0.5196906924247742, "(14, 16)": 0.5844536423683167, "(16, 0)": 0.5844536423683167, "(16, 16)": 0.6004912853240967, "(18, 0)": 0.5844536423683167, "(18, 16)": 0.8209180235862732, "(20, 0)": 0.8209180235862732, "(20, 16)": 0.5196906924247742, "(22, 0)": 0.5196906924247742, "(22, 16)": 0.5383597612380981, "(24, 0)": 0.5196906924247742, "(24, 16)": 0.5383597612380981, "(26, 0)": 0.6004912853240967, "(26, 16)": 0.5383597612380981, "(28, 0)": 0.5383597612380981, "(28, 16)": 0.5196906924247742, "(30, 0)": 0.5383597612380981, "(30, 16)": 0.5383597612380981}, "r_span": [1060, 1074], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007726550102233887}}, {"prompt_attention_score": {"(0, 0)": 0.7256823182106018, "(0, 16)": 0.7256823182106018, "(2, 0)": 0.7256823182106018, "(2, 16)": 0.7256823182106018, "(4, 0)": 0.7256823182106018, "(4, 16)": 0.7256823182106018, "(6, 0)": 0.7256823182106018, "(6, 16)": 0.8541642427444458, "(8, 0)": 0.7256823182106018, "(8, 16)": 0.7256823182106018, "(10, 0)": 0.7256823182106018, "(10, 16)": 0.7488428354263306, "(12, 0)": 0.7256823182106018, "(12, 16)": 0.8541642427444458, "(14, 0)": 0.7390034794807434, "(14, 16)": 0.8541642427444458, "(16, 0)": 0.8541642427444458, "(16, 16)": 0.7390034794807434, "(18, 0)": 0.7256823182106018, "(18, 16)": 0.8541642427444458, "(20, 0)": 0.8541642427444458, "(20, 16)": 0.7390034794807434, "(22, 0)": 0.7390034794807434, "(22, 16)": 0.8541642427444458, "(24, 0)": 0.7390034794807434, "(24, 16)": 0.8541642427444458, "(26, 0)": 0.8541642427444458, "(26, 16)": 0.7390034794807434, "(28, 0)": 0.8541642427444458, "(28, 16)": 0.7390034794807434, "(30, 0)": 0.8541642427444458, "(30, 16)": 0.8541642427444458}, "r_span": [1076, 1175], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0018789172172546387}}, {"prompt_attention_score": {"(0, 0)": 0.8187798261642456, "(0, 16)": 0.8187798261642456, "(2, 0)": 0.8187798261642456, "(2, 16)": 0.8187798261642456, "(4, 0)": 0.8187798261642456, "(4, 16)": 0.8187798261642456, "(6, 0)": 0.8187798261642456, "(6, 16)": 0.8091557025909424, "(8, 0)": 0.7149940133094788, "(8, 16)": 0.8187798261642456, "(10, 0)": 0.8187798261642456, "(10, 16)": 0.8187798261642456, "(12, 0)": 0.8187798261642456, "(12, 16)": 0.8091557025909424, "(14, 0)": 0.7149940133094788, "(14, 16)": 0.8187798261642456, "(16, 0)": 0.8187798261642456, "(16, 16)": 0.8187798261642456, "(18, 0)": 0.8187798261642456, "(18, 16)": 0.7149940133094788, "(20, 0)": 0.8187798261642456, "(20, 16)": 0.7149940133094788, "(22, 0)": 0.7149940133094788, "(22, 16)": 0.8187798261642456, "(24, 0)": 0.7149940133094788, "(24, 16)": 0.7149940133094788, "(26, 0)": 0.7425926327705383, "(26, 16)": 0.7149940133094788, "(28, 0)": 0.7425926327705383, "(28, 16)": 0.7149940133094788, "(30, 0)": 0.7425926327705383, "(30, 16)": 0.7425926327705383}, "r_span": [1173, 1250], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0019794702529907227}}]}, {"id": "2487", "source_id": "11880", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Four rainbows appeared in the sky over New York after heavy rain, causing wonder and awe on social media. The rare sight has been dubbed a \"quadruple rainbow\" and has received millions of views on YouTube. While the meaning of the phenomenon is unknown, it has left many speechless and emotional.", "response_spans": [[0, 296]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7526404857635498, "(0, 16)": 0.7526404857635498, "(2, 0)": 0.7526404857635498, "(2, 16)": 0.7526404857635498, "(4, 0)": 0.7526404857635498, "(4, 16)": 0.7526404857635498, "(6, 0)": 0.7526404857635498, "(6, 16)": 0.7816261053085327, "(8, 0)": 0.7982132434844971, "(8, 16)": 0.7982132434844971, "(10, 0)": 0.7526404857635498, "(10, 16)": 0.7526404857635498, "(12, 0)": 0.7526404857635498, "(12, 16)": 0.7526404857635498, "(14, 0)": 0.7526404857635498, "(14, 16)": 0.7526404857635498, "(16, 0)": 0.7816261053085327, "(16, 16)": 0.7982132434844971, "(18, 0)": 0.7526404857635498, "(18, 16)": 0.7982132434844971, "(20, 0)": 0.7982132434844971, "(20, 16)": 0.7982132434844971, "(22, 0)": 0.7982132434844971, "(22, 16)": 0.7982132434844971, "(24, 0)": 0.7982132434844971, "(24, 16)": 0.7982132434844971, "(26, 0)": 0.7982132434844971, "(26, 16)": 0.7982132434844971, "(28, 0)": 0.7982132434844971, "(28, 16)": 0.7982132434844971, "(30, 0)": 0.7982132434844971, "(30, 16)": 0.7982132434844971}, "r_span": [420, 489], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007159113883972168}}]}, {"id": "2535", "source_id": "11888", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Photographer Simon Brann Thorpe explores the desensitization of war imagery by using toy soldiers in a real-life desert setting. He journeyed to Western Sahara, where a 40-year conflict continues, to depict actual soldiers against the harsh desert backdrop. Thorpe's project encourages viewers to confront the reality of war and its consequences. With limited media coverage, his work aims to raise questions about how conflicts will be consumed in the future with decreasing attention spans and increased visual saturation. Pre-orders are now available for his book, \"Toy Soldiers,\" through Dewi Lewis Publishing.", "response_spans": [[0, 512], [496, 614]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7769389748573303, "(0, 16)": 0.7769389748573303, "(2, 0)": 0.7769389748573303, "(2, 16)": 0.7769389748573303, "(4, 0)": 0.7769389748573303, "(4, 16)": 0.7769389748573303, "(6, 0)": 0.7769389748573303, "(6, 16)": 0.9103323221206665, "(8, 0)": 0.7769389748573303, "(8, 16)": 0.7769389748573303, "(10, 0)": 0.7769389748573303, "(10, 16)": 0.7769389748573303, "(12, 0)": 0.7769389748573303, "(12, 16)": 0.7425623536109924, "(14, 0)": 0.7769389748573303, "(14, 16)": 0.7769389748573303, "(16, 0)": 0.9103323221206665, "(16, 16)": 0.7769389748573303, "(18, 0)": 0.7769389748573303, "(18, 16)": 0.9103323221206665, "(20, 0)": 0.7464169263839722, "(20, 16)": 0.7769389748573303, "(22, 0)": 0.7769389748573303, "(22, 16)": 0.7464169263839722, "(24, 0)": 0.7769389748573303, "(24, 16)": 0.9103323221206665, "(26, 0)": 0.9103323221206665, "(26, 16)": 0.9103323221206665, "(28, 0)": 0.9103323221206665, "(28, 16)": 0.7769389748573303, "(30, 0)": 0.9103323221206665, "(30, 16)": 0.9103323221206665}, "r_span": [729, 843], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00017917156219482422}}, {"prompt_attention_score": {"(0, 0)": 0.699270486831665, "(0, 16)": 0.699270486831665, "(2, 0)": 0.699270486831665, "(2, 16)": 0.699270486831665, "(4, 0)": 0.699270486831665, "(4, 16)": 0.699270486831665, "(6, 0)": 0.699270486831665, "(6, 16)": 0.674083948135376, "(8, 0)": 0.699270486831665, "(8, 16)": 0.699270486831665, "(10, 0)": 0.699270486831665, "(10, 16)": 0.699270486831665, "(12, 0)": 0.699270486831665, "(12, 16)": 0.699270486831665, "(14, 0)": 0.699270486831665, "(14, 16)": 0.699270486831665, "(16, 0)": 0.699270486831665, "(16, 16)": 0.699270486831665, "(18, 0)": 0.699270486831665, "(18, 16)": 0.699270486831665, "(20, 0)": 0.699270486831665, "(20, 16)": 0.699270486831665, "(22, 0)": 0.699270486831665, "(22, 16)": 0.699270486831665, "(24, 0)": 0.699270486831665, "(24, 16)": 0.699270486831665, "(26, 0)": 0.674083948135376, "(26, 16)": 0.699270486831665, "(28, 0)": 0.674083948135376, "(28, 16)": 0.699270486831665, "(30, 0)": 0.674083948135376, "(30, 16)": 0.674083948135376}, "r_span": [842, 870], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00021904706954956055}}]}, {"id": "2607", "source_id": "11900", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 75 words or less:\n\nA gunman entered a building on the campus of Wayne Community College in Goldsboro, NC and shot and killed the print shop operator, Ron Lane. The suspect, Kenneth Morgan Stancil III, is still at large and considered armed and dangerous. Authorities have cleared all buildings but are searching for the suspect. The college president praised the rapid response of first responders and offered support to the victim's family.", "response_spans": [[0, 477]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5909345149993896, "(0, 16)": 0.5909345149993896, "(2, 0)": 0.7215165495872498, "(2, 16)": 0.5909345149993896, "(4, 0)": 0.7215165495872498, "(4, 16)": 0.7215165495872498, "(6, 0)": 0.7215165495872498, "(6, 16)": 0.9156244397163391, "(8, 0)": 0.7215165495872498, "(8, 16)": 0.7215165495872498, "(10, 0)": 0.7215165495872498, "(10, 16)": 0.7215165495872498, "(12, 0)": 0.9156244397163391, "(12, 16)": 0.9156244397163391, "(14, 0)": 0.7215165495872498, "(14, 16)": 0.9156244397163391, "(16, 0)": 0.9156244397163391, "(16, 16)": 0.9156244397163391, "(18, 0)": 0.9156244397163391, "(18, 16)": 0.9156244397163391, "(20, 0)": 0.9156244397163391, "(20, 16)": 0.7215165495872498, "(22, 0)": 0.9156244397163391, "(22, 16)": 0.9156244397163391, "(24, 0)": 0.7215165495872498, "(24, 16)": 0.9156244397163391, "(26, 0)": 0.9156244397163391, "(26, 16)": 0.9156244397163391, "(28, 0)": 0.9156244397163391, "(28, 16)": 0.7215165495872498, "(30, 0)": 0.9156244397163391, "(30, 16)": 0.9156244397163391}, "r_span": [482, 586], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016353726387023926}}]}, {"id": "2655", "source_id": "11908", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 368, "end": 441, "text": "with proceeds going towards various social and environmental initiatives.", "meta": "EVIDENT CONFLICT\nOriginal: It only mentions that both of the companies are supporters of social and environmental initiatives, not that the profit of the beer inspired ice cream will go to the initiatives. \nGenerative: Suggests that the \"proceeds\" or \"profit\" going towards various social and environmental initiatives.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 77 words:\n\nNew Belgium Brewery and Ben & Jerry's are collaborating on a beer inspired by the ice cream maker's salted caramel brownie flavor. The two socially conscious companies, who share a commitment to sustainability, will announce the details of their campaign later this year. The beer is set to hit shelves in the fall, with proceeds going towards various social and environmental initiatives.", "response_spans": [[0, 441]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7759753465652466, "(0, 16)": 0.7759753465652466, "(2, 0)": 0.7759753465652466, "(2, 16)": 0.7759753465652466, "(4, 0)": 0.7759753465652466, "(4, 16)": 0.7759753465652466, "(6, 0)": 0.7759753465652466, "(6, 16)": 0.8416398167610168, "(8, 0)": 0.8272750377655029, "(8, 16)": 0.7759753465652466, "(10, 0)": 0.7759753465652466, "(10, 16)": 0.7759753465652466, "(12, 0)": 0.8272750377655029, "(12, 16)": 0.8161550760269165, "(14, 0)": 0.8272750377655029, "(14, 16)": 0.7759753465652466, "(16, 0)": 0.8416398167610168, "(16, 16)": 0.8416398167610168, "(18, 0)": 0.8416398167610168, "(18, 16)": 0.8272750377655029, "(20, 0)": 0.8161550760269165, "(20, 16)": 0.8272750377655029, "(22, 0)": 0.8416398167610168, "(22, 16)": 0.8416398167610168, "(24, 0)": 0.8416398167610168, "(24, 16)": 0.8272750377655029, "(26, 0)": 0.8416398167610168, "(26, 16)": 0.8416398167610168, "(28, 0)": 0.8416398167610168, "(28, 16)": 0.8416398167610168, "(30, 0)": 0.8416398167610168, "(30, 16)": 0.8416398167610168}, "r_span": [518, 631], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005304813385009766}}]}, {"id": "2667", "source_id": "11910", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 275, "end": 325, "text": "went on to win their first championship since 1941", "meta": "SUBTLE CONFLICT\nOriginal: It will be looking to win its first title since 1941\nGenerated: went on to win their first championship since 1941", "label_type": "Subtle Conflict", "implicit_true": false, "due_to_null": false}, {"start": 863, "end": 888, "text": "18 points and 10 rebounds", "meta": "EVIDENT CONFLICT\nOriginal: 18 points, 10 of which came in the first half\nGenerated: 18 points and 10 rebounds", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "The Wisconsin Badgers upset the top-ranked Kentucky Wildcats in the NCAA men's basketball Final Four with a 71-64 victory on Saturday night. The Badgers, led by national player of the year finalist Frank Kaminsky, overcame a 60-56 deficit with 6:39 remaining in the game and went on to win their first championship since 1941. Kentucky came into the game as the first men's team to have a 38-0 record, but the Badgers fought back from a 60-56 deficit with an 8-0 run. The Harrison twins, who shot well in the first half, struggled offensively in the second half, and the Badgers' rebounding advantage proved to be the difference in the game. Duke dominated the second half against Michigan State, leading by as many as 20 points en route to an 81-61 victory. Freshman Justise Winslow led Duke with 19 points, while national freshman of the year Jahlil Okafor had 18 points and 10 rebounds. Duke will face Wisconsin in Monday night's title game, seeking its fifth NCAA championship.", "response_spans": [[0, 508], [492, 981]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7094660997390747, "(0, 16)": 0.7094660997390747, "(2, 0)": 0.7094660997390747, "(2, 16)": 0.7094660997390747, "(4, 0)": 0.7094660997390747, "(4, 16)": 0.7094660997390747, "(6, 0)": 0.7094660997390747, "(6, 16)": 0.8140914440155029, "(8, 0)": 0.7094660997390747, "(8, 16)": 0.7094660997390747, "(10, 0)": 0.7094660997390747, "(10, 16)": 0.7094660997390747, "(12, 0)": 0.7094660997390747, "(12, 16)": 0.8140914440155029, "(14, 0)": 0.6541455984115601, "(14, 16)": 0.8781644701957703, "(16, 0)": 0.8781644701957703, "(16, 16)": 0.7094660997390747, "(18, 0)": 0.6541455984115601, "(18, 16)": 0.8781644701957703, "(20, 0)": 0.8140914440155029, "(20, 16)": 0.6541455984115601, "(22, 0)": 0.8781644701957703, "(22, 16)": 0.8140914440155029, "(24, 0)": 0.6541455984115601, "(24, 16)": 0.8140914440155029, "(26, 0)": 0.8781644701957703, "(26, 16)": 0.7094660997390747, "(28, 0)": 0.8781644701957703, "(28, 16)": 0.7094660997390747, "(30, 0)": 0.6541455984115601, "(30, 16)": 0.8781644701957703}, "r_span": [1340, 1490], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00292813777923584}}, {"prompt_attention_score": {"(0, 0)": 0.7479687929153442, "(0, 16)": 0.7479687929153442, "(2, 0)": 0.7479687929153442, "(2, 16)": 0.7479687929153442, "(4, 0)": 0.7479687929153442, "(4, 16)": 0.7479687929153442, "(6, 0)": 0.7479687929153442, "(6, 16)": 0.8542946577072144, "(8, 0)": 0.7479687929153442, "(8, 16)": 0.7694312334060669, "(10, 0)": 0.7479687929153442, "(10, 16)": 0.7479687929153442, "(12, 0)": 0.7694312334060669, "(12, 16)": 0.8542946577072144, "(14, 0)": 0.7694312334060669, "(14, 16)": 0.7479687929153442, "(16, 0)": 0.7479687929153442, "(16, 16)": 0.78829425573349, "(18, 0)": 0.7694312334060669, "(18, 16)": 0.8542946577072144, "(20, 0)": 0.8542946577072144, "(20, 16)": 0.7787971496582031, "(22, 0)": 0.78829425573349, "(22, 16)": 0.5924221277236938, "(24, 0)": 0.7787971496582031, "(24, 16)": 0.7351002097129822, "(26, 0)": 0.78829425573349, "(26, 16)": 0.7479687929153442, "(28, 0)": 0.78829425573349, "(28, 16)": 0.7694312334060669, "(30, 0)": 0.78829425573349, "(30, 16)": 0.78829425573349}, "r_span": [1487, 1611], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015593171119689941}}]}, {"id": "2673", "source_id": "11911", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Saudi Arabia has resumed airstrikes against Houthi rebels in Yemen after a brief pause, despite calls for peace talks. The U.N.-sponsored talks are set to resume, but only after a complete halt of attacks. Houthi rebels have been accused of attacking a Yemeni government military brigade, prompting the resumption of airstrikes. The Saudi-led coalition has achieved its objectives in the initial phase of the campaign, including degrading Houthi-controlled military infrastructure and securing key buildings in Sanaa. However, ground troops will continue to patrol the border and take action against any attempts to destabilize the situation. The ultimate goal of the campaign is to establish a political process and bring back security and stability to Yemen.", "response_spans": [[0, 510], [494, 760]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6615073680877686, "(0, 16)": 0.6615073680877686, "(2, 0)": 0.6615073680877686, "(2, 16)": 0.6615073680877686, "(4, 0)": 0.6615073680877686, "(4, 16)": 0.6615073680877686, "(6, 0)": 0.6670746207237244, "(6, 16)": 0.7997078895568848, "(8, 0)": 0.7517309188842773, "(8, 16)": 0.6615073680877686, "(10, 0)": 0.6615073680877686, "(10, 16)": 0.6615073680877686, "(12, 0)": 0.6615073680877686, "(12, 16)": 0.8386767506599426, "(14, 0)": 0.6615073680877686, "(14, 16)": 0.7997078895568848, "(16, 0)": 0.7997078895568848, "(16, 16)": 0.6615073680877686, "(18, 0)": 0.6615073680877686, "(18, 16)": 0.7997078895568848, "(20, 0)": 0.7997078895568848, "(20, 16)": 0.6615073680877686, "(22, 0)": 0.6615073680877686, "(22, 16)": 0.7997078895568848, "(24, 0)": 0.6615073680877686, "(24, 16)": 0.8386767506599426, "(26, 0)": 0.6615073680877686, "(26, 16)": 0.6615073680877686, "(28, 0)": 0.7997078895568848, "(28, 16)": 0.6615073680877686, "(30, 0)": 0.6615073680877686, "(30, 16)": 0.7997078895568848}, "r_span": [1237, 1365], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 7.557868957519531e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6240273714065552, "(0, 16)": 0.6166433691978455, "(2, 0)": 0.6240273714065552, "(2, 16)": 0.6240273714065552, "(4, 0)": 0.6240273714065552, "(4, 16)": 0.6240273714065552, "(6, 0)": 0.6166433691978455, "(6, 16)": 0.7264817953109741, "(8, 0)": 0.6240273714065552, "(8, 16)": 0.6240273714065552, "(10, 0)": 0.6659302711486816, "(10, 16)": 0.6659302711486816, "(12, 0)": 0.6240273714065552, "(12, 16)": 0.7264817953109741, "(14, 0)": 0.6240273714065552, "(14, 16)": 0.7264817953109741, "(16, 0)": 0.7264817953109741, "(16, 16)": 0.6240273714065552, "(18, 0)": 0.6240273714065552, "(18, 16)": 0.7264817953109741, "(20, 0)": 0.7264817953109741, "(20, 16)": 0.6240273714065552, "(22, 0)": 0.6240273714065552, "(22, 16)": 0.7264817953109741, "(24, 0)": 0.6240273714065552, "(24, 16)": 0.7264817953109741, "(26, 0)": 0.6115176677703857, "(26, 16)": 0.6240273714065552, "(28, 0)": 0.6115176677703857, "(28, 16)": 0.6240273714065552, "(30, 0)": 0.6240273714065552, "(30, 16)": 0.6115176677703857}, "r_span": [1363, 1416], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0012996196746826172}}]}, {"id": "2739", "source_id": "11922", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 783, "end": 822, "text": "but the fall of Ramadi appears imminent", "meta": "EVIDENT CONFLICT\nOriginal: \"fall of Ramadi is \"not imminent.\"\nGenerative: \"but the fall of Ramadi appears imminent\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 192 words:\n\nRamadi, a key city in Iraq's Anbar province, is under pressure from Islamic State (ISIS) militants, who are making gains despite US-led airstrikes. According to Falih Essawi, the deputy head of the Anbar Provincial Council, ISIS has advanced in three areas east of Ramadi and is rolling into the city's center. The city has seen intense fighting for months, and at least 10 Iraqi security forces have been killed and over 100 wounded in recent days. Thousands of residents have fled their homes, causing traffic jams on the roads leading outside the city. ISIS has taken control of parts of Ramadi in the past, and the latest offensive has raised concerns about the city's fate. The US military has carried out airstrikes in the area, but the fall of Ramadi appears imminent.", "response_spans": [[0, 46], [48, 559], [544, 823]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.48455536365509033, "(0, 16)": 0.48455536365509033, "(2, 0)": 0.48455536365509033, "(2, 16)": 0.48455536365509033, "(4, 0)": 0.48455536365509033, "(4, 16)": 0.48455536365509033, "(6, 0)": 0.48455536365509033, "(6, 16)": 0.790277361869812, "(8, 0)": 0.48799943923950195, "(8, 16)": 0.5770416259765625, "(10, 0)": 0.790277361869812, "(10, 16)": 0.5770416259765625, "(12, 0)": 0.5770416259765625, "(12, 16)": 0.790277361869812, "(14, 0)": 0.48455536365509033, "(14, 16)": 0.5770416259765625, "(16, 0)": 0.5770416259765625, "(16, 16)": 0.48455536365509033, "(18, 0)": 0.5770416259765625, "(18, 16)": 0.790277361869812, "(20, 0)": 0.790277361869812, "(20, 16)": 0.48455536365509033, "(22, 0)": 0.48455536365509033, "(22, 16)": 0.48799943923950195, "(24, 0)": 0.48455536365509033, "(24, 16)": 0.48799943923950195, "(26, 0)": 0.48455536365509033, "(26, 16)": 0.48455536365509033, "(28, 0)": 0.48799943923950195, "(28, 16)": 0.48455536365509033, "(30, 0)": 0.48455536365509033, "(30, 16)": 0.48799943923950195}, "r_span": [1182, 1196], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00026863813400268555}}, {"prompt_attention_score": {"(0, 0)": 0.7706977725028992, "(0, 16)": 0.7706977725028992, "(2, 0)": 0.7706977725028992, "(2, 16)": 0.7706977725028992, "(4, 0)": 0.7706977725028992, "(4, 16)": 0.7706977725028992, "(6, 0)": 0.7706977725028992, "(6, 16)": 0.8622701168060303, "(8, 0)": 0.7706977725028992, "(8, 16)": 0.7706977725028992, "(10, 0)": 0.7706977725028992, "(10, 16)": 0.7706977725028992, "(12, 0)": 0.7706977725028992, "(12, 16)": 0.8423389196395874, "(14, 0)": 0.7706977725028992, "(14, 16)": 0.8622701168060303, "(16, 0)": 0.8622701168060303, "(16, 16)": 0.7706977725028992, "(18, 0)": 0.7706977725028992, "(18, 16)": 0.8622701168060303, "(20, 0)": 0.8622701168060303, "(20, 16)": 0.7706977725028992, "(22, 0)": 0.7706977725028992, "(22, 16)": 0.774379551410675, "(24, 0)": 0.7706977725028992, "(24, 16)": 0.8622701168060303, "(26, 0)": 0.8622701168060303, "(26, 16)": 0.8423389196395874, "(28, 0)": 0.8622701168060303, "(28, 16)": 0.7706977725028992, "(30, 0)": 0.7706977725028992, "(30, 16)": 0.8622701168060303}, "r_span": [1198, 1330], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014240741729736328}}, {"prompt_attention_score": {"(0, 0)": 0.7378079295158386, "(0, 16)": 0.7378079295158386, "(2, 0)": 0.7378079295158386, "(2, 16)": 0.8083784580230713, "(4, 0)": 0.7378079295158386, "(4, 16)": 0.7378079295158386, "(6, 0)": 0.7378079295158386, "(6, 16)": 0.7222691178321838, "(8, 0)": 0.7378079295158386, "(8, 16)": 0.7378079295158386, "(10, 0)": 0.7378079295158386, "(10, 16)": 0.7378079295158386, "(12, 0)": 0.7378079295158386, "(12, 16)": 0.7378079295158386, "(14, 0)": 0.7378079295158386, "(14, 16)": 0.7378079295158386, "(16, 0)": 0.7378079295158386, "(16, 16)": 0.7378079295158386, "(18, 0)": 0.7378079295158386, "(18, 16)": 0.8083784580230713, "(20, 0)": 0.8083784580230713, "(20, 16)": 0.7378079295158386, "(22, 0)": 0.7378079295158386, "(22, 16)": 0.8083784580230713, "(24, 0)": 0.7378079295158386, "(24, 16)": 0.8268147706985474, "(26, 0)": 0.7378079295158386, "(26, 16)": 0.7378079295158386, "(28, 0)": 0.7438944578170776, "(28, 16)": 0.7378079295158386, "(30, 0)": 0.7378079295158386, "(30, 16)": 0.7438944578170776}, "r_span": [1329, 1394], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010859966278076172}}]}, {"id": "2799", "source_id": "11932", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "On Tuesday, April 14th, Hillary Clinton announced her presidential campaign and made a bold statement about the gender pay gap. She stated that if elected, she will take a 23% pay cut, equivalent to the current gender wage gap, to show solidarity with working women in America. Clinton also pledged to work towards ensuring that 100% of the population is paid 100% of what they are worth. This announcement comes on Equal Pay Day, which is calculated based on the fact that women would have to work until April 14th, 2015 to earn the same amount of money as men earned in 2014. According to the article, closing the gender wage gap would pull half of working single moms out of poverty and put money in the pockets of working people who would actually stimulate economic growth. Some argue that Clinton's gesture is a political stunt, but others see it as a powerful symbol of her commitment to addressing the issue.", "response_spans": [[0, 510], [491, 916]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6540862321853638, "(0, 16)": 0.6540862321853638, "(2, 0)": 0.6540862321853638, "(2, 16)": 0.6540862321853638, "(4, 0)": 0.6540862321853638, "(4, 16)": 0.6540862321853638, "(6, 0)": 0.6540862321853638, "(6, 16)": 0.9040005207061768, "(8, 0)": 0.5856953859329224, "(8, 16)": 0.6540862321853638, "(10, 0)": 0.9040005207061768, "(10, 16)": 0.6540862321853638, "(12, 0)": 0.6540862321853638, "(12, 16)": 0.9040005207061768, "(14, 0)": 0.6540862321853638, "(14, 16)": 0.9040005207061768, "(16, 0)": 0.9040005207061768, "(16, 16)": 0.6540862321853638, "(18, 0)": 0.5856953859329224, "(18, 16)": 0.9040005207061768, "(20, 0)": 0.9040005207061768, "(20, 16)": 0.6540862321853638, "(22, 0)": 0.9040005207061768, "(22, 16)": 0.7778903245925903, "(24, 0)": 0.7181229591369629, "(24, 16)": 0.9040005207061768, "(26, 0)": 0.9040005207061768, "(26, 16)": 0.7181229591369629, "(28, 0)": 0.9040005207061768, "(28, 16)": 0.9040005207061768, "(30, 0)": 0.9040005207061768, "(30, 16)": 0.9040005207061768}, "r_span": [1443, 1569], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0020333528518676758}}, {"prompt_attention_score": {"(0, 0)": 0.6042038202285767, "(0, 16)": 0.6042038202285767, "(2, 0)": 0.6042038202285767, "(2, 16)": 0.6948487758636475, "(4, 0)": 0.6042038202285767, "(4, 16)": 0.6042038202285767, "(6, 0)": 0.6948487758636475, "(6, 16)": 0.8389132022857666, "(8, 0)": 0.6042038202285767, "(8, 16)": 0.6948487758636475, "(10, 0)": 0.6275467872619629, "(10, 16)": 0.6042038202285767, "(12, 0)": 0.6948487758636475, "(12, 16)": 0.7750880122184753, "(14, 0)": 0.6948487758636475, "(14, 16)": 0.8389132022857666, "(16, 0)": 0.7616798281669617, "(16, 16)": 0.6948487758636475, "(18, 0)": 0.5855305790901184, "(18, 16)": 0.7750880122184753, "(20, 0)": 0.7750880122184753, "(20, 16)": 0.6042038202285767, "(22, 0)": 0.7616798281669617, "(22, 16)": 0.8389132022857666, "(24, 0)": 0.6042038202285767, "(24, 16)": 0.7750880122184753, "(26, 0)": 0.7616798281669617, "(26, 16)": 0.7616798281669617, "(28, 0)": 0.7616798281669617, "(28, 16)": 0.7616798281669617, "(30, 0)": 0.6948487758636475, "(30, 16)": 0.7616798281669617}, "r_span": [1566, 1670], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004366636276245117}}]}, {"id": "2877", "source_id": "11945", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "The latest news highlights the heinous treatment of women by extremist groups like ISIS and Boko Haram. These groups view women as more than just spoils of war, but as crucial components in their quest to build a \"caliphate\" based on their twisted interpretation of Islamic law. ISIS has been kidnapping and selling Yazidi girls as slaves, while Boko Haram has kidnapped thousands of women and girls in Nigeria, forcing them to convert to Islam and marrying them off to fighters. The treatment of these women is not just physical violence, but also psychological torture, with many attempting suicide due to the oppressive conditions. Both groups see women as essential to their goal of creating a functional society, despite the fact that their actions are clear war crimes and crimes against humanity. The horrors inflicted upon these women are not just random acts of barbarism, but part of a calculated strategy to establish a new order based on gender inequality and religious fanaticism.", "response_spans": [[0, 511], [494, 993]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7451479434967041, "(0, 16)": 0.7451479434967041, "(2, 0)": 0.7451479434967041, "(2, 16)": 0.7451479434967041, "(4, 0)": 0.7451479434967041, "(4, 16)": 0.7451479434967041, "(6, 0)": 0.7451479434967041, "(6, 16)": 0.7045982480049133, "(8, 0)": 0.7451479434967041, "(8, 16)": 0.7451479434967041, "(10, 0)": 0.7929654717445374, "(10, 16)": 0.7837486267089844, "(12, 0)": 0.7451479434967041, "(12, 16)": 0.7506824731826782, "(14, 0)": 0.7451479434967041, "(14, 16)": 0.7451479434967041, "(16, 0)": 0.7929654717445374, "(16, 16)": 0.7451479434967041, "(18, 0)": 0.7451479434967041, "(18, 16)": 0.7045982480049133, "(20, 0)": 0.7045982480049133, "(20, 16)": 0.7451479434967041, "(22, 0)": 0.7451479434967041, "(22, 16)": 0.7393187284469604, "(24, 0)": 0.7451479434967041, "(24, 16)": 0.7218017578125, "(26, 0)": 0.7929654717445374, "(26, 16)": 0.7451479434967041, "(28, 0)": 0.7929654717445374, "(28, 16)": 0.7451479434967041, "(30, 0)": 0.7451479434967041, "(30, 16)": 0.7929654717445374}, "r_span": [1248, 1371], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007788538932800293}}, {"prompt_attention_score": {"(0, 0)": 0.7785712480545044, "(0, 16)": 0.7785712480545044, "(2, 0)": 0.7785712480545044, "(2, 16)": 0.7785712480545044, "(4, 0)": 0.7785712480545044, "(4, 16)": 0.7785712480545044, "(6, 0)": 0.7785712480545044, "(6, 16)": 0.7383941411972046, "(8, 0)": 0.7785712480545044, "(8, 16)": 0.7785712480545044, "(10, 0)": 0.7785712480545044, "(10, 16)": 0.7785712480545044, "(12, 0)": 0.7785712480545044, "(12, 16)": 0.7154459953308105, "(14, 0)": 0.7785712480545044, "(14, 16)": 0.7785712480545044, "(16, 0)": 0.7785712480545044, "(16, 16)": 0.7785712480545044, "(18, 0)": 0.7785712480545044, "(18, 16)": 0.7785712480545044, "(20, 0)": 0.7648601531982422, "(20, 16)": 0.7785712480545044, "(22, 0)": 0.7785712480545044, "(22, 16)": 0.7785712480545044, "(24, 0)": 0.7785712480545044, "(24, 16)": 0.7648601531982422, "(26, 0)": 0.7710603475570679, "(26, 16)": 0.7785712480545044, "(28, 0)": 0.7710603475570679, "(28, 16)": 0.7785712480545044, "(30, 0)": 0.7785712480545044, "(30, 16)": 0.7710603475570679}, "r_span": [1368, 1469], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0017514228820800781}}]}, {"id": "2895", "source_id": "11948", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "SpaceX, a private space exploration company founded by Elon Musk, is attempting to land a rocket on a platform in the Atlantic Ocean after launching it from Cape Canaveral, Florida. The company wants to reuse rockets to reduce the cost of accessing space, with the current odds of a successful landing being around 50%. The rocket will carry a cargo spacecraft, Dragon, to the International Space Station and then attempt to land on the autonomous spaceport drone ship. If the landing doesn't succeed, the company will keep trying. The smaller top part of the rocket will carry the Dragon into orbit and later burn up in Earth's atmosphere, while the Dragon will dock with the space station to deliver supplies and then return with experiments and trash. This is the sixth SpaceX mission to the International Space Station.", "response_spans": [[0, 505], [493, 823]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.682335615158081, "(0, 16)": 0.682335615158081, "(2, 0)": 0.682335615158081, "(2, 16)": 0.682335615158081, "(4, 0)": 0.682335615158081, "(4, 16)": 0.682335615158081, "(6, 0)": 0.682335615158081, "(6, 16)": 0.8592441082000732, "(8, 0)": 0.682335615158081, "(8, 16)": 0.682335615158081, "(10, 0)": 0.8006799221038818, "(10, 16)": 0.682335615158081, "(12, 0)": 0.756346583366394, "(12, 16)": 0.8006799221038818, "(14, 0)": 0.682335615158081, "(14, 16)": 0.8592441082000732, "(16, 0)": 0.8592441082000732, "(16, 16)": 0.682335615158081, "(18, 0)": 0.682335615158081, "(18, 16)": 0.8592441082000732, "(20, 0)": 0.756346583366394, "(20, 16)": 0.682335615158081, "(22, 0)": 0.8592441082000732, "(22, 16)": 0.8592441082000732, "(24, 0)": 0.682335615158081, "(24, 16)": 0.8592441082000732, "(26, 0)": 0.8592441082000732, "(26, 16)": 0.8006799221038818, "(28, 0)": 0.8592441082000732, "(28, 16)": 0.682335615158081, "(30, 0)": 0.8592441082000732, "(30, 16)": 0.8592441082000732}, "r_span": [666, 780], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000709831714630127}}, {"prompt_attention_score": {"(0, 0)": 0.7599701285362244, "(0, 16)": 0.7599701285362244, "(2, 0)": 0.7599701285362244, "(2, 16)": 0.7599701285362244, "(4, 0)": 0.7599701285362244, "(4, 16)": 0.7599701285362244, "(6, 0)": 0.7599701285362244, "(6, 16)": 0.8647242188453674, "(8, 0)": 0.7599701285362244, "(8, 16)": 0.7599701285362244, "(10, 0)": 0.7599701285362244, "(10, 16)": 0.7599701285362244, "(12, 0)": 0.7599701285362244, "(12, 16)": 0.8647242188453674, "(14, 0)": 0.7599701285362244, "(14, 16)": 0.7599701285362244, "(16, 0)": 0.8647242188453674, "(16, 16)": 0.7599701285362244, "(18, 0)": 0.7247446775436401, "(18, 16)": 0.8647242188453674, "(20, 0)": 0.8647242188453674, "(20, 16)": 0.7599701285362244, "(22, 0)": 0.7247446775436401, "(22, 16)": 0.8647242188453674, "(24, 0)": 0.7599701285362244, "(24, 16)": 0.7599701285362244, "(26, 0)": 0.7247446775436401, "(26, 16)": 0.7599701285362244, "(28, 0)": 0.7247446775436401, "(28, 16)": 0.5586178302764893, "(30, 0)": 0.7247446775436401, "(30, 16)": 0.7247446775436401}, "r_span": [778, 843], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014001727104187012}}]}, {"id": "3081", "source_id": "11979", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 806, "end": 902, "text": "the prosecution presented a compelling case that Tsarnaev was the mastermind behind the bombing.", "meta": "EVIDENT CONFLICT\nOriginal: The prosecutor William Weinreb said that \"... the defendant and his brother are equally guilty.\" \nGenerative: It suggests that the prosecution presented that only Tsarnaev the mastermind behind the bombing.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "The trial of Dzhokhar Tsarnaev, the surviving suspect in the Boston Marathon bombing, continues with the jury deliberating for over seven hours without reaching a verdict. Prosecutors presented a strong case against Tsarnaev, highlighting the horrors of the bombing and the devastating impact on the victims and their families. The jury heard testimony from bomb survivors and first responders, as well as graphic evidence of the bombing itself, including a video of the moment the bomb exploded and dismembered an 8-year-old boy. The prosecution also presented evidence of Tsarnaev's involvement in the bombing, including his own written manifesto expressing his hatred for the US and its policies towards Muslims. Despite the defense's attempt to shift the blame onto Tsarnaev's older brother, Tamerlan, the prosecution presented a compelling case that Tsarnaev was the mastermind behind the bombing. The jury will now consider the 30 charges against Tsarnaev, including setting off weapons of mass destruction as an act of terrorism, and will decide whether he is guilty of at least one of the 17 capital counts. If convicted, the trial will proceed to a second phase to determine Tsarnaev's sentence.", "response_spans": [[0, 511], [496, 1000], [981, 1204]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6983568668365479, "(0, 16)": 0.8248974084854126, "(2, 0)": 0.6983568668365479, "(2, 16)": 0.6983568668365479, "(4, 0)": 0.6983568668365479, "(4, 16)": 0.6983568668365479, "(6, 0)": 0.6983568668365479, "(6, 16)": 0.8664025068283081, "(8, 0)": 0.6983568668365479, "(8, 16)": 0.6983568668365479, "(10, 0)": 0.6983568668365479, "(10, 16)": 0.6983568668365479, "(12, 0)": 0.6983568668365479, "(12, 16)": 0.8664025068283081, "(14, 0)": 0.6983568668365479, "(14, 16)": 0.6983568668365479, "(16, 0)": 0.6983568668365479, "(16, 16)": 0.6983568668365479, "(18, 0)": 0.6983568668365479, "(18, 16)": 0.8664025068283081, "(20, 0)": 0.8664025068283081, "(20, 16)": 0.6983568668365479, "(22, 0)": 0.6983568668365479, "(22, 16)": 0.7215285301208496, "(24, 0)": 0.6983568668365479, "(24, 16)": 0.8664025068283081, "(26, 0)": 0.6983568668365479, "(26, 16)": 0.6983568668365479, "(28, 0)": 0.6983568668365479, "(28, 16)": 0.6983568668365479, "(30, 0)": 0.6983568668365479, "(30, 16)": 0.6983568668365479}, "r_span": [1561, 1678], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014127492904663086}}, {"prompt_attention_score": {"(0, 0)": 0.6804786920547485, "(0, 16)": 0.6804786920547485, "(2, 0)": 0.62269127368927, "(2, 16)": 0.62269127368927, "(4, 0)": 0.62269127368927, "(4, 16)": 0.62269127368927, "(6, 0)": 0.62269127368927, "(6, 16)": 0.7747008800506592, "(8, 0)": 0.6804786920547485, "(8, 16)": 0.62269127368927, "(10, 0)": 0.6804786920547485, "(10, 16)": 0.62269127368927, "(12, 0)": 0.62269127368927, "(12, 16)": 0.7747008800506592, "(14, 0)": 0.62269127368927, "(14, 16)": 0.6804786920547485, "(16, 0)": 0.62269127368927, "(16, 16)": 0.62269127368927, "(18, 0)": 0.62269127368927, "(18, 16)": 0.7529991269111633, "(20, 0)": 0.7747008800506592, "(20, 16)": 0.62269127368927, "(22, 0)": 0.62269127368927, "(22, 16)": 0.62269127368927, "(24, 0)": 0.62269127368927, "(24, 16)": 0.7427783608436584, "(26, 0)": 0.62269127368927, "(26, 16)": 0.6804786920547485, "(28, 0)": 0.6804786920547485, "(28, 16)": 0.62269127368927, "(30, 0)": 0.62269127368927, "(30, 16)": 0.62269127368927}, "r_span": [1675, 1796], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012798905372619629}}, {"prompt_attention_score": {"(0, 0)": 0.5003942847251892, "(0, 16)": 0.5003942847251892, "(2, 0)": 0.5003942847251892, "(2, 16)": 0.5003942847251892, "(4, 0)": 0.5003942847251892, "(4, 16)": 0.5003942847251892, "(6, 0)": 0.5003942847251892, "(6, 16)": 0.8886853456497192, "(8, 0)": 0.5003942847251892, "(8, 16)": 0.5003942847251892, "(10, 0)": 0.5003942847251892, "(10, 16)": 0.5003942847251892, "(12, 0)": 0.5003942847251892, "(12, 16)": 0.8886853456497192, "(14, 0)": 0.5003942847251892, "(14, 16)": 0.5003942847251892, "(16, 0)": 0.5003942847251892, "(16, 16)": 0.5003942847251892, "(18, 0)": 0.5003942847251892, "(18, 16)": 0.8886853456497192, "(20, 0)": 0.8886853456497192, "(20, 16)": 0.5003942847251892, "(22, 0)": 0.5003942847251892, "(22, 16)": 0.8886853456497192, "(24, 0)": 0.5003942847251892, "(24, 16)": 0.8886853456497192, "(26, 0)": 0.5003942847251892, "(26, 16)": 0.5003942847251892, "(28, 0)": 0.5003942847251892, "(28, 16)": 0.5003942847251892, "(30, 0)": 0.5003942847251892, "(30, 16)": 0.5003942847251892}, "r_span": [1793, 1844], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010155439376831055}}]}, {"id": "3147", "source_id": "11991", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 245, "end": 317, "text": "arrested Dickens after finding a firearm and three computers at her home", "meta": "EVIDENT CONFLICT\nOriginal: Dickens was arrested because of her threatening post, the firearm and three computers was located during the search.\nGenerative: arrested Dickens after finding a firearm and three computers at her home", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 419, "end": 458, "text": "She was denied bond and remains in jail", "meta": "EVIDENT CONFLICT\nOriginal: The judge set a $10,000 bond for her and banned her from social media.\nGenerative: She was denied bond and remains in jail.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Atlanta woman, Ebony Dickens, faces charges after making threats on Facebook against white cops. Under the pseudonym Tiffany Milan, Dickens wrote a post threatening to shoot every white cop in the nation. Authorities took the post seriously and arrested Dickens after finding a firearm and three computers at her home. Dickens appeared in court and was charged with disseminating information related to terrorist acts. She was denied bond and remains in jail.", "response_spans": [[0, 459]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7635288238525391, "(0, 16)": 0.7635288238525391, "(2, 0)": 0.7635288238525391, "(2, 16)": 0.7635288238525391, "(4, 0)": 0.7635288238525391, "(4, 16)": 0.7635288238525391, "(6, 0)": 0.7635288238525391, "(6, 16)": 0.7995549440383911, "(8, 0)": 0.7635288238525391, "(8, 16)": 0.7635288238525391, "(10, 0)": 0.7995549440383911, "(10, 16)": 0.7635288238525391, "(12, 0)": 0.7635288238525391, "(12, 16)": 0.7995549440383911, "(14, 0)": 0.7635288238525391, "(14, 16)": 0.7995549440383911, "(16, 0)": 0.7995549440383911, "(16, 16)": 0.7995549440383911, "(18, 0)": 0.7635288238525391, "(18, 16)": 0.7635288238525391, "(20, 0)": 0.7635288238525391, "(20, 16)": 0.7635288238525391, "(22, 0)": 0.7635288238525391, "(22, 16)": 0.7995549440383911, "(24, 0)": 0.7635288238525391, "(24, 16)": 0.7635288238525391, "(26, 0)": 0.7995549440383911, "(26, 16)": 0.7995549440383911, "(28, 0)": 0.7995549440383911, "(28, 16)": 0.7635288238525391, "(30, 0)": 0.7995549440383911, "(30, 16)": 0.7995549440383911}, "r_span": [580, 680], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003272712230682373}}]}, {"id": "3249", "source_id": "12008", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "The news article discusses the changing attitudes towards marriage among young people, particularly millennials. Many of them are delaying marriage or avoiding it altogether due to various reasons such as financial stability, personal goals, and the prevalence of divorce. According to a Pew Research report, 50% of respondents believe that society can function well even if people have different priorities than marriage and children. The article also highlights the cultural shift in Scandinavian countries where living together without marriage, known as \"sambo,\" has become commonplace and socially accepted. The author of the article muses about the possibility of a \"marriage apocalypse\" and wonders if a society without marriage would be just as well off as one filled with married couples.", "response_spans": [[0, 508], [499, 797]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7211914658546448, "(0, 16)": 0.7393588423728943, "(2, 0)": 0.7211914658546448, "(2, 16)": 0.7211914658546448, "(4, 0)": 0.7211914658546448, "(4, 16)": 0.7211914658546448, "(6, 0)": 0.7211914658546448, "(6, 16)": 0.7947648167610168, "(8, 0)": 0.7211914658546448, "(8, 16)": 0.7211914658546448, "(10, 0)": 0.7211914658546448, "(10, 16)": 0.7211914658546448, "(12, 0)": 0.7211914658546448, "(12, 16)": 0.7947648167610168, "(14, 0)": 0.7211914658546448, "(14, 16)": 0.7211914658546448, "(16, 0)": 0.7211914658546448, "(16, 16)": 0.7211914658546448, "(18, 0)": 0.7211914658546448, "(18, 16)": 0.7947648167610168, "(20, 0)": 0.7947648167610168, "(20, 16)": 0.7211914658546448, "(22, 0)": 0.7211914658546448, "(22, 16)": 0.7947648167610168, "(24, 0)": 0.7211914658546448, "(24, 16)": 0.7947648167610168, "(26, 0)": 0.7211914658546448, "(26, 16)": 0.7211914658546448, "(28, 0)": 0.7211914658546448, "(28, 16)": 0.7211914658546448, "(30, 0)": 0.7211914658546448, "(30, 16)": 0.7211914658546448}, "r_span": [1564, 1666], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009745359420776367}}, {"prompt_attention_score": {"(0, 0)": 0.7528544068336487, "(0, 16)": 0.7528544068336487, "(2, 0)": 0.7146005630493164, "(2, 16)": 0.7146005630493164, "(4, 0)": 0.7146005630493164, "(4, 16)": 0.7146005630493164, "(6, 0)": 0.7528544068336487, "(6, 16)": 0.7031682729721069, "(8, 0)": 0.7528544068336487, "(8, 16)": 0.7146005630493164, "(10, 0)": 0.7528544068336487, "(10, 16)": 0.7528544068336487, "(12, 0)": 0.7146005630493164, "(12, 16)": 0.7058932185173035, "(14, 0)": 0.7146005630493164, "(14, 16)": 0.7528544068336487, "(16, 0)": 0.7528544068336487, "(16, 16)": 0.7146005630493164, "(18, 0)": 0.7146005630493164, "(18, 16)": 0.7528544068336487, "(20, 0)": 0.7058932185173035, "(20, 16)": 0.6419742107391357, "(22, 0)": 0.6709634065628052, "(22, 16)": 0.6751005053520203, "(24, 0)": 0.6709634065628052, "(24, 16)": 0.7528544068336487, "(26, 0)": 0.7528544068336487, "(26, 16)": 0.7528544068336487, "(28, 0)": 0.7528544068336487, "(28, 16)": 0.7528544068336487, "(30, 0)": 0.7528544068336487, "(30, 16)": 0.7146005630493164}, "r_span": [1666, 1729], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006108283996582031}}]}, {"id": "3561", "source_id": "12060", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 180 words:\n\nIraqi forces, aided by Shiite militiamen, have retaken the northern city of Tikrit from ISIS. The city was marked by brutality during ISIS' nine-month rule, including a reported massacre of 1,500 air force cadets. Iraqi forces discovered vehicles laden with explosives and booby-trapped buildings as they entered the city. The victory sets the stage for Iraqi forces to take back the larger city of Mosul, Iraq's second-largest city. The presence of Shiite militiamen in the operation has raised concerns about sectarian reprisals and the potential for further instability in the region.", "response_spans": [[0, 46], [48, 558], [544, 635]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.47526419162750244, "(0, 16)": 0.47526419162750244, "(2, 0)": 0.47526419162750244, "(2, 16)": 0.47526419162750244, "(4, 0)": 0.5408133268356323, "(4, 16)": 0.47526419162750244, "(6, 0)": 0.47526419162750244, "(6, 16)": 0.8264150023460388, "(8, 0)": 0.47526419162750244, "(8, 16)": 0.6079434156417847, "(10, 0)": 0.8264150023460388, "(10, 16)": 0.6079434156417847, "(12, 0)": 0.6079434156417847, "(12, 16)": 0.8264150023460388, "(14, 0)": 0.47526419162750244, "(14, 16)": 0.6079434156417847, "(16, 0)": 0.6079434156417847, "(16, 16)": 0.5408133268356323, "(18, 0)": 0.6079434156417847, "(18, 16)": 0.8264150023460388, "(20, 0)": 0.8264150023460388, "(20, 16)": 0.47526419162750244, "(22, 0)": 0.47526419162750244, "(22, 16)": 0.4665552079677582, "(24, 0)": 0.47526419162750244, "(24, 16)": 0.4665552079677582, "(26, 0)": 0.47526419162750244, "(26, 16)": 0.47526419162750244, "(28, 0)": 0.4665552079677582, "(28, 16)": 0.47526419162750244, "(30, 0)": 0.4665552079677582, "(30, 16)": 0.4665552079677582}, "r_span": [1171, 1185], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003902316093444824}}, {"prompt_attention_score": {"(0, 0)": 0.7652181386947632, "(0, 16)": 0.7652181386947632, "(2, 0)": 0.7652181386947632, "(2, 16)": 0.7652181386947632, "(4, 0)": 0.7652181386947632, "(4, 16)": 0.7652181386947632, "(6, 0)": 0.7652181386947632, "(6, 16)": 0.767758846282959, "(8, 0)": 0.7652181386947632, "(8, 16)": 0.7652181386947632, "(10, 0)": 0.7652181386947632, "(10, 16)": 0.7652181386947632, "(12, 0)": 0.7652181386947632, "(12, 16)": 0.767758846282959, "(14, 0)": 0.7652181386947632, "(14, 16)": 0.767758846282959, "(16, 0)": 0.7652181386947632, "(16, 16)": 0.7652181386947632, "(18, 0)": 0.7652181386947632, "(18, 16)": 0.767758846282959, "(20, 0)": 0.7652181386947632, "(20, 16)": 0.7652181386947632, "(22, 0)": 0.7652181386947632, "(22, 16)": 0.767758846282959, "(24, 0)": 0.7652181386947632, "(24, 16)": 0.767758846282959, "(26, 0)": 0.767758846282959, "(26, 16)": 0.7652181386947632, "(28, 0)": 0.767758846282959, "(28, 16)": 0.7652181386947632, "(30, 0)": 0.7652181386947632, "(30, 16)": 0.767758846282959}, "r_span": [1187, 1317], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018431544303894043}}, {"prompt_attention_score": {"(0, 0)": 0.571481466293335, "(0, 16)": 0.571481466293335, "(2, 0)": 0.571481466293335, "(2, 16)": 0.571481466293335, "(4, 0)": 0.571481466293335, "(4, 16)": 0.571481466293335, "(6, 0)": 0.571481466293335, "(6, 16)": 0.6845256090164185, "(8, 0)": 0.571481466293335, "(8, 16)": 0.571481466293335, "(10, 0)": 0.571481466293335, "(10, 16)": 0.571481466293335, "(12, 0)": 0.571481466293335, "(12, 16)": 0.6845256090164185, "(14, 0)": 0.5832144618034363, "(14, 16)": 0.6845256090164185, "(16, 0)": 0.571481466293335, "(16, 16)": 0.571481466293335, "(18, 0)": 0.571481466293335, "(18, 16)": 0.6845256090164185, "(20, 0)": 0.6845256090164185, "(20, 16)": 0.571481466293335, "(22, 0)": 0.5832144618034363, "(22, 16)": 0.6845256090164185, "(24, 0)": 0.571481466293335, "(24, 16)": 0.6845256090164185, "(26, 0)": 0.571481466293335, "(26, 16)": 0.571481466293335, "(28, 0)": 0.559131920337677, "(28, 16)": 0.571481466293335, "(30, 0)": 0.5832144618034363, "(30, 16)": 0.559131920337677}, "r_span": [1316, 1333], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002327561378479004}}]}, {"id": "3609", "source_id": "12068", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 419, "end": 493, "text": "urged the parties involved to take immediate action to stop the bloodshed.", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"urged the parties involved to take immediate action to stop the bloodshed\" was not mentioned in the source content", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "The International Red Cross (ICRC) has called for an immediate 24-hour ceasefire in Yemen to allow for the delivery of aid to wounded civilians and fighters. The ICRC made the appeal as the UN Security Council met to discuss the situation in Yemen, where Shiite rebels are fighting against external forces and pro-government fighters. The ICRC stated that many more people will die if aid is not delivered quickly, and urged the parties involved to take immediate action to stop the bloodshed. Meanwhile, Saudi special forces have been supplying weapons and communication equipment to Yemeni fighters in the city of Aden, while al Qaeda in the Arabian Peninsula (AQAP) is reportedly holding sway in the country's east. The conflict in Yemen has resulted in at least 519 deaths and 1,700 injuries in the past two weeks, according to the UN, and tens of thousands have fled to nearby countries.", "response_spans": [[0, 510], [494, 892]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6501162052154541, "(0, 16)": 0.6501162052154541, "(2, 0)": 0.5966702699661255, "(2, 16)": 0.5966702699661255, "(4, 0)": 0.6501162052154541, "(4, 16)": 0.5966702699661255, "(6, 0)": 0.5966702699661255, "(6, 16)": 0.8967105150222778, "(8, 0)": 0.6501162052154541, "(8, 16)": 0.6501162052154541, "(10, 0)": 0.8967105150222778, "(10, 16)": 0.7329260110855103, "(12, 0)": 0.6501162052154541, "(12, 16)": 0.8165239691734314, "(14, 0)": 0.6501162052154541, "(14, 16)": 0.8967105150222778, "(16, 0)": 0.8967105150222778, "(16, 16)": 0.6501162052154541, "(18, 0)": 0.6501162052154541, "(18, 16)": 0.8967105150222778, "(20, 0)": 0.8967105150222778, "(20, 16)": 0.6501162052154541, "(22, 0)": 0.6501162052154541, "(22, 16)": 0.8967105150222778, "(24, 0)": 0.6501162052154541, "(24, 16)": 0.8967105150222778, "(26, 0)": 0.8967105150222778, "(26, 16)": 0.5966702699661255, "(28, 0)": 0.8967105150222778, "(28, 16)": 0.5966702699661255, "(30, 0)": 0.8967105150222778, "(30, 16)": 0.8967105150222778}, "r_span": [1098, 1218], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015771985054016113}}, {"prompt_attention_score": {"(0, 0)": 0.824239194393158, "(0, 16)": 0.824239194393158, "(2, 0)": 0.6749593019485474, "(2, 16)": 0.6749593019485474, "(4, 0)": 0.6749593019485474, "(4, 16)": 0.6749593019485474, "(6, 0)": 0.6749593019485474, "(6, 16)": 0.8274568319320679, "(8, 0)": 0.824239194393158, "(8, 16)": 0.6749593019485474, "(10, 0)": 0.6749593019485474, "(10, 16)": 0.6749593019485474, "(12, 0)": 0.824239194393158, "(12, 16)": 0.8274568319320679, "(14, 0)": 0.824239194393158, "(14, 16)": 0.6749593019485474, "(16, 0)": 0.824239194393158, "(16, 16)": 0.6749593019485474, "(18, 0)": 0.6749593019485474, "(18, 16)": 0.824239194393158, "(20, 0)": 0.8274568319320679, "(20, 16)": 0.6749593019485474, "(22, 0)": 0.824239194393158, "(22, 16)": 0.8274568319320679, "(24, 0)": 0.6749593019485474, "(24, 16)": 0.8274568319320679, "(26, 0)": 0.6916316747665405, "(26, 16)": 0.6749593019485474, "(28, 0)": 0.6916316747665405, "(28, 16)": 0.6749593019485474, "(30, 0)": 0.6916316747665405, "(30, 16)": 0.6916316747665405}, "r_span": [1215, 1318], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00013077259063720703}}]}, {"id": "3639", "source_id": "12073", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 553, "end": 662, "text": "The mayor of New York City, Bill de Blasio, has also issued an apology to the driver and passengers involved.", "meta": "EVIDENT CONFLICT\nOriginal:  Bratton, who said the detective was on duty at the time, issued an apology to the driver and passengers\nGenerated: The mayor of New York City, Bill de Blasio, has also issued an apology to the driver and passengers involved.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "A New York City Police Department detective has been placed on modified assignment after a video surfaced of him having an angry exchange with an Uber driver. The detective, Patrick Cherry, was caught on camera using expletives and discriminatory language towards the driver, who was simply attempting to park his vehicle. The incident has sparked an investigation by the NYPD's Internal Affairs Bureau and the Civilian Complaint Review Board. The detective has apologized for his behavior, stating that he was \"just angry\" at the time of the incident. The mayor of New York City, Bill de Blasio, has also issued an apology to the driver and passengers involved. The incident has raised concerns about the behavior of NYPD officers towards civilians, particularly those from diverse backgrounds.", "response_spans": [[0, 510], [491, 795]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7595155239105225, "(0, 16)": 0.7595155239105225, "(2, 0)": 0.7595155239105225, "(2, 16)": 0.7595155239105225, "(4, 0)": 0.7595155239105225, "(4, 16)": 0.7595155239105225, "(6, 0)": 0.7595155239105225, "(6, 16)": 0.884878396987915, "(8, 0)": 0.884878396987915, "(8, 16)": 0.7363219261169434, "(10, 0)": 0.7595155239105225, "(10, 16)": 0.7595155239105225, "(12, 0)": 0.7595155239105225, "(12, 16)": 0.884878396987915, "(14, 0)": 0.7595155239105225, "(14, 16)": 0.884878396987915, "(16, 0)": 0.884878396987915, "(16, 16)": 0.884878396987915, "(18, 0)": 0.6608468294143677, "(18, 16)": 0.884878396987915, "(20, 0)": 0.884878396987915, "(20, 16)": 0.7595155239105225, "(22, 0)": 0.7595155239105225, "(22, 16)": 0.884878396987915, "(24, 0)": 0.7595155239105225, "(24, 16)": 0.7188013792037964, "(26, 0)": 0.884878396987915, "(26, 16)": 0.7595155239105225, "(28, 0)": 0.884878396987915, "(28, 16)": 0.7595155239105225, "(30, 0)": 0.884878396987915, "(30, 16)": 0.884878396987915}, "r_span": [1243, 1351], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00018036365509033203}}, {"prompt_attention_score": {"(0, 0)": 0.7561676502227783, "(0, 16)": 0.7561676502227783, "(2, 0)": 0.7561676502227783, "(2, 16)": 0.7561676502227783, "(4, 0)": 0.7561676502227783, "(4, 16)": 0.7561676502227783, "(6, 0)": 0.7561676502227783, "(6, 16)": 0.7773920297622681, "(8, 0)": 0.7561676502227783, "(8, 16)": 0.7141425013542175, "(10, 0)": 0.7561676502227783, "(10, 16)": 0.7561676502227783, "(12, 0)": 0.7141425013542175, "(12, 16)": 0.7773920297622681, "(14, 0)": 0.7417915463447571, "(14, 16)": 0.7773920297622681, "(16, 0)": 0.7417915463447571, "(16, 16)": 0.7591776847839355, "(18, 0)": 0.7417915463447571, "(18, 16)": 0.7773920297622681, "(20, 0)": 0.7773920297622681, "(20, 16)": 0.7561676502227783, "(22, 0)": 0.7591776847839355, "(22, 16)": 0.7011325359344482, "(24, 0)": 0.7561676502227783, "(24, 16)": 0.7011325359344482, "(26, 0)": 0.7591776847839355, "(26, 16)": 0.7561676502227783, "(28, 0)": 0.7591776847839355, "(28, 16)": 0.7591776847839355, "(30, 0)": 0.7591776847839355, "(30, 16)": 0.7591776847839355}, "r_span": [1348, 1412], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012531876564025879}}]}, {"id": "3771", "source_id": "13799", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Phyllis Summers (Michelle Stafford) helps Tucker McCall (Trevor St. John) hack into Jabot's and Billy Abbott's (Jason Thompson) accounts, despite initial refusal. Tucker uses leverage to coerce Phyllis, who is struggling with guilt. Phyllis reaches out to Jack Abbott (Peter Bergman) for support, but Tucker threatens to expose her if she doesn't comply. Y&R fans, will Tucker pin everything on Phyllis?", "response_spans": [[0, 403]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7676560282707214, "(0, 16)": 0.7676560282707214, "(2, 0)": 0.7676560282707214, "(2, 16)": 0.7676560282707214, "(4, 0)": 0.7676560282707214, "(4, 16)": 0.6539915800094604, "(6, 0)": 0.7676560282707214, "(6, 16)": 0.8865010738372803, "(8, 0)": 0.8865010738372803, "(8, 16)": 0.7676560282707214, "(10, 0)": 0.7676560282707214, "(10, 16)": 0.7676560282707214, "(12, 0)": 0.8865010738372803, "(12, 16)": 0.8865010738372803, "(14, 0)": 0.8865010738372803, "(14, 16)": 0.8865010738372803, "(16, 0)": 0.8865010738372803, "(16, 16)": 0.8865010738372803, "(18, 0)": 0.8865010738372803, "(18, 16)": 0.8865010738372803, "(20, 0)": 0.7023935914039612, "(20, 16)": 0.8865010738372803, "(22, 0)": 0.8865010738372803, "(22, 16)": 0.7023935914039612, "(24, 0)": 0.8865010738372803, "(24, 16)": 0.8865010738372803, "(26, 0)": 0.8865010738372803, "(26, 16)": 0.8865010738372803, "(28, 0)": 0.8865010738372803, "(28, 16)": 0.8865010738372803, "(30, 0)": 0.8865010738372803, "(30, 16)": 0.8865010738372803}, "r_span": [509, 627], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012546777725219727}}]}, {"id": "3813", "source_id": "13806", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On the latest episode of Big Brother 25, Mecole Hayes was evicted from the house with a unanimous vote of 7-0. Bowie Jane won the HOH competition and will nominate houseguests for eviction. This is Bowie's first win in a competition. Cirie Fields has set a new Big Brother record, and producers are reportedly working on an all-winners season of the show. Additionally, the cast list for the upcoming spinoff series, Traitors 2, has been released.", "response_spans": [[0, 447]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7331420183181763, "(0, 16)": 0.7331420183181763, "(2, 0)": 0.8285261988639832, "(2, 16)": 0.7331420183181763, "(4, 0)": 0.8285261988639832, "(4, 16)": 0.7331420183181763, "(6, 0)": 0.7331420183181763, "(6, 16)": 0.7969021797180176, "(8, 0)": 0.7331420183181763, "(8, 16)": 0.8285261988639832, "(10, 0)": 0.7331420183181763, "(10, 16)": 0.7331420183181763, "(12, 0)": 0.7331420183181763, "(12, 16)": 0.7331420183181763, "(14, 0)": 0.8285261988639832, "(14, 16)": 0.8285261988639832, "(16, 0)": 0.7331420183181763, "(16, 16)": 0.8409287929534912, "(18, 0)": 0.8285261988639832, "(18, 16)": 0.7331420183181763, "(20, 0)": 0.7331420183181763, "(20, 16)": 0.8285261988639832, "(22, 0)": 0.8409287929534912, "(22, 16)": 0.7331420183181763, "(24, 0)": 0.7331420183181763, "(24, 16)": 0.7331420183181763, "(26, 0)": 0.8409287929534912, "(26, 16)": 0.7331420183181763, "(28, 0)": 0.8409287929534912, "(28, 16)": 0.8285261988639832, "(30, 0)": 0.8409287929534912, "(30, 16)": 0.8409287929534912}, "r_span": [706, 826], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018782615661621094}}]}, {"id": "3861", "source_id": "13814", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 196, "end": 231, "text": "This is the highest COLA since 2000", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of these details in the source content.\nGenerative: \"This is the highest COLA since 2000...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 106 words:\n\nSocial Security beneficiaries will receive a 3.2% cost-of-living adjustment (COLA) in 2024, resulting in an average increase of over $50 per month. This is the highest COLA since 2000 and helps retirees keep up with rising living costs. The maximum amount of earnings subject to the Social Security tax will also increase to $168,600 in 2024. Beneficiaries will receive notices of the COLA increase in early December, and can view their notice online or sign up for text or email alerts.", "response_spans": [[0, 46], [48, 535]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5327253937721252, "(0, 16)": 0.5327253937721252, "(2, 0)": 0.5327253937721252, "(2, 16)": 0.5327253937721252, "(4, 0)": 0.5327253937721252, "(4, 16)": 0.6032910346984863, "(6, 0)": 0.6032910346984863, "(6, 16)": 0.5234708189964294, "(8, 0)": 0.5234708189964294, "(8, 16)": 0.6032910346984863, "(10, 0)": 0.5234708189964294, "(10, 16)": 0.6032910346984863, "(12, 0)": 0.6032910346984863, "(12, 16)": 0.5234708189964294, "(14, 0)": 0.5327253937721252, "(14, 16)": 0.5234708189964294, "(16, 0)": 0.5234708189964294, "(16, 16)": 0.5234708189964294, "(18, 0)": 0.5234708189964294, "(18, 16)": 0.5234708189964294, "(20, 0)": 0.5234708189964294, "(20, 16)": 0.5327253937721252, "(22, 0)": 0.5234708189964294, "(22, 16)": 0.5234708189964294, "(24, 0)": 0.5234708189964294, "(24, 16)": 0.5234708189964294, "(26, 0)": 0.5234708189964294, "(26, 16)": 0.5234708189964294, "(28, 0)": 0.5234708189964294, "(28, 16)": 0.5327253937721252, "(30, 0)": 0.5234708189964294, "(30, 16)": 0.5234708189964294}, "r_span": [789, 803], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001830458641052246}}, {"prompt_attention_score": {"(0, 0)": 0.948140025138855, "(0, 16)": 0.948140025138855, "(2, 0)": 0.948140025138855, "(2, 16)": 0.948140025138855, "(4, 0)": 0.948140025138855, "(4, 16)": 0.948140025138855, "(6, 0)": 0.948140025138855, "(6, 16)": 0.9198154807090759, "(8, 0)": 0.856768012046814, "(8, 16)": 0.948140025138855, "(10, 0)": 0.856768012046814, "(10, 16)": 0.948140025138855, "(12, 0)": 0.856768012046814, "(12, 16)": 0.948140025138855, "(14, 0)": 0.948140025138855, "(14, 16)": 0.856768012046814, "(16, 0)": 0.8524012565612793, "(16, 16)": 0.8524012565612793, "(18, 0)": 0.8524012565612793, "(18, 16)": 0.7900676131248474, "(20, 0)": 0.7900676131248474, "(20, 16)": 0.948140025138855, "(22, 0)": 0.8524012565612793, "(22, 16)": 0.7900676131248474, "(24, 0)": 0.948140025138855, "(24, 16)": 0.7900676131248474, "(26, 0)": 0.8524012565612793, "(26, 16)": 0.8524012565612793, "(28, 0)": 0.8524012565612793, "(28, 16)": 0.8524012565612793, "(30, 0)": 0.8524012565612793, "(30, 16)": 0.8524012565612793}, "r_span": [805, 939], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005552768707275391}}]}, {"id": "3867", "source_id": "13815", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a 93-word summary of the article:\n\nTonee Turner, a 22-year-old artist from Pittsburgh, Pennsylvania, has been missing since December 30, 2019. Her family has been searching for her daily, passing out flyers and sharing her description with the public. A man found her purse near a bridge, containing her phone, wallet, and keys, leading authorities to believe she may have traveled on Interstate 80. Tonee is described as 5'3\" with black or dark brown hair, multiple piercings, and a tattoo on her left shoulder. Anyone with information is urged to contact the Pittsburgh Police.", "response_spans": [[0, 41], [43, 553], [545, 587]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.43974223732948303, "(0, 16)": 0.43974223732948303, "(2, 0)": 0.41673773527145386, "(2, 16)": 0.43974223732948303, "(4, 0)": 0.43974223732948303, "(4, 16)": 0.43974223732948303, "(6, 0)": 0.43974223732948303, "(6, 16)": 0.41561591625213623, "(8, 0)": 0.43974223732948303, "(8, 16)": 0.43974223732948303, "(10, 0)": 0.41561591625213623, "(10, 16)": 0.43974223732948303, "(12, 0)": 0.43974223732948303, "(12, 16)": 0.41561591625213623, "(14, 0)": 0.43974223732948303, "(14, 16)": 0.41561591625213623, "(16, 0)": 0.41561591625213623, "(16, 16)": 0.43974223732948303, "(18, 0)": 0.43974223732948303, "(18, 16)": 0.41561591625213623, "(20, 0)": 0.41561591625213623, "(20, 16)": 0.41561591625213623, "(22, 0)": 0.41561591625213623, "(22, 16)": 0.41561591625213623, "(24, 0)": 0.41561591625213623, "(24, 16)": 0.41561591625213623, "(26, 0)": 0.43974223732948303, "(26, 16)": 0.41561591625213623, "(28, 0)": 0.43974223732948303, "(28, 16)": 0.43974223732948303, "(30, 0)": 0.41561591625213623, "(30, 16)": 0.41561591625213623}, "r_span": [669, 682], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003647804260253906}}, {"prompt_attention_score": {"(0, 0)": 0.7294862270355225, "(0, 16)": 0.7389706373214722, "(2, 0)": 0.7389706373214722, "(2, 16)": 0.7389706373214722, "(4, 0)": 0.7389706373214722, "(4, 16)": 0.7389706373214722, "(6, 0)": 0.7389706373214722, "(6, 16)": 0.8445568084716797, "(8, 0)": 0.7294862270355225, "(8, 16)": 0.7294862270355225, "(10, 0)": 0.7389706373214722, "(10, 16)": 0.7389706373214722, "(12, 0)": 0.7389706373214722, "(12, 16)": 0.8445568084716797, "(14, 0)": 0.7294862270355225, "(14, 16)": 0.8445568084716797, "(16, 0)": 0.8445568084716797, "(16, 16)": 0.8445568084716797, "(18, 0)": 0.7389706373214722, "(18, 16)": 0.8445568084716797, "(20, 0)": 0.7294862270355225, "(20, 16)": 0.7294862270355225, "(22, 0)": 0.8445568084716797, "(22, 16)": 0.8445568084716797, "(24, 0)": 0.8445568084716797, "(24, 16)": 0.8445568084716797, "(26, 0)": 0.8445568084716797, "(26, 16)": 0.8445568084716797, "(28, 0)": 0.8445568084716797, "(28, 16)": 0.7389706373214722, "(30, 0)": 0.8445568084716797, "(30, 16)": 0.8445568084716797}, "r_span": [684, 816], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008528828620910645}}, {"prompt_attention_score": {"(0, 0)": 0.3572979271411896, "(0, 16)": 0.3572979271411896, "(2, 0)": 0.7234066724777222, "(2, 16)": 0.7234066724777222, "(4, 0)": 0.7234066724777222, "(4, 16)": 0.7234066724777222, "(6, 0)": 0.7234066724777222, "(6, 16)": 0.5169286131858826, "(8, 0)": 0.7234066724777222, "(8, 16)": 0.7234066724777222, "(10, 0)": 0.7234066724777222, "(10, 16)": 0.7234066724777222, "(12, 0)": 0.7234066724777222, "(12, 16)": 0.7234066724777222, "(14, 0)": 0.3572979271411896, "(14, 16)": 0.7234066724777222, "(16, 0)": 0.7234066724777222, "(16, 16)": 0.5169286131858826, "(18, 0)": 0.7234066724777222, "(18, 16)": 0.7234066724777222, "(20, 0)": 0.7234066724777222, "(20, 16)": 0.3572979271411896, "(22, 0)": 0.5169286131858826, "(22, 16)": 0.7234066724777222, "(24, 0)": 0.5169286131858826, "(24, 16)": 0.7234066724777222, "(26, 0)": 0.5169286131858826, "(26, 16)": 0.5169286131858826, "(28, 0)": 0.5169286131858826, "(28, 16)": 0.5169286131858826, "(30, 0)": 0.5169286131858826, "(30, 16)": 0.5169286131858826}, "r_span": [814, 823], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000877082347869873}}]}, {"id": "3873", "source_id": "13816", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 133, "end": 158, "text": "according to a new study.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of such study\nGenerative: \"...according to a new study.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 87 words:\n\nXanax, a common medication for anxiety, may not be as effective as initially thought, according to a new study. While it provides quick relief for acute anxiety, long-term use can lead to tolerance and dependence. Alternative treatments, such as therapy and lifestyle changes, may be more sustainable for chronic anxiety management. A balanced approach to anxiety treatment is necessary to achieve long-term well-being.", "response_spans": [[0, 466]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.842501163482666, "(0, 16)": 0.842501163482666, "(2, 0)": 0.842501163482666, "(2, 16)": 0.842501163482666, "(4, 0)": 0.842501163482666, "(4, 16)": 0.842501163482666, "(6, 0)": 0.842501163482666, "(6, 16)": 0.7685403823852539, "(8, 0)": 0.842501163482666, "(8, 16)": 0.842501163482666, "(10, 0)": 0.842501163482666, "(10, 16)": 0.842501163482666, "(12, 0)": 0.842501163482666, "(12, 16)": 0.898553192615509, "(14, 0)": 0.7685403823852539, "(14, 16)": 0.7685403823852539, "(16, 0)": 0.7685403823852539, "(16, 16)": 0.7685403823852539, "(18, 0)": 0.842501163482666, "(18, 16)": 0.898553192615509, "(20, 0)": 0.898553192615509, "(20, 16)": 0.7827478647232056, "(22, 0)": 0.7685403823852539, "(22, 16)": 0.7685403823852539, "(24, 0)": 0.7685403823852539, "(24, 16)": 0.7685403823852539, "(26, 0)": 0.7685403823852539, "(26, 16)": 0.7685403823852539, "(28, 0)": 0.7685403823852539, "(28, 16)": 0.7685403823852539, "(30, 0)": 0.7685403823852539, "(30, 16)": 0.7685403823852539}, "r_span": [660, 773], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0010033249855041504}}]}, {"id": "3885", "source_id": "13818", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 105 words:\n\nHannah Rose recently spoke to Entertainment Weekly about her brief time on Survivor 45. She revealed that hunger and lack of sleep were the main reasons for her quick exit from the game. Despite facing backlash online, Hannah maintains that she didn't take someone else's spot and wanted to be on the show. The interview provides additional insight into her experience on the island.", "response_spans": [[0, 431]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5845115780830383, "(0, 16)": 0.5845115780830383, "(2, 0)": 0.7534030675888062, "(2, 16)": 0.5845115780830383, "(4, 0)": 0.5845115780830383, "(4, 16)": 0.5845115780830383, "(6, 0)": 0.5845115780830383, "(6, 16)": 0.8703306317329407, "(8, 0)": 0.6632826328277588, "(8, 16)": 0.5845115780830383, "(10, 0)": 0.7534030675888062, "(10, 16)": 0.8372490406036377, "(12, 0)": 0.8372490406036377, "(12, 16)": 0.8372490406036377, "(14, 0)": 0.8364344239234924, "(14, 16)": 0.8372490406036377, "(16, 0)": 0.8703306317329407, "(16, 16)": 0.8364344239234924, "(18, 0)": 0.8364344239234924, "(18, 16)": 0.8703306317329407, "(20, 0)": 0.8703306317329407, "(20, 16)": 0.8364344239234924, "(22, 0)": 0.8364344239234924, "(22, 16)": 0.8364344239234924, "(24, 0)": 0.7534030675888062, "(24, 16)": 0.8703306317329407, "(26, 0)": 0.8364344239234924, "(26, 16)": 0.8364344239234924, "(28, 0)": 0.8364344239234924, "(28, 16)": 0.8364344239234924, "(30, 0)": 0.8364344239234924, "(30, 16)": 0.8364344239234924}, "r_span": [685, 786], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009847283363342285}}]}, {"id": "3915", "source_id": "13823", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 385, "end": 452, "text": "are part of a larger deployment of 2,000 U.S. troops to the region.", "meta": "Introduction of new information", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the news in 89 words:\n\nU.S. troops from two Texas bases, Fort Cavazos in Killeen and Fort Bliss in El Paso, are deploying to the Middle East to protect against drone and rocket attacks. Nearly 100 soldiers from Fort Bliss will staff a Terminal High Altitude Area Defense (THAAD) System, while the rest will join air defense headquarters elements. The 900 soldiers are part of a larger deployment of 2,000 U.S. troops to the region.", "response_spans": [[0, 452]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5669357776641846, "(0, 16)": 0.5669357776641846, "(2, 0)": 0.5669357776641846, "(2, 16)": 0.5669357776641846, "(4, 0)": 0.5669357776641846, "(4, 16)": 0.5669357776641846, "(6, 0)": 0.5669357776641846, "(6, 16)": 0.9169162511825562, "(8, 0)": 0.5669357776641846, "(8, 16)": 0.5669357776641846, "(10, 0)": 0.5669357776641846, "(10, 16)": 0.5669357776641846, "(12, 0)": 0.8685106039047241, "(12, 16)": 0.8685106039047241, "(14, 0)": 0.5669357776641846, "(14, 16)": 0.9169162511825562, "(16, 0)": 0.8685106039047241, "(16, 16)": 0.5669357776641846, "(18, 0)": 0.5669357776641846, "(18, 16)": 0.8685106039047241, "(20, 0)": 0.8685106039047241, "(20, 16)": 0.8685106039047241, "(22, 0)": 0.8685106039047241, "(22, 16)": 0.9169162511825562, "(24, 0)": 0.8685106039047241, "(24, 16)": 0.8685106039047241, "(26, 0)": 0.8685106039047241, "(26, 16)": 0.8685106039047241, "(28, 0)": 0.8685106039047241, "(28, 16)": 0.5669357776641846, "(30, 0)": 0.8685106039047241, "(30, 16)": 0.8685106039047241}, "r_span": [597, 722], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -8.89897346496582e-05}}]}, {"id": "3939", "source_id": "13827", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 84 words:\n\nBig Brother 25 spoilers indicate that the house wants Bowie Jane to backdoor Cameron Hardin, but she hesitates due to his competitive prowess. Cameron wants Bowie to target Cory Wurthinger, but Bowie is unsure. Cory approaches Bowie about backdooring Cameron, but Bowie declines. This week's Power of Veto competition will determine who stays on the block.", "response_spans": [[0, 403]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6845405697822571, "(0, 16)": 0.6845405697822571, "(2, 0)": 0.6845405697822571, "(2, 16)": 0.6845405697822571, "(4, 0)": 0.6845405697822571, "(4, 16)": 0.6845405697822571, "(6, 0)": 0.8822649121284485, "(6, 16)": 0.8951560258865356, "(8, 0)": 0.7407621145248413, "(8, 16)": 0.7407621145248413, "(10, 0)": 0.8822649121284485, "(10, 16)": 0.8822649121284485, "(12, 0)": 0.7407621145248413, "(12, 16)": 0.7407621145248413, "(14, 0)": 0.7407621145248413, "(14, 16)": 0.8951560258865356, "(16, 0)": 0.8951560258865356, "(16, 16)": 0.7407621145248413, "(18, 0)": 0.7407621145248413, "(18, 16)": 0.8951560258865356, "(20, 0)": 0.8951560258865356, "(20, 16)": 0.7407621145248413, "(22, 0)": 0.7407621145248413, "(22, 16)": 0.7407621145248413, "(24, 0)": 0.7407621145248413, "(24, 16)": 0.7407621145248413, "(26, 0)": 0.7407621145248413, "(26, 16)": 0.7407621145248413, "(28, 0)": 0.7407621145248413, "(28, 16)": 0.7407621145248413, "(30, 0)": 0.7407621145248413, "(30, 16)": 0.7407621145248413}, "r_span": [557, 666], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0021927952766418457}}]}, {"id": "3951", "source_id": "13829", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On Big Brother 25, the houseguests expressed regret over voting out Cameron Hardin, who won several challenges before being backdoored. The new Head of Household, Jag Bains, nominated two players for eviction without revealing his identity, causing frustration among the others. A Double Veto take place in the upcoming week, which could greatly impact the game. Meanwhile, Blue Kim, who was nominated by Jag, has a chance to save herself and should tune in to the live feeds for clues. Former Big Brother player Michael Bruner got married on Friday the 13th, and Cameron gave his exit interview, sharing his thoughts on the current gameplay.", "response_spans": [[0, 512], [494, 642]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.702560544013977, "(0, 16)": 0.702560544013977, "(2, 0)": 0.702560544013977, "(2, 16)": 0.702560544013977, "(4, 0)": 0.702560544013977, "(4, 16)": 0.702560544013977, "(6, 0)": 0.702560544013977, "(6, 16)": 0.8203692436218262, "(8, 0)": 0.702560544013977, "(8, 16)": 0.702560544013977, "(10, 0)": 0.702560544013977, "(10, 16)": 0.702560544013977, "(12, 0)": 0.8133082389831543, "(12, 16)": 0.8484210968017578, "(14, 0)": 0.8484210968017578, "(14, 16)": 0.8203692436218262, "(16, 0)": 0.8203692436218262, "(16, 16)": 0.8484210968017578, "(18, 0)": 0.702560544013977, "(18, 16)": 0.8203692436218262, "(20, 0)": 0.8484210968017578, "(20, 16)": 0.8133082389831543, "(22, 0)": 0.8484210968017578, "(22, 16)": 0.8203692436218262, "(24, 0)": 0.702560544013977, "(24, 16)": 0.8484210968017578, "(26, 0)": 0.8484210968017578, "(26, 16)": 0.8484210968017578, "(28, 0)": 0.8484210968017578, "(28, 16)": 0.8133082389831543, "(30, 0)": 0.8484210968017578, "(30, 16)": 0.8484210968017578}, "r_span": [693, 812], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00240170955657959}}, {"prompt_attention_score": {"(0, 0)": 0.8505864143371582, "(0, 16)": 0.8505864143371582, "(2, 0)": 0.8505864143371582, "(2, 16)": 0.8505864143371582, "(4, 0)": 0.8505864143371582, "(4, 16)": 0.8505864143371582, "(6, 0)": 0.8505864143371582, "(6, 16)": 0.5758124589920044, "(8, 0)": 0.8505864143371582, "(8, 16)": 0.8505864143371582, "(10, 0)": 0.8505864143371582, "(10, 16)": 0.8505864143371582, "(12, 0)": 0.8505864143371582, "(12, 16)": 0.8505864143371582, "(14, 0)": 0.5108004808425903, "(14, 16)": 0.8505864143371582, "(16, 0)": 0.8505864143371582, "(16, 16)": 0.8505864143371582, "(18, 0)": 0.8505864143371582, "(18, 16)": 0.8505864143371582, "(20, 0)": 0.8505864143371582, "(20, 16)": 0.5108004808425903, "(22, 0)": 0.5381631851196289, "(22, 16)": 0.8505864143371582, "(24, 0)": 0.8505864143371582, "(24, 16)": 0.8505864143371582, "(26, 0)": 0.5381631851196289, "(26, 16)": 0.8505864143371582, "(28, 0)": 0.5381631851196289, "(28, 16)": 0.5381631851196289, "(30, 0)": 0.5381631851196289, "(30, 16)": 0.5381631851196289}, "r_span": [809, 842], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 7.301568984985352e-05}}]}, {"id": "3981", "source_id": "13834", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 106 words:\n\nBig Brother 25 spoilers reveal that Jag Bains won the Power of Veto, leading to a potential backdoor plan. Bowie Jane nominated Felicia Cannon and Cirie Fields for eviction, but Jag may use the Power of Veto to save one of them. The Veto Meeting is scheduled for Monday, with fireworks expected. Cameron Hardin is in a difficult position and may be at risk of being backdoored. The episode schedule for Big Brother 25 has been released, and Peacock has announced the cast list for The Traitors Season 2, featuring former reality TV stars.", "response_spans": [[0, 46], [48, 551], [533, 586]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4051622152328491, "(0, 16)": 0.4628727436065674, "(2, 0)": 0.4628727436065674, "(2, 16)": 0.4628727436065674, "(4, 0)": 0.4628727436065674, "(4, 16)": 0.4051622152328491, "(6, 0)": 0.4628727436065674, "(6, 16)": 0.4729248285293579, "(8, 0)": 0.4051622152328491, "(8, 16)": 0.4051622152328491, "(10, 0)": 0.4729248285293579, "(10, 16)": 0.4628727436065674, "(12, 0)": 0.5105274319648743, "(12, 16)": 0.4729248285293579, "(14, 0)": 0.5105274319648743, "(14, 16)": 0.4729248285293579, "(16, 0)": 0.4729248285293579, "(16, 16)": 0.5105274319648743, "(18, 0)": 0.447933554649353, "(18, 16)": 0.4729248285293579, "(20, 0)": 0.4729248285293579, "(20, 16)": 0.5105274319648743, "(22, 0)": 0.5105274319648743, "(22, 16)": 0.4729248285293579, "(24, 0)": 0.5105274319648743, "(24, 16)": 0.4729248285293579, "(26, 0)": 0.5105274319648743, "(26, 16)": 0.5105274319648743, "(28, 0)": 0.5105274319648743, "(28, 16)": 0.5105274319648743, "(30, 0)": 0.5105274319648743, "(30, 16)": 0.5105274319648743}, "r_span": [663, 677], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0001386404037475586}}, {"prompt_attention_score": {"(0, 0)": 0.8283114433288574, "(0, 16)": 0.8283114433288574, "(2, 0)": 0.8283114433288574, "(2, 16)": 0.8283114433288574, "(4, 0)": 0.8283114433288574, "(4, 16)": 0.7196110486984253, "(6, 0)": 0.8283114433288574, "(6, 16)": 0.8648171424865723, "(8, 0)": 0.7722172737121582, "(8, 16)": 0.8283114433288574, "(10, 0)": 0.8283114433288574, "(10, 16)": 0.8283114433288574, "(12, 0)": 0.813564658164978, "(12, 16)": 0.7722172737121582, "(14, 0)": 0.813564658164978, "(14, 16)": 0.8283114433288574, "(16, 0)": 0.7722172737121582, "(16, 16)": 0.813564658164978, "(18, 0)": 0.813564658164978, "(18, 16)": 0.8648171424865723, "(20, 0)": 0.7722172737121582, "(20, 16)": 0.813564658164978, "(22, 0)": 0.813564658164978, "(22, 16)": 0.7722172737121582, "(24, 0)": 0.7722172737121582, "(24, 16)": 0.813564658164978, "(26, 0)": 0.813564658164978, "(26, 16)": 0.813564658164978, "(28, 0)": 0.813564658164978, "(28, 16)": 0.813564658164978, "(30, 0)": 0.813564658164978, "(30, 16)": 0.813564658164978}, "r_span": [679, 806], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001506507396697998}}, {"prompt_attention_score": {"(0, 0)": 0.5052536129951477, "(0, 16)": 0.4442931115627289, "(2, 0)": 0.5052536129951477, "(2, 16)": 0.4442931115627289, "(4, 0)": 0.5052536129951477, "(4, 16)": 0.6819185614585876, "(6, 0)": 0.5052536129951477, "(6, 16)": 0.6819185614585876, "(8, 0)": 0.6819185614585876, "(8, 16)": 0.4442931115627289, "(10, 0)": 0.6819185614585876, "(10, 16)": 0.6819185614585876, "(12, 0)": 0.6819185614585876, "(12, 16)": 0.6819185614585876, "(14, 0)": 0.4858362674713135, "(14, 16)": 0.6819185614585876, "(16, 0)": 0.6819185614585876, "(16, 16)": 0.6819185614585876, "(18, 0)": 0.4858362674713135, "(18, 16)": 0.6819185614585876, "(20, 0)": 0.6819185614585876, "(20, 16)": 0.4858362674713135, "(22, 0)": 0.4858362674713135, "(22, 16)": 0.6819185614585876, "(24, 0)": 0.4442931115627289, "(24, 16)": 0.6819185614585876, "(26, 0)": 0.4858362674713135, "(26, 16)": 0.6819185614585876, "(28, 0)": 0.4858362674713135, "(28, 16)": 0.4858362674713135, "(30, 0)": 0.4858362674713135, "(30, 16)": 0.4858362674713135}, "r_span": [801, 812], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004780888557434082}}]}, {"id": "4011", "source_id": "13839", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the news in 77 words:\n\nElle Marketing Events is offering a $20,000 marketing services grant to small business owners in the US. The grant includes high-level consulting and support to help businesses grow. Application is open until October 31 and the winner will be notified by November 1. To apply, visit ellemarketingandevents.com/salt-city-grant-for-growth.", "response_spans": [[0, 381]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6968803405761719, "(0, 16)": 0.6968803405761719, "(2, 0)": 0.6968803405761719, "(2, 16)": 0.6968803405761719, "(4, 0)": 0.6968803405761719, "(4, 16)": 0.6968803405761719, "(6, 0)": 0.6968803405761719, "(6, 16)": 0.8960623741149902, "(8, 0)": 0.6968803405761719, "(8, 16)": 0.6968803405761719, "(10, 0)": 0.8960623741149902, "(10, 16)": 0.6968803405761719, "(12, 0)": 0.6968803405761719, "(12, 16)": 0.8960623741149902, "(14, 0)": 0.6968803405761719, "(14, 16)": 0.7904360294342041, "(16, 0)": 0.8960623741149902, "(16, 16)": 0.8960623741149902, "(18, 0)": 0.8960623741149902, "(18, 16)": 0.8960623741149902, "(20, 0)": 0.8960623741149902, "(20, 16)": 0.6968803405761719, "(22, 0)": 0.8960623741149902, "(22, 16)": 0.8960623741149902, "(24, 0)": 0.8960623741149902, "(24, 16)": 0.8960623741149902, "(26, 0)": 0.8960623741149902, "(26, 16)": 0.8960623741149902, "(28, 0)": 0.8960623741149902, "(28, 16)": 0.8960623741149902, "(30, 0)": 0.8960623741149902, "(30, 16)": 0.8960623741149902}, "r_span": [587, 694], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000751793384552002}}]}, {"id": "4017", "source_id": "13840", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the news in 79 words:\n\nNew York House Republicans are trying to remove Rep. George Santos from Congress after he was charged with 23 federal crimes, including identity theft and unauthorized use of campaign donors' credit cards. The Republicans argue that Santos is \"not fit to serve\" his constituents. However, Santos has refused to resign and it remains unclear if he will be removed from office despite the attempts by his own party.", "response_spans": [[0, 457]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7724196314811707, "(0, 16)": 0.7724196314811707, "(2, 0)": 0.7724196314811707, "(2, 16)": 0.7724196314811707, "(4, 0)": 0.7724196314811707, "(4, 16)": 0.7724196314811707, "(6, 0)": 0.7724196314811707, "(6, 16)": 0.9296425580978394, "(8, 0)": 0.8050781488418579, "(8, 16)": 0.7724196314811707, "(10, 0)": 0.9296425580978394, "(10, 16)": 0.9296425580978394, "(12, 0)": 0.9296425580978394, "(12, 16)": 0.9296425580978394, "(14, 0)": 0.9296425580978394, "(14, 16)": 0.9296425580978394, "(16, 0)": 0.9296425580978394, "(16, 16)": 0.9296425580978394, "(18, 0)": 0.9296425580978394, "(18, 16)": 0.9296425580978394, "(20, 0)": 0.9296425580978394, "(20, 16)": 0.9296425580978394, "(22, 0)": 0.9296425580978394, "(22, 16)": 0.9296425580978394, "(24, 0)": 0.9296425580978394, "(24, 16)": 0.9296425580978394, "(26, 0)": 0.9296425580978394, "(26, 16)": 0.9296425580978394, "(28, 0)": 0.9296425580978394, "(28, 16)": 0.9296425580978394, "(30, 0)": 0.9296425580978394, "(30, 16)": 0.9296425580978394}, "r_span": [459, 563], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00041937828063964844}}]}, {"id": "4029", "source_id": "13842", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 107 words:\n\nJeff Probst, the host of Survivor, has clarified the sit-out rules for the current season after fans expressed confusion. Castaways cannot sit out consecutive challenges, and anyone who does will have to participate in the next challenge. This rule change was necessitated by the shorter season length and the frequency of castaways sitting out. The change comes after Claire Rafson from Season 44 sat out three consecutive Immunity Challenges, leading to backlash from fans and her tribemates. New episodes of Survivor are now 90 minutes long and air on Wednesdays at 8/7c on CBS.", "response_spans": [[0, 46], [48, 558], [543, 629]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4363592267036438, "(0, 16)": 0.4363592267036438, "(2, 0)": 0.5164815187454224, "(2, 16)": 0.5164815187454224, "(4, 0)": 0.5164815187454224, "(4, 16)": 0.4363592267036438, "(6, 0)": 0.4363592267036438, "(6, 16)": 0.4761861562728882, "(8, 0)": 0.4363592267036438, "(8, 16)": 0.4363592267036438, "(10, 0)": 0.4761861562728882, "(10, 16)": 0.4363592267036438, "(12, 0)": 0.4363592267036438, "(12, 16)": 0.4761861562728882, "(14, 0)": 0.4363592267036438, "(14, 16)": 0.4761861562728882, "(16, 0)": 0.4761861562728882, "(16, 16)": 0.4363592267036438, "(18, 0)": 0.4363592267036438, "(18, 16)": 0.4761861562728882, "(20, 0)": 0.4761861562728882, "(20, 16)": 0.4363592267036438, "(22, 0)": 0.4363592267036438, "(22, 16)": 0.4761861562728882, "(24, 0)": 0.4363592267036438, "(24, 16)": 0.4761861562728882, "(26, 0)": 0.4363592267036438, "(26, 16)": 0.47995734214782715, "(28, 0)": 0.4363592267036438, "(28, 16)": 0.4363592267036438, "(30, 0)": 0.4363592267036438, "(30, 16)": 0.4363592267036438}, "r_span": [699, 713], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00029581785202026367}}, {"prompt_attention_score": {"(0, 0)": 0.7401357889175415, "(0, 16)": 0.7113386392593384, "(2, 0)": 0.7113386392593384, "(2, 16)": 0.7113386392593384, "(4, 0)": 0.7401357889175415, "(4, 16)": 0.7113386392593384, "(6, 0)": 0.7113386392593384, "(6, 16)": 0.8787026405334473, "(8, 0)": 0.7401357889175415, "(8, 16)": 0.7113386392593384, "(10, 0)": 0.7401357889175415, "(10, 16)": 0.7401357889175415, "(12, 0)": 0.7401357889175415, "(12, 16)": 0.8805131912231445, "(14, 0)": 0.7113386392593384, "(14, 16)": 0.7897374629974365, "(16, 0)": 0.8787026405334473, "(16, 16)": 0.7113386392593384, "(18, 0)": 0.7113386392593384, "(18, 16)": 0.8805131912231445, "(20, 0)": 0.8805131912231445, "(20, 16)": 0.7113386392593384, "(22, 0)": 0.7113386392593384, "(22, 16)": 0.8805131912231445, "(24, 0)": 0.7113386392593384, "(24, 16)": 0.8787026405334473, "(26, 0)": 0.7897374629974365, "(26, 16)": 0.7113386392593384, "(28, 0)": 0.7897374629974365, "(28, 16)": 0.7113386392593384, "(30, 0)": 0.7113386392593384, "(30, 16)": 0.7897374629974365}, "r_span": [715, 829], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008223056793212891}}, {"prompt_attention_score": {"(0, 0)": 0.6134269833564758, "(0, 16)": 0.6753029227256775, "(2, 0)": 0.6753029227256775, "(2, 16)": 0.6753029227256775, "(4, 0)": 0.6753029227256775, "(4, 16)": 0.6753029227256775, "(6, 0)": 0.6753029227256775, "(6, 16)": 0.6779541969299316, "(8, 0)": 0.6753029227256775, "(8, 16)": 0.6753029227256775, "(10, 0)": 0.6753029227256775, "(10, 16)": 0.6753029227256775, "(12, 0)": 0.6753029227256775, "(12, 16)": 0.6753029227256775, "(14, 0)": 0.6753029227256775, "(14, 16)": 0.6753029227256775, "(16, 0)": 0.6753029227256775, "(16, 16)": 0.6753029227256775, "(18, 0)": 0.6753029227256775, "(18, 16)": 0.6753029227256775, "(20, 0)": 0.6779541969299316, "(20, 16)": 0.6753029227256775, "(22, 0)": 0.6753029227256775, "(22, 16)": 0.6134269833564758, "(24, 0)": 0.6753029227256775, "(24, 16)": 0.6779541969299316, "(26, 0)": 0.6779541969299316, "(26, 16)": 0.6753029227256775, "(28, 0)": 0.6779541969299316, "(28, 16)": 0.6753029227256775, "(30, 0)": 0.6753029227256775, "(30, 16)": 0.6779541969299316}, "r_span": [827, 854], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006226301193237305}}]}, {"id": "4035", "source_id": "13843", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 89 words:\n\nOn \"The Young and the Restless,\" Nick Newman forces Sally Spectra to choose between him and his brother Adam. Despite having feelings for both, Sally must make a decision that is best for her future. The brothers fight, and Sally intervenes, demanding she can't choose between them. Her decision will shock fans. Which Newman brother will Sally pick?", "response_spans": [[0, 397]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7986600399017334, "(0, 16)": 0.7986600399017334, "(2, 0)": 0.7986600399017334, "(2, 16)": 0.7986600399017334, "(4, 0)": 0.7986600399017334, "(4, 16)": 0.7986600399017334, "(6, 0)": 0.7986600399017334, "(6, 16)": 0.8624538779258728, "(8, 0)": 0.7986600399017334, "(8, 16)": 0.7986600399017334, "(10, 0)": 0.7986600399017334, "(10, 16)": 0.7986600399017334, "(12, 0)": 0.7986600399017334, "(12, 16)": 0.8624538779258728, "(14, 0)": 0.8305670619010925, "(14, 16)": 0.7986600399017334, "(16, 0)": 0.8624538779258728, "(16, 16)": 0.8305670619010925, "(18, 0)": 0.7986600399017334, "(18, 16)": 0.8624538779258728, "(20, 0)": 0.8624538779258728, "(20, 16)": 0.8305670619010925, "(22, 0)": 0.8305670619010925, "(22, 16)": 0.8624538779258728, "(24, 0)": 0.8305670619010925, "(24, 16)": 0.8624538779258728, "(26, 0)": 0.8305670619010925, "(26, 16)": 0.8624538779258728, "(28, 0)": 0.8305670619010925, "(28, 16)": 0.8305670619010925, "(30, 0)": 0.8305670619010925, "(30, 16)": 0.8305670619010925}, "r_span": [532, 627], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.003819704055786133}}]}, {"id": "4053", "source_id": "13846", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Scientists at Rice University have developed a novel implant, HAMMR, that can potentially cure cancer in just 60 days. The implant delivers immunotherapy drugs in a closed-loop system, providing real-time data on the tumor environment to guide more effective and personalized treatments. The first clinical trial will focus on ovarian cancer, with hopes of expanding to other peritoneal cancers. This technology offers a significant breakthrough in cancer treatment, with the potential to provide more accurate and targeted drug administration, leading to improved patient outcomes.", "response_spans": [[0, 510], [497, 582]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8788625001907349, "(0, 16)": 0.8788625001907349, "(2, 0)": 0.8788625001907349, "(2, 16)": 0.8788625001907349, "(4, 0)": 0.8788625001907349, "(4, 16)": 0.7867627143859863, "(6, 0)": 0.8788625001907349, "(6, 16)": 0.9052866697311401, "(8, 0)": 0.7867627143859863, "(8, 16)": 0.8788625001907349, "(10, 0)": 0.7867627143859863, "(10, 16)": 0.7867627143859863, "(12, 0)": 0.7867627143859863, "(12, 16)": 0.9052866697311401, "(14, 0)": 0.9021949768066406, "(14, 16)": 0.7867627143859863, "(16, 0)": 0.9021949768066406, "(16, 16)": 0.9021949768066406, "(18, 0)": 0.9021949768066406, "(18, 16)": 0.9052866697311401, "(20, 0)": 0.9021949768066406, "(20, 16)": 0.9021949768066406, "(22, 0)": 0.9021949768066406, "(22, 16)": 0.9021949768066406, "(24, 0)": 0.9021949768066406, "(24, 16)": 0.9021949768066406, "(26, 0)": 0.9021949768066406, "(26, 16)": 0.9021949768066406, "(28, 0)": 0.9021949768066406, "(28, 16)": 0.9021949768066406, "(30, 0)": 0.9021949768066406, "(30, 16)": 0.9021949768066406}, "r_span": [634, 748], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012562274932861328}}, {"prompt_attention_score": {"(0, 0)": 0.6202435493469238, "(0, 16)": 0.6202435493469238, "(2, 0)": 0.6202435493469238, "(2, 16)": 0.5633982419967651, "(4, 0)": 0.6202435493469238, "(4, 16)": 0.5633982419967651, "(6, 0)": 0.6301159858703613, "(6, 16)": 0.6673017740249634, "(8, 0)": 0.5633982419967651, "(8, 16)": 0.6023436784744263, "(10, 0)": 0.5633982419967651, "(10, 16)": 0.6202435493469238, "(12, 0)": 0.6023436784744263, "(12, 16)": 0.6673017740249634, "(14, 0)": 0.6023436784744263, "(14, 16)": 0.6673017740249634, "(16, 0)": 0.5633982419967651, "(16, 16)": 0.5633982419967651, "(18, 0)": 0.6023436784744263, "(18, 16)": 0.6673017740249634, "(20, 0)": 0.6673017740249634, "(20, 16)": 0.6023436784744263, "(22, 0)": 0.6023436784744263, "(22, 16)": 0.6673017740249634, "(24, 0)": 0.6023436784744263, "(24, 16)": 0.6673017740249634, "(26, 0)": 0.6023436784744263, "(26, 16)": 0.6023436784744263, "(28, 0)": 0.6023436784744263, "(28, 16)": 0.6023436784744263, "(30, 0)": 0.6023436784744263, "(30, 16)": 0.6023436784744263}, "r_span": [747, 761], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -5.4836273193359375e-05}}]}, {"id": "4065", "source_id": "13848", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 180, "end": 254, "text": "Dolphins' current starting defensive ends have combined for only 7.5 sacks", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nCombination of sacks for Dolphins current starting defensive ends was not mentioned in the source content.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "The Miami Dolphins are considering trading for Washington Commanders defensive end Chase Young to bolster their struggling defensive line. Young has 5 sacks this season, while the Dolphins' current starting defensive ends have combined for only 7.5 sacks. Trading for Young would provide an immediate upgrade and give them more flexibility in extending his contract. However, it would also add to the team's already strained cap situation.", "response_spans": [[0, 439]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7765790224075317, "(0, 16)": 0.7765790224075317, "(2, 0)": 0.7765790224075317, "(2, 16)": 0.7765790224075317, "(4, 0)": 0.7765790224075317, "(4, 16)": 0.7765790224075317, "(6, 0)": 0.7765790224075317, "(6, 16)": 0.7556734085083008, "(8, 0)": 0.7556734085083008, "(8, 16)": 0.7765790224075317, "(10, 0)": 0.7556734085083008, "(10, 16)": 0.7765790224075317, "(12, 0)": 0.7556734085083008, "(12, 16)": 0.7556734085083008, "(14, 0)": 0.7617745995521545, "(14, 16)": 0.7765790224075317, "(16, 0)": 0.7617745995521545, "(16, 16)": 0.7556734085083008, "(18, 0)": 0.7765790224075317, "(18, 16)": 0.7617745995521545, "(20, 0)": 0.7617745995521545, "(20, 16)": 0.7617745995521545, "(22, 0)": 0.7617745995521545, "(22, 16)": 0.7617745995521545, "(24, 0)": 0.7617745995521545, "(24, 16)": 0.7556734085083008, "(26, 0)": 0.7653193473815918, "(26, 16)": 0.7556734085083008, "(28, 0)": 0.7653193473815918, "(28, 16)": 0.7617745995521545, "(30, 0)": 0.7617745995521545, "(30, 16)": 0.7653193473815918}, "r_span": [664, 760], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.001320958137512207}}]}, {"id": "4077", "source_id": "13850", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "In 1988, a woman's body was found in a dumpster in Jenkins County, Georgia. Using advanced DNA testing technology, the Georgia Bureau of Investigation (GBI) has identified the victim as Chong Un Kim, a 26-year-old Korean immigrant who lived in Hinesville, Georgia. The GBI made the announcement after collaborating with Othram, Inc., a Texas-based DNA testing company. Despite previous attempts to identify the victim through fingerprints and dental records, it wasn't until 2023 that DNA testing led to the breakthrough. The GBI is now appealing to anyone with information about Kim or who may have known him to come forward.", "response_spans": [[0, 507], [489, 626]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7362928986549377, "(0, 16)": 0.7362928986549377, "(2, 0)": 0.8430379629135132, "(2, 16)": 0.7362928986549377, "(4, 0)": 0.7362928986549377, "(4, 16)": 0.7362928986549377, "(6, 0)": 0.8430379629135132, "(6, 16)": 0.9188122153282166, "(8, 0)": 0.7362928986549377, "(8, 16)": 0.7362928986549377, "(10, 0)": 0.8430379629135132, "(10, 16)": 0.8430379629135132, "(12, 0)": 0.8430379629135132, "(12, 16)": 0.9188122153282166, "(14, 0)": 0.8430379629135132, "(14, 16)": 0.9188122153282166, "(16, 0)": 0.9188122153282166, "(16, 16)": 0.8430379629135132, "(18, 0)": 0.7362928986549377, "(18, 16)": 0.9188122153282166, "(20, 0)": 0.8430379629135132, "(20, 16)": 0.8430379629135132, "(22, 0)": 0.8430379629135132, "(22, 16)": 0.7552366852760315, "(24, 0)": 0.7552366852760315, "(24, 16)": 0.8430379629135132, "(26, 0)": 0.9188122153282166, "(26, 16)": 0.7552366852760315, "(28, 0)": 0.9188122153282166, "(28, 16)": 0.8430379629135132, "(30, 0)": 0.7552366852760315, "(30, 16)": 0.9188122153282166}, "r_span": [635, 763], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00012040138244628906}}, {"prompt_attention_score": {"(0, 0)": 0.7224259376525879, "(0, 16)": 0.6346149444580078, "(2, 0)": 0.6346149444580078, "(2, 16)": 0.6346149444580078, "(4, 0)": 0.6346149444580078, "(4, 16)": 0.6346149444580078, "(6, 0)": 0.7224259376525879, "(6, 16)": 0.6346149444580078, "(8, 0)": 0.6346149444580078, "(8, 16)": 0.6346149444580078, "(10, 0)": 0.6346149444580078, "(10, 16)": 0.6346149444580078, "(12, 0)": 0.6346149444580078, "(12, 16)": 0.6346149444580078, "(14, 0)": 0.5119091272354126, "(14, 16)": 0.6346149444580078, "(16, 0)": 0.6346149444580078, "(16, 16)": 0.5691591501235962, "(18, 0)": 0.6346149444580078, "(18, 16)": 0.7224259376525879, "(20, 0)": 0.6346149444580078, "(20, 16)": 0.7224259376525879, "(22, 0)": 0.7224259376525879, "(22, 16)": 0.6346149444580078, "(24, 0)": 0.5119091272354126, "(24, 16)": 0.7224259376525879, "(26, 0)": 0.5691591501235962, "(26, 16)": 0.5119091272354126, "(28, 0)": 0.5691591501235962, "(28, 16)": 0.7224259376525879, "(30, 0)": 0.5810068249702454, "(30, 16)": 0.5691591501235962}, "r_span": [760, 789], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00012671947479248047}}]}, {"id": "4119", "source_id": "13857", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 492, "end": 507, "text": "$750,000 prize.", "meta": "LOW INTRODUCTION OF NEW INFORMATION\nThe amount of grand prize was not specified in the source content.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the article in 113 words:\n\nBig Brother 25 has reached its final five players, and Matt Klotz has won the HOH competition. This gives him the power to nominate two housemates for eviction. The most likely nominees are Felicia Cannon, Cirie Fields, and Bowie Jane. The POV competition will take place this week, giving the winner the chance to save one of the nominated players. With only two weeks left in the game, the stakes are high as the houseguests fight to win the $750,000 prize.", "response_spans": [[0, 507]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6081358194351196, "(0, 16)": 0.7053695917129517, "(2, 0)": 0.7053695917129517, "(2, 16)": 0.7053695917129517, "(4, 0)": 0.7053695917129517, "(4, 16)": 0.6081358194351196, "(6, 0)": 0.7053695917129517, "(6, 16)": 0.7888137102127075, "(8, 0)": 0.7888137102127075, "(8, 16)": 0.6081358194351196, "(10, 0)": 0.7888137102127075, "(10, 16)": 0.8360125422477722, "(12, 0)": 0.6081358194351196, "(12, 16)": 0.8360125422477722, "(14, 0)": 0.6081358194351196, "(14, 16)": 0.7888137102127075, "(16, 0)": 0.7888137102127075, "(16, 16)": 0.6081358194351196, "(18, 0)": 0.6081358194351196, "(18, 16)": 0.8360125422477722, "(20, 0)": 0.8360125422477722, "(20, 16)": 0.6081358194351196, "(22, 0)": 0.6081358194351196, "(22, 16)": 0.8360125422477722, "(24, 0)": 0.7888137102127075, "(24, 16)": 0.8932018280029297, "(26, 0)": 0.7888137102127075, "(26, 16)": 0.7888137102127075, "(28, 0)": 0.6081358194351196, "(28, 16)": 0.6081358194351196, "(30, 0)": 0.6081358194351196, "(30, 16)": 0.7888137102127075}, "r_span": [726, 861], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00019729137420654297}}]}, {"id": "4197", "source_id": "13870", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 95 words:\n\nTameka Raymond, ex-wife of singer Usher, joined Ariel Shaw, MBA of Southern Crescent Women In Business for a fireside chat about her new memoir \"Here I Stand...In A Beautiful State.\" The event allowed attendees to learn more about Raymond's role as a businesswoman, mother, and philanthropist beyond her public divorce. Raymond discussed balancing motherhood and entrepreneurship, her foundation, and the inspiration behind her memoir, which includes songs that represented different times in her life. The event ended with a Q&A, book signing, and photo opportunities with Raymond.", "response_spans": [[0, 45], [47, 553], [537, 629]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.47870442271232605, "(0, 16)": 0.47870442271232605, "(2, 0)": 0.47870442271232605, "(2, 16)": 0.47870442271232605, "(4, 0)": 0.47870442271232605, "(4, 16)": 0.47870442271232605, "(6, 0)": 0.47870442271232605, "(6, 16)": 0.5509499907493591, "(8, 0)": 0.47870442271232605, "(8, 16)": 0.47870442271232605, "(10, 0)": 0.5509499907493591, "(10, 16)": 0.488159716129303, "(12, 0)": 0.488159716129303, "(12, 16)": 0.5509499907493591, "(14, 0)": 0.47870442271232605, "(14, 16)": 0.5509499907493591, "(16, 0)": 0.5509499907493591, "(16, 16)": 0.4270534813404083, "(18, 0)": 0.47870442271232605, "(18, 16)": 0.5509499907493591, "(20, 0)": 0.5509499907493591, "(20, 16)": 0.4270534813404083, "(22, 0)": 0.4270534813404083, "(22, 16)": 0.5509499907493591, "(24, 0)": 0.4270534813404083, "(24, 16)": 0.5509499907493591, "(26, 0)": 0.4270534813404083, "(26, 16)": 0.4270534813404083, "(28, 0)": 0.4270534813404083, "(28, 16)": 0.47870442271232605, "(30, 0)": 0.4270534813404083, "(30, 16)": 0.4270534813404083}, "r_span": [696, 709], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00010067224502563477}}, {"prompt_attention_score": {"(0, 0)": 0.5644087791442871, "(0, 16)": 0.5644087791442871, "(2, 0)": 0.5644087791442871, "(2, 16)": 0.5644087791442871, "(4, 0)": 0.5644087791442871, "(4, 16)": 0.5644087791442871, "(6, 0)": 0.5644087791442871, "(6, 16)": 0.7943099141120911, "(8, 0)": 0.7306663990020752, "(8, 16)": 0.5644087791442871, "(10, 0)": 0.7306663990020752, "(10, 16)": 0.7943099141120911, "(12, 0)": 0.7943099141120911, "(12, 16)": 0.7943099141120911, "(14, 0)": 0.7943099141120911, "(14, 16)": 0.7306663990020752, "(16, 0)": 0.7943099141120911, "(16, 16)": 0.5644087791442871, "(18, 0)": 0.8265784978866577, "(18, 16)": 0.7306663990020752, "(20, 0)": 0.7943099141120911, "(20, 16)": 0.5437393188476562, "(22, 0)": 0.8265784978866577, "(22, 16)": 0.7943099141120911, "(24, 0)": 0.8265784978866577, "(24, 16)": 0.7306663990020752, "(26, 0)": 0.8265784978866577, "(26, 16)": 0.8265784978866577, "(28, 0)": 0.8265784978866577, "(28, 16)": 0.8265784978866577, "(30, 0)": 0.8265784978866577, "(30, 16)": 0.8265784978866577}, "r_span": [711, 831], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004588961601257324}}, {"prompt_attention_score": {"(0, 0)": 0.4286958575248718, "(0, 16)": 0.4286958575248718, "(2, 0)": 0.4286958575248718, "(2, 16)": 0.4286958575248718, "(4, 0)": 0.4286958575248718, "(4, 16)": 0.4286958575248718, "(6, 0)": 0.4286958575248718, "(6, 16)": 0.5430120229721069, "(8, 0)": 0.4286958575248718, "(8, 16)": 0.4286958575248718, "(10, 0)": 0.4286958575248718, "(10, 16)": 0.5430120229721069, "(12, 0)": 0.598429262638092, "(12, 16)": 0.5430120229721069, "(14, 0)": 0.6257737874984741, "(14, 16)": 0.5430120229721069, "(16, 0)": 0.5430120229721069, "(16, 16)": 0.4286958575248718, "(18, 0)": 0.4286958575248718, "(18, 16)": 0.5430120229721069, "(20, 0)": 0.5430120229721069, "(20, 16)": 0.6257737874984741, "(22, 0)": 0.573290228843689, "(22, 16)": 0.5430120229721069, "(24, 0)": 0.573290228843689, "(24, 16)": 0.47743886709213257, "(26, 0)": 0.573290228843689, "(26, 16)": 0.573290228843689, "(28, 0)": 0.573290228843689, "(28, 16)": 0.573290228843689, "(30, 0)": 0.573290228843689, "(30, 16)": 0.573290228843689}, "r_span": [827, 849], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006676912307739258}}]}, {"id": "4209", "source_id": "13872", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 78 words or less:\n\nThe processing of work permits for migrants will continue even if the federal government shuts down this weekend. The Biden administration has expanded eligibility for Temporary Protected Status to Venezuelan nationals, which may speed up the process for thousands of asylum seekers in New York City. US Citizenship and Immigration Services (USCIS) has taken steps to expedite the application process and is seeking additional funding from Congress to process more work permits and Temporary Protected Status applications.", "response_spans": [[0, 53], [55, 563], [547, 577]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5288987755775452, "(0, 16)": 0.5288987755775452, "(2, 0)": 0.5409730076789856, "(2, 16)": 0.5288987755775452, "(4, 0)": 0.5288987755775452, "(4, 16)": 0.5288987755775452, "(6, 0)": 0.5288987755775452, "(6, 16)": 0.476040780544281, "(8, 0)": 0.5288987755775452, "(8, 16)": 0.5288987755775452, "(10, 0)": 0.476040780544281, "(10, 16)": 0.476040780544281, "(12, 0)": 0.5288987755775452, "(12, 16)": 0.476040780544281, "(14, 0)": 0.5230441093444824, "(14, 16)": 0.476040780544281, "(16, 0)": 0.476040780544281, "(16, 16)": 0.5230441093444824, "(18, 0)": 0.5288987755775452, "(18, 16)": 0.476040780544281, "(20, 0)": 0.476040780544281, "(20, 16)": 0.5409730076789856, "(22, 0)": 0.5230441093444824, "(22, 16)": 0.476040780544281, "(24, 0)": 0.5230441093444824, "(24, 16)": 0.476040780544281, "(26, 0)": 0.5230441093444824, "(26, 16)": 0.5230441093444824, "(28, 0)": 0.5230441093444824, "(28, 16)": 0.5409730076789856, "(30, 0)": 0.5230441093444824, "(30, 16)": 0.5230441093444824}, "r_span": [486, 501], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001077890396118164}}, {"prompt_attention_score": {"(0, 0)": 0.7556929588317871, "(0, 16)": 0.7556929588317871, "(2, 0)": 0.7556929588317871, "(2, 16)": 0.7556929588317871, "(4, 0)": 0.7556929588317871, "(4, 16)": 0.7556929588317871, "(6, 0)": 0.7556929588317871, "(6, 16)": 0.892894983291626, "(8, 0)": 0.7317208647727966, "(8, 16)": 0.7556929588317871, "(10, 0)": 0.7556929588317871, "(10, 16)": 0.7556929588317871, "(12, 0)": 0.892894983291626, "(12, 16)": 0.7317208647727966, "(14, 0)": 0.7317208647727966, "(14, 16)": 0.892894983291626, "(16, 0)": 0.8343088626861572, "(16, 16)": 0.892894983291626, "(18, 0)": 0.892894983291626, "(18, 16)": 0.892894983291626, "(20, 0)": 0.892894983291626, "(20, 16)": 0.7317208647727966, "(22, 0)": 0.892894983291626, "(22, 16)": 0.892894983291626, "(24, 0)": 0.892894983291626, "(24, 16)": 0.892894983291626, "(26, 0)": 0.892894983291626, "(26, 16)": 0.892894983291626, "(28, 0)": 0.892894983291626, "(28, 16)": 0.892894983291626, "(30, 0)": 0.892894983291626, "(30, 16)": 0.892894983291626}, "r_span": [503, 613], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018655061721801758}}, {"prompt_attention_score": {"(0, 0)": 0.5236071348190308, "(0, 16)": 0.5236071348190308, "(2, 0)": 0.5236071348190308, "(2, 16)": 0.5236071348190308, "(4, 0)": 0.5236071348190308, "(4, 16)": 0.5236071348190308, "(6, 0)": 0.5236071348190308, "(6, 16)": 0.5833287835121155, "(8, 0)": 0.5833287835121155, "(8, 16)": 0.5236071348190308, "(10, 0)": 0.5965791940689087, "(10, 16)": 0.5236071348190308, "(12, 0)": 0.5236071348190308, "(12, 16)": 0.5236071348190308, "(14, 0)": 0.5833287835121155, "(14, 16)": 0.5236071348190308, "(16, 0)": 0.5236071348190308, "(16, 16)": 0.5236071348190308, "(18, 0)": 0.5965791940689087, "(18, 16)": 0.5236071348190308, "(20, 0)": 0.5833287835121155, "(20, 16)": 0.5833287835121155, "(22, 0)": 0.5965791940689087, "(22, 16)": 0.5236071348190308, "(24, 0)": 0.5965791940689087, "(24, 16)": 0.5833287835121155, "(26, 0)": 0.5965791940689087, "(26, 16)": 0.5965791940689087, "(28, 0)": 0.5965791940689087, "(28, 16)": 0.5965791940689087, "(30, 0)": 0.5965791940689087, "(30, 16)": 0.5965791940689087}, "r_span": [611, 615], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 6.377696990966797e-05}}]}, {"id": "4221", "source_id": "13874", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Sure, here is a summary of the news within 85 words:\n\nChina has launched its first nuclear-powered guided missile submarines, expanding its military capabilities and boosting its power projection abilities. The submarines can conduct long-range precision strikes against land targets, raising concerns in the US military about China's growing nuclear arsenal. According to the Pentagon, China could have nearly 1000 nuclear warheads by 2030 and is constructing new ICBM silo fields. These developments coincide with China's expanding navy, now the largest in the world, which is expected to grow to 435 ships and submarines by 2030.", "response_spans": [[0, 52], [54, 562], [544, 632]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4648182988166809, "(0, 16)": 0.4648182988166809, "(2, 0)": 0.5537459850311279, "(2, 16)": 0.4648182988166809, "(4, 0)": 0.5537459850311279, "(4, 16)": 0.5537459850311279, "(6, 0)": 0.4648182988166809, "(6, 16)": 0.644823431968689, "(8, 0)": 0.4648182988166809, "(8, 16)": 0.4648182988166809, "(10, 0)": 0.644823431968689, "(10, 16)": 0.644823431968689, "(12, 0)": 0.554036557674408, "(12, 16)": 0.644823431968689, "(14, 0)": 0.4648182988166809, "(14, 16)": 0.644823431968689, "(16, 0)": 0.644823431968689, "(16, 16)": 0.644823431968689, "(18, 0)": 0.644823431968689, "(18, 16)": 0.644823431968689, "(20, 0)": 0.644823431968689, "(20, 16)": 0.4648182988166809, "(22, 0)": 0.644823431968689, "(22, 16)": 0.644823431968689, "(24, 0)": 0.4648182988166809, "(24, 16)": 0.644823431968689, "(26, 0)": 0.644823431968689, "(26, 16)": 0.644823431968689, "(28, 0)": 0.644823431968689, "(28, 16)": 0.4648182988166809, "(30, 0)": 0.644823431968689, "(30, 16)": 0.644823431968689}, "r_span": [533, 549], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005033016204833984}}, {"prompt_attention_score": {"(0, 0)": 0.7963951230049133, "(0, 16)": 0.7963951230049133, "(2, 0)": 0.7963951230049133, "(2, 16)": 0.7963951230049133, "(4, 0)": 0.7963951230049133, "(4, 16)": 0.7963951230049133, "(6, 0)": 0.7963951230049133, "(6, 16)": 0.8985528945922852, "(8, 0)": 0.7963951230049133, "(8, 16)": 0.7963951230049133, "(10, 0)": 0.7963951230049133, "(10, 16)": 0.7963951230049133, "(12, 0)": 0.7963951230049133, "(12, 16)": 0.8518460988998413, "(14, 0)": 0.7963951230049133, "(14, 16)": 0.7963951230049133, "(16, 0)": 0.8985528945922852, "(16, 16)": 0.7963951230049133, "(18, 0)": 0.7963951230049133, "(18, 16)": 0.8518460988998413, "(20, 0)": 0.8985528945922852, "(20, 16)": 0.7963951230049133, "(22, 0)": 0.7691768407821655, "(22, 16)": 0.8518460988998413, "(24, 0)": 0.7963951230049133, "(24, 16)": 0.8985528945922852, "(26, 0)": 0.7691768407821655, "(26, 16)": 0.7691768407821655, "(28, 0)": 0.7691768407821655, "(28, 16)": 0.7963951230049133, "(30, 0)": 0.7691768407821655, "(30, 16)": 0.7691768407821655}, "r_span": [551, 672], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0042838454246521}}, {"prompt_attention_score": {"(0, 0)": 0.6309129595756531, "(0, 16)": 0.6309129595756531, "(2, 0)": 0.6309129595756531, "(2, 16)": 0.6309129595756531, "(4, 0)": 0.6309129595756531, "(4, 16)": 0.6309129595756531, "(6, 0)": 0.6309129595756531, "(6, 16)": 0.647024393081665, "(8, 0)": 0.6309129595756531, "(8, 16)": 0.6309129595756531, "(10, 0)": 0.6309129595756531, "(10, 16)": 0.6309129595756531, "(12, 0)": 0.6309129595756531, "(12, 16)": 0.6309129595756531, "(14, 0)": 0.6309129595756531, "(14, 16)": 0.6309129595756531, "(16, 0)": 0.6309129595756531, "(16, 16)": 0.6309129595756531, "(18, 0)": 0.6309129595756531, "(18, 16)": 0.6309129595756531, "(20, 0)": 0.6309129595756531, "(20, 16)": 0.6309129595756531, "(22, 0)": 0.5954840183258057, "(22, 16)": 0.6309129595756531, "(24, 0)": 0.6309129595756531, "(24, 16)": 0.6309129595756531, "(26, 0)": 0.5954840183258057, "(26, 16)": 0.6309129595756531, "(28, 0)": 0.5954840183258057, "(28, 16)": 0.6309129595756531, "(30, 0)": 0.5954840183258057, "(30, 16)": 0.5954840183258057}, "r_span": [669, 696], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004106760025024414}}]}, {"id": "4227", "source_id": "13875", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Sure, here is a summary of the article in 108 words or less:\n\nThe Social Security Administration has announced a 3.2% increase in benefits for 2024, which will provide an additional $59 per month to average retiree benefits. While this increase is higher than recent years, it is lower than the record 8.7% increase in 2023. The adjustment helps retirees keep up with inflation, but Medicare Part B premiums may offset some of the increase. The Social Security program faces a funding shortfall, and Congress must address this issue to ensure the program's long-term stability.", "response_spans": [[0, 60], [62, 566], [547, 577]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5201200842857361, "(0, 16)": 0.5201200842857361, "(2, 0)": 0.5201200842857361, "(2, 16)": 0.5201200842857361, "(4, 0)": 0.5201200842857361, "(4, 16)": 0.5201200842857361, "(6, 0)": 0.5201200842857361, "(6, 16)": 0.6132495403289795, "(8, 0)": 0.5201200842857361, "(8, 16)": 0.5201200842857361, "(10, 0)": 0.6132495403289795, "(10, 16)": 0.5201200842857361, "(12, 0)": 0.5201200842857361, "(12, 16)": 0.6132495403289795, "(14, 0)": 0.5201200842857361, "(14, 16)": 0.6132495403289795, "(16, 0)": 0.6132495403289795, "(16, 16)": 0.5201200842857361, "(18, 0)": 0.5201200842857361, "(18, 16)": 0.6132495403289795, "(20, 0)": 0.6132495403289795, "(20, 16)": 0.5201200842857361, "(22, 0)": 0.4457818865776062, "(22, 16)": 0.6132495403289795, "(24, 0)": 0.5201200842857361, "(24, 16)": 0.4457818865776062, "(26, 0)": 0.5201200842857361, "(26, 16)": 0.4457818865776062, "(28, 0)": 0.4457818865776062, "(28, 16)": 0.5201200842857361, "(30, 0)": 0.4457818865776062, "(30, 16)": 0.4457818865776062}, "r_span": [754, 773], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005002617835998535}}, {"prompt_attention_score": {"(0, 0)": 0.7782473564147949, "(0, 16)": 0.7782473564147949, "(2, 0)": 0.7782473564147949, "(2, 16)": 0.7782473564147949, "(4, 0)": 0.7782473564147949, "(4, 16)": 0.7782473564147949, "(6, 0)": 0.7782473564147949, "(6, 16)": 0.88539719581604, "(8, 0)": 0.7782473564147949, "(8, 16)": 0.7782473564147949, "(10, 0)": 0.7782473564147949, "(10, 16)": 0.7782473564147949, "(12, 0)": 0.7782473564147949, "(12, 16)": 0.88539719581604, "(14, 0)": 0.7782473564147949, "(14, 16)": 0.7782473564147949, "(16, 0)": 0.88539719581604, "(16, 16)": 0.7782473564147949, "(18, 0)": 0.7782473564147949, "(18, 16)": 0.8061755299568176, "(20, 0)": 0.88539719581604, "(20, 16)": 0.7782473564147949, "(22, 0)": 0.88539719581604, "(22, 16)": 0.8061755299568176, "(24, 0)": 0.7782473564147949, "(24, 16)": 0.88539719581604, "(26, 0)": 0.88539719581604, "(26, 16)": 0.88539719581604, "(28, 0)": 0.88539719581604, "(28, 16)": 0.7782473564147949, "(30, 0)": 0.88539719581604, "(30, 16)": 0.88539719581604}, "r_span": [775, 895], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0014212727546691895}}, {"prompt_attention_score": {"(0, 0)": 0.5104565620422363, "(0, 16)": 0.5104565620422363, "(2, 0)": 0.5104565620422363, "(2, 16)": 0.5104565620422363, "(4, 0)": 0.5104565620422363, "(4, 16)": 0.5104565620422363, "(6, 0)": 0.5371786952018738, "(6, 16)": 0.5371786952018738, "(8, 0)": 0.5104565620422363, "(8, 16)": 0.5104565620422363, "(10, 0)": 0.5104565620422363, "(10, 16)": 0.5104565620422363, "(12, 0)": 0.5104565620422363, "(12, 16)": 0.7212681770324707, "(14, 0)": 0.5104565620422363, "(14, 16)": 0.5104565620422363, "(16, 0)": 0.5104565620422363, "(16, 16)": 0.5104565620422363, "(18, 0)": 0.5104565620422363, "(18, 16)": 0.7212681770324707, "(20, 0)": 0.7212681770324707, "(20, 16)": 0.5104565620422363, "(22, 0)": 0.5104565620422363, "(22, 16)": 0.7212681770324707, "(24, 0)": 0.5104565620422363, "(24, 16)": 0.5371786952018738, "(26, 0)": 0.5104565620422363, "(26, 16)": 0.48577049374580383, "(28, 0)": 0.48577049374580383, "(28, 16)": 0.5104565620422363, "(30, 0)": 0.48577049374580383, "(30, 16)": 0.48577049374580383}, "r_span": [890, 897], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004691481590270996}}]}, {"id": "4263", "source_id": "13881", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 296, "end": 400, "text": "little is known about Wardi, including her physical appearance, clothing, or any distinguishing features", "meta": "EVIDENT CONFLICT:\nAIGC:  \"little is known\" about Wardi, including her physical appearance, clothing, or any distinguishing features\nOriginal: Wardi McDonald stood 5 feet 3 to 5 feet 4 inches tall and weighed 120 to 130 pounds. She had brown hair with red/auburn tint kept short, and brown eyes. She reportedly has a mole on her nose and burns on half of her back.\n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the news in 83 words:\n\nWardi McDonald, 34, disappeared from Detroit in 2001 without a trace. Her last known whereabouts were with her siblings, but no information is available about her personal or professional life. Despite being classified as an endangered missing person, little is known about Wardi, including her physical appearance, clothing, or any distinguishing features. Any information can be reported to the Detroit Police Department.", "response_spans": [[0, 467]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7891373634338379, "(0, 16)": 0.7891373634338379, "(2, 0)": 0.7891373634338379, "(2, 16)": 0.7891373634338379, "(4, 0)": 0.7891373634338379, "(4, 16)": 0.7891373634338379, "(6, 0)": 0.8291934728622437, "(6, 16)": 0.8095791935920715, "(8, 0)": 0.7891373634338379, "(8, 16)": 0.7891373634338379, "(10, 0)": 0.8291934728622437, "(10, 16)": 0.8291934728622437, "(12, 0)": 0.8291934728622437, "(12, 16)": 0.8008980751037598, "(14, 0)": 0.7891373634338379, "(14, 16)": 0.8291934728622437, "(16, 0)": 0.8095791935920715, "(16, 16)": 0.8095791935920715, "(18, 0)": 0.7891373634338379, "(18, 16)": 0.8008980751037598, "(20, 0)": 0.8008980751037598, "(20, 16)": 0.7891373634338379, "(22, 0)": 0.7891373634338379, "(22, 16)": 0.7891373634338379, "(24, 0)": 0.7891373634338379, "(24, 16)": 0.8008980751037598, "(26, 0)": 0.8095791935920715, "(26, 16)": 0.7891373634338379, "(28, 0)": 0.8095791935920715, "(28, 16)": 0.7891373634338379, "(30, 0)": 0.8095791935920715, "(30, 16)": 0.8095791935920715}, "r_span": [534, 639], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015838146209716797}}]}, {"id": "4299", "source_id": "13887", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "The US Air Force has deployed additional F-16 fighter jets to the Middle East to enhance its capabilities and readiness in response to escalating tensions in the region. The 119th Expeditionary Fighter Squadron of the New Jersey Air National Guard will provide contingency response capabilities and deterrence missions. The deployment comes as the US deploys additional personnel to the region amidst the ongoing conflict between Israel and the militant group Hamas. The Air Forces Central Command (AFCENT) operates a formidable fleet of military aircraft, including three squadrons of F-16 fighter jets, two squadrons of A-10 Thunderbolt II aircraft, and one squadron of F-15E Strike Eagle planes.", "response_spans": [[0, 506], [490, 698]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7356914281845093, "(0, 16)": 0.7356914281845093, "(2, 0)": 0.7356914281845093, "(2, 16)": 0.7356914281845093, "(4, 0)": 0.7356914281845093, "(4, 16)": 0.7356914281845093, "(6, 0)": 0.7356914281845093, "(6, 16)": 0.8626368641853333, "(8, 0)": 0.7356914281845093, "(8, 16)": 0.7356914281845093, "(10, 0)": 0.7532857656478882, "(10, 16)": 0.7532857656478882, "(12, 0)": 0.7356914281845093, "(12, 16)": 0.8626368641853333, "(14, 0)": 0.7356914281845093, "(14, 16)": 0.8093215227127075, "(16, 0)": 0.8093215227127075, "(16, 16)": 0.7356914281845093, "(18, 0)": 0.8093215227127075, "(18, 16)": 0.8626368641853333, "(20, 0)": 0.7532857656478882, "(20, 16)": 0.7356914281845093, "(22, 0)": 0.8093215227127075, "(22, 16)": 0.7532857656478882, "(24, 0)": 0.7356914281845093, "(24, 16)": 0.8093215227127075, "(26, 0)": 0.8093215227127075, "(26, 16)": 0.8093215227127075, "(28, 0)": 0.8093215227127075, "(28, 16)": 0.7356914281845093, "(30, 0)": 0.8093215227127075, "(30, 16)": 0.8093215227127075}, "r_span": [699, 812], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008213520050048828}}, {"prompt_attention_score": {"(0, 0)": 0.8865408897399902, "(0, 16)": 0.8865408897399902, "(2, 0)": 0.8865408897399902, "(2, 16)": 0.8865408897399902, "(4, 0)": 0.8865408897399902, "(4, 16)": 0.8865408897399902, "(6, 0)": 0.8865408897399902, "(6, 16)": 0.8865408897399902, "(8, 0)": 0.8865408897399902, "(8, 16)": 0.8865408897399902, "(10, 0)": 0.8865408897399902, "(10, 16)": 0.8865408897399902, "(12, 0)": 0.8865408897399902, "(12, 16)": 0.8865408897399902, "(14, 0)": 0.8865408897399902, "(14, 16)": 0.8865408897399902, "(16, 0)": 0.8865408897399902, "(16, 16)": 0.8865408897399902, "(18, 0)": 0.7102850675582886, "(18, 16)": 0.8865408897399902, "(20, 0)": 0.8865408897399902, "(20, 16)": 0.8865408897399902, "(22, 0)": 0.7102850675582886, "(22, 16)": 0.8865408897399902, "(24, 0)": 0.7102850675582886, "(24, 16)": 0.8865408897399902, "(26, 0)": 0.7102850675582886, "(26, 16)": 0.8865408897399902, "(28, 0)": 0.7102850675582886, "(28, 16)": 0.8865408897399902, "(30, 0)": 0.7102850675582886, "(30, 16)": 0.7102850675582886}, "r_span": [807, 869], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008227825164794922}}]}, {"id": "4341", "source_id": "13894", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 307, "end": 474, "text": "It is likely that the judge will favor the Biden administration's argument that the wire was cut to provide medical aid to migrants, but the outcome remains uncertain.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nThere was no mention of a judge ruling in favor for the Biden Administration found in the source content, as it only concluded with an inquiring sentence.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Judge Alia Moses granted Texas Attorney General Ken Paxton's request to halt the removal of concertina wire along the southern border, citing the potential risk of serious harm or death to migrants. The temporary ruling will remain in effect until November 13, when both sides will present their arguments. It is likely that the judge will favor the Biden administration's argument that the wire was cut to provide medical aid to migrants, but the outcome remains uncertain.", "response_spans": [[0, 474]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9021016955375671, "(0, 16)": 0.6415248513221741, "(2, 0)": 0.7774286270141602, "(2, 16)": 0.7774286270141602, "(4, 0)": 0.6415248513221741, "(4, 16)": 0.6415248513221741, "(6, 0)": 0.9021016955375671, "(6, 16)": 0.8003031015396118, "(8, 0)": 0.8093111515045166, "(8, 16)": 0.6415248513221741, "(10, 0)": 0.6415248513221741, "(10, 16)": 0.6415248513221741, "(12, 0)": 0.6415248513221741, "(12, 16)": 0.8093111515045166, "(14, 0)": 0.8093111515045166, "(14, 16)": 0.6415248513221741, "(16, 0)": 0.6415248513221741, "(16, 16)": 0.8003031015396118, "(18, 0)": 0.6415248513221741, "(18, 16)": 0.8093111515045166, "(20, 0)": 0.9021016955375671, "(20, 16)": 0.8093111515045166, "(22, 0)": 0.8093111515045166, "(22, 16)": 0.8093111515045166, "(24, 0)": 0.8093111515045166, "(24, 16)": 0.9021016955375671, "(26, 0)": 0.8093111515045166, "(26, 16)": 0.8003031015396118, "(28, 0)": 0.8093111515045166, "(28, 16)": 0.8093111515045166, "(30, 0)": 0.8093111515045166, "(30, 16)": 0.8093111515045166}, "r_span": [503, 605], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00024521350860595703}}]}, {"id": "4347", "source_id": "13895", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 497, "end": 544, "text": "now being considered by Governor J.B. Pritzker,", "meta": "EVIDENT CONFLICT\nOriginal: Governor J.B. Pritzker, who used an amendatory veto to remove the nursing home provision. (meaning it is no longer in consideration)\nGenerated: now being considered by Governor J.B. Pritzker,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Illinois Senate President Don Harmon has faced criticism after accepting nearly $2 million in campaign contributions from the nursing home industry, including $700,000 in the past year. These contributions have raised questions about the influence of the industry on tax legislation, particularly in light of Harmon's support for a bill that could provide significant property tax breaks to nursing homes in Cook County. Despite the controversy, the legislation passed the General Assembly and is now being considered by Governor J.B. Pritzker, who vetoed the provision due to concerns about shifting the financial burden onto suburban Cook County homeowners and small businesses.", "response_spans": [[0, 506], [490, 680]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7901471853256226, "(0, 16)": 0.7901471853256226, "(2, 0)": 0.7869575023651123, "(2, 16)": 0.7901471853256226, "(4, 0)": 0.7901471853256226, "(4, 16)": 0.7901471853256226, "(6, 0)": 0.7901471853256226, "(6, 16)": 0.9450262188911438, "(8, 0)": 0.7901471853256226, "(8, 16)": 0.7901471853256226, "(10, 0)": 0.7901471853256226, "(10, 16)": 0.7901471853256226, "(12, 0)": 0.7901471853256226, "(12, 16)": 0.9450262188911438, "(14, 0)": 0.7901471853256226, "(14, 16)": 0.9450262188911438, "(16, 0)": 0.7821502685546875, "(16, 16)": 0.7901471853256226, "(18, 0)": 0.7901471853256226, "(18, 16)": 0.9450262188911438, "(20, 0)": 0.9450262188911438, "(20, 16)": 0.7901471853256226, "(22, 0)": 0.9450262188911438, "(22, 16)": 0.9450262188911438, "(24, 0)": 0.9450262188911438, "(24, 16)": 0.9450262188911438, "(26, 0)": 0.9450262188911438, "(26, 16)": 0.9450262188911438, "(28, 0)": 0.9450262188911438, "(28, 16)": 0.7901471853256226, "(30, 0)": 0.9450262188911438, "(30, 16)": 0.9450262188911438}, "r_span": [689, 790], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002240777015686035}}, {"prompt_attention_score": {"(0, 0)": 0.5819609761238098, "(0, 16)": 0.6893577575683594, "(2, 0)": 0.6893577575683594, "(2, 16)": 0.6893577575683594, "(4, 0)": 0.8476048707962036, "(4, 16)": 0.6893577575683594, "(6, 0)": 0.6893577575683594, "(6, 16)": 0.8476048707962036, "(8, 0)": 0.8476048707962036, "(8, 16)": 0.6893577575683594, "(10, 0)": 0.6893577575683594, "(10, 16)": 0.6893577575683594, "(12, 0)": 0.8476048707962036, "(12, 16)": 0.8476048707962036, "(14, 0)": 0.6893577575683594, "(14, 16)": 0.8476048707962036, "(16, 0)": 0.8476048707962036, "(16, 16)": 0.6893577575683594, "(18, 0)": 0.6893577575683594, "(18, 16)": 0.8476048707962036, "(20, 0)": 0.8476048707962036, "(20, 16)": 0.6893577575683594, "(22, 0)": 0.619916558265686, "(22, 16)": 0.8476048707962036, "(24, 0)": 0.6893577575683594, "(24, 16)": 0.8476048707962036, "(26, 0)": 0.619916558265686, "(26, 16)": 0.8476048707962036, "(28, 0)": 0.619916558265686, "(28, 16)": 0.6893577575683594, "(30, 0)": 0.619916558265686, "(30, 16)": 0.619916558265686}, "r_span": [787, 830], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00037592649459838867}}]}, {"id": "4443", "source_id": "13911", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On this day in Minnesota history, Rosalie Wahl was appointed as the state's first female Supreme Court justice in 1977, marking a significant milestone in the state's legal history. Wahl dedicated her career to championing gender fairness, racial equality, and the rights of the underserved through her work on the bench and nationally with the American Bar Association. Her legacy continues to inspire and shape the pursuit of justice, emphasizing the importance of empathy and equal treatment under the law.", "response_spans": [[0, 509]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8620980381965637, "(0, 16)": 0.8620980381965637, "(2, 0)": 0.8620980381965637, "(2, 16)": 0.8620980381965637, "(4, 0)": 0.8620980381965637, "(4, 16)": 0.8620980381965637, "(6, 0)": 0.8620980381965637, "(6, 16)": 0.9240847229957581, "(8, 0)": 0.8620980381965637, "(8, 16)": 0.8620980381965637, "(10, 0)": 0.8620980381965637, "(10, 16)": 0.8620980381965637, "(12, 0)": 0.8620980381965637, "(12, 16)": 0.9240847229957581, "(14, 0)": 0.8860689401626587, "(14, 16)": 0.9240847229957581, "(16, 0)": 0.9240847229957581, "(16, 16)": 0.8620980381965637, "(18, 0)": 0.8620980381965637, "(18, 16)": 0.9240847229957581, "(20, 0)": 0.9240847229957581, "(20, 16)": 0.8708032369613647, "(22, 0)": 0.9240847229957581, "(22, 16)": 0.9240847229957581, "(24, 0)": 0.9240847229957581, "(24, 16)": 0.9240847229957581, "(26, 0)": 0.9240847229957581, "(26, 16)": 0.9240847229957581, "(28, 0)": 0.9240847229957581, "(28, 16)": 0.9240847229957581, "(30, 0)": 0.9240847229957581, "(30, 16)": 0.9240847229957581}, "r_span": [751, 862], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007464885711669922}}]}, {"id": "4473", "source_id": "13916", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 87 words:\n\nDollar General has been sued by the EEOC for firing a pregnant worker in Georgia after she revealed her pregnancy. The worker was terminated immediately and later told she couldn't return to work due to \"health reasons.\" This violates federal law which protects pregnant employees from discrimination. The EEOC seeks $42,500 in damages and wants to address harmful stereotypes about pregnancy in the workplace.", "response_spans": [[0, 457]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8112408518791199, "(0, 16)": 0.8112408518791199, "(2, 0)": 0.8112408518791199, "(2, 16)": 0.7248225212097168, "(4, 0)": 0.8112408518791199, "(4, 16)": 0.7974919676780701, "(6, 0)": 0.8112408518791199, "(6, 16)": 0.9346736669540405, "(8, 0)": 0.7974919676780701, "(8, 16)": 0.8112408518791199, "(10, 0)": 0.7974919676780701, "(10, 16)": 0.9346736669540405, "(12, 0)": 0.9346736669540405, "(12, 16)": 0.8112408518791199, "(14, 0)": 0.9346736669540405, "(14, 16)": 0.7974919676780701, "(16, 0)": 0.9346736669540405, "(16, 16)": 0.9346736669540405, "(18, 0)": 0.9346736669540405, "(18, 16)": 0.8715969324111938, "(20, 0)": 0.9346736669540405, "(20, 16)": 0.9346736669540405, "(22, 0)": 0.9346736669540405, "(22, 16)": 0.9346736669540405, "(24, 0)": 0.9346736669540405, "(24, 16)": 0.9346736669540405, "(26, 0)": 0.9346736669540405, "(26, 16)": 0.9346736669540405, "(28, 0)": 0.9346736669540405, "(28, 16)": 0.9346736669540405, "(30, 0)": 0.9346736669540405, "(30, 16)": 0.9346736669540405}, "r_span": [626, 744], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013753175735473633}}]}, {"id": "4479", "source_id": "13917", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 493, "end": 514, "text": "JFK-Washington Dulles", "meta": "EVIDENT CONFLICT\nOriginal: \"John F. Kennedy International Airport‚ÄìRonald Reagan Washington National Airport\"\nGenerative: \"JFK-Washington Dulles\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the news in 81 words:\n\nJetBlue is cutting 14 routes from its service in the Northeast region starting in January, impacting popular destinations like Burlington, Miami, and Washington DC. The move is due to the dissolution of an alliance with American Airlines and ongoing ATC staffing challenges. JetBlue will provide alternative flights or refunds for affected passengers. The affected routes include: Boston-Newark, Boston-Rochester, Newark-Miami, JFK-Burlington, JFK-Washington Dulles, Los Angeles-Charleston, LaGuardia-Nashville, and more.", "response_spans": [[0, 47], [49, 560], [561, 570]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5866706371307373, "(0, 16)": 0.5866706371307373, "(2, 0)": 0.3953655958175659, "(2, 16)": 0.3953655958175659, "(4, 0)": 0.3953655958175659, "(4, 16)": 0.5866706371307373, "(6, 0)": 0.3953655958175659, "(6, 16)": 0.6286996006965637, "(8, 0)": 0.5866706371307373, "(8, 16)": 0.5866706371307373, "(10, 0)": 0.6286996006965637, "(10, 16)": 0.5866706371307373, "(12, 0)": 0.5866706371307373, "(12, 16)": 0.6286996006965637, "(14, 0)": 0.3953655958175659, "(14, 16)": 0.6286996006965637, "(16, 0)": 0.6286996006965637, "(16, 16)": 0.4153081774711609, "(18, 0)": 0.5866706371307373, "(18, 16)": 0.6286996006965637, "(20, 0)": 0.6286996006965637, "(20, 16)": 0.3953655958175659, "(22, 0)": 0.4153081774711609, "(22, 16)": 0.6286996006965637, "(24, 0)": 0.3953655958175659, "(24, 16)": 0.4153081774711609, "(26, 0)": 0.4153081774711609, "(26, 16)": 0.4153081774711609, "(28, 0)": 0.4153081774711609, "(28, 16)": 0.3953655958175659, "(30, 0)": 0.4153081774711609, "(30, 16)": 0.4153081774711609}, "r_span": [641, 658], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00026047229766845703}}, {"prompt_attention_score": {"(0, 0)": 0.8883374929428101, "(0, 16)": 0.8883374929428101, "(2, 0)": 0.8883374929428101, "(2, 16)": 0.8883374929428101, "(4, 0)": 0.8883374929428101, "(4, 16)": 0.8883374929428101, "(6, 0)": 0.8883374929428101, "(6, 16)": 0.8883976340293884, "(8, 0)": 0.8883374929428101, "(8, 16)": 0.8883374929428101, "(10, 0)": 0.8883374929428101, "(10, 16)": 0.8883374929428101, "(12, 0)": 0.8883374929428101, "(12, 16)": 0.6810585260391235, "(14, 0)": 0.8883374929428101, "(14, 16)": 0.8883374929428101, "(16, 0)": 0.8883976340293884, "(16, 16)": 0.8883374929428101, "(18, 0)": 0.8883976340293884, "(18, 16)": 0.8269698619842529, "(20, 0)": 0.8269698619842529, "(20, 16)": 0.8883374929428101, "(22, 0)": 0.8883976340293884, "(22, 16)": 0.8269698619842529, "(24, 0)": 0.8883374929428101, "(24, 16)": 0.8269698619842529, "(26, 0)": 0.8883976340293884, "(26, 16)": 0.8883976340293884, "(28, 0)": 0.8883976340293884, "(28, 16)": 0.8883374929428101, "(30, 0)": 0.8883976340293884, "(30, 16)": 0.8883976340293884}, "r_span": [660, 794], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009002685546875}}, {"prompt_attention_score": {"(0, 0)": 0.3923335373401642, "(0, 16)": 0.3923335373401642, "(2, 0)": 0.3923335373401642, "(2, 16)": 0.4951254427433014, "(4, 0)": 0.3923335373401642, "(4, 16)": 0.3923335373401642, "(6, 0)": 0.3923335373401642, "(6, 16)": 0.3974597454071045, "(8, 0)": 0.3923335373401642, "(8, 16)": 0.3923335373401642, "(10, 0)": 0.4951254427433014, "(10, 16)": 0.3923335373401642, "(12, 0)": 0.3974597454071045, "(12, 16)": 0.3847305476665497, "(14, 0)": 0.3923335373401642, "(14, 16)": 0.4951254427433014, "(16, 0)": 0.4951254427433014, "(16, 16)": 0.3974597454071045, "(18, 0)": 0.3974597454071045, "(18, 16)": 0.3923335373401642, "(20, 0)": 0.3847305476665497, "(20, 16)": 0.3923335373401642, "(22, 0)": 0.3923335373401642, "(22, 16)": 0.3923335373401642, "(24, 0)": 0.3923335373401642, "(24, 16)": 0.3923335373401642, "(26, 0)": 0.3923335373401642, "(26, 16)": 0.3923335373401642, "(28, 0)": 0.3974597454071045, "(28, 16)": 0.3923335373401642, "(30, 0)": 0.3974597454071045, "(30, 16)": 0.3974597454071045}, "r_span": [795, 797], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 2.562999725341797e-05}}]}, {"id": "4527", "source_id": "13925", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Former FBI agent David Paitsel was sentenced to 24 months in prison for bribery after he and real estate developer Brian Bailey were found to have shared confidential data from the DC Department of Housing and Community Development. Bailey received a sentence of 48 months in prison and a $250,000 fine for his role in the scheme. Another person involved, Dawne Dorsey, pleaded guilty in June 2019 and will be sentenced on November 6.", "response_spans": [[0, 434]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7493065595626831, "(0, 16)": 0.7493065595626831, "(2, 0)": 0.7493065595626831, "(2, 16)": 0.7493065595626831, "(4, 0)": 0.7493065595626831, "(4, 16)": 0.7493065595626831, "(6, 0)": 0.7493065595626831, "(6, 16)": 0.7937227487564087, "(8, 0)": 0.7493065595626831, "(8, 16)": 0.7493065595626831, "(10, 0)": 0.7493065595626831, "(10, 16)": 0.7493065595626831, "(12, 0)": 0.7493065595626831, "(12, 16)": 0.7366583347320557, "(14, 0)": 0.7366583347320557, "(14, 16)": 0.7937227487564087, "(16, 0)": 0.7366583347320557, "(16, 16)": 0.7366583347320557, "(18, 0)": 0.7937227487564087, "(18, 16)": 0.7937227487564087, "(20, 0)": 0.7366583347320557, "(20, 16)": 0.7366583347320557, "(22, 0)": 0.7937227487564087, "(22, 16)": 0.7937227487564087, "(24, 0)": 0.7366583347320557, "(24, 16)": 0.7937227487564087, "(26, 0)": 0.7937227487564087, "(26, 16)": 0.7937227487564087, "(28, 0)": 0.7937227487564087, "(28, 16)": 0.7366583347320557, "(30, 0)": 0.7937227487564087, "(30, 16)": 0.7937227487564087}, "r_span": [597, 709], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00034487247467041016}}]}, {"id": "4533", "source_id": "13926", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 74 words:\n\nThe Governor's Office of Pennsylvania has settled a sexual harassment claim against a senior aide, Mike Vereb, for $295,000. The accuser alleged Vereb made lewd and misogynistic remarks and faced retaliation when reporting the incident. As part of the settlement, the office will provide sexual harassment training and allow the accuser to seek employment elsewhere in state government. The case highlights the need for a culture of respect and integrity in government offices.", "response_spans": [[0, 45], [47, 524]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5429537296295166, "(0, 16)": 0.5429537296295166, "(2, 0)": 0.5429537296295166, "(2, 16)": 0.5429537296295166, "(4, 0)": 0.5429537296295166, "(4, 16)": 0.5429537296295166, "(6, 0)": 0.5429537296295166, "(6, 16)": 0.513551652431488, "(8, 0)": 0.5429537296295166, "(8, 16)": 0.5429537296295166, "(10, 0)": 0.513551652431488, "(10, 16)": 0.513551652431488, "(12, 0)": 0.5429537296295166, "(12, 16)": 0.513551652431488, "(14, 0)": 0.5429537296295166, "(14, 16)": 0.513551652431488, "(16, 0)": 0.513551652431488, "(16, 16)": 0.513551652431488, "(18, 0)": 0.5429537296295166, "(18, 16)": 0.513551652431488, "(20, 0)": 0.513551652431488, "(20, 16)": 0.513551652431488, "(22, 0)": 0.513551652431488, "(22, 16)": 0.513551652431488, "(24, 0)": 0.513551652431488, "(24, 16)": 0.513551652431488, "(26, 0)": 0.513551652431488, "(26, 16)": 0.513551652431488, "(28, 0)": 0.513551652431488, "(28, 16)": 0.513551652431488, "(30, 0)": 0.513551652431488, "(30, 16)": 0.513551652431488}, "r_span": [523, 536], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 2.950429916381836e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7060843110084534, "(0, 16)": 0.7060843110084534, "(2, 0)": 0.7060843110084534, "(2, 16)": 0.7060843110084534, "(4, 0)": 0.7060843110084534, "(4, 16)": 0.7060843110084534, "(6, 0)": 0.7060843110084534, "(6, 16)": 0.8160043954849243, "(8, 0)": 0.7614176273345947, "(8, 16)": 0.7060843110084534, "(10, 0)": 0.7060843110084534, "(10, 16)": 0.7060843110084534, "(12, 0)": 0.7060843110084534, "(12, 16)": 0.7614176273345947, "(14, 0)": 0.7060843110084534, "(14, 16)": 0.8160043954849243, "(16, 0)": 0.8160043954849243, "(16, 16)": 0.8160043954849243, "(18, 0)": 0.7060843110084534, "(18, 16)": 0.7445828914642334, "(20, 0)": 0.7614176273345947, "(20, 16)": 0.7445828914642334, "(22, 0)": 0.8160043954849243, "(22, 16)": 0.7614176273345947, "(24, 0)": 0.8160043954849243, "(24, 16)": 0.7614176273345947, "(26, 0)": 0.8160043954849243, "(26, 16)": 0.8160043954849243, "(28, 0)": 0.8160043954849243, "(28, 16)": 0.8160043954849243, "(30, 0)": 0.8160043954849243, "(30, 16)": 0.8160043954849243}, "r_span": [538, 645], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016055107116699219}}]}, {"id": "4575", "source_id": "13933", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 79 words:\n\nTexas Governor Greg Abbott condemned the attack on Israel and increased security measures for Jewish communities in Texas, including restricting state agency purchases of goods from the Gaza Strip. He also provided $4 million in grant funding to 31 Jewish organizations to enhance security and flew the Texas flag at half-staff in solidarity.", "response_spans": [[0, 389]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.876271665096283, "(0, 16)": 0.6214664578437805, "(2, 0)": 0.876271665096283, "(2, 16)": 0.876271665096283, "(4, 0)": 0.876271665096283, "(4, 16)": 0.6214664578437805, "(6, 0)": 0.876271665096283, "(6, 16)": 0.8971031308174133, "(8, 0)": 0.6214664578437805, "(8, 16)": 0.6214664578437805, "(10, 0)": 0.6214664578437805, "(10, 16)": 0.6214664578437805, "(12, 0)": 0.6214664578437805, "(12, 16)": 0.876271665096283, "(14, 0)": 0.7512580752372742, "(14, 16)": 0.8971031308174133, "(16, 0)": 0.8971031308174133, "(16, 16)": 0.7512580752372742, "(18, 0)": 0.7512580752372742, "(18, 16)": 0.876271665096283, "(20, 0)": 0.876271665096283, "(20, 16)": 0.7512580752372742, "(22, 0)": 0.7512580752372742, "(22, 16)": 0.876271665096283, "(24, 0)": 0.7512580752372742, "(24, 16)": 0.876271665096283, "(26, 0)": 0.7512580752372742, "(26, 16)": 0.7512580752372742, "(28, 0)": 0.7512580752372742, "(28, 16)": 0.7512580752372742, "(30, 0)": 0.7512580752372742, "(30, 16)": 0.7512580752372742}, "r_span": [506, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0025623440742492676}}]}, {"id": "4587", "source_id": "13935", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "On October 4th, all Mainers will experience an unexpected interruption on their phones, radios, or TVs as FEMA conducts a nationwide test of its Emergency Alert System. The test will occur at 2:20 pm EDT and will display a clear message on phones in English and Spanish. Although it may seem alarming, there's no need to take action. This is a routine test to ensure the reliability and efficiency of the system, which has been used since 1963. Local, state, territorial, and tribal authorities also use the distinctive tone for localized emergency alerts. So, on Wednesday, when the familiar tone sounds, remember it's just a test and stay informed, stay safe, and always be prepared.", "response_spans": [[0, 507], [495, 685]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.701491117477417, "(0, 16)": 0.701491117477417, "(2, 0)": 0.701491117477417, "(2, 16)": 0.701491117477417, "(4, 0)": 0.701491117477417, "(4, 16)": 0.701491117477417, "(6, 0)": 0.701491117477417, "(6, 16)": 0.9189056158065796, "(8, 0)": 0.701491117477417, "(8, 16)": 0.701491117477417, "(10, 0)": 0.701491117477417, "(10, 16)": 0.701491117477417, "(12, 0)": 0.701491117477417, "(12, 16)": 0.9189056158065796, "(14, 0)": 0.701491117477417, "(14, 16)": 0.9189056158065796, "(16, 0)": 0.9189056158065796, "(16, 16)": 0.701491117477417, "(18, 0)": 0.9189056158065796, "(18, 16)": 0.9189056158065796, "(20, 0)": 0.9189056158065796, "(20, 16)": 0.701491117477417, "(22, 0)": 0.9189056158065796, "(22, 16)": 0.9189056158065796, "(24, 0)": 0.701491117477417, "(24, 16)": 0.9189056158065796, "(26, 0)": 0.9189056158065796, "(26, 16)": 0.8119864463806152, "(28, 0)": 0.9189056158065796, "(28, 16)": 0.782315731048584, "(30, 0)": 0.9189056158065796, "(30, 16)": 0.9189056158065796}, "r_span": [688, 813], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001781165599822998}}, {"prompt_attention_score": {"(0, 0)": 0.7203390598297119, "(0, 16)": 0.7203390598297119, "(2, 0)": 0.7203390598297119, "(2, 16)": 0.7203390598297119, "(4, 0)": 0.7203390598297119, "(4, 16)": 0.7203390598297119, "(6, 0)": 0.7203390598297119, "(6, 16)": 0.7443760633468628, "(8, 0)": 0.7203390598297119, "(8, 16)": 0.7203390598297119, "(10, 0)": 0.7203390598297119, "(10, 16)": 0.7203390598297119, "(12, 0)": 0.7203390598297119, "(12, 16)": 0.7203390598297119, "(14, 0)": 0.7203390598297119, "(14, 16)": 0.7203390598297119, "(16, 0)": 0.7203390598297119, "(16, 16)": 0.7203390598297119, "(18, 0)": 0.7366540431976318, "(18, 16)": 0.7443760633468628, "(20, 0)": 0.7203390598297119, "(20, 16)": 0.7203390598297119, "(22, 0)": 0.7366540431976318, "(22, 16)": 0.7203390598297119, "(24, 0)": 0.7203390598297119, "(24, 16)": 0.7203390598297119, "(26, 0)": 0.7366540431976318, "(26, 16)": 0.7203390598297119, "(28, 0)": 0.7366540431976318, "(28, 16)": 0.7366540431976318, "(30, 0)": 0.7366540431976318, "(30, 16)": 0.7366540431976318}, "r_span": [811, 856], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001097559928894043}}]}, {"id": "4749", "source_id": "13962", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the news article in 77 words:\n\nTishomingo County high school star Reese Moore has signed with Freed-Hardeman University to play basketball. Moore, who played both basketball and volleyball, had a successful volleyball season and is now focused on basketball. She averaged 20 points and 8.2 rebounds per game and was selected for the 2023 North All-Star Game. Moore will join the Freed-Hardeman Lady Lions, who won the Mid-South Conference Tournament last season.", "response_spans": [[0, 488]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7183609008789062, "(0, 16)": 0.7183609008789062, "(2, 0)": 0.7437041997909546, "(2, 16)": 0.7437041997909546, "(4, 0)": 0.7437041997909546, "(4, 16)": 0.6802575588226318, "(6, 0)": 0.7437041997909546, "(6, 16)": 0.8690582513809204, "(8, 0)": 0.7183609008789062, "(8, 16)": 0.7437041997909546, "(10, 0)": 0.8690582513809204, "(10, 16)": 0.7437041997909546, "(12, 0)": 0.7881546020507812, "(12, 16)": 0.7183609008789062, "(14, 0)": 0.7881546020507812, "(14, 16)": 0.7183609008789062, "(16, 0)": 0.8690582513809204, "(16, 16)": 0.7881546020507812, "(18, 0)": 0.7881546020507812, "(18, 16)": 0.7881546020507812, "(20, 0)": 0.8690582513809204, "(20, 16)": 0.7881546020507812, "(22, 0)": 0.7881546020507812, "(22, 16)": 0.7881546020507812, "(24, 0)": 0.7881546020507812, "(24, 16)": 0.7881546020507812, "(26, 0)": 0.7881546020507812, "(26, 16)": 0.8690582513809204, "(28, 0)": 0.7881546020507812, "(28, 16)": 0.7881546020507812, "(30, 0)": 0.7881546020507812, "(30, 16)": 0.7881546020507812}, "r_span": [529, 657], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -6.788969039916992e-05}}]}, {"id": "4779", "source_id": "13968", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 406, "end": 451, "text": "which is the state's largest trading partner.", "meta": "LOW INTRO OF NEW INFO\nOriginal: China is indeed the largest trading partner of California, however, it is not explicitly mentioned in the source content. \nGenerative: \"...with China, which is the state's largest trading partner.\"", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 105 words or less:\n\nCalifornia Gov. Gavin Newsom is traveling to China next week to promote climate action and economic partnerships. He'll visit five cities, including Hong Kong, Guangdong, Beijing, Jiangsu, and Shanghai, where he'll meet with regional leaders, businesses, and stakeholders. The trip aims to build on California's existing partnership with China, which is the state's largest trading partner. Newsom will emphasize the importance of climate action and low-carbon economies, and he'll highlight California's experience in these areas.", "response_spans": [[0, 59], [61, 565], [553, 592]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5120421051979065, "(0, 16)": 0.45884275436401367, "(2, 0)": 0.45884275436401367, "(2, 16)": 0.45884275436401367, "(4, 0)": 0.449010968208313, "(4, 16)": 0.5120421051979065, "(6, 0)": 0.5120421051979065, "(6, 16)": 0.4274284243583679, "(8, 0)": 0.5120421051979065, "(8, 16)": 0.5120421051979065, "(10, 0)": 0.4274284243583679, "(10, 16)": 0.4274284243583679, "(12, 0)": 0.45884275436401367, "(12, 16)": 0.4274284243583679, "(14, 0)": 0.5120421051979065, "(14, 16)": 0.4274284243583679, "(16, 0)": 0.4274284243583679, "(16, 16)": 0.4274284243583679, "(18, 0)": 0.4274284243583679, "(18, 16)": 0.4274284243583679, "(20, 0)": 0.4274284243583679, "(20, 16)": 0.5120421051979065, "(22, 0)": 0.4274284243583679, "(22, 16)": 0.4274284243583679, "(24, 0)": 0.449010968208313, "(24, 16)": 0.4274284243583679, "(26, 0)": 0.4274284243583679, "(26, 16)": 0.4274284243583679, "(28, 0)": 0.4274284243583679, "(28, 16)": 0.5120421051979065, "(30, 0)": 0.449010968208313, "(30, 16)": 0.4274284243583679}, "r_span": [748, 768], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00022178888320922852}}, {"prompt_attention_score": {"(0, 0)": 0.7734923362731934, "(0, 16)": 0.7734923362731934, "(2, 0)": 0.7734923362731934, "(2, 16)": 0.7734923362731934, "(4, 0)": 0.7734923362731934, "(4, 16)": 0.735878586769104, "(6, 0)": 0.7734923362731934, "(6, 16)": 0.9128572344779968, "(8, 0)": 0.7800483703613281, "(8, 16)": 0.7734923362731934, "(10, 0)": 0.7800483703613281, "(10, 16)": 0.7800483703613281, "(12, 0)": 0.7734923362731934, "(12, 16)": 0.8789845705032349, "(14, 0)": 0.735878586769104, "(14, 16)": 0.7734923362731934, "(16, 0)": 0.9128572344779968, "(16, 16)": 0.9128572344779968, "(18, 0)": 0.9128572344779968, "(18, 16)": 0.8789845705032349, "(20, 0)": 0.8789845705032349, "(20, 16)": 0.735878586769104, "(22, 0)": 0.9128572344779968, "(22, 16)": 0.8789845705032349, "(24, 0)": 0.7800483703613281, "(24, 16)": 0.9128572344779968, "(26, 0)": 0.9128572344779968, "(26, 16)": 0.9128572344779968, "(28, 0)": 0.9128572344779968, "(28, 16)": 0.735878586769104, "(30, 0)": 0.9128572344779968, "(30, 16)": 0.9128572344779968}, "r_span": [770, 896], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002637505531311035}}, {"prompt_attention_score": {"(0, 0)": 0.5949105620384216, "(0, 16)": 0.5949105620384216, "(2, 0)": 0.5949105620384216, "(2, 16)": 0.5041656494140625, "(4, 0)": 0.5949105620384216, "(4, 16)": 0.5041656494140625, "(6, 0)": 0.5949105620384216, "(6, 16)": 0.6213353872299194, "(8, 0)": 0.5255154371261597, "(8, 16)": 0.5255154371261597, "(10, 0)": 0.6213353872299194, "(10, 16)": 0.5949105620384216, "(12, 0)": 0.576471209526062, "(12, 16)": 0.6213353872299194, "(14, 0)": 0.5041656494140625, "(14, 16)": 0.5949105620384216, "(16, 0)": 0.6213353872299194, "(16, 16)": 0.5041656494140625, "(18, 0)": 0.576471209526062, "(18, 16)": 0.555821418762207, "(20, 0)": 0.5949105620384216, "(20, 16)": 0.5041656494140625, "(22, 0)": 0.576471209526062, "(22, 16)": 0.555821418762207, "(24, 0)": 0.5041656494140625, "(24, 16)": 0.5255154371261597, "(26, 0)": 0.576471209526062, "(26, 16)": 0.5255154371261597, "(28, 0)": 0.576471209526062, "(28, 16)": 0.5041656494140625, "(30, 0)": 0.5255154371261597, "(30, 16)": 0.576471209526062}, "r_span": [894, 901], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00013959407806396484}}]}, {"id": "4797", "source_id": "13971", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 455, "end": 491, "text": "needs a dose of his favorite nephew.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"needs a dose of his favorite nephew. \"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Melissa Claire Egan has returned to The Young and the Restless after maternity leave, and fans can expect her character Chelsea to return to Genoa City soon. Egan began filming her first scenes back in early October, and based on the show's production schedule, Chelsea is likely to make her return in mid to late November. Chelsea's return comes at an exciting time for the show, as Billy (Jason Thompson) could use a confidant, and Adam (Mark Grossman) needs a dose of his favorite nephew. While it's unclear what lies ahead for Chelsea, her romance with Billy is still in its early stages, leaving room for potential drama and twists.", "response_spans": [[0, 510], [492, 637]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8631179332733154, "(0, 16)": 0.8631179332733154, "(2, 0)": 0.8631179332733154, "(2, 16)": 0.8631179332733154, "(4, 0)": 0.8631179332733154, "(4, 16)": 0.8631179332733154, "(6, 0)": 0.8631179332733154, "(6, 16)": 0.8826892375946045, "(8, 0)": 0.8631179332733154, "(8, 16)": 0.8631179332733154, "(10, 0)": 0.8631179332733154, "(10, 16)": 0.8631179332733154, "(12, 0)": 0.8631179332733154, "(12, 16)": 0.8877551555633545, "(14, 0)": 0.8631179332733154, "(14, 16)": 0.8631179332733154, "(16, 0)": 0.8826892375946045, "(16, 16)": 0.8631179332733154, "(18, 0)": 0.8631179332733154, "(18, 16)": 0.8877551555633545, "(20, 0)": 0.8877551555633545, "(20, 16)": 0.8631179332733154, "(22, 0)": 0.8631179332733154, "(22, 16)": 0.7698636054992676, "(24, 0)": 0.8631179332733154, "(24, 16)": 0.8877551555633545, "(26, 0)": 0.8499935269355774, "(26, 16)": 0.8631179332733154, "(28, 0)": 0.8499935269355774, "(28, 16)": 0.8631179332733154, "(30, 0)": 0.8499935269355774, "(30, 16)": 0.8499935269355774}, "r_span": [712, 842], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -9.08970832824707e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6639708280563354, "(0, 16)": 0.6639708280563354, "(2, 0)": 0.6639708280563354, "(2, 16)": 0.6639708280563354, "(4, 0)": 0.6639708280563354, "(4, 16)": 0.6639708280563354, "(6, 0)": 0.6639708280563354, "(6, 16)": 0.5885510444641113, "(8, 0)": 0.6639708280563354, "(8, 16)": 0.6639708280563354, "(10, 0)": 0.6639708280563354, "(10, 16)": 0.6639708280563354, "(12, 0)": 0.6639708280563354, "(12, 16)": 0.6639708280563354, "(14, 0)": 0.6639708280563354, "(14, 16)": 0.6639708280563354, "(16, 0)": 0.6639708280563354, "(16, 16)": 0.6639708280563354, "(18, 0)": 0.6639708280563354, "(18, 16)": 0.6639708280563354, "(20, 0)": 0.6639708280563354, "(20, 16)": 0.6639708280563354, "(22, 0)": 0.56048983335495, "(22, 16)": 0.6639708280563354, "(24, 0)": 0.6143026947975159, "(24, 16)": 0.6639708280563354, "(26, 0)": 0.56048983335495, "(26, 16)": 0.6639708280563354, "(28, 0)": 0.56048983335495, "(28, 16)": 0.6639708280563354, "(30, 0)": 0.56048983335495, "(30, 16)": 0.56048983335495}, "r_span": [838, 871], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004490017890930176}}]}, {"id": "4803", "source_id": "13972", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 81 words or less:\n\nThe Bold and the Beautiful spoilers reveal Eric Forrester's ego may cost him his life. Eric is preparing for a fashion showdown with his son Ridge, but his mysterious medical condition is getting worse. Despite his wife's concerns, Eric refuses to listen and insists on pushing forward with the show. His ego may lead to a dangerous outcome.", "response_spans": [[0, 396]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6878389120101929, "(0, 16)": 0.6878389120101929, "(2, 0)": 0.8099476099014282, "(2, 16)": 0.8099476099014282, "(4, 0)": 0.8099476099014282, "(4, 16)": 0.6878389120101929, "(6, 0)": 0.8099476099014282, "(6, 16)": 0.9081206917762756, "(8, 0)": 0.6690100431442261, "(8, 16)": 0.6878389120101929, "(10, 0)": 0.6878389120101929, "(10, 16)": 0.6878389120101929, "(12, 0)": 0.6878389120101929, "(12, 16)": 0.9081206917762756, "(14, 0)": 0.8099476099014282, "(14, 16)": 0.9081206917762756, "(16, 0)": 0.9081206917762756, "(16, 16)": 0.9081206917762756, "(18, 0)": 0.6878389120101929, "(18, 16)": 0.9081206917762756, "(20, 0)": 0.9081206917762756, "(20, 16)": 0.9081206917762756, "(22, 0)": 0.9081206917762756, "(22, 16)": 0.6690100431442261, "(24, 0)": 0.9081206917762756, "(24, 16)": 0.6690100431442261, "(26, 0)": 0.9081206917762756, "(26, 16)": 0.9081206917762756, "(28, 0)": 0.9081206917762756, "(28, 16)": 0.9081206917762756, "(30, 0)": 0.9081206917762756, "(30, 16)": 0.9081206917762756}, "r_span": [513, 611], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018724799156188965}}]}, {"id": "4845", "source_id": "13979", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 74 words:\n\nPreparations are underway for the Formula 1 Heineken Silver Las Vegas Grand Prix, which returns to the city after a 40-year absence. The race will take place on a newly created temporary street circuit along the Las Vegas Strip, featuring 17 corners and 3 DRS zones. Drivers will race at night, with the city's glittering lights providing a spectacular backdrop. The 1100th round of the Formula One World Championship, the race is scheduled for November 18, 2023.", "response_spans": [[0, 510]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4412690997123718, "(0, 16)": 0.4412690997123718, "(2, 0)": 0.4412690997123718, "(2, 16)": 0.4412690997123718, "(4, 0)": 0.4412690997123718, "(4, 16)": 0.4412690997123718, "(6, 0)": 0.7652976512908936, "(6, 16)": 0.876534104347229, "(8, 0)": 0.4412690997123718, "(8, 16)": 0.4412690997123718, "(10, 0)": 0.4412690997123718, "(10, 16)": 0.4412690997123718, "(12, 0)": 0.876534104347229, "(12, 16)": 0.876534104347229, "(14, 0)": 0.9011977910995483, "(14, 16)": 0.9011977910995483, "(16, 0)": 0.9011977910995483, "(16, 16)": 0.9011977910995483, "(18, 0)": 0.4412690997123718, "(18, 16)": 0.9011977910995483, "(20, 0)": 0.876534104347229, "(20, 16)": 0.7636483907699585, "(22, 0)": 0.9011977910995483, "(22, 16)": 0.876534104347229, "(24, 0)": 0.9011977910995483, "(24, 16)": 0.876534104347229, "(26, 0)": 0.9011977910995483, "(26, 16)": 0.9011977910995483, "(28, 0)": 0.9011977910995483, "(28, 16)": 0.7636483907699585, "(30, 0)": 0.9011977910995483, "(30, 16)": 0.9011977910995483}, "r_span": [539, 677], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008358955383300781}}]}, {"id": "4953", "source_id": "13481", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 94 words:\n\nMaryland woman Marilyne Chamberlain disappeared without trace in 1998 after conducting a routine transaction at a credit union at the Pentagon. Witnesses saw her at a nearby department store, and she may have taken the Metrorail to Landover Hills. Suspicious circumstances surround her disappearance, but no solid leads have emerged despite extensive investigation. Police encourage anyone with information to come forward.", "response_spans": [[0, 470]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5984136462211609, "(0, 16)": 0.5984136462211609, "(2, 0)": 0.5984136462211609, "(2, 16)": 0.5984136462211609, "(4, 0)": 0.5984136462211609, "(4, 16)": 0.5984136462211609, "(6, 0)": 0.5984136462211609, "(6, 16)": 0.8646373748779297, "(8, 0)": 0.5652364492416382, "(8, 16)": 0.5984136462211609, "(10, 0)": 0.8646373748779297, "(10, 16)": 0.5984136462211609, "(12, 0)": 0.5984136462211609, "(12, 16)": 0.8633595705032349, "(14, 0)": 0.8646373748779297, "(14, 16)": 0.8646373748779297, "(16, 0)": 0.8646373748779297, "(16, 16)": 0.8646373748779297, "(18, 0)": 0.5984136462211609, "(18, 16)": 0.8633595705032349, "(20, 0)": 0.8633595705032349, "(20, 16)": 0.8646373748779297, "(22, 0)": 0.8646373748779297, "(22, 16)": 0.8646373748779297, "(24, 0)": 0.8646373748779297, "(24, 16)": 0.8633595705032349, "(26, 0)": 0.8646373748779297, "(26, 16)": 0.8646373748779297, "(28, 0)": 0.8646373748779297, "(28, 16)": 0.8646373748779297, "(30, 0)": 0.8646373748779297, "(30, 16)": 0.8646373748779297}, "r_span": [650, 754], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00012165307998657227}}]}, {"id": "5019", "source_id": "13492", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Texas Attorney General Ken Paxton filed a lawsuit against the Biden administration to stop federal agents from cutting razor wire at the border, citing concerns over security and the environment. The state believes it has the right to construct border barriers to prevent illegal immigration, while environmental and immigration advocates are concerned about the potential harm to humans and the environment caused by the razor wire. This is not the first time Texas has clashed with the federal government over border security measures, with previous lawsuits filed over buoys installed in the Rio Grande and wall construction plans.", "response_spans": [[0, 511], [496, 634]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7266973257064819, "(0, 16)": 0.7266973257064819, "(2, 0)": 0.7266973257064819, "(2, 16)": 0.7266973257064819, "(4, 0)": 0.7266973257064819, "(4, 16)": 0.7266973257064819, "(6, 0)": 0.7266973257064819, "(6, 16)": 0.8952776193618774, "(8, 0)": 0.7843276262283325, "(8, 16)": 0.7266973257064819, "(10, 0)": 0.8952776193618774, "(10, 16)": 0.8952776193618774, "(12, 0)": 0.7843276262283325, "(12, 16)": 0.8827635049819946, "(14, 0)": 0.7843276262283325, "(14, 16)": 0.8952776193618774, "(16, 0)": 0.8952776193618774, "(16, 16)": 0.7843276262283325, "(18, 0)": 0.7843276262283325, "(18, 16)": 0.8952776193618774, "(20, 0)": 0.8827635049819946, "(20, 16)": 0.7843276262283325, "(22, 0)": 0.7843276262283325, "(22, 16)": 0.8952776193618774, "(24, 0)": 0.7843276262283325, "(24, 16)": 0.6905525922775269, "(26, 0)": 0.7843276262283325, "(26, 16)": 0.7843276262283325, "(28, 0)": 0.7843276262283325, "(28, 16)": 0.7843276262283325, "(30, 0)": 0.7843276262283325, "(30, 16)": 0.7843276262283325}, "r_span": [587, 687], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017691254615783691}}, {"prompt_attention_score": {"(0, 0)": 0.5459980964660645, "(0, 16)": 0.5459980964660645, "(2, 0)": 0.5459980964660645, "(2, 16)": 0.5459980964660645, "(4, 0)": 0.5459980964660645, "(4, 16)": 0.5459980964660645, "(6, 0)": 0.5459980964660645, "(6, 16)": 0.6356518268585205, "(8, 0)": 0.5459980964660645, "(8, 16)": 0.7811217904090881, "(10, 0)": 0.7811217904090881, "(10, 16)": 0.7811217904090881, "(12, 0)": 0.7811217904090881, "(12, 16)": 0.7811217904090881, "(14, 0)": 0.7811217904090881, "(14, 16)": 0.7811217904090881, "(16, 0)": 0.7811217904090881, "(16, 16)": 0.7811217904090881, "(18, 0)": 0.7811217904090881, "(18, 16)": 0.7811217904090881, "(20, 0)": 0.7811217904090881, "(20, 16)": 0.7811217904090881, "(22, 0)": 0.7811217904090881, "(22, 16)": 0.7811217904090881, "(24, 0)": 0.7811217904090881, "(24, 16)": 0.7811217904090881, "(26, 0)": 0.7811217904090881, "(26, 16)": 0.7811217904090881, "(28, 0)": 0.7811217904090881, "(28, 16)": 0.7811217904090881, "(30, 0)": 0.7811217904090881, "(30, 16)": 0.7811217904090881}, "r_span": [686, 712], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001293957233428955}}]}, {"id": "5037", "source_id": "13495", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 373, "end": 397, "text": "earning millions in cash", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that Jacobo earned millions in cash, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the news in 90 words:\n\nLuis Alfredo Jacobo, a California drug kingpin, was sentenced to four life terms in federal prison for directing a continuing criminal enterprise and drug conspiracies in Oklahoma and Missouri. Jacobo orchestrated the distribution of methamphetamine from California to Oklahoma and Missouri through a network of co-conspirators, earning millions in cash. Law enforcement discovered 231 pounds of methamphetamine and $465,000 in a storage unit rented by Jacobo, leading to his arrest and conviction.", "response_spans": [[0, 42], [44, 542]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4860537648200989, "(0, 16)": 0.4860537648200989, "(2, 0)": 0.4864252805709839, "(2, 16)": 0.4860537648200989, "(4, 0)": 0.4860537648200989, "(4, 16)": 0.4860537648200989, "(6, 0)": 0.4860537648200989, "(6, 16)": 0.6759817600250244, "(8, 0)": 0.4766031503677368, "(8, 16)": 0.4860537648200989, "(10, 0)": 0.6759817600250244, "(10, 16)": 0.4860537648200989, "(12, 0)": 0.4860537648200989, "(12, 16)": 0.6759817600250244, "(14, 0)": 0.4765580892562866, "(14, 16)": 0.6759817600250244, "(16, 0)": 0.6759817600250244, "(16, 16)": 0.4765580892562866, "(18, 0)": 0.4860537648200989, "(18, 16)": 0.6759817600250244, "(20, 0)": 0.6759817600250244, "(20, 16)": 0.4765580892562866, "(22, 0)": 0.4765580892562866, "(22, 16)": 0.4765580892562866, "(24, 0)": 0.4860537648200989, "(24, 16)": 0.4765580892562866, "(26, 0)": 0.4860537648200989, "(26, 16)": 0.4765580892562866, "(28, 0)": 0.4765580892562866, "(28, 16)": 0.4860537648200989, "(30, 0)": 0.4765580892562866, "(30, 16)": 0.4765580892562866}, "r_span": [652, 665], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011343955993652344}}, {"prompt_attention_score": {"(0, 0)": 0.8147482872009277, "(0, 16)": 0.7485984563827515, "(2, 0)": 0.7485984563827515, "(2, 16)": 0.7485984563827515, "(4, 0)": 0.7485984563827515, "(4, 16)": 0.8147482872009277, "(6, 0)": 0.7485984563827515, "(6, 16)": 0.8840957880020142, "(8, 0)": 0.8147482872009277, "(8, 16)": 0.8147482872009277, "(10, 0)": 0.7485984563827515, "(10, 16)": 0.7485984563827515, "(12, 0)": 0.8840957880020142, "(12, 16)": 0.8840957880020142, "(14, 0)": 0.8147482872009277, "(14, 16)": 0.8840957880020142, "(16, 0)": 0.8840957880020142, "(16, 16)": 0.8840957880020142, "(18, 0)": 0.8840957880020142, "(18, 16)": 0.8840957880020142, "(20, 0)": 0.8147482872009277, "(20, 16)": 0.8147482872009277, "(22, 0)": 0.8840957880020142, "(22, 16)": 0.8840957880020142, "(24, 0)": 0.8840957880020142, "(24, 16)": 0.8840957880020142, "(26, 0)": 0.8840957880020142, "(26, 16)": 0.8840957880020142, "(28, 0)": 0.8840957880020142, "(28, 16)": 0.8840957880020142, "(30, 0)": 0.8840957880020142, "(30, 16)": 0.8840957880020142}, "r_span": [667, 792], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007519721984863281}}]}, {"id": "5061", "source_id": "13499", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 209, "end": 275, "text": "Butler is the first Black lesbian to be elected to the U.S. Senate", "meta": "EVIDENT CONFLICT:\nAIGC:  Butler is the first Black lesbian to be \"elected\" to the U.S. Senate\nOriginal:  \"the first Black lesbian to openly serve in the U.S. Senate\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is a summary of the news in 73 words:\n\nGavin Newsom, the Governor of California, has appointed Laphonza Butler, a Black lesbian woman from Maryland, to fill the seat of the late Senator Dianne Feinstein. Butler is the first Black lesbian to be elected to the U.S. Senate and has a long history of advocating for women and working people. Her appointment takes effect immediately and she will serve until the next regularly scheduled election in 2024.", "response_spans": [[0, 455]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7387359142303467, "(0, 16)": 0.7387359142303467, "(2, 0)": 0.7387359142303467, "(2, 16)": 0.7387359142303467, "(4, 0)": 0.7387359142303467, "(4, 16)": 0.7387359142303467, "(6, 0)": 0.7387359142303467, "(6, 16)": 0.8957074880599976, "(8, 0)": 0.7387359142303467, "(8, 16)": 0.7387359142303467, "(10, 0)": 0.7387359142303467, "(10, 16)": 0.8957074880599976, "(12, 0)": 0.7387359142303467, "(12, 16)": 0.8957074880599976, "(14, 0)": 0.8957074880599976, "(14, 16)": 0.8957074880599976, "(16, 0)": 0.8957074880599976, "(16, 16)": 0.8957074880599976, "(18, 0)": 0.8957074880599976, "(18, 16)": 0.8957074880599976, "(20, 0)": 0.8957074880599976, "(20, 16)": 0.8957074880599976, "(22, 0)": 0.8957074880599976, "(22, 16)": 0.8117119073867798, "(24, 0)": 0.8957074880599976, "(24, 16)": 0.8957074880599976, "(26, 0)": 0.8957074880599976, "(26, 16)": 0.8957074880599976, "(28, 0)": 0.8957074880599976, "(28, 16)": 0.8957074880599976, "(30, 0)": 0.8957074880599976, "(30, 16)": 0.8957074880599976}, "r_span": [506, 616], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003362119197845459}}]}, {"id": "5085", "source_id": "13503", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the news in 72 words or less:\n\nThe Northern Lights were unexpectedly visible in the Midwest and Plains on October 20-21, 2023, after a weak coronal mass ejection (CME) hit Earth. Although the CME was projected to be weak, it still caused a gap in satellite data, a subtle increase in solar winds, and a decrease in negative Bz values, indicating better odds for viewing the lights further south in the US.", "response_spans": [[0, 426]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8224855065345764, "(0, 16)": 0.6603552103042603, "(2, 0)": 0.8224855065345764, "(2, 16)": 0.6603552103042603, "(4, 0)": 0.8224855065345764, "(4, 16)": 0.6603552103042603, "(6, 0)": 0.8224855065345764, "(6, 16)": 0.9186879992485046, "(8, 0)": 0.8224855065345764, "(8, 16)": 0.8224855065345764, "(10, 0)": 0.750484049320221, "(10, 16)": 0.8224855065345764, "(12, 0)": 0.750484049320221, "(12, 16)": 0.8224855065345764, "(14, 0)": 0.750484049320221, "(14, 16)": 0.9186879992485046, "(16, 0)": 0.9186879992485046, "(16, 16)": 0.750484049320221, "(18, 0)": 0.750484049320221, "(18, 16)": 0.8224855065345764, "(20, 0)": 0.8224855065345764, "(20, 16)": 0.750484049320221, "(22, 0)": 0.750484049320221, "(22, 16)": 0.9186879992485046, "(24, 0)": 0.750484049320221, "(24, 16)": 0.8224855065345764, "(26, 0)": 0.750484049320221, "(26, 16)": 0.750484049320221, "(28, 0)": 0.750484049320221, "(28, 16)": 0.750484049320221, "(30, 0)": 0.750484049320221, "(30, 16)": 0.750484049320221}, "r_span": [452, 567], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002692103385925293}}]}, {"id": "5199", "source_id": "13522", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 116, "end": 151, "text": "whom she met through mutual friends", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that Savannah Chrisley met Robert Shiver through mutual friends, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 109 words:\n\nSavannah Chrisley is in a new relationship with Robert Shiver, whom she met through mutual friends. The two recently went on a double date with her brother Grayson Chrisley and his girlfriend. Savannah is happy and grateful to be in a serious dating situation after her previous breakup. She praised Robert for understanding her commitment to her siblings as their guardian and for having children, which she values as an important aspect of her own life.", "response_spans": [[0, 508]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7830066680908203, "(0, 16)": 0.7830066680908203, "(2, 0)": 0.7830066680908203, "(2, 16)": 0.7830066680908203, "(4, 0)": 0.7830066680908203, "(4, 16)": 0.7830066680908203, "(6, 0)": 0.7830066680908203, "(6, 16)": 0.9487465620040894, "(8, 0)": 0.7830066680908203, "(8, 16)": 0.7830066680908203, "(10, 0)": 0.7830066680908203, "(10, 16)": 0.7830066680908203, "(12, 0)": 0.7830066680908203, "(12, 16)": 0.7830066680908203, "(14, 0)": 0.7830066680908203, "(14, 16)": 0.9487465620040894, "(16, 0)": 0.9487465620040894, "(16, 16)": 0.7856289744377136, "(18, 0)": 0.7830066680908203, "(18, 16)": 0.7830066680908203, "(20, 0)": 0.7830066680908203, "(20, 16)": 0.7830066680908203, "(22, 0)": 0.7856289744377136, "(22, 16)": 0.7830066680908203, "(24, 0)": 0.7856289744377136, "(24, 16)": 0.9487465620040894, "(26, 0)": 0.7856289744377136, "(26, 16)": 0.9487465620040894, "(28, 0)": 0.7856289744377136, "(28, 16)": 0.7856289744377136, "(30, 0)": 0.7856289744377136, "(30, 16)": 0.7856289744377136}, "r_span": [710, 829], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003257155418395996}}]}, {"id": "5277", "source_id": "13535", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 78 words or less:\n\nLuna reveals Eric's secret to Ridge, causing tension between RJ and Luna. Luna wants to help RJ but goes behind his back, leading to betrayal and drama. Fans wonder if RJ will forgive Luna and what Luna's true motives are.", "response_spans": [[0, 277]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8255417346954346, "(0, 16)": 0.8255417346954346, "(2, 0)": 0.8255417346954346, "(2, 16)": 0.8255417346954346, "(4, 0)": 0.8255417346954346, "(4, 16)": 0.8255417346954346, "(6, 0)": 0.8255417346954346, "(6, 16)": 0.7527366876602173, "(8, 0)": 0.8255417346954346, "(8, 16)": 0.8255417346954346, "(10, 0)": 0.8255417346954346, "(10, 16)": 0.8255417346954346, "(12, 0)": 0.8255417346954346, "(12, 16)": 0.8255417346954346, "(14, 0)": 0.8255417346954346, "(14, 16)": 0.7527366876602173, "(16, 0)": 0.8255417346954346, "(16, 16)": 0.7527366876602173, "(18, 0)": 0.8255417346954346, "(18, 16)": 0.7527366876602173, "(20, 0)": 0.8255417346954346, "(20, 16)": 0.7527366876602173, "(22, 0)": 0.7527366876602173, "(22, 16)": 0.7527366876602173, "(24, 0)": 0.7527366876602173, "(24, 16)": 0.7527366876602173, "(26, 0)": 0.7527366876602173, "(26, 16)": 0.7527366876602173, "(28, 0)": 0.7527366876602173, "(28, 16)": 0.7527366876602173, "(30, 0)": 0.7527366876602173, "(30, 16)": 0.7527366876602173}, "r_span": [527, 609], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009350180625915527}}]}, {"id": "5391", "source_id": "13554", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Cristina Husbands, a 48-year-old woman from Dallas, Texas, was sentenced to 64 months in prison for her role in a multi-state bank fraud scheme. She stole hundreds of thousands of dollars from banks in Mississippi, Alabama, Colorado, Louisiana, Tennessee, and Texas. Husbands admitted to committing the crimes under duress, struggling with drug addiction and an abusive relationship. She was targeted by recruiters at homeless shelters and was used to carry out fraudulent activities. The judge ordered her to pay $481,140 in restitution and face five years of supervised release after her prison sentence.", "response_spans": [[0, 509], [495, 606]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7949516177177429, "(0, 16)": 0.7949516177177429, "(2, 0)": 0.7949516177177429, "(2, 16)": 0.7949516177177429, "(4, 0)": 0.7949516177177429, "(4, 16)": 0.7949516177177429, "(6, 0)": 0.7949516177177429, "(6, 16)": 0.9173904061317444, "(8, 0)": 0.7949516177177429, "(8, 16)": 0.7949516177177429, "(10, 0)": 0.7824040651321411, "(10, 16)": 0.7949516177177429, "(12, 0)": 0.7949516177177429, "(12, 16)": 0.9173904061317444, "(14, 0)": 0.9173904061317444, "(14, 16)": 0.9173904061317444, "(16, 0)": 0.9173904061317444, "(16, 16)": 0.9173904061317444, "(18, 0)": 0.9173904061317444, "(18, 16)": 0.9173904061317444, "(20, 0)": 0.7824040651321411, "(20, 16)": 0.9173904061317444, "(22, 0)": 0.9173904061317444, "(22, 16)": 0.7824040651321411, "(24, 0)": 0.9173904061317444, "(24, 16)": 0.7694661617279053, "(26, 0)": 0.9173904061317444, "(26, 16)": 0.9173904061317444, "(28, 0)": 0.9173904061317444, "(28, 16)": 0.9173904061317444, "(30, 0)": 0.9173904061317444, "(30, 16)": 0.9173904061317444}, "r_span": [520, 645], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001061081886291504}}, {"prompt_attention_score": {"(0, 0)": 0.6835113763809204, "(0, 16)": 0.6835113763809204, "(2, 0)": 0.6835113763809204, "(2, 16)": 0.6835113763809204, "(4, 0)": 0.6835113763809204, "(4, 16)": 0.6835113763809204, "(6, 0)": 0.6835113763809204, "(6, 16)": 0.6835113763809204, "(8, 0)": 0.6835113763809204, "(8, 16)": 0.6835113763809204, "(10, 0)": 0.6835113763809204, "(10, 16)": 0.6835113763809204, "(12, 0)": 0.6835113763809204, "(12, 16)": 0.6835113763809204, "(14, 0)": 0.6184502243995667, "(14, 16)": 0.6835113763809204, "(16, 0)": 0.6835113763809204, "(16, 16)": 0.6835113763809204, "(18, 0)": 0.6184502243995667, "(18, 16)": 0.6835113763809204, "(20, 0)": 0.6835113763809204, "(20, 16)": 0.6184502243995667, "(22, 0)": 0.6184502243995667, "(22, 16)": 0.6835113763809204, "(24, 0)": 0.6184502243995667, "(24, 16)": 0.6835113763809204, "(26, 0)": 0.6184502243995667, "(26, 16)": 0.6184502243995667, "(28, 0)": 0.6184502243995667, "(28, 16)": 0.6184502243995667, "(30, 0)": 0.6184502243995667, "(30, 16)": 0.6184502243995667}, "r_span": [643, 670], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006645321846008301}}]}, {"id": "5415", "source_id": "13558", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 313, "end": 437, "text": "critics argue that this plan may not address the root causes of migration and could lead to exploitation of migrant workers.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nThis was not mentioned in the source content", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Texas Representative Eddie Morales proposed charging migrants $2,000 to enter the country, citing a potential revenue stream of $1.2 billion annually. He believes this could solve the issue of migrants crossing the southern border by creating a workforce agreement between governors in Mexico and Texas. However, critics argue that this plan may not address the root causes of migration and could lead to exploitation of migrant workers.", "response_spans": [[0, 437]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.694559633731842, "(0, 16)": 0.694559633731842, "(2, 0)": 0.694559633731842, "(2, 16)": 0.694559633731842, "(4, 0)": 0.694559633731842, "(4, 16)": 0.694559633731842, "(6, 0)": 0.694559633731842, "(6, 16)": 0.8886180520057678, "(8, 0)": 0.7392966151237488, "(8, 16)": 0.694559633731842, "(10, 0)": 0.694559633731842, "(10, 16)": 0.694559633731842, "(12, 0)": 0.7335683703422546, "(12, 16)": 0.694559633731842, "(14, 0)": 0.694559633731842, "(14, 16)": 0.7335683703422546, "(16, 0)": 0.7335683703422546, "(16, 16)": 0.8886180520057678, "(18, 0)": 0.8886180520057678, "(18, 16)": 0.7392966151237488, "(20, 0)": 0.694559633731842, "(20, 16)": 0.694559633731842, "(22, 0)": 0.8886180520057678, "(22, 16)": 0.7392966151237488, "(24, 0)": 0.8886180520057678, "(24, 16)": 0.7392966151237488, "(26, 0)": 0.8886180520057678, "(26, 16)": 0.8886180520057678, "(28, 0)": 0.8886180520057678, "(28, 16)": 0.8886180520057678, "(30, 0)": 0.8886180520057678, "(30, 16)": 0.8886180520057678}, "r_span": [603, 698], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0005037188529968262}}]}, {"id": "5481", "source_id": "13569", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 79 words:\n\nOn Big Brother 25, Jag Bains won the POV competition, giving him the power to save one of the nominees. Despite telling Matt he wants Blue out, Jag's target may not be secured as Cirie and Felicia could potentially vote to keep Blue. Blue is fighting to stay in the house, but her fate is likely sealed. A double eviction is coming, leaving Matt as the only hope for Jag's safety.", "response_spans": [[0, 427]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7808457612991333, "(0, 16)": 0.7808457612991333, "(2, 0)": 0.8902208209037781, "(2, 16)": 0.7808457612991333, "(4, 0)": 0.7808457612991333, "(4, 16)": 0.7808457612991333, "(6, 0)": 0.8902208209037781, "(6, 16)": 0.8369181156158447, "(8, 0)": 0.8396878242492676, "(8, 16)": 0.7808457612991333, "(10, 0)": 0.8369181156158447, "(10, 16)": 0.8902208209037781, "(12, 0)": 0.8396878242492676, "(12, 16)": 0.8396878242492676, "(14, 0)": 0.8369181156158447, "(14, 16)": 0.8369181156158447, "(16, 0)": 0.8369181156158447, "(16, 16)": 0.8369181156158447, "(18, 0)": 0.8369181156158447, "(18, 16)": 0.8369181156158447, "(20, 0)": 0.8369181156158447, "(20, 16)": 0.8369181156158447, "(22, 0)": 0.8369181156158447, "(22, 16)": 0.8369181156158447, "(24, 0)": 0.8396878242492676, "(24, 16)": 0.8369181156158447, "(26, 0)": 0.8369181156158447, "(26, 16)": 0.8369181156158447, "(28, 0)": 0.8369181156158447, "(28, 16)": 0.8369181156158447, "(30, 0)": 0.8369181156158447, "(30, 16)": 0.8369181156158447}, "r_span": [509, 619], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018153190612792969}}]}, {"id": "5529", "source_id": "13577", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is a summary of the article in 72 words or less:\n\nOn \"Bold and the Beautiful,\" Hope reveals to Brooke that Deacon is in love with Sheila, which stuns Brooke. Brooke visits Deacon to confront him, but he admits their relationship and believes people can change. Later, Ridge tells Brooke he knew about Deacon and Sheila's relationship, but kept it a secret to avoid hurting her.", "response_spans": [[0, 382]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7414082288742065, "(0, 16)": 0.7414082288742065, "(2, 0)": 0.8579394221305847, "(2, 16)": 0.7414082288742065, "(4, 0)": 0.8579394221305847, "(4, 16)": 0.8579394221305847, "(6, 0)": 0.8579394221305847, "(6, 16)": 0.8184990286827087, "(8, 0)": 0.8579394221305847, "(8, 16)": 0.8579394221305847, "(10, 0)": 0.8184990286827087, "(10, 16)": 0.7641165852546692, "(12, 0)": 0.7641165852546692, "(12, 16)": 0.8579394221305847, "(14, 0)": 0.8184990286827087, "(14, 16)": 0.8184990286827087, "(16, 0)": 0.8184990286827087, "(16, 16)": 0.8184990286827087, "(18, 0)": 0.7414082288742065, "(18, 16)": 0.8184990286827087, "(20, 0)": 0.8184990286827087, "(20, 16)": 0.8184990286827087, "(22, 0)": 0.8184990286827087, "(22, 16)": 0.8184990286827087, "(24, 0)": 0.8184990286827087, "(24, 16)": 0.8184990286827087, "(26, 0)": 0.8184990286827087, "(26, 16)": 0.8184990286827087, "(28, 0)": 0.8184990286827087, "(28, 16)": 0.8184990286827087, "(30, 0)": 0.8184990286827087, "(30, 16)": 0.8184990286827087}, "r_span": [501, 601], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010826587677001953}}]}, {"id": "5565", "source_id": "13583", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's a summary of the article in 97 words:\n\nTwo music legends, Kelly Clarkson and Lionel Richie, are returning to Las Vegas for residency shows. Clarkson has added new dates at Planet Hollywood, including New Year's Eve and Super Bowl weekend. Richie's \"King of Hearts\" residency has been extended through November 2024 at the Encore Theater at Wynn Las Vegas. Both singers are highly anticipated returns to the Las Vegas entertainment scene, with tickets selling quickly. Their intimate and energetic performances are not to be missed.", "response_spans": [[0, 50], [52, 544]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.44360560178756714, "(0, 16)": 0.44360560178756714, "(2, 0)": 0.44360560178756714, "(2, 16)": 0.44360560178756714, "(4, 0)": 0.44360560178756714, "(4, 16)": 0.4628167152404785, "(6, 0)": 0.44360560178756714, "(6, 16)": 0.42885324358940125, "(8, 0)": 0.41286376118659973, "(8, 16)": 0.4628167152404785, "(10, 0)": 0.42885324358940125, "(10, 16)": 0.42885324358940125, "(12, 0)": 0.4628167152404785, "(12, 16)": 0.42885324358940125, "(14, 0)": 0.44360560178756714, "(14, 16)": 0.42885324358940125, "(16, 0)": 0.42885324358940125, "(16, 16)": 0.42885324358940125, "(18, 0)": 0.44360560178756714, "(18, 16)": 0.42885324358940125, "(20, 0)": 0.42885324358940125, "(20, 16)": 0.42885324358940125, "(22, 0)": 0.42885324358940125, "(22, 16)": 0.42885324358940125, "(24, 0)": 0.42885324358940125, "(24, 16)": 0.42885324358940125, "(26, 0)": 0.42885324358940125, "(26, 16)": 0.42885324358940125, "(28, 0)": 0.42885324358940125, "(28, 16)": 0.44360560178756714, "(30, 0)": 0.42885324358940125, "(30, 16)": 0.42885324358940125}, "r_span": [650, 667], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000499725341796875}}, {"prompt_attention_score": {"(0, 0)": 0.8547729849815369, "(0, 16)": 0.8547729849815369, "(2, 0)": 0.8547729849815369, "(2, 16)": 0.8547729849815369, "(4, 0)": 0.8547729849815369, "(4, 16)": 0.8547729849815369, "(6, 0)": 0.8547729849815369, "(6, 16)": 0.8456310033798218, "(8, 0)": 0.9356224536895752, "(8, 16)": 0.8547729849815369, "(10, 0)": 0.9356224536895752, "(10, 16)": 0.8547729849815369, "(12, 0)": 0.9356224536895752, "(12, 16)": 0.9356224536895752, "(14, 0)": 0.8547729849815369, "(14, 16)": 0.8547729849815369, "(16, 0)": 0.8456310033798218, "(16, 16)": 0.8547729849815369, "(18, 0)": 0.8456310033798218, "(18, 16)": 0.9356224536895752, "(20, 0)": 0.9356224536895752, "(20, 16)": 0.8547729849815369, "(22, 0)": 0.8456310033798218, "(22, 16)": 0.7626610398292542, "(24, 0)": 0.8456310033798218, "(24, 16)": 0.9356224536895752, "(26, 0)": 0.8456310033798218, "(26, 16)": 0.9356224536895752, "(28, 0)": 0.8456310033798218, "(28, 16)": 0.8456310033798218, "(30, 0)": 0.8456310033798218, "(30, 16)": 0.8456310033798218}, "r_span": [669, 793], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003770589828491211}}]}, {"id": "5673", "source_id": "13601", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 365, "end": 390, "text": "has been open since 2022.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this information. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Finch & Fork is a popular breakfast and brunch spot located in downtown Santa Barbara, California. With a rating of 4.0 stars, the restaurant offers a cozy and classy atmosphere, according to customer reviews. The restaurant has a variety of categories listed, including Breakfast & Brunch, American (New), Restaurants, American (Traditional), Nightlife, Bars, and has been open since 2022. Customers have praised the restaurant's food, ambiance, and service, with one reviewer stating that their server, Jamie, was \"awesome and very hospitable.\" Another reviewer noted that while the food was overpriced, the taste and quality were great. One customer raved about the bottomless brunch option, which includes unlimited mimosas for $16, calling it the \"best bottomless brunch\" they've ever had. The restaurant is located inside a hotel lobby, providing a convenient location for visitors.", "response_spans": [[0, 511], [497, 888]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5910828709602356, "(0, 16)": 0.5910828709602356, "(2, 0)": 0.5910828709602356, "(2, 16)": 0.5910828709602356, "(4, 0)": 0.5910828709602356, "(4, 16)": 0.5910828709602356, "(6, 0)": 0.5910828709602356, "(6, 16)": 0.7851804494857788, "(8, 0)": 0.5910828709602356, "(8, 16)": 0.5910828709602356, "(10, 0)": 0.6122053861618042, "(10, 16)": 0.6122053861618042, "(12, 0)": 0.6122053861618042, "(12, 16)": 0.7851804494857788, "(14, 0)": 0.6122053861618042, "(14, 16)": 0.7851804494857788, "(16, 0)": 0.39919769763946533, "(16, 16)": 0.5910828709602356, "(18, 0)": 0.6122053861618042, "(18, 16)": 0.7851804494857788, "(20, 0)": 0.7851804494857788, "(20, 16)": 0.5910828709602356, "(22, 0)": 0.5910828709602356, "(22, 16)": 0.7851804494857788, "(24, 0)": 0.6122053861618042, "(24, 16)": 0.7851804494857788, "(26, 0)": 0.39919769763946533, "(26, 16)": 0.5910828709602356, "(28, 0)": 0.39919769763946533, "(28, 16)": 0.6122053861618042, "(30, 0)": 0.39919769763946533, "(30, 16)": 0.39919769763946533}, "r_span": [1036, 1161], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007875561714172363}}, {"prompt_attention_score": {"(0, 0)": 0.8328746557235718, "(0, 16)": 0.8469563722610474, "(2, 0)": 0.8328746557235718, "(2, 16)": 0.8328746557235718, "(4, 0)": 0.881885290145874, "(4, 16)": 0.881885290145874, "(6, 0)": 0.8328746557235718, "(6, 16)": 0.8469563722610474, "(8, 0)": 0.8328746557235718, "(8, 16)": 0.8328746557235718, "(10, 0)": 0.8469563722610474, "(10, 16)": 0.881885290145874, "(12, 0)": 0.8328746557235718, "(12, 16)": 0.8469563722610474, "(14, 0)": 0.8328746557235718, "(14, 16)": 0.881885290145874, "(16, 0)": 0.8469563722610474, "(16, 16)": 0.881885290145874, "(18, 0)": 0.8469563722610474, "(18, 16)": 0.8469563722610474, "(20, 0)": 0.8469563722610474, "(20, 16)": 0.8328746557235718, "(22, 0)": 0.8328746557235718, "(22, 16)": 0.8469563722610474, "(24, 0)": 0.8328746557235718, "(24, 16)": 0.8469563722610474, "(26, 0)": 0.504555344581604, "(26, 16)": 0.881885290145874, "(28, 0)": 0.504555344581604, "(28, 16)": 0.8328746557235718, "(30, 0)": 0.504555344581604, "(30, 16)": 0.504555344581604}, "r_span": [1157, 1248], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000614464282989502}}]}, {"id": "5685", "source_id": "13603", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 272, "end": 312, "text": "The business has a valet parking option,", "meta": "EVIDENT CONFLICT\nOriginal: false for valet\nAIGC: has a valet parking option ", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 458, "end": 481, "text": "and takes reservations,", "meta": "EVIDENT CONFLICT\nOriginal: false for reservations\nAIGC: takes reservations", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 536, "end": 580, "text": "Although the ambiance is casual and intimate", "meta": "EVIDENT CONFLICT\nOriginal: false for casual and intimate ambiance attributes \nAIGC: ambiance is casual and intimate", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 582, "end": 636, "text": "some reviewers have described it as trendy and upscale", "meta": "HIGH INTRO OF NEW INFO\nNo mention of reviewers stating this. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 677, "end": 701, "text": "takes orders for pick-up", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this information. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Tinker's Burgers:\n\nTinker's Burgers is a popular burger joint located in Summerland, California. With a rating of 4.0 out of 5 stars, the restaurant offers high-quality burgers and a cozy atmosphere. The business has a valet parking option, but it does not provide validated parking. Customers can enjoy outdoor seating, but WiFi is not available. The restaurant is suitable for groups and takes reservations, making it a great spot for families or large parties. Although the ambiance is casual and intimate, some reviewers have described it as trendy and upscale. The restaurant serves both burgers and takes orders for pick-up, making it a convenient option for locals and travelers alike. While some reviewers have praised the quality of the food and service, others have experienced long wait times and poor service. Despite these issues, many customers have raved about the taste and quality of the burgers, making Tinker's Burgers a worthwhile stop for burger lovers visiting the area.", "response_spans": [[0, 89], [91, 601], [582, 1064]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.47846680879592896, "(0, 16)": 0.47846680879592896, "(2, 0)": 0.47846680879592896, "(2, 16)": 0.47846680879592896, "(4, 0)": 0.47846680879592896, "(4, 16)": 0.47846680879592896, "(6, 0)": 0.47846680879592896, "(6, 16)": 0.6528273224830627, "(8, 0)": 0.47846680879592896, "(8, 16)": 0.47846680879592896, "(10, 0)": 0.6528273224830627, "(10, 16)": 0.6528273224830627, "(12, 0)": 0.5610405206680298, "(12, 16)": 0.6528273224830627, "(14, 0)": 0.47846680879592896, "(14, 16)": 0.6528273224830627, "(16, 0)": 0.6528273224830627, "(16, 16)": 0.47846680879592896, "(18, 0)": 0.47846680879592896, "(18, 16)": 0.6528273224830627, "(20, 0)": 0.6528273224830627, "(20, 16)": 0.4266122281551361, "(22, 0)": 0.6528273224830627, "(22, 16)": 0.6528273224830627, "(24, 0)": 0.4266122281551361, "(24, 16)": 0.6528273224830627, "(26, 0)": 0.6528273224830627, "(26, 16)": 0.543468713760376, "(28, 0)": 0.6528273224830627, "(28, 16)": 0.4266122281551361, "(30, 0)": 0.6528273224830627, "(30, 16)": 0.6528273224830627}, "r_span": [936, 960], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -5.9604644775390625e-06}}, {"prompt_attention_score": {"(0, 0)": 0.5894932150840759, "(0, 16)": 0.5894932150840759, "(2, 0)": 0.5894932150840759, "(2, 16)": 0.5894932150840759, "(4, 0)": 0.5894932150840759, "(4, 16)": 0.5894932150840759, "(6, 0)": 0.5894932150840759, "(6, 16)": 0.7596057653427124, "(8, 0)": 0.5894932150840759, "(8, 16)": 0.5894932150840759, "(10, 0)": 0.5894932150840759, "(10, 16)": 0.5894932150840759, "(12, 0)": 0.5894932150840759, "(12, 16)": 0.5511653423309326, "(14, 0)": 0.47931766510009766, "(14, 16)": 0.5511653423309326, "(16, 0)": 0.5511653423309326, "(16, 16)": 0.5894932150840759, "(18, 0)": 0.39327138662338257, "(18, 16)": 0.5511653423309326, "(20, 0)": 0.7596057653427124, "(20, 16)": 0.47931766510009766, "(22, 0)": 0.39327138662338257, "(22, 16)": 0.7596057653427124, "(24, 0)": 0.47931766510009766, "(24, 16)": 0.7596057653427124, "(26, 0)": 0.39327138662338257, "(26, 16)": 0.6226043701171875, "(28, 0)": 0.39327138662338257, "(28, 16)": 0.47931766510009766, "(30, 0)": 0.39327138662338257, "(30, 16)": 0.39327138662338257}, "r_span": [962, 1084], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0010256767272949219}}, {"prompt_attention_score": {"(0, 0)": 0.711593747138977, "(0, 16)": 0.711593747138977, "(2, 0)": 0.711593747138977, "(2, 16)": 0.711593747138977, "(4, 0)": 0.711593747138977, "(4, 16)": 0.711593747138977, "(6, 0)": 0.711593747138977, "(6, 16)": 0.7543542385101318, "(8, 0)": 0.711593747138977, "(8, 16)": 0.711593747138977, "(10, 0)": 0.711593747138977, "(10, 16)": 0.711593747138977, "(12, 0)": 0.711593747138977, "(12, 16)": 0.6578906774520874, "(14, 0)": 0.613461971282959, "(14, 16)": 0.711593747138977, "(16, 0)": 0.711593747138977, "(16, 16)": 0.711593747138977, "(18, 0)": 0.613461971282959, "(18, 16)": 0.6578906774520874, "(20, 0)": 0.6578906774520874, "(20, 16)": 0.613461971282959, "(22, 0)": 0.47781822085380554, "(22, 16)": 0.7543542385101318, "(24, 0)": 0.613461971282959, "(24, 16)": 0.6578906774520874, "(26, 0)": 0.47781822085380554, "(26, 16)": 0.7543542385101318, "(28, 0)": 0.47781822085380554, "(28, 16)": 0.613461971282959, "(30, 0)": 0.47781822085380554, "(30, 16)": 0.47781822085380554}, "r_span": [1081, 1189], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009142160415649414}}]}, {"id": "5691", "source_id": "13604", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 22, "end": 35, "text": "locally owned", "meta": "Original: No mention of th restaurant being locally owned. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 422, "end": 474, "text": "the restaurant offers a cozy and intimate atmosphere", "meta": "EVIDENT CONFLICT\nOriginal: \"intimate\": false,\nGenerative: \"the restaurant offers a cozy and intimate atmosphere\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Benchmark Eatery is a locally owned restaurant located in downtown Santa Barbara, California. With a variety of categories listed in their structured data, including American (Traditional) and American (New), the establishment offers a range of dishes to suit various tastes. Customers have left reviews of their experiences, providing valuable insights into the quality of the food and service.\n\nAccording to one review, the restaurant offers a cozy and intimate atmosphere, with friendly staff and good WiFi. However, another reviewer had a disappointing experience with their meal, citing bland and unseasoned food, as well as a lack of attention to allergies. The patio area is also praised for its ambiance.\n\nIn terms of menu offerings, Benchmark Eatery seems to specialize in flatbreads and burgers, with some customers enjoying their meals while others finding them unimpressive. The Spanish soup appears to be a popular item, but some customers have noted that its spiciness level varies.\n\nOverall, Benchmark Eatery appears to be a decent spot for a meal in downtown Santa Barbara, with some areas for improvement in the quality of food and customer service.", "response_spans": [[0, 395], [397, 712], [714, 1166]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5521988868713379, "(0, 16)": 0.5521988868713379, "(2, 0)": 0.5521988868713379, "(2, 16)": 0.5521988868713379, "(4, 0)": 0.5521988868713379, "(4, 16)": 0.5521988868713379, "(6, 0)": 0.5521988868713379, "(6, 16)": 0.8208592534065247, "(8, 0)": 0.5521988868713379, "(8, 16)": 0.5521988868713379, "(10, 0)": 0.5521988868713379, "(10, 16)": 0.5521988868713379, "(12, 0)": 0.5521988868713379, "(12, 16)": 0.8208592534065247, "(14, 0)": 0.5270073413848877, "(14, 16)": 0.5013480186462402, "(16, 0)": 0.5201659798622131, "(16, 16)": 0.5521988868713379, "(18, 0)": 0.5521988868713379, "(18, 16)": 0.8208592534065247, "(20, 0)": 0.8208592534065247, "(20, 16)": 0.5270073413848877, "(22, 0)": 0.5270073413848877, "(22, 16)": 0.6156007051467896, "(24, 0)": 0.5270073413848877, "(24, 16)": 0.8208592534065247, "(26, 0)": 0.5201659798622131, "(26, 16)": 0.5270073413848877, "(28, 0)": 0.5201659798622131, "(28, 16)": 0.5270073413848877, "(30, 0)": 0.5270073413848877, "(30, 16)": 0.5201659798622131}, "r_span": [1166, 1247], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006844401359558105}}, {"prompt_attention_score": {"(0, 0)": 0.7370004057884216, "(0, 16)": 0.7370004057884216, "(2, 0)": 0.7370004057884216, "(2, 16)": 0.7370004057884216, "(4, 0)": 0.7370004057884216, "(4, 16)": 0.7370004057884216, "(6, 0)": 0.7370004057884216, "(6, 16)": 0.6948227882385254, "(8, 0)": 0.7370004057884216, "(8, 16)": 0.7370004057884216, "(10, 0)": 0.7370004057884216, "(10, 16)": 0.7370004057884216, "(12, 0)": 0.7768985033035278, "(12, 16)": 0.7768985033035278, "(14, 0)": 0.7768985033035278, "(14, 16)": 0.7768985033035278, "(16, 0)": 0.6948227882385254, "(16, 16)": 0.7370004057884216, "(18, 0)": 0.7768985033035278, "(18, 16)": 0.616757869720459, "(20, 0)": 0.7768985033035278, "(20, 16)": 0.7768985033035278, "(22, 0)": 0.7768985033035278, "(22, 16)": 0.616757869720459, "(24, 0)": 0.7768985033035278, "(24, 16)": 0.6948227882385254, "(26, 0)": 0.5269949436187744, "(26, 16)": 0.7768985033035278, "(28, 0)": 0.5269949436187744, "(28, 16)": 0.7768985033035278, "(30, 0)": 0.7768985033035278, "(30, 16)": 0.5269949436187744}, "r_span": [1249, 1323], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.004209339618682861}}, {"prompt_attention_score": {"(0, 0)": 0.7028348445892334, "(0, 16)": 0.7028348445892334, "(2, 0)": 0.7028348445892334, "(2, 16)": 0.7028348445892334, "(4, 0)": 0.7028348445892334, "(4, 16)": 0.7028348445892334, "(6, 0)": 0.6152397394180298, "(6, 16)": 0.7032584547996521, "(8, 0)": 0.7028348445892334, "(8, 16)": 0.6152397394180298, "(10, 0)": 0.7028348445892334, "(10, 16)": 0.7028348445892334, "(12, 0)": 0.6152397394180298, "(12, 16)": 0.7028348445892334, "(14, 0)": 0.6152397394180298, "(14, 16)": 0.47059810161590576, "(16, 0)": 0.7028348445892334, "(16, 16)": 0.6152397394180298, "(18, 0)": 0.6152397394180298, "(18, 16)": 0.7447561025619507, "(20, 0)": 0.7032584547996521, "(20, 16)": 0.6152397394180298, "(22, 0)": 0.6152397394180298, "(22, 16)": 0.7032584547996521, "(24, 0)": 0.6152397394180298, "(24, 16)": 0.7032584547996521, "(26, 0)": 0.4881829619407654, "(26, 16)": 0.6152397394180298, "(28, 0)": 0.4881829619407654, "(28, 16)": 0.6152397394180298, "(30, 0)": 0.6152397394180298, "(30, 16)": 0.4881829619407654}, "r_span": [1325, 1432], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005867481231689453}}]}, {"id": "5733", "source_id": "13613", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 719, "end": 885, "text": "A third customer left a four-star review, expressing disappointment with the restaurant's limited menu options and slow service, but praising the quality of the food.", "meta": "EVIDENT CONFLICT\nOriginal: the review states that \"they have a huge list of different kinds of pizzas, pastas, salads, and more!\"\nAIGC: limited options", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Pizza Mizza:\n\nPizza Mizza is a popular food delivery services and restaurant located in Santa Barbara, California. The establishment has received mixed reviews from customers, with some praising its delicious food and others criticizing its slow service and poor customer care.\n\nOne customer gave the restaurant five stars for its food quality, mentioning that it is their favorite pizza place in town and that they have a huge list of different kinds of pizzas, pastas, salads, and more. However, another customer left a three-star review, stating that the staff is unorganized and takes too long to prepare orders, resulting in long wait times. A third customer left a four-star review, expressing disappointment with the restaurant's limited menu options and slow service, but praising the quality of the food.\n\nOne positive aspect of Pizza Mizza is its free WiFi for customers. However, the restaurant has room for improvement in terms of staff training and customer service, as some customers have reported poor communication and long wait times for their orders. Despite these issues, many customers continue to frequent the restaurant due to its high-quality food offerings.", "response_spans": [[0, 349], [351, 860], [848, 885], [887, 1253]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.516237735748291, "(0, 16)": 0.516237735748291, "(2, 0)": 0.516237735748291, "(2, 16)": 0.516237735748291, "(4, 0)": 0.516237735748291, "(4, 16)": 0.516237735748291, "(6, 0)": 0.516237735748291, "(6, 16)": 0.496448278427124, "(8, 0)": 0.7794264554977417, "(8, 16)": 0.516237735748291, "(10, 0)": 0.496448278427124, "(10, 16)": 0.5395414233207703, "(12, 0)": 0.4694058895111084, "(12, 16)": 0.7794264554977417, "(14, 0)": 0.516237735748291, "(14, 16)": 0.4694058895111084, "(16, 0)": 0.496448278427124, "(16, 16)": 0.516237735748291, "(18, 0)": 0.516237735748291, "(18, 16)": 0.496448278427124, "(20, 0)": 0.7794264554977417, "(20, 16)": 0.516237735748291, "(22, 0)": 0.516237735748291, "(22, 16)": 0.6642115116119385, "(24, 0)": 0.516237735748291, "(24, 16)": 0.496448278427124, "(26, 0)": 0.496448278427124, "(26, 16)": 0.7144113779067993, "(28, 0)": 0.496448278427124, "(28, 16)": 0.516237735748291, "(30, 0)": 0.496448278427124, "(30, 16)": 0.496448278427124}, "r_span": [1268, 1339], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004750490188598633}}, {"prompt_attention_score": {"(0, 0)": 0.7185678482055664, "(0, 16)": 0.7185678482055664, "(2, 0)": 0.7185678482055664, "(2, 16)": 0.7185678482055664, "(4, 0)": 0.7185678482055664, "(4, 16)": 0.7185678482055664, "(6, 0)": 0.7185678482055664, "(6, 16)": 0.8175227642059326, "(8, 0)": 0.7185678482055664, "(8, 16)": 0.7185678482055664, "(10, 0)": 0.795172393321991, "(10, 16)": 0.7185678482055664, "(12, 0)": 0.7185678482055664, "(12, 16)": 0.8175227642059326, "(14, 0)": 0.7185678482055664, "(14, 16)": 0.7185678482055664, "(16, 0)": 0.795172393321991, "(16, 16)": 0.7185678482055664, "(18, 0)": 0.6794934868812561, "(18, 16)": 0.8175227642059326, "(20, 0)": 0.750685453414917, "(20, 16)": 0.7185678482055664, "(22, 0)": 0.5432036519050598, "(22, 16)": 0.750685453414917, "(24, 0)": 0.7185678482055664, "(24, 16)": 0.7408009767532349, "(26, 0)": 0.5432036519050598, "(26, 16)": 0.750685453414917, "(28, 0)": 0.5432036519050598, "(28, 16)": 0.7185678482055664, "(30, 0)": 0.5432036519050598, "(30, 16)": 0.5432036519050598}, "r_span": [1341, 1451], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0017526745796203613}}, {"prompt_attention_score": {"(0, 0)": 0.5377925634384155, "(0, 16)": 0.5377925634384155, "(2, 0)": 0.5377925634384155, "(2, 16)": 0.5377925634384155, "(4, 0)": 0.5377925634384155, "(4, 16)": 0.5377925634384155, "(6, 0)": 0.5377925634384155, "(6, 16)": 0.6003771424293518, "(8, 0)": 0.5377925634384155, "(8, 16)": 0.5377925634384155, "(10, 0)": 0.5509829521179199, "(10, 16)": 0.6003771424293518, "(12, 0)": 0.4065946340560913, "(12, 16)": 0.6003771424293518, "(14, 0)": 0.5377925634384155, "(14, 16)": 0.4331682622432709, "(16, 0)": 0.5377925634384155, "(16, 16)": 0.4065946340560913, "(18, 0)": 0.6539871692657471, "(18, 16)": 0.6003771424293518, "(20, 0)": 0.5377925634384155, "(20, 16)": 0.5377925634384155, "(22, 0)": 0.5377925634384155, "(22, 16)": 0.5377925634384155, "(24, 0)": 0.5377925634384155, "(24, 16)": 0.5377925634384155, "(26, 0)": 0.4065946340560913, "(26, 16)": 0.5377925634384155, "(28, 0)": 0.4065946340560913, "(28, 16)": 0.5377925634384155, "(30, 0)": 0.4065946340560913, "(30, 16)": 0.4065946340560913}, "r_span": [1449, 1457], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007799863815307617}}, {"prompt_attention_score": {"(0, 0)": 0.6333009004592896, "(0, 16)": 0.6333009004592896, "(2, 0)": 0.6333009004592896, "(2, 16)": 0.6333009004592896, "(4, 0)": 0.6333009004592896, "(4, 16)": 0.6333009004592896, "(6, 0)": 0.6333009004592896, "(6, 16)": 0.6763291954994202, "(8, 0)": 0.6333009004592896, "(8, 16)": 0.6333009004592896, "(10, 0)": 0.6580222845077515, "(10, 16)": 0.6333009004592896, "(12, 0)": 0.6333009004592896, "(12, 16)": 0.6763291954994202, "(14, 0)": 0.6333009004592896, "(14, 16)": 0.4454836845397949, "(16, 0)": 0.7219113111495972, "(16, 16)": 0.4998595714569092, "(18, 0)": 0.6333009004592896, "(18, 16)": 0.6763291954994202, "(20, 0)": 0.6763291954994202, "(20, 16)": 0.6333009004592896, "(22, 0)": 0.4998595714569092, "(22, 16)": 0.6333009004592896, "(24, 0)": 0.6333009004592896, "(24, 16)": 0.6333009004592896, "(26, 0)": 0.4998595714569092, "(26, 16)": 0.6333009004592896, "(28, 0)": 0.4998595714569092, "(28, 16)": 0.4998595714569092, "(30, 0)": 0.4998595714569092, "(30, 16)": 0.4998595714569092}, "r_span": [1459, 1528], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002232789993286133}}]}, {"id": "5739", "source_id": "13614", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 940, "end": 966, "text": "open Monday through Sunday", "meta": "EVIDENT CONFLICT\nOriginal: closed on Mondays\nAIGC: open Monday through Sunday", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Taffy's Pizza:\n\nTaffy's Pizza is a popular restaurant located in Santa Barbara, California, offering a range of dining options including pizza, salads, pasta, sandwiches, and more. The business has received generally positive reviews from customers, with an average rating of 4.0 stars out of 5.\n\nOne reviewer left a negative review, stating that they purchased an access card but were refused acceptance by the restaurant. Another customer praised the restaurant's extensive menu, great beer selection, and excellent customer service. A third reviewer also highlighted the variety of toppings available and the free delivery option.\n\nThe restaurant has a cozy atmosphere, with outdoor seating and an arcade room in the back. Customers have described the ambiance as casual and family-friendly, with a nostalgic feel.\n\nIn terms of hours of operation, Taffy's Pizza is open Monday through Sunday from 11:00 AM to 10:00 PM, with varying closing times on weekends.\n\nOverall, Taffy's Pizza appears to offer high-quality food and drink options, excellent customer service, and a welcoming atmosphere. While some reviewers have had negative experiences, the majority of customers have given the restaurant positive feedback.", "response_spans": [[0, 367], [369, 705], [707, 1033], [1035, 1290]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7153146862983704, "(0, 16)": 0.7153146862983704, "(2, 0)": 0.7153146862983704, "(2, 16)": 0.7153146862983704, "(4, 0)": 0.7153146862983704, "(4, 16)": 0.7153146862983704, "(6, 0)": 0.7153146862983704, "(6, 16)": 0.7730808258056641, "(8, 0)": 0.5656725168228149, "(8, 16)": 0.7153146862983704, "(10, 0)": 0.7153146862983704, "(10, 16)": 0.7153146862983704, "(12, 0)": 0.7153146862983704, "(12, 16)": 0.5656725168228149, "(14, 0)": 0.5656725168228149, "(14, 16)": 0.46093684434890747, "(16, 0)": 0.46093684434890747, "(16, 16)": 0.7153146862983704, "(18, 0)": 0.7153146862983704, "(18, 16)": 0.46093684434890747, "(20, 0)": 0.7730808258056641, "(20, 16)": 0.5656725168228149, "(22, 0)": 0.5656725168228149, "(22, 16)": 0.7730808258056641, "(24, 0)": 0.5656725168228149, "(24, 16)": 0.7730808258056641, "(26, 0)": 0.46093684434890747, "(26, 16)": 0.49369990825653076, "(28, 0)": 0.46093684434890747, "(28, 16)": 0.5656725168228149, "(30, 0)": 0.46093684434890747, "(30, 16)": 0.46093684434890747}, "r_span": [1053, 1146], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016217231750488281}}, {"prompt_attention_score": {"(0, 0)": 0.6400721073150635, "(0, 16)": 0.6400721073150635, "(2, 0)": 0.6400721073150635, "(2, 16)": 0.6400721073150635, "(4, 0)": 0.6400721073150635, "(4, 16)": 0.6400721073150635, "(6, 0)": 0.6400721073150635, "(6, 16)": 0.7304530739784241, "(8, 0)": 0.6803649663925171, "(8, 16)": 0.6400721073150635, "(10, 0)": 0.6400721073150635, "(10, 16)": 0.6400721073150635, "(12, 0)": 0.6400721073150635, "(12, 16)": 0.7304530739784241, "(14, 0)": 0.7304530739784241, "(14, 16)": 0.6400721073150635, "(16, 0)": 0.6936551332473755, "(16, 16)": 0.6400721073150635, "(18, 0)": 0.7580294609069824, "(18, 16)": 0.7304530739784241, "(20, 0)": 0.6936551332473755, "(20, 16)": 0.7304530739784241, "(22, 0)": 0.5025635957717896, "(22, 16)": 0.6936551332473755, "(24, 0)": 0.7304530739784241, "(24, 16)": 0.6803649663925171, "(26, 0)": 0.5025635957717896, "(26, 16)": 0.7304530739784241, "(28, 0)": 0.5025635957717896, "(28, 16)": 0.5025635957717896, "(30, 0)": 0.5025635957717896, "(30, 16)": 0.5025635957717896}, "r_span": [1148, 1212], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00023001432418823242}}, {"prompt_attention_score": {"(0, 0)": 0.7585649490356445, "(0, 16)": 0.7585649490356445, "(2, 0)": 0.7585649490356445, "(2, 16)": 0.5857004523277283, "(4, 0)": 0.7585649490356445, "(4, 16)": 0.7585649490356445, "(6, 0)": 0.5857004523277283, "(6, 16)": 0.7350343465805054, "(8, 0)": 0.5857004523277283, "(8, 16)": 0.5857004523277283, "(10, 0)": 0.7585649490356445, "(10, 16)": 0.7585649490356445, "(12, 0)": 0.7585649490356445, "(12, 16)": 0.7350343465805054, "(14, 0)": 0.5873270034790039, "(14, 16)": 0.7350343465805054, "(16, 0)": 0.7585649490356445, "(16, 16)": 0.3841036856174469, "(18, 0)": 0.5857004523277283, "(18, 16)": 0.7350343465805054, "(20, 0)": 0.7350343465805054, "(20, 16)": 0.5873270034790039, "(22, 0)": 0.3841036856174469, "(22, 16)": 0.5857004523277283, "(24, 0)": 0.5873270034790039, "(24, 16)": 0.5857004523277283, "(26, 0)": 0.3841036856174469, "(26, 16)": 0.5873270034790039, "(28, 0)": 0.3841036856174469, "(28, 16)": 0.3841036856174469, "(30, 0)": 0.3841036856174469, "(30, 16)": 0.3841036856174469}, "r_span": [1214, 1305], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0011515617370605469}}, {"prompt_attention_score": {"(0, 0)": 0.8030337691307068, "(0, 16)": 0.8030337691307068, "(2, 0)": 0.8030337691307068, "(2, 16)": 0.8030337691307068, "(4, 0)": 0.8030337691307068, "(4, 16)": 0.8030337691307068, "(6, 0)": 0.8030337691307068, "(6, 16)": 0.6789023280143738, "(8, 0)": 0.6532207727432251, "(8, 16)": 0.8030337691307068, "(10, 0)": 0.8030337691307068, "(10, 16)": 0.8030337691307068, "(12, 0)": 0.8030337691307068, "(12, 16)": 0.8030337691307068, "(14, 0)": 0.6789023280143738, "(14, 16)": 0.4510461390018463, "(16, 0)": 0.7620940208435059, "(16, 16)": 0.4402495324611664, "(18, 0)": 0.5615622997283936, "(18, 16)": 0.6789023280143738, "(20, 0)": 0.8030337691307068, "(20, 16)": 0.6789023280143738, "(22, 0)": 0.4402495324611664, "(22, 16)": 0.8030337691307068, "(24, 0)": 0.6789023280143738, "(24, 16)": 0.6532207727432251, "(26, 0)": 0.4402495324611664, "(26, 16)": 0.6789023280143738, "(28, 0)": 0.4402495324611664, "(28, 16)": 0.4402495324611664, "(30, 0)": 0.4402495324611664, "(30, 16)": 0.4402495324611664}, "r_span": [1307, 1358], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00025212764739990234}}]}, {"id": "5763", "source_id": "13619", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Goodland Kitchen is a local restaurant located in Goleta, California, serving a variety of dishes including American New cuisine. With an overall rating of 3.5 stars, the business offers outdoor seating, takeout options, and good service. While some reviews praise the quality of their food, others have expressed disappointment with the lack of innovation in their menu and the quality of their bread. Despite this, Goodland Kitchen remains a popular spot for both locals and tourists, with many appreciating their friendly service.", "response_spans": [[0, 509], [492, 533]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5938604474067688, "(0, 16)": 0.5938604474067688, "(2, 0)": 0.5938604474067688, "(2, 16)": 0.5938604474067688, "(4, 0)": 0.5938604474067688, "(4, 16)": 0.5938604474067688, "(6, 0)": 0.5938604474067688, "(6, 16)": 0.7258521318435669, "(8, 0)": 0.5938604474067688, "(8, 16)": 0.5938604474067688, "(10, 0)": 0.5938604474067688, "(10, 16)": 0.5938604474067688, "(12, 0)": 0.5938604474067688, "(12, 16)": 0.5991610288619995, "(14, 0)": 0.5938604474067688, "(14, 16)": 0.4287913143634796, "(16, 0)": 0.5938604474067688, "(16, 16)": 0.5938604474067688, "(18, 0)": 0.4306258261203766, "(18, 16)": 0.7258521318435669, "(20, 0)": 0.5991610288619995, "(20, 16)": 0.5938604474067688, "(22, 0)": 0.4306258261203766, "(22, 16)": 0.7258521318435669, "(24, 0)": 0.5938604474067688, "(24, 16)": 0.7258521318435669, "(26, 0)": 0.4306258261203766, "(26, 16)": 0.7258521318435669, "(28, 0)": 0.4306258261203766, "(28, 16)": 0.5938604474067688, "(30, 0)": 0.4306258261203766, "(30, 16)": 0.4306258261203766}, "r_span": [707, 818], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0016402602195739746}}, {"prompt_attention_score": {"(0, 0)": 0.566461443901062, "(0, 16)": 0.566461443901062, "(2, 0)": 0.566461443901062, "(2, 16)": 0.566461443901062, "(4, 0)": 0.566461443901062, "(4, 16)": 0.566461443901062, "(6, 0)": 0.566461443901062, "(6, 16)": 0.41183924674987793, "(8, 0)": 0.566461443901062, "(8, 16)": 0.566461443901062, "(10, 0)": 0.566461443901062, "(10, 16)": 0.566461443901062, "(12, 0)": 0.41183924674987793, "(12, 16)": 0.5266053080558777, "(14, 0)": 0.566461443901062, "(14, 16)": 0.48400184512138367, "(16, 0)": 0.566461443901062, "(16, 16)": 0.566461443901062, "(18, 0)": 0.41183924674987793, "(18, 16)": 0.5266053080558777, "(20, 0)": 0.5266053080558777, "(20, 16)": 0.566461443901062, "(22, 0)": 0.41183924674987793, "(22, 16)": 0.46941643953323364, "(24, 0)": 0.566461443901062, "(24, 16)": 0.5266053080558777, "(26, 0)": 0.41183924674987793, "(26, 16)": 0.41183924674987793, "(28, 0)": 0.41183924674987793, "(28, 16)": 0.566461443901062, "(30, 0)": 0.41183924674987793, "(30, 16)": 0.41183924674987793}, "r_span": [816, 822], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -3.463029861450195e-05}}]}, {"id": "5823", "source_id": "13632", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 288, "end": 338, "text": "The atmosphere is described as casual and intimate", "meta": "EVIDENT CONFLICT\nOriginal: false for casual and intimate\nAIGC: described as casual and intimate", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Sam's To Go:\n\nSam's To Go is a popular sandwich shop located in Santa Barbara, California. With a rating of 4.5 stars, the business offers high-quality sandwiches, including Italian cold cuts and vegetarian options. The atmosphere is described as casual and intimate, with free WiFi available. The business is open seven days a week and offers takeout options. Although some reviews praise the excellent customer service and delicious sandwiches, one review notes that the quality of the sandwiches has declined recently, with a negative review citing poorly wrapped sandwiches and a grumpy server. Despite this, Sam's To Go remains a popular destination for sandwich lovers in the area.", "response_spans": [[0, 84], [86, 593], [575, 759]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.39538443088531494, "(0, 16)": 0.39538443088531494, "(2, 0)": 0.39538443088531494, "(2, 16)": 0.39538443088531494, "(4, 0)": 0.39538443088531494, "(4, 16)": 0.39538443088531494, "(6, 0)": 0.3807457983493805, "(6, 16)": 0.6833683848381042, "(8, 0)": 0.47931718826293945, "(8, 16)": 0.39538443088531494, "(10, 0)": 0.6833683848381042, "(10, 16)": 0.6833683848381042, "(12, 0)": 0.596920371055603, "(12, 16)": 0.6833683848381042, "(14, 0)": 0.3807457983493805, "(14, 16)": 0.6833683848381042, "(16, 0)": 0.6833683848381042, "(16, 16)": 0.596920371055603, "(18, 0)": 0.39538443088531494, "(18, 16)": 0.6833683848381042, "(20, 0)": 0.6833683848381042, "(20, 16)": 0.3807457983493805, "(22, 0)": 0.6833683848381042, "(22, 16)": 0.6833683848381042, "(24, 0)": 0.3807457983493805, "(24, 16)": 0.6833683848381042, "(26, 0)": 0.6833683848381042, "(26, 16)": 0.3807457983493805, "(28, 0)": 0.6833683848381042, "(28, 16)": 0.6833683848381042, "(30, 0)": 0.6833683848381042, "(30, 16)": 0.6833683848381042}, "r_span": [993, 1015], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007036328315734863}}, {"prompt_attention_score": {"(0, 0)": 0.5661740303039551, "(0, 16)": 0.5661740303039551, "(2, 0)": 0.5661740303039551, "(2, 16)": 0.5661740303039551, "(4, 0)": 0.5661740303039551, "(4, 16)": 0.5661740303039551, "(6, 0)": 0.5661740303039551, "(6, 16)": 0.6536455154418945, "(8, 0)": 0.5661740303039551, "(8, 16)": 0.5661740303039551, "(10, 0)": 0.6993857026100159, "(10, 16)": 0.6993857026100159, "(12, 0)": 0.5661740303039551, "(12, 16)": 0.6536455154418945, "(14, 0)": 0.5828900933265686, "(14, 16)": 0.6993857026100159, "(16, 0)": 0.6536455154418945, "(16, 16)": 0.5661740303039551, "(18, 0)": 0.5828900933265686, "(18, 16)": 0.6536455154418945, "(20, 0)": 0.7696527242660522, "(20, 16)": 0.5828900933265686, "(22, 0)": 0.47649461030960083, "(22, 16)": 0.7696527242660522, "(24, 0)": 0.5828900933265686, "(24, 16)": 0.5828900933265686, "(26, 0)": 0.47649461030960083, "(26, 16)": 0.5828900933265686, "(28, 0)": 0.47649461030960083, "(28, 16)": 0.47649461030960083, "(30, 0)": 0.47649461030960083, "(30, 16)": 0.47649461030960083}, "r_span": [1017, 1128], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0013592243194580078}}, {"prompt_attention_score": {"(0, 0)": 0.7066552639007568, "(0, 16)": 0.7384817004203796, "(2, 0)": 0.7066552639007568, "(2, 16)": 0.7384817004203796, "(4, 0)": 0.7066552639007568, "(4, 16)": 0.7066552639007568, "(6, 0)": 0.7384817004203796, "(6, 16)": 0.6202101111412048, "(8, 0)": 0.7066552639007568, "(8, 16)": 0.7384817004203796, "(10, 0)": 0.7066552639007568, "(10, 16)": 0.7066552639007568, "(12, 0)": 0.7066552639007568, "(12, 16)": 0.7066552639007568, "(14, 0)": 0.6139127016067505, "(14, 16)": 0.7066552639007568, "(16, 0)": 0.7066552639007568, "(16, 16)": 0.7066552639007568, "(18, 0)": 0.45813000202178955, "(18, 16)": 0.7066552639007568, "(20, 0)": 0.7066552639007568, "(20, 16)": 0.6139127016067505, "(22, 0)": 0.45813000202178955, "(22, 16)": 0.7066552639007568, "(24, 0)": 0.6139127016067505, "(24, 16)": 0.7066552639007568, "(26, 0)": 0.45813000202178955, "(26, 16)": 0.6139127016067505, "(28, 0)": 0.45813000202178955, "(28, 16)": 0.45813000202178955, "(30, 0)": 0.45813000202178955, "(30, 16)": 0.45813000202178955}, "r_span": [1125, 1168], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000246584415435791}}]}, {"id": "5829", "source_id": "13633", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Viva Modern Mexican is a popular restaurant located in Santa Barbara, California, offering a unique blend of Peruvian and Mexican cuisine. With a rating of 3.5 stars, the business provides a warm and inviting atmosphere, including outdoor seating and free WiFi. While some customers have praised the restaurant's margaritas and salads, others have had negative experiences with food poisoning and poor service. Despite these issues, Viva Modern Mexican remains a popular spot for both locals and visitors, particularly for private events such as rehearsal dinners and welcome parties.", "response_spans": [[0, 505], [492, 584]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5377528667449951, "(0, 16)": 0.5377528667449951, "(2, 0)": 0.5296173095703125, "(2, 16)": 0.5296173095703125, "(4, 0)": 0.5296173095703125, "(4, 16)": 0.5296173095703125, "(6, 0)": 0.5296173095703125, "(6, 16)": 0.741679310798645, "(8, 0)": 0.5377528667449951, "(8, 16)": 0.5296173095703125, "(10, 0)": 0.5377528667449951, "(10, 16)": 0.5377528667449951, "(12, 0)": 0.5377528667449951, "(12, 16)": 0.741679310798645, "(14, 0)": 0.5377528667449951, "(14, 16)": 0.5296173095703125, "(16, 0)": 0.741679310798645, "(16, 16)": 0.5296173095703125, "(18, 0)": 0.4079399108886719, "(18, 16)": 0.741679310798645, "(20, 0)": 0.741679310798645, "(20, 16)": 0.5377528667449951, "(22, 0)": 0.4079399108886719, "(22, 16)": 0.5377528667449951, "(24, 0)": 0.5377528667449951, "(24, 16)": 0.5393784642219543, "(26, 0)": 0.4079399108886719, "(26, 16)": 0.4079399108886719, "(28, 0)": 0.4079399108886719, "(28, 16)": 0.5377528667449951, "(30, 0)": 0.4079399108886719, "(30, 16)": 0.4079399108886719}, "r_span": [766, 875], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001984536647796631}}, {"prompt_attention_score": {"(0, 0)": 0.4624258279800415, "(0, 16)": 0.4624258279800415, "(2, 0)": 0.6347308158874512, "(2, 16)": 0.6347308158874512, "(4, 0)": 0.6347308158874512, "(4, 16)": 0.6347308158874512, "(6, 0)": 0.6347308158874512, "(6, 16)": 0.44989949464797974, "(8, 0)": 0.4624258279800415, "(8, 16)": 0.4624258279800415, "(10, 0)": 0.6347308158874512, "(10, 16)": 0.6347308158874512, "(12, 0)": 0.6347308158874512, "(12, 16)": 0.6347308158874512, "(14, 0)": 0.4624258279800415, "(14, 16)": 0.44989949464797974, "(16, 0)": 0.6347308158874512, "(16, 16)": 0.6347308158874512, "(18, 0)": 0.4624258279800415, "(18, 16)": 0.6347308158874512, "(20, 0)": 0.6347308158874512, "(20, 16)": 0.4624258279800415, "(22, 0)": 0.3710821270942688, "(22, 16)": 0.6347308158874512, "(24, 0)": 0.4624258279800415, "(24, 16)": 0.6347308158874512, "(26, 0)": 0.3710821270942688, "(26, 16)": 0.6347308158874512, "(28, 0)": 0.3710821270942688, "(28, 16)": 0.4624258279800415, "(30, 0)": 0.3710821270942688, "(30, 16)": 0.3710821270942688}, "r_span": [873, 891], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000672757625579834}}]}, {"id": "5853", "source_id": "13637", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 670, "end": 694, "text": "for parties of all sizes", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"reservation ffor parties of all sizes\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 729, "end": 735, "text": "garage", "meta": "EVIDENT CONFLICT\nOriginal: \"garage\": false,\nGenerative: \"Parking is available in a nearby garage\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 737, "end": 743, "text": "street", "meta": "EVIDENT CONFLICT\nOriginal: \"street\": false,\nGenerative: \"Parking is available in a nearby... street\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Hollister Brewing Company:\n\nLocated in Goleta, California, Hollister Brewing Company is a popular restaurant and brewery known for its American-style cuisine and craft beers. With a rating of 3.5 stars, the business offers a range of dining options, including indoor and outdoor seating, and provides free Wi-Fi to its patrons. While some customers have expressed concerns about the quality of service and slow speeds, others have praised the new menu and improvements made by the restaurant. The business is open seven days a week, with varying hours depending on the day, and offers reservations for parties of all sizes. Parking is available in a nearby garage, street, or lot, although valet parking is not offered. Overall, Hollister Brewing Company appears to offer a comfortable and welcoming atmosphere for both casual and larger groups, although some areas for improvement may exist in terms of service efficiency.", "response_spans": [[0, 98], [100, 609], [592, 995]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.37578675150871277, "(0, 16)": 0.37578675150871277, "(2, 0)": 0.37578675150871277, "(2, 16)": 0.37578675150871277, "(4, 0)": 0.37578675150871277, "(4, 16)": 0.37578675150871277, "(6, 0)": 0.37578675150871277, "(6, 16)": 0.6351070404052734, "(8, 0)": 0.37578675150871277, "(8, 16)": 0.37578675150871277, "(10, 0)": 0.6351070404052734, "(10, 16)": 0.6351070404052734, "(12, 0)": 0.37578675150871277, "(12, 16)": 0.6351070404052734, "(14, 0)": 0.37578675150871277, "(14, 16)": 0.6351070404052734, "(16, 0)": 0.6351070404052734, "(16, 16)": 0.5409412384033203, "(18, 0)": 0.37578675150871277, "(18, 16)": 0.6351070404052734, "(20, 0)": 0.6351070404052734, "(20, 16)": 0.37578675150871277, "(22, 0)": 0.37578675150871277, "(22, 16)": 0.6351070404052734, "(24, 0)": 0.37578675150871277, "(24, 16)": 0.6351070404052734, "(26, 0)": 0.6351070404052734, "(26, 16)": 0.46828508377075195, "(28, 0)": 0.6351070404052734, "(28, 16)": 0.37578675150871277, "(30, 0)": 0.6351070404052734, "(30, 16)": 0.6351070404052734}, "r_span": [930, 954], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00029331445693969727}}, {"prompt_attention_score": {"(0, 0)": 0.5832765698432922, "(0, 16)": 0.5832765698432922, "(2, 0)": 0.5832765698432922, "(2, 16)": 0.5832765698432922, "(4, 0)": 0.5832765698432922, "(4, 16)": 0.5832765698432922, "(6, 0)": 0.5832765698432922, "(6, 16)": 0.7788374423980713, "(8, 0)": 0.6284730434417725, "(8, 16)": 0.5832765698432922, "(10, 0)": 0.5832765698432922, "(10, 16)": 0.5832765698432922, "(12, 0)": 0.5832765698432922, "(12, 16)": 0.5599867701530457, "(14, 0)": 0.5832765698432922, "(14, 16)": 0.7788374423980713, "(16, 0)": 0.5599867701530457, "(16, 16)": 0.5832765698432922, "(18, 0)": 0.5832765698432922, "(18, 16)": 0.7788374423980713, "(20, 0)": 0.5599867701530457, "(20, 16)": 0.5832765698432922, "(22, 0)": 0.5832765698432922, "(22, 16)": 0.7788374423980713, "(24, 0)": 0.5832765698432922, "(24, 16)": 0.5599867701530457, "(26, 0)": 0.4743928909301758, "(26, 16)": 0.5599867701530457, "(28, 0)": 0.4743928909301758, "(28, 16)": 0.5832765698432922, "(30, 0)": 0.4743928909301758, "(30, 16)": 0.4743928909301758}, "r_span": [956, 1074], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009696483612060547}}, {"prompt_attention_score": {"(0, 0)": 0.512420654296875, "(0, 16)": 0.512420654296875, "(2, 0)": 0.512420654296875, "(2, 16)": 0.512420654296875, "(4, 0)": 0.512420654296875, "(4, 16)": 0.512420654296875, "(6, 0)": 0.512420654296875, "(6, 16)": 0.7445883750915527, "(8, 0)": 0.512420654296875, "(8, 16)": 0.512420654296875, "(10, 0)": 0.512420654296875, "(10, 16)": 0.512420654296875, "(12, 0)": 0.512420654296875, "(12, 16)": 0.7445883750915527, "(14, 0)": 0.512420654296875, "(14, 16)": 0.4593028724193573, "(16, 0)": 0.5626572370529175, "(16, 16)": 0.512420654296875, "(18, 0)": 0.5579383373260498, "(18, 16)": 0.7445883750915527, "(20, 0)": 0.7445883750915527, "(20, 16)": 0.512420654296875, "(22, 0)": 0.42593252658843994, "(22, 16)": 0.7445883750915527, "(24, 0)": 0.512420654296875, "(24, 16)": 0.5626572370529175, "(26, 0)": 0.42593252658843994, "(26, 16)": 0.5626572370529175, "(28, 0)": 0.42593252658843994, "(28, 16)": 0.512420654296875, "(30, 0)": 0.42593252658843994, "(30, 16)": 0.42593252658843994}, "r_span": [1070, 1156], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0016936659812927246}}]}, {"id": "6027", "source_id": "13669", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 302, "end": 338, "text": "The business has a casual atmosphere", "meta": "EVIDENT CONFLICT\nOriginal: \"casual\": false\nGenerative: \"The business has a casual atmosphere...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 339, "end": 365, "text": "and provides valet parking", "meta": "EVIDENT CONFLICT\nOriginal: \"valet\": false\nGenerative: \"...and provides valet parking...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 391, "end": 431, "text": "The restaurant is open seven days a week", "meta": "EVIDENT CONFLICT\nOriginal: 5 days a week\nGenerative: 7 days a week", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Jeannine's American Bakery Restaurant:\n\nJeannine's American Bakery Restaurant is located in Goleta, California and offers a range of baked goods, food, and beverages. The restaurant has a rating of 4.5 stars and offers free WiFi. The business has a casual atmosphere and provides valet parking, although it is limited. The restaurant is open seven days a week, with varying hours depending on the day.\n\nReviews of the restaurant are mixed, with some customers expressing disappointment with their experiences. One customer noted that the coffee was not great, and their chilequiles were the worst they had ever had. Another customer enjoyed their visit, praising the top-notch food and service, as well as the cute decor inside. A third customer appreciated the ambiance and the bacon, which they found to be smoky and crisp. However, they did note that the eggs were overcooked. Overall, the reviews suggest that Jeannine's American Bakery Restaurant has some room for improvement in terms of consistency and quality.", "response_spans": [[0, 473], [475, 985], [973, 1090]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6601113080978394, "(0, 16)": 0.6601113080978394, "(2, 0)": 0.6601113080978394, "(2, 16)": 0.6601113080978394, "(4, 0)": 0.6601113080978394, "(4, 16)": 0.6601113080978394, "(6, 0)": 0.6601113080978394, "(6, 16)": 0.8463329076766968, "(8, 0)": 0.6601113080978394, "(8, 16)": 0.6601113080978394, "(10, 0)": 0.5621269941329956, "(10, 16)": 0.5621269941329956, "(12, 0)": 0.6601113080978394, "(12, 16)": 0.8463329076766968, "(14, 0)": 0.5621269941329956, "(14, 16)": 0.8463329076766968, "(16, 0)": 0.49117887020111084, "(16, 16)": 0.5621269941329956, "(18, 0)": 0.5621269941329956, "(18, 16)": 0.8463329076766968, "(20, 0)": 0.8463329076766968, "(20, 16)": 0.5621269941329956, "(22, 0)": 0.5621269941329956, "(22, 16)": 0.8463329076766968, "(24, 0)": 0.5621269941329956, "(24, 16)": 0.8463329076766968, "(26, 0)": 0.49117887020111084, "(26, 16)": 0.5684167146682739, "(28, 0)": 0.49117887020111084, "(28, 16)": 0.5621269941329956, "(30, 0)": 0.49117887020111084, "(30, 16)": 0.49117887020111084}, "r_span": [1023, 1141], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0030819177627563477}}, {"prompt_attention_score": {"(0, 0)": 0.7853467464447021, "(0, 16)": 0.7853467464447021, "(2, 0)": 0.7853467464447021, "(2, 16)": 0.7853467464447021, "(4, 0)": 0.7853467464447021, "(4, 16)": 0.7853467464447021, "(6, 0)": 0.7853467464447021, "(6, 16)": 0.7555687427520752, "(8, 0)": 0.7853467464447021, "(8, 16)": 0.7233352661132812, "(10, 0)": 0.7853467464447021, "(10, 16)": 0.7853467464447021, "(12, 0)": 0.7853467464447021, "(12, 16)": 0.7555687427520752, "(14, 0)": 0.7233352661132812, "(14, 16)": 0.7853467464447021, "(16, 0)": 0.7555687427520752, "(16, 16)": 0.7853467464447021, "(18, 0)": 0.7392196655273438, "(18, 16)": 0.7555687427520752, "(20, 0)": 0.7853467464447021, "(20, 16)": 0.7392196655273438, "(22, 0)": 0.7392196655273438, "(22, 16)": 0.7555687427520752, "(24, 0)": 0.7392196655273438, "(24, 16)": 0.7853467464447021, "(26, 0)": 0.4776001572608948, "(26, 16)": 0.7392196655273438, "(28, 0)": 0.4776001572608948, "(28, 16)": 0.4776001572608948, "(30, 0)": 0.7392196655273438, "(30, 16)": 0.4776001572608948}, "r_span": [1143, 1256], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0023186206817626953}}, {"prompt_attention_score": {"(0, 0)": 0.6274262070655823, "(0, 16)": 0.6274262070655823, "(2, 0)": 0.6274262070655823, "(2, 16)": 0.6274262070655823, "(4, 0)": 0.6274262070655823, "(4, 16)": 0.6274262070655823, "(6, 0)": 0.6274262070655823, "(6, 16)": 0.6335430145263672, "(8, 0)": 0.6274262070655823, "(8, 16)": 0.6274262070655823, "(10, 0)": 0.542783260345459, "(10, 16)": 0.542783260345459, "(12, 0)": 0.6274262070655823, "(12, 16)": 0.6335430145263672, "(14, 0)": 0.542783260345459, "(14, 16)": 0.4776342213153839, "(16, 0)": 0.4942801594734192, "(16, 16)": 0.542783260345459, "(18, 0)": 0.542783260345459, "(18, 16)": 0.5467259883880615, "(20, 0)": 0.5467259883880615, "(20, 16)": 0.542783260345459, "(22, 0)": 0.542783260345459, "(22, 16)": 0.5467259883880615, "(24, 0)": 0.542783260345459, "(24, 16)": 0.542783260345459, "(26, 0)": 0.4942801594734192, "(26, 16)": 0.5321086645126343, "(28, 0)": 0.4942801594734192, "(28, 16)": 0.6097390651702881, "(30, 0)": 0.4942801594734192, "(30, 16)": 0.4942801594734192}, "r_span": [1255, 1280], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001080334186553955}}]}, {"id": "6051", "source_id": "13673", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 351, "end": 459, "text": "Hours: Holdren's Grill operates from 4 pm to 10 pm from Monday to Saturday and from 11 am to 10 pm on Sunday", "meta": "EVIDENT CONFLICT\nOriginal: Monday to Thursday & Sunday: \"16:0-21:0\", Friday & Saturday: \"16:0-22:0\"\nGenerative: \"operates from 4 pm to 10 pm from Monday to Saturday and from 11 am to 10 pm on Sunday\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Holdren's Grill:\n\nLocation: Holdren's Grill is located in Goleta, California, with its address at 6920 Market Pl Dr.\n\nCategories: The restaurant offers various categories, including Seafood, American (New), Restaurants, Nightlife, Steakhouses, American (Traditional), and Bars.\n\nHours: Holdren's Grill operates from 4 pm to 10 pm from Monday to Saturday and from 11 am to 10 pm on Sunday.\n\nAttributes: The restaurant provides free WiFi, has outdoor seating, and offers takeout options. However, some reviews mention poor service, particularly with regard to the server taking long to deliver orders and checking on customers. Additionally, one reviewer experienced difficulty with the billing process, resulting in double charging for their meal.\n\nBusiness Stars: Based on the reviews, Holdren's Grill has an overall rating of 2.5 stars out of 5.\n\nReviews: Three reviews are provided in the structured data, each offering a different perspective on the restaurant. One reviewer gave a 1-star rating due to poor service, while another reviewer praised the quality of the food and excellent service. A third reviewer had a negative experience with the billing process.", "response_spans": [[0, 460], [462, 918], [920, 1238]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5308634042739868, "(0, 16)": 0.5308634042739868, "(2, 0)": 0.5308634042739868, "(2, 16)": 0.5308634042739868, "(4, 0)": 0.5308634042739868, "(4, 16)": 0.5308634042739868, "(6, 0)": 0.5308634042739868, "(6, 16)": 0.8546814322471619, "(8, 0)": 0.5308634042739868, "(8, 16)": 0.5308634042739868, "(10, 0)": 0.5308634042739868, "(10, 16)": 0.5308634042739868, "(12, 0)": 0.5308634042739868, "(12, 16)": 0.8546814322471619, "(14, 0)": 0.5308634042739868, "(14, 16)": 0.8546814322471619, "(16, 0)": 0.43869104981422424, "(16, 16)": 0.5308634042739868, "(18, 0)": 0.5308634042739868, "(18, 16)": 0.8546814322471619, "(20, 0)": 0.8546814322471619, "(20, 16)": 0.5308634042739868, "(22, 0)": 0.5308634042739868, "(22, 16)": 0.8546814322471619, "(24, 0)": 0.5308634042739868, "(24, 16)": 0.8546814322471619, "(26, 0)": 0.43869104981422424, "(26, 16)": 0.6569947004318237, "(28, 0)": 0.43869104981422424, "(28, 16)": 0.5308634042739868, "(30, 0)": 0.43869104981422424, "(30, 16)": 0.43869104981422424}, "r_span": [1323, 1459], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0025246739387512207}}, {"prompt_attention_score": {"(0, 0)": 0.7116765975952148, "(0, 16)": 0.7116765975952148, "(2, 0)": 0.7116765975952148, "(2, 16)": 0.7116765975952148, "(4, 0)": 0.7116765975952148, "(4, 16)": 0.7116765975952148, "(6, 0)": 0.7116765975952148, "(6, 16)": 0.6438184976577759, "(8, 0)": 0.7116765975952148, "(8, 16)": 0.7116765975952148, "(10, 0)": 0.7116765975952148, "(10, 16)": 0.7116765975952148, "(12, 0)": 0.7116765975952148, "(12, 16)": 0.6438184976577759, "(14, 0)": 0.7116765975952148, "(14, 16)": 0.4850207567214966, "(16, 0)": 0.7116765975952148, "(16, 16)": 0.7116765975952148, "(18, 0)": 0.7116765975952148, "(18, 16)": 0.6438184976577759, "(20, 0)": 0.6438184976577759, "(20, 16)": 0.7116765975952148, "(22, 0)": 0.5273785591125488, "(22, 16)": 0.7100251913070679, "(24, 0)": 0.7116765975952148, "(24, 16)": 0.6438184976577759, "(26, 0)": 0.5273785591125488, "(26, 16)": 0.7116765975952148, "(28, 0)": 0.5273785591125488, "(28, 16)": 0.7116765975952148, "(30, 0)": 0.5273785591125488, "(30, 16)": 0.5273785591125488}, "r_span": [1461, 1561], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0015917420387268066}}, {"prompt_attention_score": {"(0, 0)": 0.7129027247428894, "(0, 16)": 0.7129027247428894, "(2, 0)": 0.7129027247428894, "(2, 16)": 0.7129027247428894, "(4, 0)": 0.7129027247428894, "(4, 16)": 0.7129027247428894, "(6, 0)": 0.7129027247428894, "(6, 16)": 0.64844810962677, "(8, 0)": 0.7129027247428894, "(8, 16)": 0.7129027247428894, "(10, 0)": 0.7129027247428894, "(10, 16)": 0.7129027247428894, "(12, 0)": 0.7129027247428894, "(12, 16)": 0.6950916647911072, "(14, 0)": 0.7129027247428894, "(14, 16)": 0.5019493103027344, "(16, 0)": 0.7129027247428894, "(16, 16)": 0.7129027247428894, "(18, 0)": 0.7129027247428894, "(18, 16)": 0.6950916647911072, "(20, 0)": 0.6950916647911072, "(20, 16)": 0.7129027247428894, "(22, 0)": 0.679547905921936, "(22, 16)": 0.7129027247428894, "(24, 0)": 0.7129027247428894, "(24, 16)": 0.7129027247428894, "(26, 0)": 0.679547905921936, "(26, 16)": 0.679547905921936, "(28, 0)": 0.679547905921936, "(28, 16)": 0.7129027247428894, "(30, 0)": 0.679547905921936, "(30, 16)": 0.679547905921936}, "r_span": [1563, 1629], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017006397247314453}}]}, {"id": "6141", "source_id": "13688", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 478, "end": 485, "text": "upscale", "meta": "EVIDENT CONFLICT:\nAIGC: the ambiance is upscale,\nOriginal: \"upscale\": false,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 1046, "end": 1060, "text": "street parking", "meta": "EVIDENT CONFLICT:\nAIGC:  parking options include  street parking\nOriginal: \"street\": false,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Uniboil:\n\nUniboil is a locally-owned food establishment located in Goleta, California, offering a variety of options including Food, Bubble Tea, Chinese, Restaurants, Asian Fusion, and Hot Pot. The business has received positive reviews for its hotpots, which are known to be of high quality, and its convenient parking facilities. Customers have praised the restaurant's ambiance, citing it as trendy and upscale, with both indoor and outdoor seating available. Additionally, WiFi is provided free of charge. While some customers have noted inconsistent customer service, staff are generally friendly. Uniboil has a rating of 4.0 stars and offers takeout options.\n\nSome specific comments from customers include:\n\n* Good selection of hotpots and other dishes, including a Beef Thai Tom Yum Hotpot that is particularly popular.\n* Friendly staff and good customer service, although service can be inconsistent at times.\n* Convenient parking options, including a large lot and street parking.\n* High-quality bubble tea, with one reviewer praising the Kumquat drink and another recommending the milk drink with less sugar.\n* Confusing atmosphere due to the restaurant being connected to a tea shop next door, which may lead to longer wait times for tables.\n* Limited coffee options, with one reviewer reporting that the restaurant did not have coffee available despite having advertised it.\n* Some disappointment with the beef noodle soup, which was found to be lacking in the type of noodles used.", "response_spans": [[0, 80], [82, 592], [574, 736], [738, 784], [786, 1190], [1191, 1566]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3769299387931824, "(0, 16)": 0.3769299387931824, "(2, 0)": 0.3769299387931824, "(2, 16)": 0.3769299387931824, "(4, 0)": 0.3769299387931824, "(4, 16)": 0.3690526485443115, "(6, 0)": 0.3769299387931824, "(6, 16)": 0.619713306427002, "(8, 0)": 0.3769299387931824, "(8, 16)": 0.5708692073822021, "(10, 0)": 0.619713306427002, "(10, 16)": 0.619713306427002, "(12, 0)": 0.5708692073822021, "(12, 16)": 0.619713306427002, "(14, 0)": 0.2965766191482544, "(14, 16)": 0.619713306427002, "(16, 0)": 0.619713306427002, "(16, 16)": 0.5708692073822021, "(18, 0)": 0.3769299387931824, "(18, 16)": 0.619713306427002, "(20, 0)": 0.619713306427002, "(20, 16)": 0.2965766191482544, "(22, 0)": 0.2965766191482544, "(22, 16)": 0.619713306427002, "(24, 0)": 0.2965766191482544, "(24, 16)": 0.619713306427002, "(26, 0)": 0.619713306427002, "(26, 16)": 0.5024349689483643, "(28, 0)": 0.619713306427002, "(28, 16)": 0.2965766191482544, "(30, 0)": 0.619713306427002, "(30, 16)": 0.619713306427002}, "r_span": [1140, 1161], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 3.838539123535156e-05}}, {"prompt_attention_score": {"(0, 0)": 0.5549865365028381, "(0, 16)": 0.5549865365028381, "(2, 0)": 0.5549865365028381, "(2, 16)": 0.5549865365028381, "(4, 0)": 0.5549865365028381, "(4, 16)": 0.5549865365028381, "(6, 0)": 0.5549865365028381, "(6, 16)": 0.76720130443573, "(8, 0)": 0.5549865365028381, "(8, 16)": 0.5549865365028381, "(10, 0)": 0.5549865365028381, "(10, 16)": 0.5549865365028381, "(12, 0)": 0.5549865365028381, "(12, 16)": 0.515731692314148, "(14, 0)": 0.4504762887954712, "(14, 16)": 0.76720130443573, "(16, 0)": 0.7814233303070068, "(16, 16)": 0.5549865365028381, "(18, 0)": 0.5549865365028381, "(18, 16)": 0.76720130443573, "(20, 0)": 0.76720130443573, "(20, 16)": 0.4504762887954712, "(22, 0)": 0.4504762887954712, "(22, 16)": 0.76720130443573, "(24, 0)": 0.4504762887954712, "(24, 16)": 0.76720130443573, "(26, 0)": 0.4220822751522064, "(26, 16)": 0.76720130443573, "(28, 0)": 0.4220822751522064, "(28, 16)": 0.4504762887954712, "(30, 0)": 0.4220822751522064, "(30, 16)": 0.4220822751522064}, "r_span": [1163, 1284], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002770841121673584}}, {"prompt_attention_score": {"(0, 0)": 0.6193885207176208, "(0, 16)": 0.6193885207176208, "(2, 0)": 0.6193885207176208, "(2, 16)": 0.6539970636367798, "(4, 0)": 0.6193885207176208, "(4, 16)": 0.6193885207176208, "(6, 0)": 0.6193885207176208, "(6, 16)": 0.7060484290122986, "(8, 0)": 0.6193885207176208, "(8, 16)": 0.49736130237579346, "(10, 0)": 0.6193885207176208, "(10, 16)": 0.6193885207176208, "(12, 0)": 0.49736130237579346, "(12, 16)": 0.6539970636367798, "(14, 0)": 0.49736130237579346, "(14, 16)": 0.48627611994743347, "(16, 0)": 0.6193885207176208, "(16, 16)": 0.49736130237579346, "(18, 0)": 0.49736130237579346, "(18, 16)": 0.5792244672775269, "(20, 0)": 0.5792244672775269, "(20, 16)": 0.49736130237579346, "(22, 0)": 0.49736130237579346, "(22, 16)": 0.542296290397644, "(24, 0)": 0.49736130237579346, "(24, 16)": 0.5792244672775269, "(26, 0)": 0.4821527600288391, "(26, 16)": 0.49736130237579346, "(28, 0)": 0.4821527600288391, "(28, 16)": 0.49736130237579346, "(30, 0)": 0.4821527600288391, "(30, 16)": 0.4821527600288391}, "r_span": [1281, 1316], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000767052173614502}}, {"prompt_attention_score": {"(0, 0)": 0.6671808362007141, "(0, 16)": 0.6671808362007141, "(2, 0)": 0.6671808362007141, "(2, 16)": 0.556948184967041, "(4, 0)": 0.6671808362007141, "(4, 16)": 0.5179027318954468, "(6, 0)": 0.6671808362007141, "(6, 16)": 0.5633059740066528, "(8, 0)": 0.6671808362007141, "(8, 16)": 0.556948184967041, "(10, 0)": 0.6671808362007141, "(10, 16)": 0.5179027318954468, "(12, 0)": 0.556948184967041, "(12, 16)": 0.49315476417541504, "(14, 0)": 0.556948184967041, "(14, 16)": 0.5179027318954468, "(16, 0)": 0.6099759340286255, "(16, 16)": 0.5633059740066528, "(18, 0)": 0.556948184967041, "(18, 16)": 0.5633059740066528, "(20, 0)": 0.6192697286605835, "(20, 16)": 0.556948184967041, "(22, 0)": 0.556948184967041, "(22, 16)": 0.6192697286605835, "(24, 0)": 0.556948184967041, "(24, 16)": 0.6192697286605835, "(26, 0)": 0.5633059740066528, "(26, 16)": 0.556948184967041, "(28, 0)": 0.5633059740066528, "(28, 16)": 0.556948184967041, "(30, 0)": 0.556948184967041, "(30, 16)": 0.5633059740066528}, "r_span": [1318, 1325], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003858208656311035}}, {"prompt_attention_score": {"(0, 0)": 0.6995723247528076, "(0, 16)": 0.6995723247528076, "(2, 0)": 0.6995723247528076, "(2, 16)": 0.6995723247528076, "(4, 0)": 0.6995723247528076, "(4, 16)": 0.6995723247528076, "(6, 0)": 0.6995723247528076, "(6, 16)": 0.7381575107574463, "(8, 0)": 0.6995723247528076, "(8, 16)": 0.6995723247528076, "(10, 0)": 0.6995723247528076, "(10, 16)": 0.6995723247528076, "(12, 0)": 0.6995723247528076, "(12, 16)": 0.7407262921333313, "(14, 0)": 0.49677416682243347, "(14, 16)": 0.7381575107574463, "(16, 0)": 0.7407262921333313, "(16, 16)": 0.6995723247528076, "(18, 0)": 0.6995723247528076, "(18, 16)": 0.7407262921333313, "(20, 0)": 0.7407262921333313, "(20, 16)": 0.49677416682243347, "(22, 0)": 0.49677416682243347, "(22, 16)": 0.7242275476455688, "(24, 0)": 0.49677416682243347, "(24, 16)": 0.7407262921333313, "(26, 0)": 0.44777604937553406, "(26, 16)": 0.7407262921333313, "(28, 0)": 0.44777604937553406, "(28, 16)": 0.49677416682243347, "(30, 0)": 0.44777604937553406, "(30, 16)": 0.44777604937553406}, "r_span": [1327, 1424], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0013312101364135742}}, {"prompt_attention_score": {"(0, 0)": 0.8328898549079895, "(0, 16)": 0.8328898549079895, "(2, 0)": 0.8328898549079895, "(2, 16)": 0.8328898549079895, "(4, 0)": 0.8328898549079895, "(4, 16)": 0.7495617866516113, "(6, 0)": 0.8328898549079895, "(6, 16)": 0.7013288736343384, "(8, 0)": 0.8328898549079895, "(8, 16)": 0.7013288736343384, "(10, 0)": 0.8328898549079895, "(10, 16)": 0.8328898549079895, "(12, 0)": 0.7002023458480835, "(12, 16)": 0.8328898549079895, "(14, 0)": 0.7002023458480835, "(14, 16)": 0.8328898549079895, "(16, 0)": 0.8328898549079895, "(16, 16)": 0.5745415687561035, "(18, 0)": 0.7002023458480835, "(18, 16)": 0.8328898549079895, "(20, 0)": 0.7002023458480835, "(20, 16)": 0.7002023458480835, "(22, 0)": 0.7002023458480835, "(22, 16)": 0.8328898549079895, "(24, 0)": 0.7002023458480835, "(24, 16)": 0.8328898549079895, "(26, 0)": 0.5745415687561035, "(26, 16)": 0.8328898549079895, "(28, 0)": 0.5745415687561035, "(28, 16)": 0.7002023458480835, "(30, 0)": 0.5745415687561035, "(30, 16)": 0.5745415687561035}, "r_span": [1425, 1507], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001977980136871338}}]}, {"id": "6171", "source_id": "13693", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 446, "end": 463, "text": "WiFi is available", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerative: WiFi is available", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 367, "end": 383, "text": "delivery options", "meta": null, "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "La Salsa Fresh Mexican Grill is a popular eatery located in Santa Barbara, California, serving up delicious Mexican cuisine. With a rating of 4.0 stars and an average of 4.5-star reviews, this restaurant is highly rated by its patrons. The menu offers a variety of options including traditional dishes such as quesadillas, burritos, and tacos, as well as takeout and delivery options. The restaurant provides both indoor and outdoor seating, and WiFi is available for customers to enjoy while they dine. The staff is described as friendly and accommodating, with one reviewer mentioning that their order was prepared just the way they liked it. However, one reviewer had a negative experience with the taste and quality of the food.", "response_spans": [[0, 507], [493, 732]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6758624315261841, "(0, 16)": 0.6758624315261841, "(2, 0)": 0.6012617349624634, "(2, 16)": 0.6012617349624634, "(4, 0)": 0.6012617349624634, "(4, 16)": 0.6012617349624634, "(6, 0)": 0.6012617349624634, "(6, 16)": 0.779773473739624, "(8, 0)": 0.6012617349624634, "(8, 16)": 0.6012617349624634, "(10, 0)": 0.6758624315261841, "(10, 16)": 0.6758624315261841, "(12, 0)": 0.6012617349624634, "(12, 16)": 0.542967677116394, "(14, 0)": 0.6012617349624634, "(14, 16)": 0.779773473739624, "(16, 0)": 0.779773473739624, "(16, 16)": 0.6012617349624634, "(18, 0)": 0.389591783285141, "(18, 16)": 0.779773473739624, "(20, 0)": 0.779773473739624, "(20, 16)": 0.6012617349624634, "(22, 0)": 0.389591783285141, "(22, 16)": 0.779773473739624, "(24, 0)": 0.6012617349624634, "(24, 16)": 0.779773473739624, "(26, 0)": 0.389591783285141, "(26, 16)": 0.542967677116394, "(28, 0)": 0.389591783285141, "(28, 16)": 0.6012617349624634, "(30, 0)": 0.389591783285141, "(30, 16)": 0.389591783285141}, "r_span": [778, 903], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0011250972747802734}}, {"prompt_attention_score": {"(0, 0)": 0.699664294719696, "(0, 16)": 0.699664294719696, "(2, 0)": 0.733471155166626, "(2, 16)": 0.733471155166626, "(4, 0)": 0.733471155166626, "(4, 16)": 0.733471155166626, "(6, 0)": 0.733471155166626, "(6, 16)": 0.5140758752822876, "(8, 0)": 0.733471155166626, "(8, 16)": 0.733471155166626, "(10, 0)": 0.699664294719696, "(10, 16)": 0.733471155166626, "(12, 0)": 0.699664294719696, "(12, 16)": 0.733471155166626, "(14, 0)": 0.733471155166626, "(14, 16)": 0.733471155166626, "(16, 0)": 0.733471155166626, "(16, 16)": 0.733471155166626, "(18, 0)": 0.5140758752822876, "(18, 16)": 0.699664294719696, "(20, 0)": 0.733471155166626, "(20, 16)": 0.733471155166626, "(22, 0)": 0.5140758752822876, "(22, 16)": 0.699664294719696, "(24, 0)": 0.733471155166626, "(24, 16)": 0.733471155166626, "(26, 0)": 0.5140758752822876, "(26, 16)": 0.733471155166626, "(28, 0)": 0.5140758752822876, "(28, 16)": 0.733471155166626, "(30, 0)": 0.5140758752822876, "(30, 16)": 0.5140758752822876}, "r_span": [899, 948], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007137060165405273}}]}, {"id": "6237", "source_id": "13706", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 752, "end": 756, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerative:  \"offers... WiFi\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 882, "end": 922, "text": "the business provides validated parking,", "meta": "EVIDENT CONFLICT\nOriginal: \"validated\": \"no\",\nGenerative:  \"provides validated parking\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 1510, "end": 1585, "text": "some customers may find the menu items to be less impressive than expected.", "meta": "Original: \"...some customers...less impressive...\" this does not appear in the original source. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Backyard Bowls:\n\nBackyard Bowls is a popular health food restaurant located in Santa Barbara, California. With categories including Health Markets, Coffee & Tea, Ice Cream & Frozen Yogurt, Restaurants, Juice Bars & Smoothies, Breakfast & Brunch, and Food, they offer a wide range of options for health-conscious diners. Their address at 331 Motor Way suggests a convenient location near the heart of the city. The business has a rating of 4.0 out of 5 stars, indicating generally positive reviews from customers.\n\nTheir hours of operation are as follows: Monday through Sunday from 8:00 AM to 5:00 PM, with no availability for reservations. The restaurant offers outdoor seating, WiFi, and takeout services, making it a versatile dining option. While some customers have noted that the parking can be limited, the business provides validated parking, which may alleviate this issue.\n\nIn terms of food quality, one customer praised their porridge selection, describing it as \"hot and delicious\" with honey on top and bananas. Another reviewer gave the restaurant high marks, calling it \"best in class\" and highlighting the quality ingredients used in their a√ßa√≠ bowls. However, one customer found their toast to be \"slightly tasteless,\" suggesting that it may not be the best option for those looking for a more flavorful dish. Overall, Backyard Bowls appears to offer healthy and nutritious options in a cozy and casual setting, although some customers may find the menu items to be less impressive than expected.", "response_spans": [[0, 87], [89, 584], [586, 954], [956, 1462], [1448, 1585]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4894475042819977, "(0, 16)": 0.4894475042819977, "(2, 0)": 0.4894475042819977, "(2, 16)": 0.4894475042819977, "(4, 0)": 0.4894475042819977, "(4, 16)": 0.4894475042819977, "(6, 0)": 0.4894475042819977, "(6, 16)": 0.6096410155296326, "(8, 0)": 0.4894475042819977, "(8, 16)": 0.4894475042819977, "(10, 0)": 0.6096410155296326, "(10, 16)": 0.6096410155296326, "(12, 0)": 0.4894475042819977, "(12, 16)": 0.6096410155296326, "(14, 0)": 0.4894475042819977, "(14, 16)": 0.6096410155296326, "(16, 0)": 0.6096410155296326, "(16, 16)": 0.6096410155296326, "(18, 0)": 0.4894475042819977, "(18, 16)": 0.6096410155296326, "(20, 0)": 0.6096410155296326, "(20, 16)": 0.4894475042819977, "(22, 0)": 0.6096410155296326, "(22, 16)": 0.6096410155296326, "(24, 0)": 0.4894475042819977, "(24, 16)": 0.6096410155296326, "(26, 0)": 0.6096410155296326, "(26, 16)": 0.5687265396118164, "(28, 0)": 0.6096410155296326, "(28, 16)": 0.4894475042819977, "(30, 0)": 0.6096410155296326, "(30, 16)": 0.6096410155296326}, "r_span": [807, 828], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005769729614257812}}, {"prompt_attention_score": {"(0, 0)": 0.6265681982040405, "(0, 16)": 0.6265681982040405, "(2, 0)": 0.6265681982040405, "(2, 16)": 0.6265681982040405, "(4, 0)": 0.6265681982040405, "(4, 16)": 0.6265681982040405, "(6, 0)": 0.6265681982040405, "(6, 16)": 0.8379254341125488, "(8, 0)": 0.6265681982040405, "(8, 16)": 0.6265681982040405, "(10, 0)": 0.6265681982040405, "(10, 16)": 0.6265681982040405, "(12, 0)": 0.6265681982040405, "(12, 16)": 0.8379254341125488, "(14, 0)": 0.6265681982040405, "(14, 16)": 0.8379254341125488, "(16, 0)": 0.8379254341125488, "(16, 16)": 0.6265681982040405, "(18, 0)": 0.6265681982040405, "(18, 16)": 0.8379254341125488, "(20, 0)": 0.8379254341125488, "(20, 16)": 0.6265681982040405, "(22, 0)": 0.6265681982040405, "(22, 16)": 0.8379254341125488, "(24, 0)": 0.7779176235198975, "(24, 16)": 0.8379254341125488, "(26, 0)": 0.4167168140411377, "(26, 16)": 0.48662620782852173, "(28, 0)": 0.4167168140411377, "(28, 16)": 0.6265681982040405, "(30, 0)": 0.4167168140411377, "(30, 16)": 0.4167168140411377}, "r_span": [830, 951], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.002564728260040283}}, {"prompt_attention_score": {"(0, 0)": 0.5222325325012207, "(0, 16)": 0.5222325325012207, "(2, 0)": 0.5222325325012207, "(2, 16)": 0.5222325325012207, "(4, 0)": 0.5222325325012207, "(4, 16)": 0.5222325325012207, "(6, 0)": 0.5222325325012207, "(6, 16)": 0.6837059259414673, "(8, 0)": 0.5222325325012207, "(8, 16)": 0.5222325325012207, "(10, 0)": 0.5222325325012207, "(10, 16)": 0.5222325325012207, "(12, 0)": 0.5222325325012207, "(12, 16)": 0.6030471920967102, "(14, 0)": 0.5222325325012207, "(14, 16)": 0.6837059259414673, "(16, 0)": 0.6030471920967102, "(16, 16)": 0.5222325325012207, "(18, 0)": 0.4807271957397461, "(18, 16)": 0.6837059259414673, "(20, 0)": 0.6030471920967102, "(20, 16)": 0.5222325325012207, "(22, 0)": 0.5222325325012207, "(22, 16)": 0.6837059259414673, "(24, 0)": 0.5222325325012207, "(24, 16)": 0.6030471920967102, "(26, 0)": 0.4807271957397461, "(26, 16)": 0.5510543584823608, "(28, 0)": 0.4807271957397461, "(28, 16)": 0.5222325325012207, "(30, 0)": 0.4807271957397461, "(30, 16)": 0.4807271957397461}, "r_span": [953, 1043], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008586645126342773}}, {"prompt_attention_score": {"(0, 0)": 0.8456628322601318, "(0, 16)": 0.8456628322601318, "(2, 0)": 0.8456628322601318, "(2, 16)": 0.8456628322601318, "(4, 0)": 0.8456628322601318, "(4, 16)": 0.8456628322601318, "(6, 0)": 0.8456628322601318, "(6, 16)": 0.8429162502288818, "(8, 0)": 0.8456628322601318, "(8, 16)": 0.8456628322601318, "(10, 0)": 0.8456628322601318, "(10, 16)": 0.8456628322601318, "(12, 0)": 0.8456628322601318, "(12, 16)": 0.8429162502288818, "(14, 0)": 0.8456628322601318, "(14, 16)": 0.8456628322601318, "(16, 0)": 0.8456628322601318, "(16, 16)": 0.8456628322601318, "(18, 0)": 0.8456628322601318, "(18, 16)": 0.8429162502288818, "(20, 0)": 0.8429162502288818, "(20, 16)": 0.8456628322601318, "(22, 0)": 0.47272568941116333, "(22, 16)": 0.8429162502288818, "(24, 0)": 0.8456628322601318, "(24, 16)": 0.8429162502288818, "(26, 0)": 0.47272568941116333, "(26, 16)": 0.8429162502288818, "(28, 0)": 0.47272568941116333, "(28, 16)": 0.47272568941116333, "(30, 0)": 0.47272568941116333, "(30, 16)": 0.47272568941116333}, "r_span": [1045, 1166], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.003426194190979004}}, {"prompt_attention_score": {"(0, 0)": 0.5003423690795898, "(0, 16)": 0.5278950333595276, "(2, 0)": 0.5003423690795898, "(2, 16)": 0.5003423690795898, "(4, 0)": 0.5355427265167236, "(4, 16)": 0.5003423690795898, "(6, 0)": 0.5003423690795898, "(6, 16)": 0.5003423690795898, "(8, 0)": 0.5003423690795898, "(8, 16)": 0.5003423690795898, "(10, 0)": 0.5003423690795898, "(10, 16)": 0.5003423690795898, "(12, 0)": 0.5003423690795898, "(12, 16)": 0.5003423690795898, "(14, 0)": 0.5003423690795898, "(14, 16)": 0.5003423690795898, "(16, 0)": 0.5003423690795898, "(16, 16)": 0.42961689829826355, "(18, 0)": 0.5003423690795898, "(18, 16)": 0.5355427265167236, "(20, 0)": 0.5278950333595276, "(20, 16)": 0.5003423690795898, "(22, 0)": 0.42961689829826355, "(22, 16)": 0.5355427265167236, "(24, 0)": 0.5003423690795898, "(24, 16)": 0.5003423690795898, "(26, 0)": 0.42961689829826355, "(26, 16)": 0.5003423690795898, "(28, 0)": 0.42961689829826355, "(28, 16)": 0.42961689829826355, "(30, 0)": 0.42961689829826355, "(30, 16)": 0.42961689829826355}, "r_span": [1163, 1192], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0004391670227050781}}]}, {"id": "6249", "source_id": "13708", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 347, "end": 398, "text": "While some mention that the restaurant can get busy", "meta": "HIGH INTRODUCTION OF INFORMATION\nOriginal: *not mentioned*\nGenerative: \" While some mention that the restaurant can get busy\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Lure Fish House is a popular restaurant located in Santa Barbara, California, offering a unique dining experience with fresh seafood and a trendy atmosphere. With a rating of 4.5 stars, the business provides excellent service, delicious food, and ample parking options. Reviewers praise the quality of the fish, friendly servers, and good drinks. While some mention that the restaurant can get busy, they highly recommend it for both dine-in and take-out options. Overall, Lure Fish House is a great spot for seafood lovers and those looking for a trendy night out.", "response_spans": [[0, 508], [489, 565]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6495975255966187, "(0, 16)": 0.6495975255966187, "(2, 0)": 0.6495975255966187, "(2, 16)": 0.6495975255966187, "(4, 0)": 0.6495975255966187, "(4, 16)": 0.6495975255966187, "(6, 0)": 0.6495975255966187, "(6, 16)": 0.8068434000015259, "(8, 0)": 0.6495975255966187, "(8, 16)": 0.6495975255966187, "(10, 0)": 0.6495975255966187, "(10, 16)": 0.6495975255966187, "(12, 0)": 0.6495975255966187, "(12, 16)": 0.6495975255966187, "(14, 0)": 0.6495975255966187, "(14, 16)": 0.6495975255966187, "(16, 0)": 0.6495975255966187, "(16, 16)": 0.6495975255966187, "(18, 0)": 0.6495975255966187, "(18, 16)": 0.8068434000015259, "(20, 0)": 0.5059207677841187, "(20, 16)": 0.3948071002960205, "(22, 0)": 0.3948071002960205, "(22, 16)": 0.6495975255966187, "(24, 0)": 0.3948071002960205, "(24, 16)": 0.6495975255966187, "(26, 0)": 0.3948071002960205, "(26, 16)": 0.3948071002960205, "(28, 0)": 0.3948071002960205, "(28, 16)": 0.3948071002960205, "(30, 0)": 0.3948071002960205, "(30, 16)": 0.3948071002960205}, "r_span": [712, 828], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009281039237976074}}, {"prompt_attention_score": {"(0, 0)": 0.6938934326171875, "(0, 16)": 0.6938934326171875, "(2, 0)": 0.6938934326171875, "(2, 16)": 0.6938934326171875, "(4, 0)": 0.6938934326171875, "(4, 16)": 0.6938934326171875, "(6, 0)": 0.6938934326171875, "(6, 16)": 0.6281466484069824, "(8, 0)": 0.6938934326171875, "(8, 16)": 0.6938934326171875, "(10, 0)": 0.6938934326171875, "(10, 16)": 0.6938934326171875, "(12, 0)": 0.4017479121685028, "(12, 16)": 0.534870445728302, "(14, 0)": 0.6938934326171875, "(14, 16)": 0.6938934326171875, "(16, 0)": 0.4017479121685028, "(16, 16)": 0.6938934326171875, "(18, 0)": 0.4017479121685028, "(18, 16)": 0.6281466484069824, "(20, 0)": 0.534870445728302, "(20, 16)": 0.4017479121685028, "(22, 0)": 0.4017479121685028, "(22, 16)": 0.534870445728302, "(24, 0)": 0.4017479121685028, "(24, 16)": 0.534870445728302, "(26, 0)": 0.4017479121685028, "(26, 16)": 0.4017479121685028, "(28, 0)": 0.4017479121685028, "(28, 16)": 0.4017479121685028, "(30, 0)": 0.4017479121685028, "(30, 16)": 0.4017479121685028}, "r_span": [824, 844], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00039637088775634766}}]}, {"id": "6255", "source_id": "13709", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 521, "end": 549, "text": "vegetarian and vegan options", "meta": "Original: No mention if the restaurant offers vegetarian and vegan options.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Spudnuts & Bagels:\n\nSpudnuts & Bagels is a popular restaurant located in Santa Barbara, California, serving a variety of food items such as donuts, bagels, coffee, tea, and bubble tea. The business has received positive reviews from customers, with an overall rating of 4.5 stars. Customers have praised the wide selection of donuts and bagels, particularly the homemade cream cheese flavors which are unique and delicious. The business also offers vegetarian and vegan options, including a vegetable cream cheese that contains chopped up veggies. Reviewers have appreciated the friendly service and the quality of the food. One reviewer even mentioned that they were so impressed with the business that they had to stop by multiple times during their visit to Santa Barbara.", "response_spans": [[0, 90], [92, 599], [586, 847]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5378248691558838, "(0, 16)": 0.5378248691558838, "(2, 0)": 0.5378248691558838, "(2, 16)": 0.5378248691558838, "(4, 0)": 0.5378248691558838, "(4, 16)": 0.5378248691558838, "(6, 0)": 0.5378248691558838, "(6, 16)": 0.6480093598365784, "(8, 0)": 0.5378248691558838, "(8, 16)": 0.5378248691558838, "(10, 0)": 0.6480093598365784, "(10, 16)": 0.6480093598365784, "(12, 0)": 0.5637898445129395, "(12, 16)": 0.6480093598365784, "(14, 0)": 0.5720341205596924, "(14, 16)": 0.6480093598365784, "(16, 0)": 0.6480093598365784, "(16, 16)": 0.6480093598365784, "(18, 0)": 0.6480093598365784, "(18, 16)": 0.6480093598365784, "(20, 0)": 0.6480093598365784, "(20, 16)": 0.5720341205596924, "(22, 0)": 0.6480093598365784, "(22, 16)": 0.6480093598365784, "(24, 0)": 0.5720341205596924, "(24, 16)": 0.6480093598365784, "(26, 0)": 0.6480093598365784, "(26, 16)": 0.5720341205596924, "(28, 0)": 0.6480093598365784, "(28, 16)": 0.6480093598365784, "(30, 0)": 0.6480093598365784, "(30, 16)": 0.6480093598365784}, "r_span": [828, 852], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010560154914855957}}, {"prompt_attention_score": {"(0, 0)": 0.6161266565322876, "(0, 16)": 0.6161266565322876, "(2, 0)": 0.6161266565322876, "(2, 16)": 0.6161266565322876, "(4, 0)": 0.6161266565322876, "(4, 16)": 0.6161266565322876, "(6, 0)": 0.6161266565322876, "(6, 16)": 0.752568781375885, "(8, 0)": 0.6161266565322876, "(8, 16)": 0.6161266565322876, "(10, 0)": 0.7142069339752197, "(10, 16)": 0.6161266565322876, "(12, 0)": 0.399150013923645, "(12, 16)": 0.6870694160461426, "(14, 0)": 0.6870694160461426, "(14, 16)": 0.752568781375885, "(16, 0)": 0.6870694160461426, "(16, 16)": 0.6161266565322876, "(18, 0)": 0.399150013923645, "(18, 16)": 0.752568781375885, "(20, 0)": 0.6870694160461426, "(20, 16)": 0.6870694160461426, "(22, 0)": 0.399150013923645, "(22, 16)": 0.6870694160461426, "(24, 0)": 0.6870694160461426, "(24, 16)": 0.6870694160461426, "(26, 0)": 0.399150013923645, "(26, 16)": 0.6870694160461426, "(28, 0)": 0.399150013923645, "(28, 16)": 0.399150013923645, "(30, 0)": 0.399150013923645, "(30, 16)": 0.399150013923645}, "r_span": [854, 969], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0015267133712768555}}, {"prompt_attention_score": {"(0, 0)": 0.6881358623504639, "(0, 16)": 0.6881358623504639, "(2, 0)": 0.6881358623504639, "(2, 16)": 0.6881358623504639, "(4, 0)": 0.6881358623504639, "(4, 16)": 0.6881358623504639, "(6, 0)": 0.6881358623504639, "(6, 16)": 0.7286694645881653, "(8, 0)": 0.6881358623504639, "(8, 16)": 0.6881358623504639, "(10, 0)": 0.6881358623504639, "(10, 16)": 0.6881358623504639, "(12, 0)": 0.6881358623504639, "(12, 16)": 0.7286694645881653, "(14, 0)": 0.7154265642166138, "(14, 16)": 0.6881358623504639, "(16, 0)": 0.6881358623504639, "(16, 16)": 0.48763060569763184, "(18, 0)": 0.48763060569763184, "(18, 16)": 0.6881358623504639, "(20, 0)": 0.6881358623504639, "(20, 16)": 0.7154265642166138, "(22, 0)": 0.48763060569763184, "(22, 16)": 0.6881358623504639, "(24, 0)": 0.7154265642166138, "(24, 16)": 0.6881358623504639, "(26, 0)": 0.48763060569763184, "(26, 16)": 0.7154265642166138, "(28, 0)": 0.48763060569763184, "(28, 16)": 0.48763060569763184, "(30, 0)": 0.48763060569763184, "(30, 16)": 0.48763060569763184}, "r_span": [968, 1019], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00150221586227417}}]}, {"id": "6279", "source_id": "13713", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 611, "end": 683, "text": "The menu is priced moderately, with most dishes ranging from $10 to $15.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of a price range. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 685, "end": 766, "text": "According to customer reviews, the restaurant has a cozy and intimate atmosphere,", "meta": "HIGH INTRO OF NEW INFO\nNo review mentions this. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 303, "end": 322, "text": "based on 3 reviews.", "meta": "It is unknown if the rating is only based off of the three reviews showcased in the source information, or more than those three reviews", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Mala Town:\n\nMala Town is a Chinese restaurant located in Goleta, California, offering a variety of dishes including Chinese soups, hot pots, and appetizers. The restaurant has a good reputation, with an average rating of 4.0 stars based on 3 reviews.\n\nThe menu features a range of options, including traditional Chinese dishes such as mala tang and dry pot (peanut-based sauce), as well as jian bing (Chinese crepe). The restaurant offers a unique blend of modern and traditional Chinese cuisine, using fresh and high-quality ingredients. The menu is priced moderately, with most dishes ranging from $10 to $15.\n\nAccording to customer reviews, the restaurant has a cozy and intimate atmosphere, with a large and lush patio area perfect for outdoor dining. Customers have praised the friendly and attentive service, as well as the delicious and flavorful food. However, some reviews have noted that the restaurant could benefit from improved utensils, particularly for soups.\n\nOverall, Mala Town appears to be a popular and enjoyable dining destination for those looking for authentic and delicious Chinese cuisine in a cozy setting.", "response_spans": [[0, 322], [324, 683], [685, 1046], [1048, 1204]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6368405222892761, "(0, 16)": 0.5228932499885559, "(2, 0)": 0.6368405222892761, "(2, 16)": 0.6368405222892761, "(4, 0)": 0.6368405222892761, "(4, 16)": 0.6368405222892761, "(6, 0)": 0.6368405222892761, "(6, 16)": 0.47801655530929565, "(8, 0)": 0.5678703784942627, "(8, 16)": 0.6368405222892761, "(10, 0)": 0.5228932499885559, "(10, 16)": 0.5228932499885559, "(12, 0)": 0.5228932499885559, "(12, 16)": 0.6526152491569519, "(14, 0)": 0.6368405222892761, "(14, 16)": 0.44033151865005493, "(16, 0)": 0.47801655530929565, "(16, 16)": 0.6368405222892761, "(18, 0)": 0.6368405222892761, "(18, 16)": 0.47801655530929565, "(20, 0)": 0.748489260673523, "(20, 16)": 0.6368405222892761, "(22, 0)": 0.6368405222892761, "(22, 16)": 0.6232606172561646, "(24, 0)": 0.6368405222892761, "(24, 16)": 0.748489260673523, "(26, 0)": 0.47801655530929565, "(26, 16)": 0.6368405222892761, "(28, 0)": 0.47801655530929565, "(28, 16)": 0.6368405222892761, "(30, 0)": 0.6368405222892761, "(30, 16)": 0.47801655530929565}, "r_span": [1303, 1383], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00047844648361206055}}, {"prompt_attention_score": {"(0, 0)": 0.7960203289985657, "(0, 16)": 0.7960203289985657, "(2, 0)": 0.7960203289985657, "(2, 16)": 0.6094750761985779, "(4, 0)": 0.7960203289985657, "(4, 16)": 0.7960203289985657, "(6, 0)": 0.7960203289985657, "(6, 16)": 0.7163450717926025, "(8, 0)": 0.7960203289985657, "(8, 16)": 0.7960203289985657, "(10, 0)": 0.6094750761985779, "(10, 16)": 0.7960203289985657, "(12, 0)": 0.7960203289985657, "(12, 16)": 0.7960203289985657, "(14, 0)": 0.7960203289985657, "(14, 16)": 0.7960203289985657, "(16, 0)": 0.7960203289985657, "(16, 16)": 0.7960203289985657, "(18, 0)": 0.6660975217819214, "(18, 16)": 0.7960203289985657, "(20, 0)": 0.7960203289985657, "(20, 16)": 0.7960203289985657, "(22, 0)": 0.7960203289985657, "(22, 16)": 0.7960203289985657, "(24, 0)": 0.7960203289985657, "(24, 16)": 0.7960203289985657, "(26, 0)": 0.4655782878398895, "(26, 16)": 0.7960203289985657, "(28, 0)": 0.4655782878398895, "(28, 16)": 0.7960203289985657, "(30, 0)": 0.7960203289985657, "(30, 16)": 0.4655782878398895}, "r_span": [1385, 1477], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006561875343322754}}, {"prompt_attention_score": {"(0, 0)": 0.6750280261039734, "(0, 16)": 0.6750280261039734, "(2, 0)": 0.6750280261039734, "(2, 16)": 0.6750280261039734, "(4, 0)": 0.6750280261039734, "(4, 16)": 0.6750280261039734, "(6, 0)": 0.6750280261039734, "(6, 16)": 0.7406453490257263, "(8, 0)": 0.6750280261039734, "(8, 16)": 0.6750280261039734, "(10, 0)": 0.7121803760528564, "(10, 16)": 0.6750280261039734, "(12, 0)": 0.6750280261039734, "(12, 16)": 0.6424688100814819, "(14, 0)": 0.6750280261039734, "(14, 16)": 0.6750280261039734, "(16, 0)": 0.6750280261039734, "(16, 16)": 0.6750280261039734, "(18, 0)": 0.6831439137458801, "(18, 16)": 0.6424688100814819, "(20, 0)": 0.6424688100814819, "(20, 16)": 0.6750280261039734, "(22, 0)": 0.6750280261039734, "(22, 16)": 0.7406453490257263, "(24, 0)": 0.6750280261039734, "(24, 16)": 0.7406453490257263, "(26, 0)": 0.5184572339057922, "(26, 16)": 0.6750280261039734, "(28, 0)": 0.5184572339057922, "(28, 16)": 0.6750280261039734, "(30, 0)": 0.6750280261039734, "(30, 16)": 0.5184572339057922}, "r_span": [1479, 1559], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0035544633865356445}}, {"prompt_attention_score": {"(0, 0)": 0.6235066056251526, "(0, 16)": 0.6235066056251526, "(2, 0)": 0.6235066056251526, "(2, 16)": 0.6235066056251526, "(4, 0)": 0.5702540874481201, "(4, 16)": 0.6235066056251526, "(6, 0)": 0.6235066056251526, "(6, 16)": 0.6080255508422852, "(8, 0)": 0.6235066056251526, "(8, 16)": 0.6235066056251526, "(10, 0)": 0.5484699606895447, "(10, 16)": 0.5484699606895447, "(12, 0)": 0.6235066056251526, "(12, 16)": 0.6226720213890076, "(14, 0)": 0.6235066056251526, "(14, 16)": 0.4438331127166748, "(16, 0)": 0.4267738461494446, "(16, 16)": 0.4267738461494446, "(18, 0)": 0.5702540874481201, "(18, 16)": 0.4267738461494446, "(20, 0)": 0.6673665046691895, "(20, 16)": 0.6235066056251526, "(22, 0)": 0.6235066056251526, "(22, 16)": 0.6235066056251526, "(24, 0)": 0.6235066056251526, "(24, 16)": 0.6235066056251526, "(26, 0)": 0.4267738461494446, "(26, 16)": 0.6235066056251526, "(28, 0)": 0.4267738461494446, "(28, 16)": 0.6235066056251526, "(30, 0)": 0.6235066056251526, "(30, 16)": 0.4267738461494446}, "r_span": [1561, 1596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004921555519104004}}]}, {"id": "6285", "source_id": "13714", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Alchemy Wellness Spa is a top-rated spa located in Santa Barbara, California, offering a range of services including skin care, massages, acupuncture, and more. Customers have given the spa high ratings for its peaceful and relaxing atmosphere, professional and caring staff, and excellent quality of services. One customer praised the spa's \"gorgeous setting\" and \"heart-centered service,\" while another raved about their exceptional facial treatment with Danielle, stating that they looked \"much younger\" after the session. However, one customer had a negative experience with a massage therapist named Lizzie, who they felt was inexperienced and failed to provide the desired level of pressure during the massage. Despite this negative review, Alchemy Wellness Spa remains a popular choice for those seeking a tranquil and rejuvenating spa experience.", "response_spans": [[0, 512], [498, 854]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.591865062713623, "(0, 16)": 0.591865062713623, "(2, 0)": 0.5155017971992493, "(2, 16)": 0.5155017971992493, "(4, 0)": 0.591865062713623, "(4, 16)": 0.591865062713623, "(6, 0)": 0.5155017971992493, "(6, 16)": 0.802818775177002, "(8, 0)": 0.591865062713623, "(8, 16)": 0.591865062713623, "(10, 0)": 0.671440601348877, "(10, 16)": 0.5155017971992493, "(12, 0)": 0.671440601348877, "(12, 16)": 0.671440601348877, "(14, 0)": 0.5155017971992493, "(14, 16)": 0.45110437273979187, "(16, 0)": 0.671440601348877, "(16, 16)": 0.591865062713623, "(18, 0)": 0.5155017971992493, "(18, 16)": 0.802818775177002, "(20, 0)": 0.5770179629325867, "(20, 16)": 0.671440601348877, "(22, 0)": 0.4407229423522949, "(22, 16)": 0.5770179629325867, "(24, 0)": 0.671440601348877, "(24, 16)": 0.5770179629325867, "(26, 0)": 0.4407229423522949, "(26, 16)": 0.5770179629325867, "(28, 0)": 0.4407229423522949, "(28, 16)": 0.4407229423522949, "(30, 0)": 0.4407229423522949, "(30, 16)": 0.4407229423522949}, "r_span": [1031, 1151], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014160871505737305}}, {"prompt_attention_score": {"(0, 0)": 0.7545822262763977, "(0, 16)": 0.7545822262763977, "(2, 0)": 0.6948386430740356, "(2, 16)": 0.6948386430740356, "(4, 0)": 0.6948386430740356, "(4, 16)": 0.6948386430740356, "(6, 0)": 0.6948386430740356, "(6, 16)": 0.6366394758224487, "(8, 0)": 0.7545822262763977, "(8, 16)": 0.6948386430740356, "(10, 0)": 0.6948386430740356, "(10, 16)": 0.6948386430740356, "(12, 0)": 0.7545822262763977, "(12, 16)": 0.7545822262763977, "(14, 0)": 0.6948386430740356, "(14, 16)": 0.7545822262763977, "(16, 0)": 0.7545822262763977, "(16, 16)": 0.6948386430740356, "(18, 0)": 0.6948386430740356, "(18, 16)": 0.7545822262763977, "(20, 0)": 0.7545822262763977, "(20, 16)": 0.6948386430740356, "(22, 0)": 0.45656996965408325, "(22, 16)": 0.7545822262763977, "(24, 0)": 0.7185461521148682, "(24, 16)": 0.7545822262763977, "(26, 0)": 0.45656996965408325, "(26, 16)": 0.7185461521148682, "(28, 0)": 0.45656996965408325, "(28, 16)": 0.45656996965408325, "(30, 0)": 0.45656996965408325, "(30, 16)": 0.45656996965408325}, "r_span": [1149, 1229], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0001570582389831543}}]}, {"id": "6411", "source_id": "13736", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 438, "end": 464, "text": "with free Wi-Fi available.", "meta": "EVIDENT CONFLICT:\nAIGC: with free Wi-Fi available. \nOriginal: \"WiFi\": \"no\",", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Blaze Pizza:\n\nBlaze Pizza is a popular fast-food restaurant located in Goleta, California, offering a variety of gluten-free and traditional pizzas, salads, and other menu items. The establishment has a convenient location and reasonable prices, with unlimited toppings available for personal-sized pizzas. Customers can enjoy their meals both indoors and outdoors, with free Wi-Fi available. Despite some positive reviews, there have been complaints about the cleanliness of the restaurant and instances of employees not wearing gloves. One reviewer also mentioned a rude employee encounter. Nonetheless, many customers have praised Blaze Pizza for its tasty pizzas and friendly service during a difficult time.", "response_spans": [[0, 84], [86, 593], [577, 784]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5718152523040771, "(0, 16)": 0.5718152523040771, "(2, 0)": 0.5718152523040771, "(2, 16)": 0.5718152523040771, "(4, 0)": 0.5718152523040771, "(4, 16)": 0.5718152523040771, "(6, 0)": 0.5718152523040771, "(6, 16)": 0.6260071992874146, "(8, 0)": 0.6494208574295044, "(8, 16)": 0.5190668106079102, "(10, 0)": 0.6260071992874146, "(10, 16)": 0.6260071992874146, "(12, 0)": 0.533183217048645, "(12, 16)": 0.6260071992874146, "(14, 0)": 0.5190668106079102, "(14, 16)": 0.6260071992874146, "(16, 0)": 0.6260071992874146, "(16, 16)": 0.6260071992874146, "(18, 0)": 0.5249829888343811, "(18, 16)": 0.6260071992874146, "(20, 0)": 0.6260071992874146, "(20, 16)": 0.5249829888343811, "(22, 0)": 0.5249829888343811, "(22, 16)": 0.6260071992874146, "(24, 0)": 0.5190668106079102, "(24, 16)": 0.6260071992874146, "(26, 0)": 0.6260071992874146, "(26, 16)": 0.6180390119552612, "(28, 0)": 0.6260071992874146, "(28, 16)": 0.5190668106079102, "(30, 0)": 0.6260071992874146, "(30, 16)": 0.6260071992874146}, "r_span": [994, 1015], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00037747621536254883}}, {"prompt_attention_score": {"(0, 0)": 0.6250509023666382, "(0, 16)": 0.6250509023666382, "(2, 0)": 0.5383214950561523, "(2, 16)": 0.5383214950561523, "(4, 0)": 0.6250509023666382, "(4, 16)": 0.6250509023666382, "(6, 0)": 0.6250509023666382, "(6, 16)": 0.7923334836959839, "(8, 0)": 0.5901637673377991, "(8, 16)": 0.5383214950561523, "(10, 0)": 0.5901637673377991, "(10, 16)": 0.6250509023666382, "(12, 0)": 0.5901637673377991, "(12, 16)": 0.7923334836959839, "(14, 0)": 0.5383214950561523, "(14, 16)": 0.5383214950561523, "(16, 0)": 0.5889031887054443, "(16, 16)": 0.5383214950561523, "(18, 0)": 0.5901637673377991, "(18, 16)": 0.7923334836959839, "(20, 0)": 0.7923334836959839, "(20, 16)": 0.5383214950561523, "(22, 0)": 0.5383214950561523, "(22, 16)": 0.5901637673377991, "(24, 0)": 0.5901637673377991, "(24, 16)": 0.7923334836959839, "(26, 0)": 0.41126328706741333, "(26, 16)": 0.5889031887054443, "(28, 0)": 0.41126328706741333, "(28, 16)": 0.5383214950561523, "(30, 0)": 0.5901637673377991, "(30, 16)": 0.41126328706741333}, "r_span": [1017, 1131], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0025038719177246094}}, {"prompt_attention_score": {"(0, 0)": 0.8314588069915771, "(0, 16)": 0.8314588069915771, "(2, 0)": 0.7163888216018677, "(2, 16)": 0.7163888216018677, "(4, 0)": 0.7163888216018677, "(4, 16)": 0.7163888216018677, "(6, 0)": 0.7163888216018677, "(6, 16)": 0.6740843653678894, "(8, 0)": 0.7163888216018677, "(8, 16)": 0.7163888216018677, "(10, 0)": 0.8314588069915771, "(10, 16)": 0.8314588069915771, "(12, 0)": 0.7163888216018677, "(12, 16)": 0.8314588069915771, "(14, 0)": 0.7163888216018677, "(14, 16)": 0.7163888216018677, "(16, 0)": 0.7163888216018677, "(16, 16)": 0.7163888216018677, "(18, 0)": 0.7518271207809448, "(18, 16)": 0.8314588069915771, "(20, 0)": 0.8314588069915771, "(20, 16)": 0.7163888216018677, "(22, 0)": 0.7518271207809448, "(22, 16)": 0.8314588069915771, "(24, 0)": 0.7163888216018677, "(24, 16)": 0.8314588069915771, "(26, 0)": 0.45780685544013977, "(26, 16)": 0.7163888216018677, "(28, 0)": 0.45780685544013977, "(28, 16)": 0.7163888216018677, "(30, 0)": 0.45780685544013977, "(30, 16)": 0.45780685544013977}, "r_span": [1129, 1176], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0013942122459411621}}]}, {"id": "6417", "source_id": "13737", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 480, "end": 517, "text": "including vegetarian and vegan dishes", "meta": "HIGH INTRO OF NEW INFO\nAIGC:   including vegetarian and vegan dishes\nOriginal: Vegetarian and vegan dishes are  not mentioned in business info or reviews.\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Live Oak Cafe:\n\nLocated in Santa Barbara, California, Live Oak Cafe is a popular farm-to-table restaurant offering a variety of cuisines including Farmers Market, Food, Fast Food, American (New), Bars, Wine Bars, Breakfast & Brunch, Cafes, and Restaurants. With a rating of 4.5 stars, the business offers a cozy and relaxed atmosphere, free WiFi, and outdoor seating. Their menu features a range of options, including vegetarian and vegan dishes, and they are known for their quality ingredients and delicious food. The cafe is conveniently located near Cottage Hospital, Sansum Clinic, and other nearby medical offices, making it a great spot for a quick bite or meal.\n\nCustomers have consistently praised the cafe's breakfast and brunch items, with one reviewer noting that their eggs and omelette were cooked perfectly and the coffee was fresh and hot. Another customer enjoyed their skillet with eggs, spinach, and quinoa, describing the dish as tasty and healthy. One reviewer was pleasantly surprised by the quality of the food, finding it to be fresh, healthy, and delicious despite its unexpected location away from the main thoroughfare. Overall, Live Oak Cafe appears to offer a welcoming and satisfying dining experience with a focus on quality ingredients and friendly service.", "response_spans": [[0, 86], [88, 599], [582, 741], [743, 1252], [1233, 1361]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.480716347694397, "(0, 16)": 0.480716347694397, "(2, 0)": 0.480716347694397, "(2, 16)": 0.480716347694397, "(4, 0)": 0.480716347694397, "(4, 16)": 0.480716347694397, "(6, 0)": 0.480716347694397, "(6, 16)": 0.6436872482299805, "(8, 0)": 0.6426668167114258, "(8, 16)": 0.480716347694397, "(10, 0)": 0.6436872482299805, "(10, 16)": 0.6436872482299805, "(12, 0)": 0.5254626870155334, "(12, 16)": 0.6436872482299805, "(14, 0)": 0.480716347694397, "(14, 16)": 0.6436872482299805, "(16, 0)": 0.6436872482299805, "(16, 16)": 0.5254626870155334, "(18, 0)": 0.480716347694397, "(18, 16)": 0.6436872482299805, "(20, 0)": 0.6436872482299805, "(20, 16)": 0.4629579484462738, "(22, 0)": 0.4629579484462738, "(22, 16)": 0.6436872482299805, "(24, 0)": 0.4629579484462738, "(24, 16)": 0.6436872482299805, "(26, 0)": 0.6436872482299805, "(26, 16)": 0.4629579484462738, "(28, 0)": 0.6436872482299805, "(28, 16)": 0.6436872482299805, "(30, 0)": 0.6436872482299805, "(30, 16)": 0.6436872482299805}, "r_span": [956, 977], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006069540977478027}}, {"prompt_attention_score": {"(0, 0)": 0.5967168807983398, "(0, 16)": 0.5967168807983398, "(2, 0)": 0.5967168807983398, "(2, 16)": 0.5967168807983398, "(4, 0)": 0.5967168807983398, "(4, 16)": 0.5967168807983398, "(6, 0)": 0.5967168807983398, "(6, 16)": 0.7985478639602661, "(8, 0)": 0.6116316914558411, "(8, 16)": 0.5967168807983398, "(10, 0)": 0.7223081588745117, "(10, 16)": 0.5967168807983398, "(12, 0)": 0.5967168807983398, "(12, 16)": 0.7985478639602661, "(14, 0)": 0.5967168807983398, "(14, 16)": 0.7985478639602661, "(16, 0)": 0.5359808802604675, "(16, 16)": 0.5967168807983398, "(18, 0)": 0.5967168807983398, "(18, 16)": 0.7985478639602661, "(20, 0)": 0.7985478639602661, "(20, 16)": 0.6116316914558411, "(22, 0)": 0.439241886138916, "(22, 16)": 0.7985478639602661, "(24, 0)": 0.6116316914558411, "(24, 16)": 0.5359808802604675, "(26, 0)": 0.439241886138916, "(26, 16)": 0.7223081588745117, "(28, 0)": 0.439241886138916, "(28, 16)": 0.6116316914558411, "(30, 0)": 0.439241886138916, "(30, 16)": 0.439241886138916}, "r_span": [979, 1111], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010315179824829102}}, {"prompt_attention_score": {"(0, 0)": 0.6126713156700134, "(0, 16)": 0.6126713156700134, "(2, 0)": 0.6126713156700134, "(2, 16)": 0.6126713156700134, "(4, 0)": 0.6126713156700134, "(4, 16)": 0.6126713156700134, "(6, 0)": 0.5851939916610718, "(6, 16)": 0.7184463143348694, "(8, 0)": 0.6126713156700134, "(8, 16)": 0.5851939916610718, "(10, 0)": 0.6126713156700134, "(10, 16)": 0.6126713156700134, "(12, 0)": 0.5851939916610718, "(12, 16)": 0.7184463143348694, "(14, 0)": 0.5851939916610718, "(14, 16)": 0.7184463143348694, "(16, 0)": 0.7184463143348694, "(16, 16)": 0.6126713156700134, "(18, 0)": 0.5851939916610718, "(18, 16)": 0.7184463143348694, "(20, 0)": 0.7184463143348694, "(20, 16)": 0.5851939916610718, "(22, 0)": 0.46237656474113464, "(22, 16)": 0.7184463143348694, "(24, 0)": 0.5851939916610718, "(24, 16)": 0.7184463143348694, "(26, 0)": 0.46237656474113464, "(26, 16)": 0.5851939916610718, "(28, 0)": 0.46237656474113464, "(28, 16)": 0.46237656474113464, "(30, 0)": 0.46237656474113464, "(30, 16)": 0.46237656474113464}, "r_span": [1106, 1146], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001240372657775879}}, {"prompt_attention_score": {"(0, 0)": 0.7415755391120911, "(0, 16)": 0.7415755391120911, "(2, 0)": 0.7415755391120911, "(2, 16)": 0.7415755391120911, "(4, 0)": 0.7415755391120911, "(4, 16)": 0.7415755391120911, "(6, 0)": 0.7415755391120911, "(6, 16)": 0.8443880677223206, "(8, 0)": 0.7415755391120911, "(8, 16)": 0.7415755391120911, "(10, 0)": 0.7415755391120911, "(10, 16)": 0.7415755391120911, "(12, 0)": 0.7415755391120911, "(12, 16)": 0.7498537302017212, "(14, 0)": 0.7415755391120911, "(14, 16)": 0.7415755391120911, "(16, 0)": 0.7415755391120911, "(16, 16)": 0.7415755391120911, "(18, 0)": 0.7415755391120911, "(18, 16)": 0.7415755391120911, "(20, 0)": 0.7415755391120911, "(20, 16)": 0.7498537302017212, "(22, 0)": 0.45738330483436584, "(22, 16)": 0.7498537302017212, "(24, 0)": 0.7498537302017212, "(24, 16)": 0.7498537302017212, "(26, 0)": 0.45738330483436584, "(26, 16)": 0.7498537302017212, "(28, 0)": 0.45738330483436584, "(28, 16)": 0.45738330483436584, "(30, 0)": 0.45738330483436584, "(30, 16)": 0.45738330483436584}, "r_span": [1148, 1267], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0022260546684265137}}, {"prompt_attention_score": {"(0, 0)": 0.640202522277832, "(0, 16)": 0.640202522277832, "(2, 0)": 0.640202522277832, "(2, 16)": 0.640202522277832, "(4, 0)": 0.640202522277832, "(4, 16)": 0.640202522277832, "(6, 0)": 0.640202522277832, "(6, 16)": 0.6794523596763611, "(8, 0)": 0.640202522277832, "(8, 16)": 0.640202522277832, "(10, 0)": 0.640202522277832, "(10, 16)": 0.6794523596763611, "(12, 0)": 0.640202522277832, "(12, 16)": 0.640202522277832, "(14, 0)": 0.640202522277832, "(14, 16)": 0.4632892310619354, "(16, 0)": 0.44008755683898926, "(16, 16)": 0.640202522277832, "(18, 0)": 0.640202522277832, "(18, 16)": 0.640202522277832, "(20, 0)": 0.4748506247997284, "(20, 16)": 0.5276769399642944, "(22, 0)": 0.5276769399642944, "(22, 16)": 0.640202522277832, "(24, 0)": 0.5276769399642944, "(24, 16)": 0.640202522277832, "(26, 0)": 0.44008755683898926, "(26, 16)": 0.640202522277832, "(28, 0)": 0.44008755683898926, "(28, 16)": 0.44008755683898926, "(30, 0)": 0.44008755683898926, "(30, 16)": 0.44008755683898926}, "r_span": [1263, 1288], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00029021501541137695}}]}, {"id": "6549", "source_id": "13761", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 604, "end": 621, "text": "WiFi availability", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerated: has...WiFi availability", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 384, "end": 447, "text": "including breakfast specials, omelets, pancakes, and sandwiches", "meta": "LOW INTRODUCTION OF NEW INFORMATION\nStructured data did not specify the restaurant's breakfast specials.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of The Worker Bee Cafe:\n\nThe Worker Bee Cafe is a popular breakfast and brunch spot located in Carpinteria, California. With a 4.0-star rating, the cafe has received positive reviews from customers who praise its service, food quality, and cozy atmosphere. The cafe offers a variety of traditional American dishes, including breakfast specials, omelets, pancakes, and sandwiches. Customers particularly enjoy the mimosas and daily specials menu, which feature unique and high-quality ingredients. The cafe also has outdoor seating and WiFi availability. While there is no valet or validated parking available, street parking is available nearby. Overall, The Worker Bee Cafe is a great choice for breakfast or brunch in Carpinteria, especially for those looking for a cozy and welcoming atmosphere with excellent service and food quality.", "response_spans": [[0, 92], [94, 603], [584, 907]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4625914394855499, "(0, 16)": 0.4625914394855499, "(2, 0)": 0.427472323179245, "(2, 16)": 0.4625914394855499, "(4, 0)": 0.4625914394855499, "(4, 16)": 0.4625914394855499, "(6, 0)": 0.4625914394855499, "(6, 16)": 0.6439568400382996, "(8, 0)": 0.4625914394855499, "(8, 16)": 0.4625914394855499, "(10, 0)": 0.6439568400382996, "(10, 16)": 0.6439568400382996, "(12, 0)": 0.4625914394855499, "(12, 16)": 0.6439568400382996, "(14, 0)": 0.4625914394855499, "(14, 16)": 0.6439568400382996, "(16, 0)": 0.6439568400382996, "(16, 16)": 0.6439568400382996, "(18, 0)": 0.4625914394855499, "(18, 16)": 0.6439568400382996, "(20, 0)": 0.6439568400382996, "(20, 16)": 0.4625914394855499, "(22, 0)": 0.6439568400382996, "(22, 16)": 0.6439568400382996, "(24, 0)": 0.4625914394855499, "(24, 16)": 0.6439568400382996, "(26, 0)": 0.6439568400382996, "(26, 16)": 0.4789881110191345, "(28, 0)": 0.6439568400382996, "(28, 16)": 0.4625914394855499, "(30, 0)": 0.6439568400382996, "(30, 16)": 0.6439568400382996}, "r_span": [790, 814], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004819035530090332}}, {"prompt_attention_score": {"(0, 0)": 0.6589082479476929, "(0, 16)": 0.6589082479476929, "(2, 0)": 0.6589082479476929, "(2, 16)": 0.6589082479476929, "(4, 0)": 0.6589082479476929, "(4, 16)": 0.6589082479476929, "(6, 0)": 0.6589082479476929, "(6, 16)": 0.7802870273590088, "(8, 0)": 0.6589082479476929, "(8, 16)": 0.6589082479476929, "(10, 0)": 0.6589082479476929, "(10, 16)": 0.6589082479476929, "(12, 0)": 0.6589082479476929, "(12, 16)": 0.6209837794303894, "(14, 0)": 0.6589082479476929, "(14, 16)": 0.6589082479476929, "(16, 0)": 0.7802870273590088, "(16, 16)": 0.6589082479476929, "(18, 0)": 0.43421050906181335, "(18, 16)": 0.7802870273590088, "(20, 0)": 0.7802870273590088, "(20, 16)": 0.6589082479476929, "(22, 0)": 0.6589082479476929, "(22, 16)": 0.7802870273590088, "(24, 0)": 0.6589082479476929, "(24, 16)": 0.7802870273590088, "(26, 0)": 0.43421050906181335, "(26, 16)": 0.6589082479476929, "(28, 0)": 0.43421050906181335, "(28, 16)": 0.6589082479476929, "(30, 0)": 0.43421050906181335, "(30, 16)": 0.43421050906181335}, "r_span": [816, 940], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001115560531616211}}, {"prompt_attention_score": {"(0, 0)": 0.630199670791626, "(0, 16)": 0.630199670791626, "(2, 0)": 0.630199670791626, "(2, 16)": 0.630199670791626, "(4, 0)": 0.630199670791626, "(4, 16)": 0.630199670791626, "(6, 0)": 0.630199670791626, "(6, 16)": 0.7863670587539673, "(8, 0)": 0.630199670791626, "(8, 16)": 0.630199670791626, "(10, 0)": 0.630199670791626, "(10, 16)": 0.630199670791626, "(12, 0)": 0.630199670791626, "(12, 16)": 0.7863670587539673, "(14, 0)": 0.630199670791626, "(14, 16)": 0.630199670791626, "(16, 0)": 0.7863670587539673, "(16, 16)": 0.630199670791626, "(18, 0)": 0.44755735993385315, "(18, 16)": 0.624384880065918, "(20, 0)": 0.624384880065918, "(20, 16)": 0.630199670791626, "(22, 0)": 0.44755735993385315, "(22, 16)": 0.7863670587539673, "(24, 0)": 0.630199670791626, "(24, 16)": 0.624384880065918, "(26, 0)": 0.44755735993385315, "(26, 16)": 0.624384880065918, "(28, 0)": 0.44755735993385315, "(28, 16)": 0.630199670791626, "(30, 0)": 0.44755735993385315, "(30, 16)": 0.44755735993385315}, "r_span": [936, 1009], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001963496208190918}}]}, {"id": "6633", "source_id": "13775", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 217, "end": 305, "text": "The hours of operation are varied, with limited availability on certain days of the week", "meta": "EVIDENT CONFLICT\nOriginal: Monday to Sunday: \"0:0-0:0\" (open 24/7)\nGenerative: \"The hours of operation are varied, with limited availability on certain days of the week\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Winchell's Donuts appears to be a local business located in Santa Barbara, California. The business offers a variety of food items including donuts, sandwiches, coffee, and tea. The hours of operation are varied, with limited availability on certain days of the week. The business has received mixed reviews from customers, with some expressing disappointment in the quality of their donuts, particularly in terms of freshness and taste. One reviewer mentions the staff member they encountered was friendly and wore a mask, however. Overall, while some customers have had positive experiences at Winchell's Donuts, others have been disappointed with their visits.", "response_spans": [[0, 508], [490, 702]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6302489042282104, "(0, 16)": 0.6302489042282104, "(2, 0)": 0.5947778224945068, "(2, 16)": 0.6302489042282104, "(4, 0)": 0.5947778224945068, "(4, 16)": 0.5947778224945068, "(6, 0)": 0.6302489042282104, "(6, 16)": 0.8001911640167236, "(8, 0)": 0.6494895219802856, "(8, 16)": 0.6302489042282104, "(10, 0)": 0.6494895219802856, "(10, 16)": 0.6302489042282104, "(12, 0)": 0.6302489042282104, "(12, 16)": 0.8001911640167236, "(14, 0)": 0.6302489042282104, "(14, 16)": 0.8001911640167236, "(16, 0)": 0.5810818672180176, "(16, 16)": 0.6302489042282104, "(18, 0)": 0.5810818672180176, "(18, 16)": 0.8001911640167236, "(20, 0)": 0.8001911640167236, "(20, 16)": 0.6302489042282104, "(22, 0)": 0.5810818672180176, "(22, 16)": 0.6494895219802856, "(24, 0)": 0.6494895219802856, "(24, 16)": 0.6494895219802856, "(26, 0)": 0.5810818672180176, "(26, 16)": 0.6302489042282104, "(28, 0)": 0.5810818672180176, "(28, 16)": 0.6302489042282104, "(30, 0)": 0.5810818672180176, "(30, 16)": 0.5810818672180176}, "r_span": [764, 870], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002043426036834717}}, {"prompt_attention_score": {"(0, 0)": 0.5859876871109009, "(0, 16)": 0.5859876871109009, "(2, 0)": 0.7707583904266357, "(2, 16)": 0.7707583904266357, "(4, 0)": 0.7707583904266357, "(4, 16)": 0.7707583904266357, "(6, 0)": 0.7707583904266357, "(6, 16)": 0.5852735638618469, "(8, 0)": 0.5792030096054077, "(8, 16)": 0.7707583904266357, "(10, 0)": 0.7707583904266357, "(10, 16)": 0.7707583904266357, "(12, 0)": 0.7707583904266357, "(12, 16)": 0.7707583904266357, "(14, 0)": 0.7707583904266357, "(14, 16)": 0.7707583904266357, "(16, 0)": 0.7707583904266357, "(16, 16)": 0.7707583904266357, "(18, 0)": 0.5859876871109009, "(18, 16)": 0.7707583904266357, "(20, 0)": 0.7707583904266357, "(20, 16)": 0.7707583904266357, "(22, 0)": 0.4326412081718445, "(22, 16)": 0.7707583904266357, "(24, 0)": 0.5859876871109009, "(24, 16)": 0.5859876871109009, "(26, 0)": 0.4326412081718445, "(26, 16)": 0.7707583904266357, "(28, 0)": 0.4326412081718445, "(28, 16)": 0.7707583904266357, "(30, 0)": 0.4326412081718445, "(30, 16)": 0.4326412081718445}, "r_span": [868, 911], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0033437013626098633}}]}, {"id": "6675", "source_id": "13783", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 426, "end": 439, "text": "a golf course", "meta": "HIGH INTRO OF NEW INFO\nAIGC: a golf course\nOriginal: No mentioned of \"golf course\" in business info or reviews.\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "The Ritz-Carlton Bacara, Santa Barbara is a luxury resort located in Santa Barbara, California. It offers a range of amenities and services, including a spa, fitness center, and several dining options. According to reviews, the resort has a beautiful setting and nice atmosphere, with friendly and attentive staff. Some guests have praised the resort's activities and facilities, including hiking and biking opportunities and a golf course. However, some reviews have noted issues with the TVs in the rooms, which have been reported to be broken on occasion, and the resort's parking fees, which are $53 per day. Additionally, one reviewer noted that the resort's location is somewhat isolate from downtown Santa Barbara, which may be a drawback for some guests. Overall, The Ritz-Carlton Bacara, Santa Barbara appears to offer a high-end experience for those looking for a luxurious retreat in a scenic location.", "response_spans": [[0, 507], [490, 913]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5822902917861938, "(0, 16)": 0.5655896663665771, "(2, 0)": 0.5822902917861938, "(2, 16)": 0.5822902917861938, "(4, 0)": 0.5822902917861938, "(4, 16)": 0.5822902917861938, "(6, 0)": 0.5822902917861938, "(6, 16)": 0.7806116342544556, "(8, 0)": 0.5822902917861938, "(8, 16)": 0.5822902917861938, "(10, 0)": 0.5655896663665771, "(10, 16)": 0.5655896663665771, "(12, 0)": 0.5655896663665771, "(12, 16)": 0.5503349304199219, "(14, 0)": 0.5655896663665771, "(14, 16)": 0.4541703462600708, "(16, 0)": 0.4117056131362915, "(16, 16)": 0.5822902917861938, "(18, 0)": 0.5655896663665771, "(18, 16)": 0.5335108041763306, "(20, 0)": 0.5335108041763306, "(20, 16)": 0.5655896663665771, "(22, 0)": 0.5655896663665771, "(22, 16)": 0.7815624475479126, "(24, 0)": 0.5655896663665771, "(24, 16)": 0.7806116342544556, "(26, 0)": 0.4117056131362915, "(26, 16)": 0.5822902917861938, "(28, 0)": 0.4541703462600708, "(28, 16)": 0.5655896663665771, "(30, 0)": 0.4117056131362915, "(30, 16)": 0.4117056131362915}, "r_span": [1594, 1708], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0001429915428161621}}, {"prompt_attention_score": {"(0, 0)": 0.585972249507904, "(0, 16)": 0.69524085521698, "(2, 0)": 0.585972249507904, "(2, 16)": 0.585972249507904, "(4, 0)": 0.585972249507904, "(4, 16)": 0.585972249507904, "(6, 0)": 0.69524085521698, "(6, 16)": 0.788800835609436, "(8, 0)": 0.585972249507904, "(8, 16)": 0.585972249507904, "(10, 0)": 0.69524085521698, "(10, 16)": 0.69524085521698, "(12, 0)": 0.69524085521698, "(12, 16)": 0.69524085521698, "(14, 0)": 0.69524085521698, "(14, 16)": 0.4453250765800476, "(16, 0)": 0.69524085521698, "(16, 16)": 0.69524085521698, "(18, 0)": 0.69524085521698, "(18, 16)": 0.6499162912368774, "(20, 0)": 0.69524085521698, "(20, 16)": 0.69524085521698, "(22, 0)": 0.69524085521698, "(22, 16)": 0.6499162912368774, "(24, 0)": 0.69524085521698, "(24, 16)": 0.69524085521698, "(26, 0)": 0.42130768299102783, "(26, 16)": 0.42130768299102783, "(28, 0)": 0.42130768299102783, "(28, 16)": 0.69524085521698, "(30, 0)": 0.69524085521698, "(30, 16)": 0.42130768299102783}, "r_span": [1703, 1808], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.002737700939178467}}]}, {"id": "6687", "source_id": "13785", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 293, "end": 304, "text": "light meals", "meta": "HIGH INTRO OF NEW INFO\nIt mentions 'light meals' which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 364, "end": 390, "text": "availability of vegetarian", "meta": "HIGH INTRO OF NEW INFO\nIt mentions 'availability of vegetarian options' which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Campus Point Coffee:\n\nCampus Point Coffee is a popular food and beverage establishment located in Goleta, California. With a rating of 4.5 stars, the business offers a variety of options for coffee, tea, baked goods, and light meals. Customers praise the cozy atmosphere, friendly staff, and availability of vegetarian and vegan options. The indoor and outdoor seating areas are also appreciated, as well as the convenience of having a restroom available. While some customers have expressed disappointment at finding the vegan cookies sold out, the quality of the drinks and food items has been consistently high. Overall, Campus Point Coffee appears to be a cozy and welcoming spot for students and locals alike.", "response_spans": [[0, 92], [94, 599], [582, 786]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5484108328819275, "(0, 16)": 0.5484108328819275, "(2, 0)": 0.5484108328819275, "(2, 16)": 0.5484108328819275, "(4, 0)": 0.5484108328819275, "(4, 16)": 0.4878990650177002, "(6, 0)": 0.5484108328819275, "(6, 16)": 0.6292974948883057, "(8, 0)": 0.6232377290725708, "(8, 16)": 0.5484108328819275, "(10, 0)": 0.6292974948883057, "(10, 16)": 0.6292974948883057, "(12, 0)": 0.5484108328819275, "(12, 16)": 0.6292974948883057, "(14, 0)": 0.5484108328819275, "(14, 16)": 0.6292974948883057, "(16, 0)": 0.6292974948883057, "(16, 16)": 0.6292974948883057, "(18, 0)": 0.5484108328819275, "(18, 16)": 0.6292974948883057, "(20, 0)": 0.6292974948883057, "(20, 16)": 0.5484108328819275, "(22, 0)": 0.6292974948883057, "(22, 16)": 0.6292974948883057, "(24, 0)": 0.5484108328819275, "(24, 16)": 0.6292974948883057, "(26, 0)": 0.6292974948883057, "(26, 16)": 0.6893595457077026, "(28, 0)": 0.6292974948883057, "(28, 16)": 0.5484108328819275, "(30, 0)": 0.6292974948883057, "(30, 16)": 0.6292974948883057}, "r_span": [754, 777], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006774663925170898}}, {"prompt_attention_score": {"(0, 0)": 0.6431870460510254, "(0, 16)": 0.6431870460510254, "(2, 0)": 0.6431870460510254, "(2, 16)": 0.6431870460510254, "(4, 0)": 0.6431870460510254, "(4, 16)": 0.6431870460510254, "(6, 0)": 0.6431870460510254, "(6, 16)": 0.7866961359977722, "(8, 0)": 0.6377154588699341, "(8, 16)": 0.6431870460510254, "(10, 0)": 0.6431870460510254, "(10, 16)": 0.6431870460510254, "(12, 0)": 0.6431870460510254, "(12, 16)": 0.7866961359977722, "(14, 0)": 0.6431870460510254, "(14, 16)": 0.7866961359977722, "(16, 0)": 0.7475308179855347, "(16, 16)": 0.6431870460510254, "(18, 0)": 0.4357645511627197, "(18, 16)": 0.7866961359977722, "(20, 0)": 0.7866961359977722, "(20, 16)": 0.6431870460510254, "(22, 0)": 0.6431870460510254, "(22, 16)": 0.6377154588699341, "(24, 0)": 0.6431870460510254, "(24, 16)": 0.7866961359977722, "(26, 0)": 0.4357645511627197, "(26, 16)": 0.6377154588699341, "(28, 0)": 0.4357645511627197, "(28, 16)": 0.6431870460510254, "(30, 0)": 0.4357645511627197, "(30, 16)": 0.4357645511627197}, "r_span": [779, 893], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008224844932556152}}, {"prompt_attention_score": {"(0, 0)": 0.6849122643470764, "(0, 16)": 0.6849122643470764, "(2, 0)": 0.6849122643470764, "(2, 16)": 0.6849122643470764, "(4, 0)": 0.6849122643470764, "(4, 16)": 0.6849122643470764, "(6, 0)": 0.6849122643470764, "(6, 16)": 0.8130002021789551, "(8, 0)": 0.6849122643470764, "(8, 16)": 0.6849122643470764, "(10, 0)": 0.6849122643470764, "(10, 16)": 0.6849122643470764, "(12, 0)": 0.6849122643470764, "(12, 16)": 0.8130002021789551, "(14, 0)": 0.6849122643470764, "(14, 16)": 0.6849122643470764, "(16, 0)": 0.8130002021789551, "(16, 16)": 0.42256420850753784, "(18, 0)": 0.42256420850753784, "(18, 16)": 0.8130002021789551, "(20, 0)": 0.8130002021789551, "(20, 16)": 0.6849122643470764, "(22, 0)": 0.42256420850753784, "(22, 16)": 0.8130002021789551, "(24, 0)": 0.6849122643470764, "(24, 16)": 0.8130002021789551, "(26, 0)": 0.42256420850753784, "(26, 16)": 0.6553906202316284, "(28, 0)": 0.42256420850753784, "(28, 16)": 0.6849122643470764, "(30, 0)": 0.42256420850753784, "(30, 16)": 0.42256420850753784}, "r_span": [890, 939], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009117722511291504}}]}, {"id": "6717", "source_id": "13790", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 354, "end": 370, "text": "made fresh daily", "meta": "LOW INTRO OF NEW INFO\nIt was not specified that hummus is made fres daily", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Mr. B Restaurant & Cafe is a popular eatery located in Santa Barbara, California, offering a variety of Middle Eastern and Mediterranean cuisine. With a rating of 4.0 stars, the restaurant is known for its cleanliness, friendly staff, and good energy. Customers have praised the delicious food, particularly the shawarma sandwiches and hummus, which are made fresh daily. Outdoor seating is available, and Wi-Fi is free for patrons. Although some reviewers have noted slow service and a quiet atmosphere, most have been impressed with their dining experience at Mr. B Restaurant & Cafe.", "response_spans": [[0, 509], [493, 586]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.588215172290802, "(0, 16)": 0.588215172290802, "(2, 0)": 0.588215172290802, "(2, 16)": 0.5952916145324707, "(4, 0)": 0.5952916145324707, "(4, 16)": 0.5952916145324707, "(6, 0)": 0.5952916145324707, "(6, 16)": 0.756527304649353, "(8, 0)": 0.5952916145324707, "(8, 16)": 0.5952916145324707, "(10, 0)": 0.588215172290802, "(10, 16)": 0.5952916145324707, "(12, 0)": 0.588215172290802, "(12, 16)": 0.6568158864974976, "(14, 0)": 0.5952916145324707, "(14, 16)": 0.452124685049057, "(16, 0)": 0.6568158864974976, "(16, 16)": 0.5952916145324707, "(18, 0)": 0.42831867933273315, "(18, 16)": 0.756527304649353, "(20, 0)": 0.6568158864974976, "(20, 16)": 0.6568158864974976, "(22, 0)": 0.42831867933273315, "(22, 16)": 0.7139970064163208, "(24, 0)": 0.6568158864974976, "(24, 16)": 0.6568158864974976, "(26, 0)": 0.42831867933273315, "(26, 16)": 0.6568158864974976, "(28, 0)": 0.42831867933273315, "(28, 16)": 0.42831867933273315, "(30, 0)": 0.42831867933273315, "(30, 16)": 0.42831867933273315}, "r_span": [902, 1023], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 3.606081008911133e-05}}, {"prompt_attention_score": {"(0, 0)": 0.5437037944793701, "(0, 16)": 0.5437037944793701, "(2, 0)": 0.4597591757774353, "(2, 16)": 0.4597591757774353, "(4, 0)": 0.4597591757774353, "(4, 16)": 0.4597591757774353, "(6, 0)": 0.4597591757774353, "(6, 16)": 0.6116759777069092, "(8, 0)": 0.4597591757774353, "(8, 16)": 0.4597591757774353, "(10, 0)": 0.4597591757774353, "(10, 16)": 0.4597591757774353, "(12, 0)": 0.4597591757774353, "(12, 16)": 0.6116759777069092, "(14, 0)": 0.4597591757774353, "(14, 16)": 0.4351749122142792, "(16, 0)": 0.4597591757774353, "(16, 16)": 0.38840699195861816, "(18, 0)": 0.38840699195861816, "(18, 16)": 0.5963055491447449, "(20, 0)": 0.6609195470809937, "(20, 16)": 0.5963055491447449, "(22, 0)": 0.38840699195861816, "(22, 16)": 0.6609195470809937, "(24, 0)": 0.5963055491447449, "(24, 16)": 0.5963055491447449, "(26, 0)": 0.38840699195861816, "(26, 16)": 0.5963055491447449, "(28, 0)": 0.38840699195861816, "(28, 16)": 0.38840699195861816, "(30, 0)": 0.38840699195861816, "(30, 16)": 0.38840699195861816}, "r_span": [1021, 1043], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003642439842224121}}]}, {"id": "6765", "source_id": "13992", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 488, "end": 511, "text": "and takes reservations,", "meta": "EVIDENT CONFLICT\nOriginal: \"RestaurantsReservations\": false\nGenerative: \"...and takes reservations...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Kogilicious:\n\nKogilicious is a Korean restaurant located in Isla Vista, California, with a rating of 4.0 out of 5 stars. The restaurant offers a variety of dishes, including Korean favorites such as beef ribs, pork, tofu, and spicy chicken burritos. Customers have praised the quality and taste of the food, with one reviewer calling it the best Korean food they've ever had. The restaurant also has outdoor seating and takes reservations, although WiFi is not available. While some customers have noted that the prices are reasonable, others have expressed that using cash is preferred due to higher charges when paying with a card. Overall, Kogilicious appears to be a popular and well-regarded Korean restaurant in the area.", "response_spans": [[0, 84], [86, 595], [576, 799]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5006861686706543, "(0, 16)": 0.5006861686706543, "(2, 0)": 0.5006861686706543, "(2, 16)": 0.5006861686706543, "(4, 0)": 0.5006861686706543, "(4, 16)": 0.5006861686706543, "(6, 0)": 0.5006861686706543, "(6, 16)": 0.6559094190597534, "(8, 0)": 0.5006861686706543, "(8, 16)": 0.5006861686706543, "(10, 0)": 0.6559094190597534, "(10, 16)": 0.6559094190597534, "(12, 0)": 0.5506505966186523, "(12, 16)": 0.6559094190597534, "(14, 0)": 0.5006861686706543, "(14, 16)": 0.6559094190597534, "(16, 0)": 0.6559094190597534, "(16, 16)": 0.6559094190597534, "(18, 0)": 0.5006861686706543, "(18, 16)": 0.6559094190597534, "(20, 0)": 0.6559094190597534, "(20, 16)": 0.4820476174354553, "(22, 0)": 0.6559094190597534, "(22, 16)": 0.6559094190597534, "(24, 0)": 0.5006861686706543, "(24, 16)": 0.6559094190597534, "(26, 0)": 0.6559094190597534, "(26, 16)": 0.5811156630516052, "(28, 0)": 0.6559094190597534, "(28, 16)": 0.4820476174354553, "(30, 0)": 0.6559094190597534, "(30, 16)": 0.6559094190597534}, "r_span": [767, 788], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00017714500427246094}}, {"prompt_attention_score": {"(0, 0)": 0.7888915538787842, "(0, 16)": 0.6317814588546753, "(2, 0)": 0.7888915538787842, "(2, 16)": 0.7888915538787842, "(4, 0)": 0.7888915538787842, "(4, 16)": 0.7888915538787842, "(6, 0)": 0.7888915538787842, "(6, 16)": 0.7392123937606812, "(8, 0)": 0.7888915538787842, "(8, 16)": 0.7888915538787842, "(10, 0)": 0.7888915538787842, "(10, 16)": 0.7888915538787842, "(12, 0)": 0.7888915538787842, "(12, 16)": 0.6317814588546753, "(14, 0)": 0.6317814588546753, "(14, 16)": 0.7888915538787842, "(16, 0)": 0.6317814588546753, "(16, 16)": 0.7888915538787842, "(18, 0)": 0.6317814588546753, "(18, 16)": 0.7392123937606812, "(20, 0)": 0.6317814588546753, "(20, 16)": 0.7888915538787842, "(22, 0)": 0.4778591990470886, "(22, 16)": 0.7888915538787842, "(24, 0)": 0.6317814588546753, "(24, 16)": 0.7888915538787842, "(26, 0)": 0.4778591990470886, "(26, 16)": 0.7888915538787842, "(28, 0)": 0.4778591990470886, "(28, 16)": 0.4778591990470886, "(30, 0)": 0.4778591990470886, "(30, 16)": 0.4778591990470886}, "r_span": [790, 915], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0011728405952453613}}, {"prompt_attention_score": {"(0, 0)": 0.7531886100769043, "(0, 16)": 0.612684965133667, "(2, 0)": 0.7531886100769043, "(2, 16)": 0.7531886100769043, "(4, 0)": 0.7531886100769043, "(4, 16)": 0.7531886100769043, "(6, 0)": 0.7531886100769043, "(6, 16)": 0.7531886100769043, "(8, 0)": 0.7531886100769043, "(8, 16)": 0.7531886100769043, "(10, 0)": 0.7531886100769043, "(10, 16)": 0.7531886100769043, "(12, 0)": 0.6479870080947876, "(12, 16)": 0.6479870080947876, "(14, 0)": 0.7531886100769043, "(14, 16)": 0.7531886100769043, "(16, 0)": 0.6479870080947876, "(16, 16)": 0.49949246644973755, "(18, 0)": 0.49949246644973755, "(18, 16)": 0.49949246644973755, "(20, 0)": 0.6479870080947876, "(20, 16)": 0.7531886100769043, "(22, 0)": 0.49949246644973755, "(22, 16)": 0.7531886100769043, "(24, 0)": 0.7531886100769043, "(24, 16)": 0.7531886100769043, "(26, 0)": 0.49949246644973755, "(26, 16)": 0.7531886100769043, "(28, 0)": 0.49949246644973755, "(28, 16)": 0.49949246644973755, "(30, 0)": 0.49949246644973755, "(30, 16)": 0.49949246644973755}, "r_span": [912, 960], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00020682811737060547}}]}, {"id": "6771", "source_id": "13994", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Dargan's Irish Pub & Restaurant is a popular gathering spot in Santa Barbara, CA, offering a cozy atmosphere and a wide range of Irish-inspired cuisine. With a rating of 4.0 stars, the restaurant boasts a welcoming environment, delicious food, and excellent service. Reviewers appreciate the spacious and clean establishment, as well as the availability of outdoor seating. Patrons can enjoy a variety of activities, including pool, music, and a relaxed atmosphere that makes it a great spot for both locals and visitors. While some reviewers have noted that the pub can get crowded on weekends, the friendly staff and quality of food make it a standout destination in the area.", "response_spans": [[0, 511], [492, 678]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7045449018478394, "(0, 16)": 0.7045449018478394, "(2, 0)": 0.7045449018478394, "(2, 16)": 0.7045449018478394, "(4, 0)": 0.7045449018478394, "(4, 16)": 0.7045449018478394, "(6, 0)": 0.7045449018478394, "(6, 16)": 0.7729306817054749, "(8, 0)": 0.7045449018478394, "(8, 16)": 0.7045449018478394, "(10, 0)": 0.6446713209152222, "(10, 16)": 0.6446713209152222, "(12, 0)": 0.6446713209152222, "(12, 16)": 0.6446713209152222, "(14, 0)": 0.5407727956771851, "(14, 16)": 0.7729306817054749, "(16, 0)": 0.7729306817054749, "(16, 16)": 0.7045449018478394, "(18, 0)": 0.5407727956771851, "(18, 16)": 0.5407727956771851, "(20, 0)": 0.5407727956771851, "(20, 16)": 0.5407727956771851, "(22, 0)": 0.40763598680496216, "(22, 16)": 0.6446713209152222, "(24, 0)": 0.5407727956771851, "(24, 16)": 0.5407727956771851, "(26, 0)": 0.40763598680496216, "(26, 16)": 0.5407727956771851, "(28, 0)": 0.40763598680496216, "(28, 16)": 0.40763598680496216, "(30, 0)": 0.40763598680496216, "(30, 16)": 0.40763598680496216}, "r_span": [841, 963], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006327629089355469}}, {"prompt_attention_score": {"(0, 0)": 0.7022562026977539, "(0, 16)": 0.7022562026977539, "(2, 0)": 0.7022562026977539, "(2, 16)": 0.7022562026977539, "(4, 0)": 0.7022562026977539, "(4, 16)": 0.7022562026977539, "(6, 0)": 0.7022562026977539, "(6, 16)": 0.661832869052887, "(8, 0)": 0.7022562026977539, "(8, 16)": 0.7022562026977539, "(10, 0)": 0.7022562026977539, "(10, 16)": 0.8224196434020996, "(12, 0)": 0.8224196434020996, "(12, 16)": 0.8224196434020996, "(14, 0)": 0.8224196434020996, "(14, 16)": 0.8224196434020996, "(16, 0)": 0.8224196434020996, "(16, 16)": 0.4657997488975525, "(18, 0)": 0.4657997488975525, "(18, 16)": 0.661832869052887, "(20, 0)": 0.8224196434020996, "(20, 16)": 0.8224196434020996, "(22, 0)": 0.4657997488975525, "(22, 16)": 0.7022562026977539, "(24, 0)": 0.8224196434020996, "(24, 16)": 0.661832869052887, "(26, 0)": 0.4657997488975525, "(26, 16)": 0.661832869052887, "(28, 0)": 0.4657997488975525, "(28, 16)": 0.4657997488975525, "(30, 0)": 0.4657997488975525, "(30, 16)": 0.4657997488975525}, "r_span": [959, 999], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003001689910888672}}]}, {"id": "6777", "source_id": "13995", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 638, "end": 721, "text": "Uncorked Wine Tasting and Kitchen has maintained a high overall rating of 4.5 stars", "meta": "EVIDENT CONFLICT\nAIGC: overall rating of 4.5 stars\nOriginal:\"business_stars\": 5.0\n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Uncorked Wine Tasting and Kitchen:\n\nUncorked Wine Tasting and Kitchen is a local business located in Santa Barbara, California. The business offers a range of services and amenities, including wine tastings, kitchen dishes, and takeout options. Customers have rated the business highly for its food quality and convenience, with some praising the generous portion sizes and delicious meals available for pickup. However, there have been some complaints about delayed meal deliveries and poor customer service, particularly during peak periods. Despite these issues, Uncorked Wine Tasting and Kitchen has maintained a high overall rating of 4.5 stars and has been recommended by customers for its excellent food and convenient offerings.", "response_spans": [[0, 106], [108, 615], [602, 808]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5102176070213318, "(0, 16)": 0.5102176070213318, "(2, 0)": 0.5102176070213318, "(2, 16)": 0.5102176070213318, "(4, 0)": 0.5102176070213318, "(4, 16)": 0.5102176070213318, "(6, 0)": 0.5102176070213318, "(6, 16)": 0.6413455605506897, "(8, 0)": 0.4489264488220215, "(8, 16)": 0.5102176070213318, "(10, 0)": 0.6001515984535217, "(10, 16)": 0.6001515984535217, "(12, 0)": 0.5239236354827881, "(12, 16)": 0.6001515984535217, "(14, 0)": 0.5102176070213318, "(14, 16)": 0.6413455605506897, "(16, 0)": 0.6001515984535217, "(16, 16)": 0.5102176070213318, "(18, 0)": 0.5102176070213318, "(18, 16)": 0.6001515984535217, "(20, 0)": 0.6001515984535217, "(20, 16)": 0.5102176070213318, "(22, 0)": 0.5102176070213318, "(22, 16)": 0.6001515984535217, "(24, 0)": 0.5102176070213318, "(24, 16)": 0.6001515984535217, "(26, 0)": 0.6001515984535217, "(26, 16)": 0.540364146232605, "(28, 0)": 0.6001515984535217, "(28, 16)": 0.5102176070213318, "(30, 0)": 0.6001515984535217, "(30, 16)": 0.6001515984535217}, "r_span": [861, 890], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005396008491516113}}, {"prompt_attention_score": {"(0, 0)": 0.6440895199775696, "(0, 16)": 0.6440895199775696, "(2, 0)": 0.6440895199775696, "(2, 16)": 0.6440895199775696, "(4, 0)": 0.6440895199775696, "(4, 16)": 0.6440895199775696, "(6, 0)": 0.6440895199775696, "(6, 16)": 0.8128765821456909, "(8, 0)": 0.5529488325119019, "(8, 16)": 0.6440895199775696, "(10, 0)": 0.5529488325119019, "(10, 16)": 0.5529488325119019, "(12, 0)": 0.5529488325119019, "(12, 16)": 0.6440895199775696, "(14, 0)": 0.6440895199775696, "(14, 16)": 0.6440895199775696, "(16, 0)": 0.5529488325119019, "(16, 16)": 0.6440895199775696, "(18, 0)": 0.5529488325119019, "(18, 16)": 0.8128765821456909, "(20, 0)": 0.6440895199775696, "(20, 16)": 0.6440895199775696, "(22, 0)": 0.6440895199775696, "(22, 16)": 0.5529488325119019, "(24, 0)": 0.6440895199775696, "(24, 16)": 0.5529488325119019, "(26, 0)": 0.44050389528274536, "(26, 16)": 0.6440895199775696, "(28, 0)": 0.44050389528274536, "(28, 16)": 0.6440895199775696, "(30, 0)": 0.44050389528274536, "(30, 16)": 0.44050389528274536}, "r_span": [892, 999], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0021118521690368652}}, {"prompt_attention_score": {"(0, 0)": 0.7173727750778198, "(0, 16)": 0.7173727750778198, "(2, 0)": 0.7173727750778198, "(2, 16)": 0.569237232208252, "(4, 0)": 0.7173727750778198, "(4, 16)": 0.7173727750778198, "(6, 0)": 0.7173727750778198, "(6, 16)": 0.6897656321525574, "(8, 0)": 0.6022642254829407, "(8, 16)": 0.569237232208252, "(10, 0)": 0.6022642254829407, "(10, 16)": 0.6022642254829407, "(12, 0)": 0.43108391761779785, "(12, 16)": 0.6022642254829407, "(14, 0)": 0.7173727750778198, "(14, 16)": 0.7173727750778198, "(16, 0)": 0.6022642254829407, "(16, 16)": 0.43108391761779785, "(18, 0)": 0.43108391761779785, "(18, 16)": 0.541808009147644, "(20, 0)": 0.541808009147644, "(20, 16)": 0.7173727750778198, "(22, 0)": 0.43108391761779785, "(22, 16)": 0.541808009147644, "(24, 0)": 0.7173727750778198, "(24, 16)": 0.541808009147644, "(26, 0)": 0.43108391761779785, "(26, 16)": 0.7173727750778198, "(28, 0)": 0.43108391761779785, "(28, 16)": 0.7173727750778198, "(30, 0)": 0.43108391761779785, "(30, 16)": 0.43108391761779785}, "r_span": [997, 1042], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00011295080184936523}}]}, {"id": "6783", "source_id": "13996", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 120, "end": 142, "text": "Southern-style cuisine", "meta": "Original: Not mentioned in structured data", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 207, "end": 224, "text": "slow-smoked meats", "meta": "Original: Not mentioned in structured data", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 514, "end": 585, "text": "with one reviewer stating that the staff is friendly and accommodating.", "meta": "LOW INTRO OF NEW INFO\nThere was no mention about the staff being friendly and accommodating.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Neighbor Tim's BBQ is a popular food truck and restaurant located in Goleta, California, serving delicious barbecue and Southern-style cuisine. According to customer reviews, the restaurant is known for its slow-smoked meats, particularly the brisket and pork ribs, which are perfectly cooked and flavorful. The menu offers a variety of options, including mac and cheese, potato salad, and white bread, all of which are made with high-quality ingredients. Customers have praised the restaurant's customer service, with one reviewer stating that the staff is friendly and accommodating. However, some customers have noted that the sides, such as the potato salad and mac and cheese, could benefit from more acidity and seasoning. Nonetheless, Neighbor Tim's BBQ has received positive reviews for its tasty and authentic barbecue dishes.", "response_spans": [[0, 504], [496, 835]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6766591668128967, "(0, 16)": 0.6766591668128967, "(2, 0)": 0.6766591668128967, "(2, 16)": 0.6766591668128967, "(4, 0)": 0.6766591668128967, "(4, 16)": 0.6766591668128967, "(6, 0)": 0.6766591668128967, "(6, 16)": 0.7616350650787354, "(8, 0)": 0.6766591668128967, "(8, 16)": 0.6766591668128967, "(10, 0)": 0.6688766479492188, "(10, 16)": 0.5610504746437073, "(12, 0)": 0.5610504746437073, "(12, 16)": 0.7004801034927368, "(14, 0)": 0.5191514492034912, "(14, 16)": 0.44526728987693787, "(16, 0)": 0.7004801034927368, "(16, 16)": 0.6766591668128967, "(18, 0)": 0.6766591668128967, "(18, 16)": 0.7004801034927368, "(20, 0)": 0.7616350650787354, "(20, 16)": 0.5191514492034912, "(22, 0)": 0.5191514492034912, "(22, 16)": 0.7616350650787354, "(24, 0)": 0.5191514492034912, "(24, 16)": 0.7616350650787354, "(26, 0)": 0.4200679063796997, "(26, 16)": 0.5191514492034912, "(28, 0)": 0.4200679063796997, "(28, 16)": 0.5191514492034912, "(30, 0)": 0.5191514492034912, "(30, 16)": 0.4200679063796997}, "r_span": [1765, 1888], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009697675704956055}}, {"prompt_attention_score": {"(0, 0)": 0.7324777841567993, "(0, 16)": 0.7324777841567993, "(2, 0)": 0.7324777841567993, "(2, 16)": 0.6669009327888489, "(4, 0)": 0.7324777841567993, "(4, 16)": 0.7324777841567993, "(6, 0)": 0.7324777841567993, "(6, 16)": 0.770704984664917, "(8, 0)": 0.7324777841567993, "(8, 16)": 0.6669009327888489, "(10, 0)": 0.6154541373252869, "(10, 16)": 0.6154541373252869, "(12, 0)": 0.6154541373252869, "(12, 16)": 0.6669009327888489, "(14, 0)": 0.6669009327888489, "(14, 16)": 0.45823514461517334, "(16, 0)": 0.6669009327888489, "(16, 16)": 0.6154541373252869, "(18, 0)": 0.6669009327888489, "(18, 16)": 0.6669009327888489, "(20, 0)": 0.7743323445320129, "(20, 16)": 0.6669009327888489, "(22, 0)": 0.6669009327888489, "(22, 16)": 0.7482193112373352, "(24, 0)": 0.6669009327888489, "(24, 16)": 0.5404015779495239, "(26, 0)": 0.46368032693862915, "(26, 16)": 0.6669009327888489, "(28, 0)": 0.46368032693862915, "(28, 16)": 0.6669009327888489, "(30, 0)": 0.6669009327888489, "(30, 16)": 0.46368032693862915}, "r_span": [1888, 1966], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009815096855163574}}]}, {"id": "6843", "source_id": "14006", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 165, "end": 194, "text": "other Italian-inspired dishes", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"other Italian-inspired dishes\" was not mentioned in the business info", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 536, "end": 583, "text": "communication with the owner can be challenging", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"communication with the owner can be challenging\" was not mentioned in the business info", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 761, "end": 784, "text": "unique catering options", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"unique catering options\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "California Wood-Fired Catering is a highly rated catering service located in Santa Barbara, California. They offer a variety of options including pizza, gelato, and other Italian-inspired dishes for events and gatherings. According to customer reviews, the quality of their food is consistently high, with one reviewer praising the flavors and presentation of their salads and pizzas. Another reviewer mentions that the team works hard to accommodate large crowds and provides excellent service. However, some customers have noted that communication with the owner can be challenging, with slower email responses and occasional underestimation of salad quantities. Overall, California Wood-Fired Catering is a popular choice for those looking for delicious and unique catering options in the Santa Barbara area.", "response_spans": [[0, 509], [496, 811]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6355117559432983, "(0, 16)": 0.6355117559432983, "(2, 0)": 0.6355117559432983, "(2, 16)": 0.6355117559432983, "(4, 0)": 0.6355117559432983, "(4, 16)": 0.5650973320007324, "(6, 0)": 0.6355117559432983, "(6, 16)": 0.7237494587898254, "(8, 0)": 0.7438651323318481, "(8, 16)": 0.6355117559432983, "(10, 0)": 0.6355117559432983, "(10, 16)": 0.7438651323318481, "(12, 0)": 0.6355117559432983, "(12, 16)": 0.5801182985305786, "(14, 0)": 0.6355117559432983, "(14, 16)": 0.6355117559432983, "(16, 0)": 0.5801182985305786, "(16, 16)": 0.6355117559432983, "(18, 0)": 0.4221534729003906, "(18, 16)": 0.7237494587898254, "(20, 0)": 0.7438651323318481, "(20, 16)": 0.6355117559432983, "(22, 0)": 0.4221534729003906, "(22, 16)": 0.7438651323318481, "(24, 0)": 0.6355117559432983, "(24, 16)": 0.7438651323318481, "(26, 0)": 0.4221534729003906, "(26, 16)": 0.5801182985305786, "(28, 0)": 0.4221534729003906, "(28, 16)": 0.6355117559432983, "(30, 0)": 0.4221534729003906, "(30, 16)": 0.4221534729003906}, "r_span": [791, 903], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.000762939453125}}, {"prompt_attention_score": {"(0, 0)": 0.6622310280799866, "(0, 16)": 0.6622310280799866, "(2, 0)": 0.536968469619751, "(2, 16)": 0.536968469619751, "(4, 0)": 0.536968469619751, "(4, 16)": 0.536968469619751, "(6, 0)": 0.7766034603118896, "(6, 16)": 0.7766034603118896, "(8, 0)": 0.7766034603118896, "(8, 16)": 0.536968469619751, "(10, 0)": 0.6622310280799866, "(10, 16)": 0.6622310280799866, "(12, 0)": 0.536968469619751, "(12, 16)": 0.7766034603118896, "(14, 0)": 0.6622310280799866, "(14, 16)": 0.6622310280799866, "(16, 0)": 0.6622310280799866, "(16, 16)": 0.536968469619751, "(18, 0)": 0.45003604888916016, "(18, 16)": 0.7766034603118896, "(20, 0)": 0.7766034603118896, "(20, 16)": 0.6622310280799866, "(22, 0)": 0.45003604888916016, "(22, 16)": 0.7766034603118896, "(24, 0)": 0.6622310280799866, "(24, 16)": 0.7766034603118896, "(26, 0)": 0.45003604888916016, "(26, 16)": 0.6622310280799866, "(28, 0)": 0.45003604888916016, "(28, 16)": 0.6622310280799866, "(30, 0)": 0.45003604888916016, "(30, 16)": 0.45003604888916016}, "r_span": [901, 964], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006843209266662598}}]}, {"id": "6855", "source_id": "14008", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 830, "end": 851, "text": "a loyal customer base", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"a loyal customer base\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Sushi Ai:\n\nSushi Ai is a popular sushi restaurant located in Goleta, California, with a rating of 3.0 stars. The restaurant offers a wide range of traditional sushi dishes, as well as Americanized options, and has a reputation for being clean and accommodating. Customers have praised the quality of the food, particularly the freshness of the seafood and the flavorful sauces. However, some reviews have criticized the service, suggesting that the restaurant may be understaffed during busy periods. Additionally, some customers have expressed disappointment with the temperature of their food, with one reviewer stating that their sushi was served too hot and another stating that their dish was not cooked properly. Despite these criticisms, Sushi Ai has a loyal customer base and is known for its excellent tempura and soups.", "response_spans": [[0, 81], [83, 591], [573, 901]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.48415160179138184, "(0, 16)": 0.48415160179138184, "(2, 0)": 0.48415160179138184, "(2, 16)": 0.48415160179138184, "(4, 0)": 0.48415160179138184, "(4, 16)": 0.48415160179138184, "(6, 0)": 0.48415160179138184, "(6, 16)": 0.6246415376663208, "(8, 0)": 0.516875147819519, "(8, 16)": 0.48415160179138184, "(10, 0)": 0.6246415376663208, "(10, 16)": 0.6246415376663208, "(12, 0)": 0.5223879218101501, "(12, 16)": 0.6246415376663208, "(14, 0)": 0.48415160179138184, "(14, 16)": 0.6246415376663208, "(16, 0)": 0.6246415376663208, "(16, 16)": 0.48415160179138184, "(18, 0)": 0.48415160179138184, "(18, 16)": 0.6246415376663208, "(20, 0)": 0.6246415376663208, "(20, 16)": 0.48415160179138184, "(22, 0)": 0.516875147819519, "(22, 16)": 0.6246415376663208, "(24, 0)": 0.516875147819519, "(24, 16)": 0.6246415376663208, "(26, 0)": 0.6246415376663208, "(26, 16)": 0.516875147819519, "(28, 0)": 0.6246415376663208, "(28, 16)": 0.48415160179138184, "(30, 0)": 0.6246415376663208, "(30, 16)": 0.6246415376663208}, "r_span": [1013, 1035], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00024896860122680664}}, {"prompt_attention_score": {"(0, 0)": 0.6068320870399475, "(0, 16)": 0.6068320870399475, "(2, 0)": 0.6068320870399475, "(2, 16)": 0.6068320870399475, "(4, 0)": 0.6068320870399475, "(4, 16)": 0.6068320870399475, "(6, 0)": 0.6068320870399475, "(6, 16)": 0.6627848148345947, "(8, 0)": 0.6403235197067261, "(8, 16)": 0.6068320870399475, "(10, 0)": 0.6068320870399475, "(10, 16)": 0.6068320870399475, "(12, 0)": 0.6068320870399475, "(12, 16)": 0.6403235197067261, "(14, 0)": 0.6068320870399475, "(14, 16)": 0.6068320870399475, "(16, 0)": 0.6068320870399475, "(16, 16)": 0.6068320870399475, "(18, 0)": 0.6068320870399475, "(18, 16)": 0.6977006196975708, "(20, 0)": 0.6977006196975708, "(20, 16)": 0.6068320870399475, "(22, 0)": 0.6068320870399475, "(22, 16)": 0.6403235197067261, "(24, 0)": 0.6403235197067261, "(24, 16)": 0.6403235197067261, "(26, 0)": 0.42565542459487915, "(26, 16)": 0.6403235197067261, "(28, 0)": 0.42565542459487915, "(28, 16)": 0.6068320870399475, "(30, 0)": 0.42565542459487915, "(30, 16)": 0.42565542459487915}, "r_span": [1037, 1154], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001452028751373291}}, {"prompt_attention_score": {"(0, 0)": 0.7362090349197388, "(0, 16)": 0.7362090349197388, "(2, 0)": 0.7362090349197388, "(2, 16)": 0.5944335460662842, "(4, 0)": 0.7362090349197388, "(4, 16)": 0.7362090349197388, "(6, 0)": 0.7362090349197388, "(6, 16)": 0.7236422896385193, "(8, 0)": 0.7362090349197388, "(8, 16)": 0.7362090349197388, "(10, 0)": 0.5944335460662842, "(10, 16)": 0.7362090349197388, "(12, 0)": 0.7362090349197388, "(12, 16)": 0.7362090349197388, "(14, 0)": 0.7362090349197388, "(14, 16)": 0.7362090349197388, "(16, 0)": 0.7362090349197388, "(16, 16)": 0.7362090349197388, "(18, 0)": 0.7362090349197388, "(18, 16)": 0.5944335460662842, "(20, 0)": 0.5944335460662842, "(20, 16)": 0.7362090349197388, "(22, 0)": 0.7236422896385193, "(22, 16)": 0.7362090349197388, "(24, 0)": 0.7236422896385193, "(24, 16)": 0.7362090349197388, "(26, 0)": 0.49437928199768066, "(26, 16)": 0.7362090349197388, "(28, 0)": 0.49437928199768066, "(28, 16)": 0.7362090349197388, "(30, 0)": 0.49437928199768066, "(30, 16)": 0.49437928199768066}, "r_span": [1152, 1220], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0017738938331604004}}]}, {"id": "6861", "source_id": "14009", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 834, "end": 853, "text": "pleasant atmosphere", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"pleasant atmosphere\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Minnow Cafe is a popular restaurant located in Santa Barbara, California, offering a variety of seafood dishes in a casual setting. According to reviews, the cafe has a great location near the harbor, providing a pleasant outdoor seating area with views of the ocean. Reviewers generally praise the quality of their food, particularly their clam chowder bread bowl and fish and chips, which are described as fresh and expertly prepared. Some patrons also appreciate the speed of service, making it a convenient option for a quick meal while exploring the area. However, a few reviewers express dissatisfaction with the cost of the food, describing it as expensive despite being served in a casual setting. Nonetheless, Minnow Cafe appears to be a great spot for seafood lovers visiting the area, offering a unique blend of good food, pleasant atmosphere, and convenient location.", "response_spans": [[0, 510], [495, 879]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6123319864273071, "(0, 16)": 0.6123319864273071, "(2, 0)": 0.6123319864273071, "(2, 16)": 0.6123319864273071, "(4, 0)": 0.6123319864273071, "(4, 16)": 0.6123319864273071, "(6, 0)": 0.6123319864273071, "(6, 16)": 0.6936130523681641, "(8, 0)": 0.6123319864273071, "(8, 16)": 0.6123319864273071, "(10, 0)": 0.7933850288391113, "(10, 16)": 0.6123319864273071, "(12, 0)": 0.6123319864273071, "(12, 16)": 0.6936130523681641, "(14, 0)": 0.6123319864273071, "(14, 16)": 0.4304405152797699, "(16, 0)": 0.6936130523681641, "(16, 16)": 0.6123319864273071, "(18, 0)": 0.4327760934829712, "(18, 16)": 0.7070183753967285, "(20, 0)": 0.7933850288391113, "(20, 16)": 0.6123319864273071, "(22, 0)": 0.4327760934829712, "(22, 16)": 0.6936130523681641, "(24, 0)": 0.6123319864273071, "(24, 16)": 0.6936130523681641, "(26, 0)": 0.4327760934829712, "(26, 16)": 0.6936130523681641, "(28, 0)": 0.4327760934829712, "(28, 16)": 0.6123319864273071, "(30, 0)": 0.4327760934829712, "(30, 16)": 0.4327760934829712}, "r_span": [773, 885], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001098036766052246}}, {"prompt_attention_score": {"(0, 0)": 0.7160753011703491, "(0, 16)": 0.7160753011703491, "(2, 0)": 0.7160753011703491, "(2, 16)": 0.7160753011703491, "(4, 0)": 0.7160753011703491, "(4, 16)": 0.7160753011703491, "(6, 0)": 0.7160753011703491, "(6, 16)": 0.7551907896995544, "(8, 0)": 0.7160753011703491, "(8, 16)": 0.7160753011703491, "(10, 0)": 0.7160753011703491, "(10, 16)": 0.7160753011703491, "(12, 0)": 0.7160753011703491, "(12, 16)": 0.7160753011703491, "(14, 0)": 0.7160753011703491, "(14, 16)": 0.7160753011703491, "(16, 0)": 0.7160753011703491, "(16, 16)": 0.7160753011703491, "(18, 0)": 0.4632960557937622, "(18, 16)": 0.7160753011703491, "(20, 0)": 0.7160753011703491, "(20, 16)": 0.7160753011703491, "(22, 0)": 0.4632960557937622, "(22, 16)": 0.7160753011703491, "(24, 0)": 0.7160753011703491, "(24, 16)": 0.7160753011703491, "(26, 0)": 0.4632960557937622, "(26, 16)": 0.7160753011703491, "(28, 0)": 0.4632960557937622, "(28, 16)": 0.7160753011703491, "(30, 0)": 0.4632960557937622, "(30, 16)": 0.4632960557937622}, "r_span": [883, 968], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006162524223327637}}]}, {"id": "6903", "source_id": "14017", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 158, "end": 194, "text": "sunset cruises, and private charters", "meta": "Although the business offers boat charters, it was not specified in the structured data if they offers \"private charters\" as well.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Celebration Cruises is a popular local business located in Santa Barbara, California, offering a range of boating experiences including whale watching tours, sunset cruises, and private charters. With a rating of 4.5 stars, the business has received positive reviews from customers praising the smooth ride, fair prices, and friendly crew. One reviewer even mentioned that the company goes above and beyond to make special occasions extra memorable. The business offers ample parking and does not have WiFi on board, but the captain provides interesting information about the area and marine life. Overall, Celebration Cruises appears to provide a high-quality boating experience for visitors and locals alike.", "response_spans": [[0, 509], [493, 710]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7367053627967834, "(0, 16)": 0.7367053627967834, "(2, 0)": 0.6953458189964294, "(2, 16)": 0.6953458189964294, "(4, 0)": 0.6953458189964294, "(4, 16)": 0.6953458189964294, "(6, 0)": 0.6953458189964294, "(6, 16)": 0.7595043182373047, "(8, 0)": 0.7367053627967834, "(8, 16)": 0.6953458189964294, "(10, 0)": 0.7367053627967834, "(10, 16)": 0.6953458189964294, "(12, 0)": 0.7367053627967834, "(12, 16)": 0.7595043182373047, "(14, 0)": 0.6953458189964294, "(14, 16)": 0.7367053627967834, "(16, 0)": 0.7595043182373047, "(16, 16)": 0.4346597194671631, "(18, 0)": 0.4346597194671631, "(18, 16)": 0.7595043182373047, "(20, 0)": 0.7595043182373047, "(20, 16)": 0.6953458189964294, "(22, 0)": 0.4346597194671631, "(22, 16)": 0.7595043182373047, "(24, 0)": 0.6953458189964294, "(24, 16)": 0.595630407333374, "(26, 0)": 0.4346597194671631, "(26, 16)": 0.4346597194671631, "(28, 0)": 0.4346597194671631, "(28, 16)": 0.6953458189964294, "(30, 0)": 0.4346597194671631, "(30, 16)": 0.4346597194671631}, "r_span": [747, 854], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0019594430923461914}}, {"prompt_attention_score": {"(0, 0)": 0.7156591415405273, "(0, 16)": 0.7156591415405273, "(2, 0)": 0.6589126586914062, "(2, 16)": 0.6589126586914062, "(4, 0)": 0.6589126586914062, "(4, 16)": 0.6589126586914062, "(6, 0)": 0.6589126586914062, "(6, 16)": 0.6210743188858032, "(8, 0)": 0.6589126586914062, "(8, 16)": 0.6589126586914062, "(10, 0)": 0.6589126586914062, "(10, 16)": 0.6589126586914062, "(12, 0)": 0.6589126586914062, "(12, 16)": 0.6589126586914062, "(14, 0)": 0.6589126586914062, "(14, 16)": 0.6589126586914062, "(16, 0)": 0.6589126586914062, "(16, 16)": 0.6589126586914062, "(18, 0)": 0.4467661380767822, "(18, 16)": 0.6210743188858032, "(20, 0)": 0.5951687097549438, "(20, 16)": 0.6589126586914062, "(22, 0)": 0.6589126586914062, "(22, 16)": 0.5951687097549438, "(24, 0)": 0.6589126586914062, "(24, 16)": 0.5951687097549438, "(26, 0)": 0.4467661380767822, "(26, 16)": 0.6589126586914062, "(28, 0)": 0.4467661380767822, "(28, 16)": 0.6589126586914062, "(30, 0)": 0.4467661380767822, "(30, 16)": 0.4467661380767822}, "r_span": [850, 896], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00032448768615722656}}]}, {"id": "6915", "source_id": "14019", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 287, "end": 301, "text": "or valet style", "meta": "EVIDENT CONFLICT\nOriginal: \"valet\": false\nGenerative: \"...can park...or valet style...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of The India Club:\n\nThe India Club is an Indian restaurant located in Goleta, California, with a rating of 3.5 stars. The restaurant offers outdoor seating and has free WiFi. Customers can park their vehicles in a lot or valet style, but street parking is not available. The restaurant is known for its good ambiance, fresh food, and friendly staff. However, the restaurant has faced some criticism for suddenly closing without notice, which has caused disappointment among customers. Despite this, some customers have praised the restaurant's food quality and service.", "response_spans": [[0, 87], [89, 599], [583, 638]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4517764747142792, "(0, 16)": 0.4517764747142792, "(2, 0)": 0.4517764747142792, "(2, 16)": 0.4517764747142792, "(4, 0)": 0.3728838860988617, "(4, 16)": 0.4517764747142792, "(6, 0)": 0.4517764747142792, "(6, 16)": 0.6053286194801331, "(8, 0)": 0.44673576951026917, "(8, 16)": 0.3728838860988617, "(10, 0)": 0.6053286194801331, "(10, 16)": 0.6053286194801331, "(12, 0)": 0.5415008068084717, "(12, 16)": 0.6053286194801331, "(14, 0)": 0.3728838860988617, "(14, 16)": 0.6053286194801331, "(16, 0)": 0.6053286194801331, "(16, 16)": 0.5415008068084717, "(18, 0)": 0.3728838860988617, "(18, 16)": 0.6053286194801331, "(20, 0)": 0.6053286194801331, "(20, 16)": 0.3728838860988617, "(22, 0)": 0.3728838860988617, "(22, 16)": 0.6053286194801331, "(24, 0)": 0.3728838860988617, "(24, 16)": 0.6053286194801331, "(26, 0)": 0.6053286194801331, "(26, 16)": 0.45963865518569946, "(28, 0)": 0.6053286194801331, "(28, 16)": 0.3728838860988617, "(30, 0)": 0.6053286194801331, "(30, 16)": 0.6053286194801331}, "r_span": [906, 926], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00048536062240600586}}, {"prompt_attention_score": {"(0, 0)": 0.6745834946632385, "(0, 16)": 0.6745834946632385, "(2, 0)": 0.6745834946632385, "(2, 16)": 0.6745834946632385, "(4, 0)": 0.6745834946632385, "(4, 16)": 0.6745834946632385, "(6, 0)": 0.6745834946632385, "(6, 16)": 0.7738929390907288, "(8, 0)": 0.6438580751419067, "(8, 16)": 0.6010684967041016, "(10, 0)": 0.6745834946632385, "(10, 16)": 0.6745834946632385, "(12, 0)": 0.6010684967041016, "(12, 16)": 0.7738929390907288, "(14, 0)": 0.6010684967041016, "(14, 16)": 0.7738929390907288, "(16, 0)": 0.6010684967041016, "(16, 16)": 0.6010684967041016, "(18, 0)": 0.6010684967041016, "(18, 16)": 0.7738929390907288, "(20, 0)": 0.7738929390907288, "(20, 16)": 0.6010684967041016, "(22, 0)": 0.6010684967041016, "(22, 16)": 0.6010684967041016, "(24, 0)": 0.6010684967041016, "(24, 16)": 0.7738929390907288, "(26, 0)": 0.4070817232131958, "(26, 16)": 0.6010684967041016, "(28, 0)": 0.4070817232131958, "(28, 16)": 0.6010684967041016, "(30, 0)": 0.6010684967041016, "(30, 16)": 0.4070817232131958}, "r_span": [928, 1036], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0004684329032897949}}, {"prompt_attention_score": {"(0, 0)": 0.6235702037811279, "(0, 16)": 0.6235702037811279, "(2, 0)": 0.6235702037811279, "(2, 16)": 0.6235702037811279, "(4, 0)": 0.6235702037811279, "(4, 16)": 0.6235702037811279, "(6, 0)": 0.6235702037811279, "(6, 16)": 0.6677118539810181, "(8, 0)": 0.646252453327179, "(8, 16)": 0.6235702037811279, "(10, 0)": 0.6235702037811279, "(10, 16)": 0.6235702037811279, "(12, 0)": 0.646252453327179, "(12, 16)": 0.6677118539810181, "(14, 0)": 0.646252453327179, "(14, 16)": 0.6235702037811279, "(16, 0)": 0.646252453327179, "(16, 16)": 0.646252453327179, "(18, 0)": 0.646252453327179, "(18, 16)": 0.6677118539810181, "(20, 0)": 0.6677118539810181, "(20, 16)": 0.646252453327179, "(22, 0)": 0.646252453327179, "(22, 16)": 0.646252453327179, "(24, 0)": 0.646252453327179, "(24, 16)": 0.6677118539810181, "(26, 0)": 0.44548940658569336, "(26, 16)": 0.646252453327179, "(28, 0)": 0.44548940658569336, "(28, 16)": 0.646252453327179, "(30, 0)": 0.44548940658569336, "(30, 16)": 0.44548940658569336}, "r_span": [1033, 1044], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006969571113586426}}]}, {"id": "6921", "source_id": "14020", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 271, "end": 294, "text": "and Vietnamese cuisine.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of the restaurant offering Vietnamese cuisine.\nGenerative: \"...and Vietnamese cuisine.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 630, "end": 659, "text": "during the COVID-19 pandemic.", "meta": "LOW INTRO OF NEW INFO\nOriginal: It is correct that the delivery happened during COVID-19 pandemic since the review is dated 2020. However, it is not specified in the data.\nGenerative: \"...delivery service's attention to safety protocols during the COVID-19 pandemic.\"", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 171, "end": 203, "text": "a rating of 4.0 out of two stars", "meta": "\"rating of 4.0 out of two stars\" was not mention in the structured data and it seems unclear since this should be \"out of 5 stars\" instead of two.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of PokeCeviche:\n\nPokeCeviche is an Asian fusion restaurant located in Santa Barbara, California. With a rating of 4.0 out of two stars, the business offers a variety of dishes, including poke, seafood, and Vietnamese cuisine. However, recent reviews suggest that the quality of the food has been inconsistent, with some reviewers expressing disappointment with their orders. Additionally, one reviewer noted that the business's online ordering process is friendly and customizable, while another appreciated the delivery service's attention to safety protocols during the COVID-19 pandemic. Despite this mixed feedback, PokeCeviche remains a popular option for those looking for a flavorful and unique dining experience in the area.", "response_spans": [[0, 84], [86, 589], [577, 801]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.46391409635543823, "(0, 16)": 0.46391409635543823, "(2, 0)": 0.46391409635543823, "(2, 16)": 0.46391409635543823, "(4, 0)": 0.46391409635543823, "(4, 16)": 0.46391409635543823, "(6, 0)": 0.46391409635543823, "(6, 16)": 0.614504337310791, "(8, 0)": 0.46391409635543823, "(8, 16)": 0.46391409635543823, "(10, 0)": 0.614504337310791, "(10, 16)": 0.614504337310791, "(12, 0)": 0.5370329022407532, "(12, 16)": 0.614504337310791, "(14, 0)": 0.46391409635543823, "(14, 16)": 0.614504337310791, "(16, 0)": 0.614504337310791, "(16, 16)": 0.46391409635543823, "(18, 0)": 0.48837006092071533, "(18, 16)": 0.614504337310791, "(20, 0)": 0.614504337310791, "(20, 16)": 0.46391409635543823, "(22, 0)": 0.46391409635543823, "(22, 16)": 0.614504337310791, "(24, 0)": 0.46391409635543823, "(24, 16)": 0.614504337310791, "(26, 0)": 0.614504337310791, "(26, 16)": 0.614504337310791, "(28, 0)": 0.614504337310791, "(28, 16)": 0.46391409635543823, "(30, 0)": 0.614504337310791, "(30, 16)": 0.614504337310791}, "r_span": [738, 760], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005824565887451172}}, {"prompt_attention_score": {"(0, 0)": 0.6273118257522583, "(0, 16)": 0.6273118257522583, "(2, 0)": 0.6273118257522583, "(2, 16)": 0.6273118257522583, "(4, 0)": 0.6273118257522583, "(4, 16)": 0.6273118257522583, "(6, 0)": 0.6273118257522583, "(6, 16)": 0.7517896890640259, "(8, 0)": 0.6273118257522583, "(8, 16)": 0.6273118257522583, "(10, 0)": 0.6273118257522583, "(10, 16)": 0.6273118257522583, "(12, 0)": 0.6273118257522583, "(12, 16)": 0.7517896890640259, "(14, 0)": 0.6273118257522583, "(14, 16)": 0.7517896890640259, "(16, 0)": 0.6273118257522583, "(16, 16)": 0.6273118257522583, "(18, 0)": 0.5660555958747864, "(18, 16)": 0.7517896890640259, "(20, 0)": 0.7517896890640259, "(20, 16)": 0.6273118257522583, "(22, 0)": 0.6273118257522583, "(22, 16)": 0.6273118257522583, "(24, 0)": 0.6273118257522583, "(24, 16)": 0.7517896890640259, "(26, 0)": 0.42402830719947815, "(26, 16)": 0.6273118257522583, "(28, 0)": 0.42402830719947815, "(28, 16)": 0.6273118257522583, "(30, 0)": 0.42402830719947815, "(30, 16)": 0.42402830719947815}, "r_span": [762, 869], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0029321908950805664}}, {"prompt_attention_score": {"(0, 0)": 0.5755358338356018, "(0, 16)": 0.5755358338356018, "(2, 0)": 0.5755358338356018, "(2, 16)": 0.5755358338356018, "(4, 0)": 0.5755358338356018, "(4, 16)": 0.5755358338356018, "(6, 0)": 0.5755358338356018, "(6, 16)": 0.6462156176567078, "(8, 0)": 0.5755358338356018, "(8, 16)": 0.5755358338356018, "(10, 0)": 0.5755358338356018, "(10, 16)": 0.5755358338356018, "(12, 0)": 0.5755358338356018, "(12, 16)": 0.6417837142944336, "(14, 0)": 0.5755358338356018, "(14, 16)": 0.5755358338356018, "(16, 0)": 0.5755358338356018, "(16, 16)": 0.5755358338356018, "(18, 0)": 0.5688984394073486, "(18, 16)": 0.6417837142944336, "(20, 0)": 0.5688984394073486, "(20, 16)": 0.5755358338356018, "(22, 0)": 0.5755358338356018, "(22, 16)": 0.6417837142944336, "(24, 0)": 0.5755358338356018, "(24, 16)": 0.5755358338356018, "(26, 0)": 0.41828882694244385, "(26, 16)": 0.5755358338356018, "(28, 0)": 0.41828882694244385, "(28, 16)": 0.5755358338356018, "(30, 0)": 0.41828882694244385, "(30, 16)": 0.41828882694244385}, "r_span": [868, 917], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0008985996246337891}}]}, {"id": "6927", "source_id": "14021", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 383, "end": 412, "text": "with garage parking available", "meta": "EVIDENT CONFLICT\nOriginal: \"garage\": false\nGenerative: \"...with garage parking available...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of the Santa Barbara Bay Cafe:\n\nThe Santa Barbara Bay Cafe is a seafood restaurant located in downtown Santa Barbara, California. With a rating of 3.5 stars, the restaurant offers outdoor seating and provides takeout options. According to customer reviews, the restaurant's Business Parking attributes are decent, with garage parking available but no valet service. The Restaurants Reservations attribute is true, indicating that reservations can be made. Customers have praised the restaurant's food quality, with one reviewer describing it as \"legit\" and another recommending it for a relaxed meal. However, some reviewers have criticized the restaurant's clam chowder, describing it as too watery, and the oysters Rockefeller, which were described as being overpowered by cheese. Despite these issues, the majority of customers have given the restaurant high ratings, with one reviewer calling it the best seafood in town.", "response_spans": [[0, 99], [101, 610], [597, 994]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.45811325311660767, "(0, 16)": 0.45811325311660767, "(2, 0)": 0.45811325311660767, "(2, 16)": 0.45811325311660767, "(4, 0)": 0.45811325311660767, "(4, 16)": 0.45811325311660767, "(6, 0)": 0.45811325311660767, "(6, 16)": 0.6399738192558289, "(8, 0)": 0.45811325311660767, "(8, 16)": 0.45811325311660767, "(10, 0)": 0.6399738192558289, "(10, 16)": 0.6399738192558289, "(12, 0)": 0.45811325311660767, "(12, 16)": 0.6399738192558289, "(14, 0)": 0.45811325311660767, "(14, 16)": 0.6399738192558289, "(16, 0)": 0.6399738192558289, "(16, 16)": 0.45811325311660767, "(18, 0)": 0.45811325311660767, "(18, 16)": 0.6399738192558289, "(20, 0)": 0.6399738192558289, "(20, 16)": 0.45811325311660767, "(22, 0)": 0.6399738192558289, "(22, 16)": 0.6399738192558289, "(24, 0)": 0.45811325311660767, "(24, 16)": 0.6399738192558289, "(26, 0)": 0.6399738192558289, "(26, 16)": 0.48581498861312866, "(28, 0)": 0.6399738192558289, "(28, 16)": 0.45811325311660767, "(30, 0)": 0.6399738192558289, "(30, 16)": 0.6399738192558289}, "r_span": [863, 886], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00036156177520751953}}, {"prompt_attention_score": {"(0, 0)": 0.589219331741333, "(0, 16)": 0.589219331741333, "(2, 0)": 0.589219331741333, "(2, 16)": 0.589219331741333, "(4, 0)": 0.589219331741333, "(4, 16)": 0.589219331741333, "(6, 0)": 0.589219331741333, "(6, 16)": 0.7413364052772522, "(8, 0)": 0.589219331741333, "(8, 16)": 0.589219331741333, "(10, 0)": 0.589219331741333, "(10, 16)": 0.589219331741333, "(12, 0)": 0.589219331741333, "(12, 16)": 0.7413364052772522, "(14, 0)": 0.589219331741333, "(14, 16)": 0.7413364052772522, "(16, 0)": 0.6652170419692993, "(16, 16)": 0.589219331741333, "(18, 0)": 0.589219331741333, "(18, 16)": 0.7413364052772522, "(20, 0)": 0.7413364052772522, "(20, 16)": 0.589219331741333, "(22, 0)": 0.4596542716026306, "(22, 16)": 0.7413364052772522, "(24, 0)": 0.589219331741333, "(24, 16)": 0.7413364052772522, "(26, 0)": 0.4596542716026306, "(26, 16)": 0.589219331741333, "(28, 0)": 0.4596542716026306, "(28, 16)": 0.589219331741333, "(30, 0)": 0.4596542716026306, "(30, 16)": 0.4596542716026306}, "r_span": [888, 999], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.000540614128112793}}, {"prompt_attention_score": {"(0, 0)": 0.7540791630744934, "(0, 16)": 0.7540791630744934, "(2, 0)": 0.7540791630744934, "(2, 16)": 0.7540791630744934, "(4, 0)": 0.7540791630744934, "(4, 16)": 0.7540791630744934, "(6, 0)": 0.7540791630744934, "(6, 16)": 0.7883535623550415, "(8, 0)": 0.7540791630744934, "(8, 16)": 0.7540791630744934, "(10, 0)": 0.7540791630744934, "(10, 16)": 0.7540791630744934, "(12, 0)": 0.7540791630744934, "(12, 16)": 0.7883535623550415, "(14, 0)": 0.7540791630744934, "(14, 16)": 0.7540791630744934, "(16, 0)": 0.7540791630744934, "(16, 16)": 0.7540791630744934, "(18, 0)": 0.4603118300437927, "(18, 16)": 0.7883535623550415, "(20, 0)": 0.7540791630744934, "(20, 16)": 0.7540791630744934, "(22, 0)": 0.4603118300437927, "(22, 16)": 0.7709411382675171, "(24, 0)": 0.7540791630744934, "(24, 16)": 0.7709411382675171, "(26, 0)": 0.4603118300437927, "(26, 16)": 0.7540791630744934, "(28, 0)": 0.4603118300437927, "(28, 16)": 0.7540791630744934, "(30, 0)": 0.4603118300437927, "(30, 16)": 0.4603118300437927}, "r_span": [998, 1091], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014144182205200195}}]}, {"id": "6933", "source_id": "14022", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 625, "end": 646, "text": "with a romantic vibe.", "meta": "EVIDENT CONFLICT\nOriginal: \"romantic\": false\nGenerative: \"...with a romantic vibe.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Le Cafe Stella is a charming French restaurant located in Santa Barbara, California. With a rating of 3.5 stars, it offers a cozy atmosphere and excellent service. Customers have praised the restaurant's classic French cuisine, including dishes such as French onion soup and frog legs, which are reasonably priced. While some customers have expressed disappointment with the wine selection by the glass, the cocktail menu has been well-received. The restaurant features outdoor seating, free WiFi, and takes reservations, making it a great option for both locals and visitors. The ambiance is described as casual and classy, with a romantic vibe. Overall, Le Cafe Stella provides a pleasant dining experience with delicious food and friendly service.", "response_spans": [[0, 507], [492, 750]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6707994937896729, "(0, 16)": 0.6707994937896729, "(2, 0)": 0.6044665575027466, "(2, 16)": 0.6707994937896729, "(4, 0)": 0.6044665575027466, "(4, 16)": 0.6044665575027466, "(6, 0)": 0.6707994937896729, "(6, 16)": 0.7715751528739929, "(8, 0)": 0.6044665575027466, "(8, 16)": 0.6707994937896729, "(10, 0)": 0.6707994937896729, "(10, 16)": 0.6707994937896729, "(12, 0)": 0.6707994937896729, "(12, 16)": 0.6441158056259155, "(14, 0)": 0.6707994937896729, "(14, 16)": 0.6707994937896729, "(16, 0)": 0.6441158056259155, "(16, 16)": 0.6707994937896729, "(18, 0)": 0.6707994937896729, "(18, 16)": 0.6441158056259155, "(20, 0)": 0.6441158056259155, "(20, 16)": 0.6660401225090027, "(22, 0)": 0.4147395193576813, "(22, 16)": 0.6441158056259155, "(24, 0)": 0.6660401225090027, "(24, 16)": 0.6441158056259155, "(26, 0)": 0.4147395193576813, "(26, 16)": 0.6441158056259155, "(28, 0)": 0.4147395193576813, "(28, 16)": 0.4147395193576813, "(30, 0)": 0.4147395193576813, "(30, 16)": 0.4147395193576813}, "r_span": [893, 1008], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014137029647827148}}, {"prompt_attention_score": {"(0, 0)": 0.6380355358123779, "(0, 16)": 0.6380355358123779, "(2, 0)": 0.6380355358123779, "(2, 16)": 0.6380355358123779, "(4, 0)": 0.6380355358123779, "(4, 16)": 0.6380355358123779, "(6, 0)": 0.6380355358123779, "(6, 16)": 0.6864556074142456, "(8, 0)": 0.634584903717041, "(8, 16)": 0.6380355358123779, "(10, 0)": 0.6380355358123779, "(10, 16)": 0.6380355358123779, "(12, 0)": 0.6380355358123779, "(12, 16)": 0.6291339993476868, "(14, 0)": 0.4225127100944519, "(14, 16)": 0.6380355358123779, "(16, 0)": 0.6291339993476868, "(16, 16)": 0.6380355358123779, "(18, 0)": 0.4225127100944519, "(18, 16)": 0.6291339993476868, "(20, 0)": 0.6291339993476868, "(20, 16)": 0.6291089057922363, "(22, 0)": 0.4225127100944519, "(22, 16)": 0.6291339993476868, "(24, 0)": 0.634584903717041, "(24, 16)": 0.6291339993476868, "(26, 0)": 0.4225127100944519, "(26, 16)": 0.6291089057922363, "(28, 0)": 0.4225127100944519, "(28, 16)": 0.4225127100944519, "(30, 0)": 0.4225127100944519, "(30, 16)": 0.4225127100944519}, "r_span": [1004, 1065], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012615323066711426}}]}, {"id": "6975", "source_id": "14030", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is an objective overview of Panera Bread based on the structured data provided:\n\nPanera Bread is a popular restaurant located in Santa Barbara, California, offering a variety of dining options including bagels, sandwiches, soups, and salads. Customers praise the friendly staff and prompt service, with one reviewer highlighting the employee's politeness and respect towards outdoor guests and curbside pickups. However, some reviews mention disappointing experiences with cold or incorrect orders, and poor management and training practices within the restaurant. Despite these issues, Panera Bread maintains a rating of 2.5 stars and is known for providing free WiFi to its customers.", "response_spans": [[0, 84], [86, 591], [578, 691]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.46395936608314514, "(0, 16)": 0.46395936608314514, "(2, 0)": 0.46395936608314514, "(2, 16)": 0.46395936608314514, "(4, 0)": 0.46395936608314514, "(4, 16)": 0.46395936608314514, "(6, 0)": 0.5349748134613037, "(6, 16)": 0.6632639169692993, "(8, 0)": 0.4243215024471283, "(8, 16)": 0.46395936608314514, "(10, 0)": 0.6632639169692993, "(10, 16)": 0.6632639169692993, "(12, 0)": 0.5791686773300171, "(12, 16)": 0.6632639169692993, "(14, 0)": 0.4243215024471283, "(14, 16)": 0.6632639169692993, "(16, 0)": 0.6632639169692993, "(16, 16)": 0.4243215024471283, "(18, 0)": 0.46395936608314514, "(18, 16)": 0.6632639169692993, "(20, 0)": 0.6632639169692993, "(20, 16)": 0.4243215024471283, "(22, 0)": 0.4243215024471283, "(22, 16)": 0.6632639169692993, "(24, 0)": 0.4243215024471283, "(24, 16)": 0.6632639169692993, "(26, 0)": 0.6632639169692993, "(26, 16)": 0.6143676042556763, "(28, 0)": 0.6632639169692993, "(28, 16)": 0.4243215024471283, "(30, 0)": 0.6632639169692993, "(30, 16)": 0.6632639169692993}, "r_span": [948, 967], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002874135971069336}}, {"prompt_attention_score": {"(0, 0)": 0.5690133571624756, "(0, 16)": 0.7105426788330078, "(2, 0)": 0.5690133571624756, "(2, 16)": 0.5690133571624756, "(4, 0)": 0.5690133571624756, "(4, 16)": 0.5690133571624756, "(6, 0)": 0.5690133571624756, "(6, 16)": 0.785456657409668, "(8, 0)": 0.5690133571624756, "(8, 16)": 0.5690133571624756, "(10, 0)": 0.7105426788330078, "(10, 16)": 0.7105426788330078, "(12, 0)": 0.7105426788330078, "(12, 16)": 0.533194363117218, "(14, 0)": 0.5690133571624756, "(14, 16)": 0.5690133571624756, "(16, 0)": 0.533194363117218, "(16, 16)": 0.5690133571624756, "(18, 0)": 0.5690133571624756, "(18, 16)": 0.785456657409668, "(20, 0)": 0.533194363117218, "(20, 16)": 0.533194363117218, "(22, 0)": 0.533194363117218, "(22, 16)": 0.785456657409668, "(24, 0)": 0.533194363117218, "(24, 16)": 0.533194363117218, "(26, 0)": 0.4565693140029907, "(26, 16)": 0.533194363117218, "(28, 0)": 0.4565693140029907, "(28, 16)": 0.533194363117218, "(30, 0)": 0.4565693140029907, "(30, 16)": 0.4565693140029907}, "r_span": [969, 1070], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0030235648155212402}}, {"prompt_attention_score": {"(0, 0)": 0.5987502336502075, "(0, 16)": 0.5987502336502075, "(2, 0)": 0.5307711362838745, "(2, 16)": 0.5307711362838745, "(4, 0)": 0.5307711362838745, "(4, 16)": 0.5307711362838745, "(6, 0)": 0.5307711362838745, "(6, 16)": 0.6209099292755127, "(8, 0)": 0.5307711362838745, "(8, 16)": 0.5307711362838745, "(10, 0)": 0.5987502336502075, "(10, 16)": 0.5987502336502075, "(12, 0)": 0.5307711362838745, "(12, 16)": 0.6209099292755127, "(14, 0)": 0.42475998401641846, "(14, 16)": 0.4726303219795227, "(16, 0)": 0.6209099292755127, "(16, 16)": 0.5307711362838745, "(18, 0)": 0.42475998401641846, "(18, 16)": 0.6209099292755127, "(20, 0)": 0.6209099292755127, "(20, 16)": 0.42475998401641846, "(22, 0)": 0.42475998401641846, "(22, 16)": 0.6209099292755127, "(24, 0)": 0.42475998401641846, "(24, 16)": 0.6209099292755127, "(26, 0)": 0.43313565850257874, "(26, 16)": 0.42475998401641846, "(28, 0)": 0.43313565850257874, "(28, 16)": 0.42475998401641846, "(30, 0)": 0.43313565850257874, "(30, 16)": 0.43313565850257874}, "r_span": [1068, 1096], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011681318283081055}}]}, {"id": "6981", "source_id": "14031", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Domingo's Cafe is a cozy local eatery located in Goleta, California, offering a variety of breakfast and brunch options, including Mexican and American favorites. With a rating of 4.0 stars and numerous positive reviews, customers appreciate the cafe's home-style feel, comfortable seating both indoors and outdoors, and friendly service. Standout menu items include breakfast burritos, omelets, and fresh fruit cups, as well as the option to customize dishes to suit individual preferences. While some reviewers have noted minor issues with food temperature and toilet maintenance, overall, Domingo's Cafe appears to be a popular and enjoyable destination for both locals and visitors alike.", "response_spans": [[0, 512], [498, 692]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6096869707107544, "(0, 16)": 0.6096869707107544, "(2, 0)": 0.6096869707107544, "(2, 16)": 0.6096869707107544, "(4, 0)": 0.6096869707107544, "(4, 16)": 0.6096869707107544, "(6, 0)": 0.6096869707107544, "(6, 16)": 0.7453469038009644, "(8, 0)": 0.6096869707107544, "(8, 16)": 0.6096869707107544, "(10, 0)": 0.6096869707107544, "(10, 16)": 0.6096869707107544, "(12, 0)": 0.6096869707107544, "(12, 16)": 0.6980113983154297, "(14, 0)": 0.6096869707107544, "(14, 16)": 0.6096869707107544, "(16, 0)": 0.6980113983154297, "(16, 16)": 0.6096869707107544, "(18, 0)": 0.6096869707107544, "(18, 16)": 0.7453469038009644, "(20, 0)": 0.6980113983154297, "(20, 16)": 0.6096869707107544, "(22, 0)": 0.6096869707107544, "(22, 16)": 0.6980113983154297, "(24, 0)": 0.6096869707107544, "(24, 16)": 0.6096869707107544, "(26, 0)": 0.4046577215194702, "(26, 16)": 0.6096869707107544, "(28, 0)": 0.4046577215194702, "(28, 16)": 0.6096869707107544, "(30, 0)": 0.4046577215194702, "(30, 16)": 0.4046577215194702}, "r_span": [883, 1003], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0022882819175720215}}, {"prompt_attention_score": {"(0, 0)": 0.6560549736022949, "(0, 16)": 0.6560549736022949, "(2, 0)": 0.6560549736022949, "(2, 16)": 0.5731236934661865, "(4, 0)": 0.6560549736022949, "(4, 16)": 0.6560549736022949, "(6, 0)": 0.6560549736022949, "(6, 16)": 0.5914419293403625, "(8, 0)": 0.6560549736022949, "(8, 16)": 0.6560549736022949, "(10, 0)": 0.6560549736022949, "(10, 16)": 0.6560549736022949, "(12, 0)": 0.6560549736022949, "(12, 16)": 0.6560549736022949, "(14, 0)": 0.6560549736022949, "(14, 16)": 0.6560549736022949, "(16, 0)": 0.6560549736022949, "(16, 16)": 0.6560549736022949, "(18, 0)": 0.4011048972606659, "(18, 16)": 0.6560549736022949, "(20, 0)": 0.6560549736022949, "(20, 16)": 0.6560549736022949, "(22, 0)": 0.6560549736022949, "(22, 16)": 0.6560549736022949, "(24, 0)": 0.6560549736022949, "(24, 16)": 0.6560549736022949, "(26, 0)": 0.4011048972606659, "(26, 16)": 0.6560549736022949, "(28, 0)": 0.4011048972606659, "(28, 16)": 0.6560549736022949, "(30, 0)": 0.4011048972606659, "(30, 16)": 0.4011048972606659}, "r_span": [1001, 1042], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018428564071655273}}]}, {"id": "6999", "source_id": "14034", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Harbor of Santa Barbara Inc is a popular destination located on Stearns Wharf in Santa Barbara, California. The business offers a variety of activities, including boating and dining options. Customers have praised the scenic views and the opportunity to watch fishermen and rowers. However, some have criticized the high dockage fees and the perception that the location caters more to wealthy individuals rather than families or budget-conscious travelers. Despite this, the business has received generally positive reviews for its friendly staff and relaxed atmosphere.", "response_spans": [[0, 507], [489, 571]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6359355449676514, "(0, 16)": 0.6359355449676514, "(2, 0)": 0.6359355449676514, "(2, 16)": 0.6359355449676514, "(4, 0)": 0.6359355449676514, "(4, 16)": 0.6359355449676514, "(6, 0)": 0.604279637336731, "(6, 16)": 0.7210865616798401, "(8, 0)": 0.604279637336731, "(8, 16)": 0.6359355449676514, "(10, 0)": 0.6359355449676514, "(10, 16)": 0.6359355449676514, "(12, 0)": 0.6359355449676514, "(12, 16)": 0.6359355449676514, "(14, 0)": 0.604279637336731, "(14, 16)": 0.6359355449676514, "(16, 0)": 0.6359355449676514, "(16, 16)": 0.41717827320098877, "(18, 0)": 0.4459817707538605, "(18, 16)": 0.7210865616798401, "(20, 0)": 0.7210865616798401, "(20, 16)": 0.604279637336731, "(22, 0)": 0.41717827320098877, "(22, 16)": 0.6359355449676514, "(24, 0)": 0.604279637336731, "(24, 16)": 0.604279637336731, "(26, 0)": 0.41717827320098877, "(26, 16)": 0.41717827320098877, "(28, 0)": 0.41717827320098877, "(28, 16)": 0.604279637336731, "(30, 0)": 0.41717827320098877, "(30, 16)": 0.41717827320098877}, "r_span": [721, 826], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00038748979568481445}}, {"prompt_attention_score": {"(0, 0)": 0.46056848764419556, "(0, 16)": 0.5483094453811646, "(2, 0)": 0.5483094453811646, "(2, 16)": 0.5483094453811646, "(4, 0)": 0.5483094453811646, "(4, 16)": 0.5483094453811646, "(6, 0)": 0.5483094453811646, "(6, 16)": 0.4823624789714813, "(8, 0)": 0.46056848764419556, "(8, 16)": 0.5483094453811646, "(10, 0)": 0.5483094453811646, "(10, 16)": 0.5483094453811646, "(12, 0)": 0.5483094453811646, "(12, 16)": 0.5483094453811646, "(14, 0)": 0.4823624789714813, "(14, 16)": 0.47445443272590637, "(16, 0)": 0.5483094453811646, "(16, 16)": 0.5483094453811646, "(18, 0)": 0.4161381125450134, "(18, 16)": 0.5483094453811646, "(20, 0)": 0.5483094453811646, "(20, 16)": 0.46056848764419556, "(22, 0)": 0.4161381125450134, "(22, 16)": 0.46056848764419556, "(24, 0)": 0.46056848764419556, "(24, 16)": 0.46056848764419556, "(26, 0)": 0.4161381125450134, "(26, 16)": 0.4161381125450134, "(28, 0)": 0.4161381125450134, "(28, 16)": 0.46056848764419556, "(30, 0)": 0.4161381125450134, "(30, 16)": 0.4161381125450134}, "r_span": [825, 837], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004851818084716797}}]}, {"id": "7005", "source_id": "14035", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 166, "end": 194, "text": "vegetarian and vegan choices", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the restaurant offers vegetarian and vegan options, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Peebee & Jays is a local sandwich shop located in Carpinteria, California, with a rating of 4.0 stars. The restaurant offers a variety of sandwich options, including vegetarian and vegan choices, and has outdoor seating available. However, some customers have reported issues with the restaurant's online ordering system, including confusion and difficulty with redeeming points. Some reviews praise the quality of the sandwiches, while others have had negative experiences with the staff and service. Specifically, one reviewer found the crust of their sandwich to be rubbery and difficult to eat, while another had a frustrating experience with a pickup order being drenched in mayonnaise despite requesting it to be on the side. A third reviewer had a particularly poor experience with a rude manager who lacked basic customer service skills. Despite these issues, many reviewers have praised the quality of the sandwiches and the value for money.", "response_spans": [[0, 501], [483, 950]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5435766577720642, "(0, 16)": 0.5435766577720642, "(2, 0)": 0.5435766577720642, "(2, 16)": 0.5435766577720642, "(4, 0)": 0.5435766577720642, "(4, 16)": 0.5435766577720642, "(6, 0)": 0.5435766577720642, "(6, 16)": 0.7264543175697327, "(8, 0)": 0.5435766577720642, "(8, 16)": 0.5435766577720642, "(10, 0)": 0.555708646774292, "(10, 16)": 0.5435766577720642, "(12, 0)": 0.5435766577720642, "(12, 16)": 0.5774433016777039, "(14, 0)": 0.5209834575653076, "(14, 16)": 0.4336315393447876, "(16, 0)": 0.5774433016777039, "(16, 16)": 0.5435766577720642, "(18, 0)": 0.5435766577720642, "(18, 16)": 0.5774433016777039, "(20, 0)": 0.7264543175697327, "(20, 16)": 0.555708646774292, "(22, 0)": 0.43710821866989136, "(22, 16)": 0.5774433016777039, "(24, 0)": 0.573691725730896, "(24, 16)": 0.7264543175697327, "(26, 0)": 0.43710821866989136, "(26, 16)": 0.555708646774292, "(28, 0)": 0.43710821866989136, "(28, 16)": 0.43710821866989136, "(30, 0)": 0.43710821866989136, "(30, 16)": 0.43710821866989136}, "r_span": [1150, 1258], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0013681650161743164}}, {"prompt_attention_score": {"(0, 0)": 0.7106090784072876, "(0, 16)": 0.7106090784072876, "(2, 0)": 0.7106090784072876, "(2, 16)": 0.7106090784072876, "(4, 0)": 0.7106090784072876, "(4, 16)": 0.7106090784072876, "(6, 0)": 0.7106090784072876, "(6, 16)": 0.7889026999473572, "(8, 0)": 0.7106090784072876, "(8, 16)": 0.7106090784072876, "(10, 0)": 0.7106090784072876, "(10, 16)": 0.7106090784072876, "(12, 0)": 0.7360599040985107, "(12, 16)": 0.7889026999473572, "(14, 0)": 0.7360599040985107, "(14, 16)": 0.48172008991241455, "(16, 0)": 0.7106090784072876, "(16, 16)": 0.7106090784072876, "(18, 0)": 0.7106090784072876, "(18, 16)": 0.7889026999473572, "(20, 0)": 0.7889026999473572, "(20, 16)": 0.7360599040985107, "(22, 0)": 0.5219948291778564, "(22, 16)": 0.7889026999473572, "(24, 0)": 0.7889026999473572, "(24, 16)": 0.7889026999473572, "(26, 0)": 0.5219948291778564, "(26, 16)": 0.6599467992782593, "(28, 0)": 0.5219948291778564, "(28, 16)": 0.5219948291778564, "(30, 0)": 0.5219948291778564, "(30, 16)": 0.5219948291778564}, "r_span": [1255, 1357], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -2.09808349609375e-05}}]}, {"id": "7011", "source_id": "14036", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 304, "end": 360, "text": "The establishment has a modern and functional atmosphere", "meta": "AIGC: The establishment has a modern and functional atmosphere,\nOriginal:  the bathrooms are modern and functional", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 592, "end": 635, "text": "the bathrooms are clean and well-maintained", "meta": "Original: These claims was not mentioned \" the bathrooms are clean and well-maintained.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Soho Restaurant & Music Club is a popular local business in Santa Barbara, California. With a rating of 3.5 stars, the venue offers a variety of services, including music venues, bars, nightlife, arts & entertainment, restaurants, and American traditional cuisine. The establishment has a modern and functional atmosphere, with comfortable seating and good sound quality. The restaurant serves delicious food, including burgers, ravioli, and creme brule, and has a bar area where customers can enjoy their drinks. The staff is friendly and helpful, and the bathrooms are clean and well-maintained. Despite some negative reviews regarding the no refund policy for event tickets, Soho Restaurant & Music Club has received mostly positive feedback for its food, atmosphere, and overall experience.", "response_spans": [[0, 512], [494, 833]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6838020086288452, "(0, 16)": 0.6838020086288452, "(2, 0)": 0.6838020086288452, "(2, 16)": 0.6838020086288452, "(4, 0)": 0.6838020086288452, "(4, 16)": 0.6838020086288452, "(6, 0)": 0.6838020086288452, "(6, 16)": 0.790780782699585, "(8, 0)": 0.5840869545936584, "(8, 16)": 0.6838020086288452, "(10, 0)": 0.5840869545936584, "(10, 16)": 0.6731780767440796, "(12, 0)": 0.6731780767440796, "(12, 16)": 0.790780782699585, "(14, 0)": 0.4734037220478058, "(14, 16)": 0.790780782699585, "(16, 0)": 0.5685355067253113, "(16, 16)": 0.6838020086288452, "(18, 0)": 0.6731780767440796, "(18, 16)": 0.790780782699585, "(20, 0)": 0.790780782699585, "(20, 16)": 0.4734037220478058, "(22, 0)": 0.4734037220478058, "(22, 16)": 0.6309012770652771, "(24, 0)": 0.4734037220478058, "(24, 16)": 0.6838020086288452, "(26, 0)": 0.5685355067253113, "(26, 16)": 0.4734037220478058, "(28, 0)": 0.5685355067253113, "(28, 16)": 0.4734037220478058, "(30, 0)": 0.4734037220478058, "(30, 16)": 0.5685355067253113}, "r_span": [1627, 1743], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0017321109771728516}}, {"prompt_attention_score": {"(0, 0)": 0.7688940763473511, "(0, 16)": 0.7688940763473511, "(2, 0)": 0.7688940763473511, "(2, 16)": 0.5464993715286255, "(4, 0)": 0.7688940763473511, "(4, 16)": 0.7688940763473511, "(6, 0)": 0.5464993715286255, "(6, 16)": 0.6198819875717163, "(8, 0)": 0.5464993715286255, "(8, 16)": 0.5464993715286255, "(10, 0)": 0.6571643352508545, "(10, 16)": 0.6571643352508545, "(12, 0)": 0.6571643352508545, "(12, 16)": 0.7688940763473511, "(14, 0)": 0.5464993715286255, "(14, 16)": 0.46623191237449646, "(16, 0)": 0.7688940763473511, "(16, 16)": 0.5464993715286255, "(18, 0)": 0.5464993715286255, "(18, 16)": 0.7688940763473511, "(20, 0)": 0.70438152551651, "(20, 16)": 0.5464993715286255, "(22, 0)": 0.5464993715286255, "(22, 16)": 0.70438152551651, "(24, 0)": 0.5464993715286255, "(24, 16)": 0.7688940763473511, "(26, 0)": 0.44407719373703003, "(26, 16)": 0.5464993715286255, "(28, 0)": 0.44407719373703003, "(28, 16)": 0.5464993715286255, "(30, 0)": 0.5464993715286255, "(30, 16)": 0.44407719373703003}, "r_span": [1739, 1809], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.000578463077545166}}]}, {"id": "7017", "source_id": "14037", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 280, "end": 344, "text": "Customers have praised the restaurant's use of fresh ingredients", "meta": "HIGH INTRO OF NEW INFO\nIt mentions the use of fresh ingredients, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Eladio's Restaurant is a popular dining spot in Santa Barbara, California, offering a variety of cuisines including seafood, sandwiches, breakfast, and brunch. With a rating of 3.5 stars, the restaurant has received positive reviews for its food quality, atmosphere, and service. Customers have praised the restaurant's use of fresh ingredients, creative dishes, and friendly staff. While some have noted that the interior could be improved, the outdoor seating area offers great views of the surrounding waterfront. The restaurant also offers takeout options and has a happy hour menu. Overall, Eladio's Restaurant is a great choice for those looking for a casual dining experience with good food and service.", "response_spans": [[0, 504], [486, 710]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5857747793197632, "(0, 16)": 0.5857747793197632, "(2, 0)": 0.5857747793197632, "(2, 16)": 0.5857747793197632, "(4, 0)": 0.5857747793197632, "(4, 16)": 0.5857747793197632, "(6, 0)": 0.5857747793197632, "(6, 16)": 0.7460435628890991, "(8, 0)": 0.5857747793197632, "(8, 16)": 0.5857747793197632, "(10, 0)": 0.6067051887512207, "(10, 16)": 0.5857747793197632, "(12, 0)": 0.5857747793197632, "(12, 16)": 0.7460435628890991, "(14, 0)": 0.5857747793197632, "(14, 16)": 0.5857747793197632, "(16, 0)": 0.6272509098052979, "(16, 16)": 0.5857747793197632, "(18, 0)": 0.5857747793197632, "(18, 16)": 0.7460435628890991, "(20, 0)": 0.6272509098052979, "(20, 16)": 0.5857747793197632, "(22, 0)": 0.5857747793197632, "(22, 16)": 0.7460435628890991, "(24, 0)": 0.5857747793197632, "(24, 16)": 0.5857747793197632, "(26, 0)": 0.4452235996723175, "(26, 16)": 0.5857747793197632, "(28, 0)": 0.4452235996723175, "(28, 16)": 0.5857747793197632, "(30, 0)": 0.4452235996723175, "(30, 16)": 0.4452235996723175}, "r_span": [881, 997], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0021756887435913086}}, {"prompt_attention_score": {"(0, 0)": 0.5885387063026428, "(0, 16)": 0.5885387063026428, "(2, 0)": 0.5885387063026428, "(2, 16)": 0.672159731388092, "(4, 0)": 0.5885387063026428, "(4, 16)": 0.5885387063026428, "(6, 0)": 0.5885387063026428, "(6, 16)": 0.657792329788208, "(8, 0)": 0.5885387063026428, "(8, 16)": 0.5885387063026428, "(10, 0)": 0.5885387063026428, "(10, 16)": 0.5885387063026428, "(12, 0)": 0.5885387063026428, "(12, 16)": 0.6353257894515991, "(14, 0)": 0.5885387063026428, "(14, 16)": 0.5885387063026428, "(16, 0)": 0.5885387063026428, "(16, 16)": 0.5885387063026428, "(18, 0)": 0.43606996536254883, "(18, 16)": 0.6353257894515991, "(20, 0)": 0.657792329788208, "(20, 16)": 0.5885387063026428, "(22, 0)": 0.5885387063026428, "(22, 16)": 0.6564372777938843, "(24, 0)": 0.5885387063026428, "(24, 16)": 0.657792329788208, "(26, 0)": 0.43606996536254883, "(26, 16)": 0.5885387063026428, "(28, 0)": 0.43606996536254883, "(28, 16)": 0.5885387063026428, "(30, 0)": 0.43606996536254883, "(30, 16)": 0.43606996536254883}, "r_span": [995, 1045], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014747977256774902}}]}, {"id": "7023", "source_id": "14038", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 591, "end": 634, "text": "with one reviewer describing it as \"trendy\"", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No reviews of the restaurant being trendy\nGenerative: \"...with one reviewer describing it as \"trendy\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Longboard's Grill is a popular nightlife spot in Santa Barbara, California, offering a unique blend of seafood, American traditional cuisine, and bar experiences. With a 3.0-star rating and positive reviews, the restaurant is known for its outdoor seating, takeout options, and casual atmosphere. While some patrons have praised the oysters as \"fresh and tasty,\" another reviewer had a disappointing experience with their Thanksgiving dinner, citing poor service and lack of menus. However, the majority of reviews highlight the restaurant's ambiance, with one reviewer describing it as \"trendy\" and \"classy.\" Overall, Longboard's Grill appears to be a decent dining option in the area, although some improvements may be necessary to address the criticisms raised by certain patrons.", "response_spans": [[0, 510], [494, 822]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5791622996330261, "(0, 16)": 0.5791622996330261, "(2, 0)": 0.5791622996330261, "(2, 16)": 0.5395689606666565, "(4, 0)": 0.5791622996330261, "(4, 16)": 0.5791622996330261, "(6, 0)": 0.5791622996330261, "(6, 16)": 0.7794169187545776, "(8, 0)": 0.6223459839820862, "(8, 16)": 0.5791622996330261, "(10, 0)": 0.6223459839820862, "(10, 16)": 0.5791622996330261, "(12, 0)": 0.5791622996330261, "(12, 16)": 0.6296851634979248, "(14, 0)": 0.5791622996330261, "(14, 16)": 0.7794169187545776, "(16, 0)": 0.5300090312957764, "(16, 16)": 0.5791622996330261, "(18, 0)": 0.5791622996330261, "(18, 16)": 0.7794169187545776, "(20, 0)": 0.7794169187545776, "(20, 16)": 0.5791622996330261, "(22, 0)": 0.5300090312957764, "(22, 16)": 0.7794169187545776, "(24, 0)": 0.5791622996330261, "(24, 16)": 0.6296851634979248, "(26, 0)": 0.5300090312957764, "(26, 16)": 0.6296851634979248, "(28, 0)": 0.5300090312957764, "(28, 16)": 0.5791622996330261, "(30, 0)": 0.5300090312957764, "(30, 16)": 0.5300090312957764}, "r_span": [909, 1030], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001349806785583496}}, {"prompt_attention_score": {"(0, 0)": 0.6828990578651428, "(0, 16)": 0.6828990578651428, "(2, 0)": 0.6792018413543701, "(2, 16)": 0.6792018413543701, "(4, 0)": 0.6792018413543701, "(4, 16)": 0.6792018413543701, "(6, 0)": 0.6828990578651428, "(6, 16)": 0.6629669666290283, "(8, 0)": 0.6828990578651428, "(8, 16)": 0.6792018413543701, "(10, 0)": 0.6792018413543701, "(10, 16)": 0.6792018413543701, "(12, 0)": 0.6828990578651428, "(12, 16)": 0.6629669666290283, "(14, 0)": 0.6828990578651428, "(14, 16)": 0.48647648096084595, "(16, 0)": 0.6792018413543701, "(16, 16)": 0.6792018413543701, "(18, 0)": 0.6828990578651428, "(18, 16)": 0.6629669666290283, "(20, 0)": 0.6629669666290283, "(20, 16)": 0.6828990578651428, "(22, 0)": 0.5341616868972778, "(22, 16)": 0.6629669666290283, "(24, 0)": 0.6828990578651428, "(24, 16)": 0.6629669666290283, "(26, 0)": 0.5341616868972778, "(26, 16)": 0.6629669666290283, "(28, 0)": 0.5341616868972778, "(28, 16)": 0.6828990578651428, "(30, 0)": 0.5341616868972778, "(30, 16)": 0.5341616868972778}, "r_span": [1028, 1103], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.000814974308013916}}]}, {"id": "7029", "source_id": "14039", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 203, "end": 275, "text": "some reviewers praise the restaurant's convenient location and good food", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that some reviewers praise the restaurant's convenient location and good food, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Killer B's BBQ Bar and Grill in Santa Barbara, CA:\n\nKiller B's BBQ Bar and Grill has a mixed reputation among its customers. While some reviewers praise the restaurant's convenient location and good food, others complain about poor service, long wait times, and subpar drinks. One reviewer specifically mentions that their experience was marred by a rude and unfriendly bartender, while another notes that their cosmopolitan was watered down and tasteless. Additionally, several reviewers express frustration with the lack of attention and service they received during their visits. Despite these issues, some reviewers mention that the restaurant's ambiance is casual and enjoyable. Overall, Killer B's BBQ Bar and Grill appears to have room for improvement in terms of customer service and overall experience.", "response_spans": [[0, 122], [124, 633], [620, 883]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5431722402572632, "(0, 16)": 0.5431722402572632, "(2, 0)": 0.5431722402572632, "(2, 16)": 0.5431722402572632, "(4, 0)": 0.5431722402572632, "(4, 16)": 0.5431722402572632, "(6, 0)": 0.5431722402572632, "(6, 16)": 0.7149853706359863, "(8, 0)": 0.5431722402572632, "(8, 16)": 0.5431722402572632, "(10, 0)": 0.6214897632598877, "(10, 16)": 0.5431722402572632, "(12, 0)": 0.5274959802627563, "(12, 16)": 0.6107746958732605, "(14, 0)": 0.5431722402572632, "(14, 16)": 0.6107746958732605, "(16, 0)": 0.6107746958732605, "(16, 16)": 0.5274959802627563, "(18, 0)": 0.5431722402572632, "(18, 16)": 0.6107746958732605, "(20, 0)": 0.6107746958732605, "(20, 16)": 0.5431722402572632, "(22, 0)": 0.6214897632598877, "(22, 16)": 0.7149853706359863, "(24, 0)": 0.6214897632598877, "(24, 16)": 0.6107746958732605, "(26, 0)": 0.6107746958732605, "(26, 16)": 0.6107746958732605, "(28, 0)": 0.5274959802627563, "(28, 16)": 0.6214897632598877, "(30, 0)": 0.6107746958732605, "(30, 16)": 0.6107746958732605}, "r_span": [1433, 1466], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010528564453125}}, {"prompt_attention_score": {"(0, 0)": 0.7232966423034668, "(0, 16)": 0.7232966423034668, "(2, 0)": 0.7232966423034668, "(2, 16)": 0.7232966423034668, "(4, 0)": 0.7232966423034668, "(4, 16)": 0.7232966423034668, "(6, 0)": 0.7232966423034668, "(6, 16)": 0.671074628829956, "(8, 0)": 0.7232966423034668, "(8, 16)": 0.7232966423034668, "(10, 0)": 0.7445077896118164, "(10, 16)": 0.7232966423034668, "(12, 0)": 0.7232966423034668, "(12, 16)": 0.7383438348770142, "(14, 0)": 0.7232966423034668, "(14, 16)": 0.4696299433708191, "(16, 0)": 0.7232966423034668, "(16, 16)": 0.7232966423034668, "(18, 0)": 0.7232966423034668, "(18, 16)": 0.7383438348770142, "(20, 0)": 0.7383438348770142, "(20, 16)": 0.7445077896118164, "(22, 0)": 0.7445077896118164, "(22, 16)": 0.7383438348770142, "(24, 0)": 0.7445077896118164, "(24, 16)": 0.7383438348770142, "(26, 0)": 0.485008180141449, "(26, 16)": 0.7445077896118164, "(28, 0)": 0.485008180141449, "(28, 16)": 0.7445077896118164, "(30, 0)": 0.485008180141449, "(30, 16)": 0.485008180141449}, "r_span": [1468, 1577], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0022240877151489258}}, {"prompt_attention_score": {"(0, 0)": 0.6918671131134033, "(0, 16)": 0.6918671131134033, "(2, 0)": 0.6918671131134033, "(2, 16)": 0.6918671131134033, "(4, 0)": 0.6918671131134033, "(4, 16)": 0.6918671131134033, "(6, 0)": 0.6918671131134033, "(6, 16)": 0.6679819822311401, "(8, 0)": 0.6918671131134033, "(8, 16)": 0.6918671131134033, "(10, 0)": 0.6918671131134033, "(10, 16)": 0.6918671131134033, "(12, 0)": 0.6918671131134033, "(12, 16)": 0.653434157371521, "(14, 0)": 0.6918671131134033, "(14, 16)": 0.5196661949157715, "(16, 0)": 0.485727995634079, "(16, 16)": 0.6918671131134033, "(18, 0)": 0.7094879150390625, "(18, 16)": 0.6679819822311401, "(20, 0)": 0.653434157371521, "(20, 16)": 0.6918671131134033, "(22, 0)": 0.485727995634079, "(22, 16)": 0.6679819822311401, "(24, 0)": 0.7094879150390625, "(24, 16)": 0.6679819822311401, "(26, 0)": 0.485727995634079, "(26, 16)": 0.7094879150390625, "(28, 0)": 0.485727995634079, "(28, 16)": 0.6918671131134033, "(30, 0)": 0.485727995634079, "(30, 16)": 0.485727995634079}, "r_span": [1576, 1633], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -7.736682891845703e-05}}]}, {"id": "7035", "source_id": "14040", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 378, "end": 453, "text": "While some reviewers have expressed disappointment with the quality of food", "meta": "HIGH INTRO OF NEW INFO\nAIGC: While some reviewers have expressed disappointment with the quality of food\nOriginal: This information is not mentioned in the reviews.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Denny's:\n\nDenny's is a popular restaurant located in Goleta, California, serving American traditional cuisine. The establishment has been praised for its exceptional service, with reviewers mentioning friendly and attentive staff. The restaurant offers free WiFi and caters to both individuals and groups. While some reviewers have expressed disappointment with the quality of food, most have appreciated the comfortable seating and affordable prices. Unfortunately, the restaurant is set to close due to increased rent costs, which is a significant loss to the community. Despite this closure, Denny's has maintained a positive reputation among locals and visitors alike.", "response_spans": [[0, 80], [82, 591], [574, 744]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5452637076377869, "(0, 16)": 0.5452637076377869, "(2, 0)": 0.5452637076377869, "(2, 16)": 0.5452637076377869, "(4, 0)": 0.5452637076377869, "(4, 16)": 0.5452637076377869, "(6, 0)": 0.5452637076377869, "(6, 16)": 0.6679301261901855, "(8, 0)": 0.5452637076377869, "(8, 16)": 0.5452637076377869, "(10, 0)": 0.6679301261901855, "(10, 16)": 0.6679301261901855, "(12, 0)": 0.5652812719345093, "(12, 16)": 0.6679301261901855, "(14, 0)": 0.5452637076377869, "(14, 16)": 0.6679301261901855, "(16, 0)": 0.6679301261901855, "(16, 16)": 0.6679301261901855, "(18, 0)": 0.5452637076377869, "(18, 16)": 0.6679301261901855, "(20, 0)": 0.6679301261901855, "(20, 16)": 0.5452637076377869, "(22, 0)": 0.6679301261901855, "(22, 16)": 0.6679301261901855, "(24, 0)": 0.5865302085876465, "(24, 16)": 0.6679301261901855, "(26, 0)": 0.6679301261901855, "(26, 16)": 0.5865302085876465, "(28, 0)": 0.6679301261901855, "(28, 16)": 0.5452637076377869, "(30, 0)": 0.6679301261901855, "(30, 16)": 0.6679301261901855}, "r_span": [759, 780], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00026035308837890625}}, {"prompt_attention_score": {"(0, 0)": 0.7156606912612915, "(0, 16)": 0.7156606912612915, "(2, 0)": 0.7156606912612915, "(2, 16)": 0.7156606912612915, "(4, 0)": 0.7156606912612915, "(4, 16)": 0.7156606912612915, "(6, 0)": 0.7156606912612915, "(6, 16)": 0.7321418523788452, "(8, 0)": 0.7156606912612915, "(8, 16)": 0.7156606912612915, "(10, 0)": 0.7156606912612915, "(10, 16)": 0.7156606912612915, "(12, 0)": 0.7156606912612915, "(12, 16)": 0.7321418523788452, "(14, 0)": 0.7156606912612915, "(14, 16)": 0.7156606912612915, "(16, 0)": 0.6046161651611328, "(16, 16)": 0.7156606912612915, "(18, 0)": 0.4552251994609833, "(18, 16)": 0.7321418523788452, "(20, 0)": 0.7321418523788452, "(20, 16)": 0.7156606912612915, "(22, 0)": 0.4552251994609833, "(22, 16)": 0.668665885925293, "(24, 0)": 0.6046161651611328, "(24, 16)": 0.7321418523788452, "(26, 0)": 0.4552251994609833, "(26, 16)": 0.6046161651611328, "(28, 0)": 0.4552251994609833, "(28, 16)": 0.7156606912612915, "(30, 0)": 0.4552251994609833, "(30, 16)": 0.4552251994609833}, "r_span": [782, 882], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -6.556510925292969e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7002385854721069, "(0, 16)": 0.7002385854721069, "(2, 0)": 0.7002385854721069, "(2, 16)": 0.7002385854721069, "(4, 0)": 0.7002385854721069, "(4, 16)": 0.7002385854721069, "(6, 0)": 0.7002385854721069, "(6, 16)": 0.7219834327697754, "(8, 0)": 0.7002385854721069, "(8, 16)": 0.7002385854721069, "(10, 0)": 0.7002385854721069, "(10, 16)": 0.7002385854721069, "(12, 0)": 0.7002385854721069, "(12, 16)": 0.7219834327697754, "(14, 0)": 0.7002385854721069, "(14, 16)": 0.7002385854721069, "(16, 0)": 0.7002385854721069, "(16, 16)": 0.7002385854721069, "(18, 0)": 0.41320914030075073, "(18, 16)": 0.7219834327697754, "(20, 0)": 0.7219834327697754, "(20, 16)": 0.7002385854721069, "(22, 0)": 0.41320914030075073, "(22, 16)": 0.7002385854721069, "(24, 0)": 0.5499011278152466, "(24, 16)": 0.7002385854721069, "(26, 0)": 0.41320914030075073, "(26, 16)": 0.7002385854721069, "(28, 0)": 0.41320914030075073, "(28, 16)": 0.41320914030075073, "(30, 0)": 0.41320914030075073, "(30, 16)": 0.41320914030075073}, "r_span": [880, 914], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013809800148010254}}]}, {"id": "7053", "source_id": "14043", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 447, "end": 546, "text": "useful for customers, such as Business Parking (with a validated parking lot) and WiFi availability", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"validated\": false, \"WiFi\": \"no\"\nGenerative: \"useful for customers, such as Business Parking (with a validated parking lot) and WiFi availability\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 557, "end": 607, "text": "they do not offer valet parking or outdoor seating", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"OutdoorSeating\": null\nGenerative: \"they do not offer... outdoor seating\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 644, "end": 661, "text": "catering services", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the restaurant offers catering services, which is not mentioned in the origina sources", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Pattaya Thai Restaurant:\n\nPattaya Thai Restaurant is a Thai restaurant located in Goleta, California, with a rating of 3.5 out of five stars. The restaurant offers a variety of categories, including Restaurants and Thai cuisine. According to their hours of operation, they are open Tuesday through Sunday from 17:00 to 21:00.\n\nThe restaurant has a few attributes that may be useful for customers, such as Business Parking (with a validated parking lot) and WiFi availability. However, they do not offer valet parking or outdoor seating. They also allow takeout orders and catering services.\n\nReviews from customers suggest that the service at the restaurant is subpar, with one reviewer mentioning that they had to wait a long time for a server. Another reviewer experienced food poisoning after eating at the restaurant. While some reviews praise the quality of the food, particularly the Pad Thai dish, others find the flavors to be lacking.\n\nIn conclusion, while Pattaya Thai Restaurant has some positive aspects, such as convenient parking and takeout options, negative reviews suggest that the service and food quality could be improved.", "response_spans": [[0, 397], [399, 662], [664, 1015], [1017, 1214]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6372121572494507, "(0, 16)": 0.6372121572494507, "(2, 0)": 0.6526855230331421, "(2, 16)": 0.6526855230331421, "(4, 0)": 0.6526855230331421, "(4, 16)": 0.6372121572494507, "(6, 0)": 0.6372121572494507, "(6, 16)": 0.8252306580543518, "(8, 0)": 0.5861414670944214, "(8, 16)": 0.6526855230331421, "(10, 0)": 0.6372121572494507, "(10, 16)": 0.6372121572494507, "(12, 0)": 0.6372121572494507, "(12, 16)": 0.8252306580543518, "(14, 0)": 0.5861414670944214, "(14, 16)": 0.8252306580543518, "(16, 0)": 0.49290329217910767, "(16, 16)": 0.49290329217910767, "(18, 0)": 0.5861414670944214, "(18, 16)": 0.8252306580543518, "(20, 0)": 0.8252306580543518, "(20, 16)": 0.5861414670944214, "(22, 0)": 0.49290329217910767, "(22, 16)": 0.8252306580543518, "(24, 0)": 0.5861414670944214, "(24, 16)": 0.8252306580543518, "(26, 0)": 0.49290329217910767, "(26, 16)": 0.8252306580543518, "(28, 0)": 0.49290329217910767, "(28, 16)": 0.49290329217910767, "(30, 0)": 0.49290329217910767, "(30, 16)": 0.49290329217910767}, "r_span": [801, 911], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013752579689025879}}, {"prompt_attention_score": {"(0, 0)": 0.5210902094841003, "(0, 16)": 0.5210902094841003, "(2, 0)": 0.5650179386138916, "(2, 16)": 0.5650179386138916, "(4, 0)": 0.5650179386138916, "(4, 16)": 0.5650179386138916, "(6, 0)": 0.5210902094841003, "(6, 16)": 0.640465497970581, "(8, 0)": 0.5210902094841003, "(8, 16)": 0.5650179386138916, "(10, 0)": 0.5210902094841003, "(10, 16)": 0.6507226228713989, "(12, 0)": 0.5322624444961548, "(12, 16)": 0.640465497970581, "(14, 0)": 0.6507226228713989, "(14, 16)": 0.640465497970581, "(16, 0)": 0.640465497970581, "(16, 16)": 0.5650179386138916, "(18, 0)": 0.5322624444961548, "(18, 16)": 0.640465497970581, "(20, 0)": 0.640465497970581, "(20, 16)": 0.6507226228713989, "(22, 0)": 0.5322624444961548, "(22, 16)": 0.640465497970581, "(24, 0)": 0.5322624444961548, "(24, 16)": 0.640465497970581, "(26, 0)": 0.5322624444961548, "(26, 16)": 0.6507226228713989, "(28, 0)": 0.5322624444961548, "(28, 16)": 0.5322624444961548, "(30, 0)": 0.5322624444961548, "(30, 16)": 0.5322624444961548}, "r_span": [913, 974], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00031107664108276367}}, {"prompt_attention_score": {"(0, 0)": 0.8151505589485168, "(0, 16)": 0.8151505589485168, "(2, 0)": 0.801222562789917, "(2, 16)": 0.8151505589485168, "(4, 0)": 0.801222562789917, "(4, 16)": 0.801222562789917, "(6, 0)": 0.8151505589485168, "(6, 16)": 0.8151505589485168, "(8, 0)": 0.8151505589485168, "(8, 16)": 0.8151505589485168, "(10, 0)": 0.8151505589485168, "(10, 16)": 0.801222562789917, "(12, 0)": 0.8151505589485168, "(12, 16)": 0.8151505589485168, "(14, 0)": 0.7079601883888245, "(14, 16)": 0.7079601883888245, "(16, 0)": 0.7079601883888245, "(16, 16)": 0.5043458938598633, "(18, 0)": 0.7079601883888245, "(18, 16)": 0.8151505589485168, "(20, 0)": 0.8151505589485168, "(20, 16)": 0.7079601883888245, "(22, 0)": 0.5043458938598633, "(22, 16)": 0.8151505589485168, "(24, 0)": 0.7079601883888245, "(24, 16)": 0.8151505589485168, "(26, 0)": 0.5043458938598633, "(26, 16)": 0.7079601883888245, "(28, 0)": 0.5043458938598633, "(28, 16)": 0.5043458938598633, "(30, 0)": 0.5043458938598633, "(30, 16)": 0.5043458938598633}, "r_span": [976, 1052], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00015151500701904297}}, {"prompt_attention_score": {"(0, 0)": 0.6431865692138672, "(0, 16)": 0.6431865692138672, "(2, 0)": 0.7103267908096313, "(2, 16)": 0.7103267908096313, "(4, 0)": 0.7103267908096313, "(4, 16)": 0.7103267908096313, "(6, 0)": 0.6431865692138672, "(6, 16)": 0.6277252435684204, "(8, 0)": 0.7103267908096313, "(8, 16)": 0.7103267908096313, "(10, 0)": 0.7103267908096313, "(10, 16)": 0.7103267908096313, "(12, 0)": 0.7103267908096313, "(12, 16)": 0.6431865692138672, "(14, 0)": 0.6668177843093872, "(14, 16)": 0.474553644657135, "(16, 0)": 0.45846104621887207, "(16, 16)": 0.45846104621887207, "(18, 0)": 0.6668177843093872, "(18, 16)": 0.6668177843093872, "(20, 0)": 0.6668177843093872, "(20, 16)": 0.6668177843093872, "(22, 0)": 0.45846104621887207, "(22, 16)": 0.6431865692138672, "(24, 0)": 0.45846104621887207, "(24, 16)": 0.6668177843093872, "(26, 0)": 0.45846104621887207, "(26, 16)": 0.6668177843093872, "(28, 0)": 0.45846104621887207, "(28, 16)": 0.45846104621887207, "(30, 0)": 0.45846104621887207, "(30, 16)": 0.45846104621887207}, "r_span": [1054, 1094], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00036770105361938477}}]}, {"id": "7065", "source_id": "14045", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 283, "end": 321, "text": "Monday to Friday (10:00 AM - 10:00 PM)", "meta": "EVIDENT CONFLICT\nOriginal: Monday to Thursday: 10am to 9:30pm, Friday: 10am to 10pm\nGenerated: Monday to Friday (10:00 AM - 10:00 PM)", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 326, "end": 367, "text": "Saturday and Sunday (10:00 AM - 10:00 PM)", "meta": "EVIDENT CONFLICT\nOriginal: Sunday: 10:30am to 9:30pm, Saturday: 10am to 10pm\nGenerated: Saturday and Sunday (10:00 AM - 10:00 PM)", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 421, "end": 436, "text": "outdoor seating", "meta": "EVIDENT CONFLICT\nOriginal: \"OutdoorSeating\": true,\nGenerated: does not offer...outdoor seating", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 441, "end": 464, "text": "does provide free Wi-Fi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerated: does provide free Wi-Fi", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 495, "end": 574, "text": "Some customers have praised the business for its good ambiance and quality food", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nNo mention of a review praising the restaurant's ambiance found in the structured data.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Panda Express:\n\nPanda Express is a popular Chinese restaurant located in Goleta, California, with a rating of 2.5 stars. The business has a convenient location on North Fairview Avenue, with extended hours from Monday to Friday (10:00 AM - 10:00 PM) and Saturday and Sunday (10:00 AM - 10:00 PM). While the restaurant does not offer reservations or outdoor seating, it does provide free Wi-Fi and takes orders for takeout. Some customers have praised the business for its good ambiance and quality food, while others have complained about poor service, including long wait times and a lack of allergy accommodation. One customer even reported finding empty cream cheese rangoons in their order, despite paying extra for them. Overall, Panda Express appears to have mixed reviews, with some customers satisfied with their experience and others disappointed with various aspects of the business.", "response_spans": [[0, 86], [88, 593], [576, 965]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.37775832414627075, "(0, 16)": 0.37775832414627075, "(2, 0)": 0.37775832414627075, "(2, 16)": 0.37775832414627075, "(4, 0)": 0.37775832414627075, "(4, 16)": 0.37775832414627075, "(6, 0)": 0.37775832414627075, "(6, 16)": 0.6601657867431641, "(8, 0)": 0.37775832414627075, "(8, 16)": 0.37775832414627075, "(10, 0)": 0.6601657867431641, "(10, 16)": 0.6601657867431641, "(12, 0)": 0.5593346953392029, "(12, 16)": 0.6601657867431641, "(14, 0)": 0.6601657867431641, "(14, 16)": 0.6601657867431641, "(16, 0)": 0.6601657867431641, "(16, 16)": 0.37775832414627075, "(18, 0)": 0.37775832414627075, "(18, 16)": 0.6601657867431641, "(20, 0)": 0.6601657867431641, "(20, 16)": 0.3978516459465027, "(22, 0)": 0.3978516459465027, "(22, 16)": 0.6601657867431641, "(24, 0)": 0.3978516459465027, "(24, 16)": 0.6601657867431641, "(26, 0)": 0.6601657867431641, "(26, 16)": 0.5931650400161743, "(28, 0)": 0.6601657867431641, "(28, 16)": 0.3978516459465027, "(30, 0)": 0.6601657867431641, "(30, 16)": 0.6601657867431641}, "r_span": [843, 863], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003298521041870117}}, {"prompt_attention_score": {"(0, 0)": 0.5246402025222778, "(0, 16)": 0.5246402025222778, "(2, 0)": 0.5246402025222778, "(2, 16)": 0.5246402025222778, "(4, 0)": 0.5246402025222778, "(4, 16)": 0.5246402025222778, "(6, 0)": 0.5246402025222778, "(6, 16)": 0.7849799394607544, "(8, 0)": 0.6142008900642395, "(8, 16)": 0.5246402025222778, "(10, 0)": 0.6142008900642395, "(10, 16)": 0.5246402025222778, "(12, 0)": 0.5246402025222778, "(12, 16)": 0.7849799394607544, "(14, 0)": 0.6142008900642395, "(14, 16)": 0.7849799394607544, "(16, 0)": 0.701565146446228, "(16, 16)": 0.5246402025222778, "(18, 0)": 0.701565146446228, "(18, 16)": 0.7849799394607544, "(20, 0)": 0.7849799394607544, "(20, 16)": 0.6142008900642395, "(22, 0)": 0.42932242155075073, "(22, 16)": 0.7849799394607544, "(24, 0)": 0.6142008900642395, "(24, 16)": 0.7849799394607544, "(26, 0)": 0.42932242155075073, "(26, 16)": 0.701565146446228, "(28, 0)": 0.42932242155075073, "(28, 16)": 0.6142008900642395, "(30, 0)": 0.42932242155075073, "(30, 16)": 0.42932242155075073}, "r_span": [865, 994], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.001675248146057129}}, {"prompt_attention_score": {"(0, 0)": 0.7824920415878296, "(0, 16)": 0.7824920415878296, "(2, 0)": 0.7824920415878296, "(2, 16)": 0.7824920415878296, "(4, 0)": 0.7824920415878296, "(4, 16)": 0.7824920415878296, "(6, 0)": 0.7824920415878296, "(6, 16)": 0.7824920415878296, "(8, 0)": 0.631554365158081, "(8, 16)": 0.7824920415878296, "(10, 0)": 0.7824920415878296, "(10, 16)": 0.7824920415878296, "(12, 0)": 0.7824920415878296, "(12, 16)": 0.7824920415878296, "(14, 0)": 0.631554365158081, "(14, 16)": 0.7824920415878296, "(16, 0)": 0.7824920415878296, "(16, 16)": 0.7824920415878296, "(18, 0)": 0.4799187183380127, "(18, 16)": 0.7824920415878296, "(20, 0)": 0.7824920415878296, "(20, 16)": 0.631554365158081, "(22, 0)": 0.4799187183380127, "(22, 16)": 0.7824920415878296, "(24, 0)": 0.631554365158081, "(24, 16)": 0.7824920415878296, "(26, 0)": 0.4799187183380127, "(26, 16)": 0.7824920415878296, "(28, 0)": 0.4799187183380127, "(28, 16)": 0.4799187183380127, "(30, 0)": 0.631554365158081, "(30, 16)": 0.4799187183380127}, "r_span": [992, 1067], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00024002790451049805}}]}, {"id": "7089", "source_id": "14051", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 450, "end": 508, "text": "Some customers have praised the bar for its friendly staff", "meta": "Original: It was only one customer who have said positive reviews about the restaurant\nGenerative \"Some customers\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of O'Malleys Bar in Santa Barbara, California:\n\nO'Malleys Bar is a popular nightlife spot in Santa Barbara, known for its lively atmosphere and wide selection of drinks. Located in the heart of downtown Santa Barbara, the bar offers a range of categories including Nightlife, Bars, and Sports Bars. The bar has a rating of 2.5 stars and has received mixed reviews from customers.\n\nSome customers have praised the bar for its friendly staff, great margaritas, and abundance of TVs showing various sporting events. One reviewer noted that the bar feels like a \"neighborhood bar located at ground zero of tourist central,\" suggesting that it may not be the best option for those looking for a more upscale experience.\n\nHowever, other customers have had negative experiences at the bar. One reviewer reported being given a hard time by the bouncers upon entering the bar, while another described being overcharged for drinks. A third reviewer noted that the bar's atmosphere is not typically what they expect from a Santa Barbara establishment, preferring a more \"upscale\" vibe.\n\nOverall, O'Malleys Bar seems to be a hit or miss establishment, with some customers enjoying its laid-back atmosphere and wide selection of drinks, while others have experienced poor service or been disappointed by the bar's perceived lack of quality.", "response_spans": [[0, 448], [450, 783], [785, 1143], [1145, 1396]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.642849326133728, "(0, 16)": 0.642849326133728, "(2, 0)": 0.642849326133728, "(2, 16)": 0.642849326133728, "(4, 0)": 0.6749631762504578, "(4, 16)": 0.6749631762504578, "(6, 0)": 0.642849326133728, "(6, 16)": 0.7976844310760498, "(8, 0)": 0.6275888085365295, "(8, 16)": 0.642849326133728, "(10, 0)": 0.6425843834877014, "(10, 16)": 0.642849326133728, "(12, 0)": 0.642849326133728, "(12, 16)": 0.7976844310760498, "(14, 0)": 0.7640179395675659, "(14, 16)": 0.46160462498664856, "(16, 0)": 0.46160462498664856, "(16, 16)": 0.642849326133728, "(18, 0)": 0.7640179395675659, "(18, 16)": 0.7976844310760498, "(20, 0)": 0.7976844310760498, "(20, 16)": 0.7640179395675659, "(22, 0)": 0.7640179395675659, "(22, 16)": 0.7976844310760498, "(24, 0)": 0.7640179395675659, "(24, 16)": 0.7976844310760498, "(26, 0)": 0.46160462498664856, "(26, 16)": 0.7640179395675659, "(28, 0)": 0.46160462498664856, "(28, 16)": 0.7640179395675659, "(30, 0)": 0.7640179395675659, "(30, 16)": 0.46160462498664856}, "r_span": [1369, 1478], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001451730728149414}}, {"prompt_attention_score": {"(0, 0)": 0.6954600214958191, "(0, 16)": 0.6954600214958191, "(2, 0)": 0.6954600214958191, "(2, 16)": 0.6954600214958191, "(4, 0)": 0.6954600214958191, "(4, 16)": 0.6954600214958191, "(6, 0)": 0.6954600214958191, "(6, 16)": 0.7775380611419678, "(8, 0)": 0.767202615737915, "(8, 16)": 0.6954600214958191, "(10, 0)": 0.6954600214958191, "(10, 16)": 0.6954600214958191, "(12, 0)": 0.6954600214958191, "(12, 16)": 0.7775380611419678, "(14, 0)": 0.7775380611419678, "(14, 16)": 0.7775380611419678, "(16, 0)": 0.7775380611419678, "(16, 16)": 0.6954600214958191, "(18, 0)": 0.7775380611419678, "(18, 16)": 0.7775380611419678, "(20, 0)": 0.7775380611419678, "(20, 16)": 0.7775380611419678, "(22, 0)": 0.46042436361312866, "(22, 16)": 0.7775380611419678, "(24, 0)": 0.7775380611419678, "(24, 16)": 0.7775380611419678, "(26, 0)": 0.46042436361312866, "(26, 16)": 0.7775380611419678, "(28, 0)": 0.46042436361312866, "(28, 16)": 0.5916929841041565, "(30, 0)": 0.7775380611419678, "(30, 16)": 0.46042436361312866}, "r_span": [1480, 1554], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0007939338684082031}}, {"prompt_attention_score": {"(0, 0)": 0.7687064409255981, "(0, 16)": 0.7687064409255981, "(2, 0)": 0.7411721348762512, "(2, 16)": 0.7411721348762512, "(4, 0)": 0.7687064409255981, "(4, 16)": 0.7687064409255981, "(6, 0)": 0.7687064409255981, "(6, 16)": 0.7328449487686157, "(8, 0)": 0.7411721348762512, "(8, 16)": 0.7411721348762512, "(10, 0)": 0.7322227954864502, "(10, 16)": 0.7687064409255981, "(12, 0)": 0.7322227954864502, "(12, 16)": 0.7328449487686157, "(14, 0)": 0.7138084173202515, "(14, 16)": 0.7687064409255981, "(16, 0)": 0.7322227954864502, "(16, 16)": 0.506628155708313, "(18, 0)": 0.7138084173202515, "(18, 16)": 0.7687064409255981, "(20, 0)": 0.7328449487686157, "(20, 16)": 0.7138084173202515, "(22, 0)": 0.7138084173202515, "(22, 16)": 0.7138084173202515, "(24, 0)": 0.7138084173202515, "(24, 16)": 0.7138084173202515, "(26, 0)": 0.506628155708313, "(26, 16)": 0.7138084173202515, "(28, 0)": 0.506628155708313, "(28, 16)": 0.506628155708313, "(30, 0)": 0.506628155708313, "(30, 16)": 0.506628155708313}, "r_span": [1556, 1633], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001979529857635498}}, {"prompt_attention_score": {"(0, 0)": 0.5954118967056274, "(0, 16)": 0.7081270217895508, "(2, 0)": 0.7081270217895508, "(2, 16)": 0.7081270217895508, "(4, 0)": 0.7081270217895508, "(4, 16)": 0.7081270217895508, "(6, 0)": 0.7089913487434387, "(6, 16)": 0.7089913487434387, "(8, 0)": 0.7081270217895508, "(8, 16)": 0.7081270217895508, "(10, 0)": 0.7081270217895508, "(10, 16)": 0.7081270217895508, "(12, 0)": 0.7081270217895508, "(12, 16)": 0.5954118967056274, "(14, 0)": 0.7089913487434387, "(14, 16)": 0.4748896360397339, "(16, 0)": 0.4501485824584961, "(16, 16)": 0.4501485824584961, "(18, 0)": 0.7081270217895508, "(18, 16)": 0.7081270217895508, "(20, 0)": 0.7081270217895508, "(20, 16)": 0.7089913487434387, "(22, 0)": 0.4501485824584961, "(22, 16)": 0.7081270217895508, "(24, 0)": 0.7089913487434387, "(24, 16)": 0.7089913487434387, "(26, 0)": 0.4501485824584961, "(26, 16)": 0.7089913487434387, "(28, 0)": 0.4501485824584961, "(28, 16)": 0.7089913487434387, "(30, 0)": 0.4501485824584961, "(30, 16)": 0.4501485824584961}, "r_span": [1635, 1691], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008049607276916504}}]}, {"id": "7095", "source_id": "14052", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 171, "end": 209, "text": "including vegetarian and vegan options", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"including vegetarian and vegan options\" was not mentioned in the business info", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 617, "end": 638, "text": "ample parking options", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"ample parking options\" was not mentioned in the business info", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "South Coast Deli-Goleta is a popular sandwich shop located in Goleta, California, with a rating of 4.5 stars. The deli offers a variety of sandwiches, salads, and drinks, including vegetarian and vegan options. The reviews suggest that the quality of the food is consistently high, with many customers praising the freshness and taste of the ingredients. However, some reviewers have noted issues with service, including slow service and incorrect orders. Despite these complaints, the majority of customers appear to be satisfied with their experiences at South Coast Deli-Goleta. The deli's convenient location and ample parking options are also appreciated by patrons.", "response_spans": [[0, 507], [495, 671]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5892125964164734, "(0, 16)": 0.5892125964164734, "(2, 0)": 0.5892125964164734, "(2, 16)": 0.5892125964164734, "(4, 0)": 0.5892125964164734, "(4, 16)": 0.5892125964164734, "(6, 0)": 0.5892125964164734, "(6, 16)": 0.7857851982116699, "(8, 0)": 0.5892125964164734, "(8, 16)": 0.5892125964164734, "(10, 0)": 0.5892125964164734, "(10, 16)": 0.5892125964164734, "(12, 0)": 0.5892125964164734, "(12, 16)": 0.6487693786621094, "(14, 0)": 0.5892125964164734, "(14, 16)": 0.5892125964164734, "(16, 0)": 0.5892125964164734, "(16, 16)": 0.5892125964164734, "(18, 0)": 0.5892125964164734, "(18, 16)": 0.7857851982116699, "(20, 0)": 0.6487693786621094, "(20, 16)": 0.6487693786621094, "(22, 0)": 0.43795397877693176, "(22, 16)": 0.7857851982116699, "(24, 0)": 0.6487693786621094, "(24, 16)": 0.6487693786621094, "(26, 0)": 0.43795397877693176, "(26, 16)": 0.6487693786621094, "(28, 0)": 0.43795397877693176, "(28, 16)": 0.5892125964164734, "(30, 0)": 0.43795397877693176, "(30, 16)": 0.43795397877693176}, "r_span": [975, 1090], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0010857582092285156}}, {"prompt_attention_score": {"(0, 0)": 0.540988564491272, "(0, 16)": 0.540988564491272, "(2, 0)": 0.540988564491272, "(2, 16)": 0.540988564491272, "(4, 0)": 0.540988564491272, "(4, 16)": 0.540988564491272, "(6, 0)": 0.540988564491272, "(6, 16)": 0.7285128831863403, "(8, 0)": 0.540988564491272, "(8, 16)": 0.540988564491272, "(10, 0)": 0.540988564491272, "(10, 16)": 0.540988564491272, "(12, 0)": 0.540988564491272, "(12, 16)": 0.6684006452560425, "(14, 0)": 0.540988564491272, "(14, 16)": 0.540988564491272, "(16, 0)": 0.540988564491272, "(16, 16)": 0.540988564491272, "(18, 0)": 0.6383435130119324, "(18, 16)": 0.7285128831863403, "(20, 0)": 0.7285128831863403, "(20, 16)": 0.540988564491272, "(22, 0)": 0.4608481228351593, "(22, 16)": 0.7285128831863403, "(24, 0)": 0.6684006452560425, "(24, 16)": 0.6684006452560425, "(26, 0)": 0.4608481228351593, "(26, 16)": 0.540988564491272, "(28, 0)": 0.4608481228351593, "(28, 16)": 0.4608481228351593, "(30, 0)": 0.4608481228351593, "(30, 16)": 0.4608481228351593}, "r_span": [1089, 1126], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002070009708404541}}]}, {"id": "7101", "source_id": "14053", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "La Casa De Maria is a health retreat, venue, and hotel located in Santa Barbara, California. The establishment offers a serene environment for self-discovery, contemplation, and relaxation. Guests appreciate the accommodations, even though they are described as \"a little rustic,\" and the beautiful grounds and gardens. The restaurant serves good food, and some guests have praised the quality of the massages offered by Vesalina. However, recent reviews have raised concerns about bedbug infestations in certain rooms, particularly Room 12. While the staff has been friendly and helpful, the management has not addressed these issues satisfactorily, according to some guests. Despite these criticisms, La Casa De Maria remains a popular choice for those seeking a peaceful escape in a beautiful setting.", "response_spans": [[0, 512], [502, 804]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6821598410606384, "(0, 16)": 0.6821598410606384, "(2, 0)": 0.6821598410606384, "(2, 16)": 0.6821598410606384, "(4, 0)": 0.6821598410606384, "(4, 16)": 0.6821598410606384, "(6, 0)": 0.6821598410606384, "(6, 16)": 0.560897946357727, "(8, 0)": 0.6821598410606384, "(8, 16)": 0.6821598410606384, "(10, 0)": 0.560897946357727, "(10, 16)": 0.5471658706665039, "(12, 0)": 0.6821598410606384, "(12, 16)": 0.6311249136924744, "(14, 0)": 0.6821598410606384, "(14, 16)": 0.4352171719074249, "(16, 0)": 0.6311249136924744, "(16, 16)": 0.6821598410606384, "(18, 0)": 0.6821598410606384, "(18, 16)": 0.6311249136924744, "(20, 0)": 0.560897946357727, "(20, 16)": 0.6821598410606384, "(22, 0)": 0.6821598410606384, "(22, 16)": 0.560897946357727, "(24, 0)": 0.6821598410606384, "(24, 16)": 0.707278311252594, "(26, 0)": 0.36696597933769226, "(26, 16)": 0.6821598410606384, "(28, 0)": 0.36696597933769226, "(28, 16)": 0.6821598410606384, "(30, 0)": 0.36696597933769226, "(30, 16)": 0.36696597933769226}, "r_span": [1242, 1353], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009182095527648926}}, {"prompt_attention_score": {"(0, 0)": 0.7262728810310364, "(0, 16)": 0.7262728810310364, "(2, 0)": 0.7262728810310364, "(2, 16)": 0.7262728810310364, "(4, 0)": 0.7262728810310364, "(4, 16)": 0.7262728810310364, "(6, 0)": 0.7262728810310364, "(6, 16)": 0.6246873140335083, "(8, 0)": 0.7262728810310364, "(8, 16)": 0.7262728810310364, "(10, 0)": 0.7262728810310364, "(10, 16)": 0.7262728810310364, "(12, 0)": 0.7262728810310364, "(12, 16)": 0.7262728810310364, "(14, 0)": 0.7262728810310364, "(14, 16)": 0.4549405574798584, "(16, 0)": 0.7262728810310364, "(16, 16)": 0.7262728810310364, "(18, 0)": 0.7262728810310364, "(18, 16)": 0.7068910598754883, "(20, 0)": 0.7262728810310364, "(20, 16)": 0.7262728810310364, "(22, 0)": 0.7262728810310364, "(22, 16)": 0.6246873140335083, "(24, 0)": 0.7262728810310364, "(24, 16)": 0.6246873140335083, "(26, 0)": 0.3910940885543823, "(26, 16)": 0.7262728810310364, "(28, 0)": 0.3910940885543823, "(28, 16)": 0.7262728810310364, "(30, 0)": 0.3910940885543823, "(30, 16)": 0.3910940885543823}, "r_span": [1352, 1411], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 5.3048133850097656e-05}}]}, {"id": "7137", "source_id": "14059", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 641, "end": 687, "text": "loyal following among both locals and tourists", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"loyal following among both locals and tourists\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Savoy Cafe & Deli:\n\nSavoy Cafe & Deli is a popular restaurant located in downtown Santa Barbara, California. With a rating of 4.5 stars, the cafe offers a variety of dining options, including breakfast, lunch, and dinner. Customers praise the restaurant's gluten-free bread options and high-quality ingredients, as well as its cozy atmosphere and friendly service. The cafe is known for its salad bar, which is considered one of the best in the city, and its extensive menu of sandwiches and entrees. Despite being a small establishment, Savoy Cafe & Deli has gained a loyal following among both locals and tourists, with many customers returning multiple times for its delicious food and pleasant ambiance.", "response_spans": [[0, 90], [92, 594], [581, 779]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.49211153388023376, "(0, 16)": 0.49211153388023376, "(2, 0)": 0.5737358927726746, "(2, 16)": 0.49211153388023376, "(4, 0)": 0.5737358927726746, "(4, 16)": 0.49211153388023376, "(6, 0)": 0.49211153388023376, "(6, 16)": 0.6648358106613159, "(8, 0)": 0.49211153388023376, "(8, 16)": 0.49211153388023376, "(10, 0)": 0.6648358106613159, "(10, 16)": 0.6648358106613159, "(12, 0)": 0.49211153388023376, "(12, 16)": 0.6648358106613159, "(14, 0)": 0.49211153388023376, "(14, 16)": 0.6648358106613159, "(16, 0)": 0.6648358106613159, "(16, 16)": 0.6648358106613159, "(18, 0)": 0.49211153388023376, "(18, 16)": 0.6648358106613159, "(20, 0)": 0.6648358106613159, "(20, 16)": 0.49211153388023376, "(22, 0)": 0.6648358106613159, "(22, 16)": 0.6648358106613159, "(24, 0)": 0.49211153388023376, "(24, 16)": 0.6653891801834106, "(26, 0)": 0.6648358106613159, "(26, 16)": 0.6648358106613159, "(28, 0)": 0.6648358106613159, "(28, 16)": 0.49211153388023376, "(30, 0)": 0.6648358106613159, "(30, 16)": 0.6648358106613159}, "r_span": [790, 814], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00045222043991088867}}, {"prompt_attention_score": {"(0, 0)": 0.6784601807594299, "(0, 16)": 0.6784601807594299, "(2, 0)": 0.6784601807594299, "(2, 16)": 0.6784601807594299, "(4, 0)": 0.6784601807594299, "(4, 16)": 0.6784601807594299, "(6, 0)": 0.6784601807594299, "(6, 16)": 0.7781868577003479, "(8, 0)": 0.7569436430931091, "(8, 16)": 0.6784601807594299, "(10, 0)": 0.6784601807594299, "(10, 16)": 0.6784601807594299, "(12, 0)": 0.6784601807594299, "(12, 16)": 0.7569436430931091, "(14, 0)": 0.6784601807594299, "(14, 16)": 0.6784601807594299, "(16, 0)": 0.7569436430931091, "(16, 16)": 0.6784601807594299, "(18, 0)": 0.4234668016433716, "(18, 16)": 0.7781868577003479, "(20, 0)": 0.7569436430931091, "(20, 16)": 0.6784601807594299, "(22, 0)": 0.4234668016433716, "(22, 16)": 0.7569436430931091, "(24, 0)": 0.6784601807594299, "(24, 16)": 0.7569436430931091, "(26, 0)": 0.4234668016433716, "(26, 16)": 0.6784601807594299, "(28, 0)": 0.4234668016433716, "(28, 16)": 0.6784601807594299, "(30, 0)": 0.4234668016433716, "(30, 16)": 0.4234668016433716}, "r_span": [816, 939], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009188055992126465}}, {"prompt_attention_score": {"(0, 0)": 0.6288083791732788, "(0, 16)": 0.5425692796707153, "(2, 0)": 0.5425692796707153, "(2, 16)": 0.5425692796707153, "(4, 0)": 0.5425692796707153, "(4, 16)": 0.5425692796707153, "(6, 0)": 0.5425692796707153, "(6, 16)": 0.5876336097717285, "(8, 0)": 0.5425692796707153, "(8, 16)": 0.5425692796707153, "(10, 0)": 0.5425692796707153, "(10, 16)": 0.5425692796707153, "(12, 0)": 0.5425692796707153, "(12, 16)": 0.5425692796707153, "(14, 0)": 0.5425692796707153, "(14, 16)": 0.5425692796707153, "(16, 0)": 0.5425692796707153, "(16, 16)": 0.4085067808628082, "(18, 0)": 0.6288083791732788, "(18, 16)": 0.4854734241962433, "(20, 0)": 0.4854734241962433, "(20, 16)": 0.5425692796707153, "(22, 0)": 0.4085067808628082, "(22, 16)": 0.5425692796707153, "(24, 0)": 0.5425692796707153, "(24, 16)": 0.4854734241962433, "(26, 0)": 0.4085067808628082, "(26, 16)": 0.5425692796707153, "(28, 0)": 0.4085067808628082, "(28, 16)": 0.5425692796707153, "(30, 0)": 0.4085067808628082, "(30, 16)": 0.4085067808628082}, "r_span": [937, 977], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009987950325012207}}]}, {"id": "7143", "source_id": "14060", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 388, "end": 431, "text": "9:00 AM to 6:00 PM from Monday to Saturday,", "meta": "EVIDENT CONFLICT\nOriginal: \"Saturday\": \"8:0-18:0\"\nGenerated: 9:00 AM to 6:00 PM from Monday to Saturday,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 506, "end": 510, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerated: WiFi", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 699, "end": 768, "text": "Some reviewers have noted that the service is friendly and efficient.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"Some reviewers have noted that the service is friendly and efficient.\" was not mentioned in the business info", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 787, "end": 817, "text": "one negative review mentioning", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"one negative review mentioning\" was not mentioned in the business info", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Danny's Deli Bait & Tackle:\n\nDanny's Deli Bait & Tackle is a local business located in Carpinteria, California, offering a range of services and products including Restaurants, Hunting & Fishing Supplies, Delis, Sporting Goods, Automotive, Car Wash, and Shopping. The business has a 4.0-star rating and is open from 9:00 AM to 6:00 PM from Monday to Saturday, and 9:00 AM to 5:00 PM on Sunday. The business offers outdoor seating and WiFi, but does not validate parking. Reviews for the business are mostly positive, with many customers praising the quality of their sandwiches, particularly the pastrami, turkey, and tri tip. Some reviewers have noted that the service is friendly and efficient. However, there is one negative review mentioning that the business does not offer reservations for restaurants. Overall, Danny's Deli Bait & Tackle appears to be a popular and well-regarded local business in the area.", "response_spans": [[0, 99], [101, 608], [589, 986]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.48779547214508057, "(0, 16)": 0.48779547214508057, "(2, 0)": 0.48779547214508057, "(2, 16)": 0.48779547214508057, "(4, 0)": 0.48779547214508057, "(4, 16)": 0.48779547214508057, "(6, 0)": 0.48779547214508057, "(6, 16)": 0.6422215700149536, "(8, 0)": 0.48779547214508057, "(8, 16)": 0.48779547214508057, "(10, 0)": 0.6158632040023804, "(10, 16)": 0.6158632040023804, "(12, 0)": 0.48779547214508057, "(12, 16)": 0.6422215700149536, "(14, 0)": 0.48779547214508057, "(14, 16)": 0.6422215700149536, "(16, 0)": 0.6158632040023804, "(16, 16)": 0.48779547214508057, "(18, 0)": 0.48779547214508057, "(18, 16)": 0.6158632040023804, "(20, 0)": 0.6158632040023804, "(20, 16)": 0.48779547214508057, "(22, 0)": 0.48779547214508057, "(22, 16)": 0.6422215700149536, "(24, 0)": 0.48779547214508057, "(24, 16)": 0.6158632040023804, "(26, 0)": 0.6158632040023804, "(26, 16)": 0.48779547214508057, "(28, 0)": 0.6158632040023804, "(28, 16)": 0.48779547214508057, "(30, 0)": 0.6158632040023804, "(30, 16)": 0.6158632040023804}, "r_span": [742, 771], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009897947311401367}}, {"prompt_attention_score": {"(0, 0)": 0.6029043197631836, "(0, 16)": 0.6029043197631836, "(2, 0)": 0.6029043197631836, "(2, 16)": 0.6029043197631836, "(4, 0)": 0.6029043197631836, "(4, 16)": 0.6029043197631836, "(6, 0)": 0.6029043197631836, "(6, 16)": 0.8596689701080322, "(8, 0)": 0.6029043197631836, "(8, 16)": 0.6029043197631836, "(10, 0)": 0.6029043197631836, "(10, 16)": 0.6029043197631836, "(12, 0)": 0.6029043197631836, "(12, 16)": 0.8596689701080322, "(14, 0)": 0.6029043197631836, "(14, 16)": 0.8596689701080322, "(16, 0)": 0.8596689701080322, "(16, 16)": 0.6029043197631836, "(18, 0)": 0.6029043197631836, "(18, 16)": 0.8596689701080322, "(20, 0)": 0.8596689701080322, "(20, 16)": 0.6029043197631836, "(22, 0)": 0.6029043197631836, "(22, 16)": 0.8596689701080322, "(24, 0)": 0.6029043197631836, "(24, 16)": 0.8596689701080322, "(26, 0)": 0.46288761496543884, "(26, 16)": 0.6029043197631836, "(28, 0)": 0.46288761496543884, "(28, 16)": 0.6029043197631836, "(30, 0)": 0.46288761496543884, "(30, 16)": 0.46288761496543884}, "r_span": [773, 918], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005891919136047363}}, {"prompt_attention_score": {"(0, 0)": 0.8242543935775757, "(0, 16)": 0.8242543935775757, "(2, 0)": 0.8242543935775757, "(2, 16)": 0.8242543935775757, "(4, 0)": 0.8242543935775757, "(4, 16)": 0.8242543935775757, "(6, 0)": 0.8242543935775757, "(6, 16)": 0.6894832253456116, "(8, 0)": 0.8242543935775757, "(8, 16)": 0.8242543935775757, "(10, 0)": 0.8242543935775757, "(10, 16)": 0.8242543935775757, "(12, 0)": 0.8242543935775757, "(12, 16)": 0.8242543935775757, "(14, 0)": 0.8242543935775757, "(14, 16)": 0.8242543935775757, "(16, 0)": 0.8242543935775757, "(16, 16)": 0.49417510628700256, "(18, 0)": 0.49417510628700256, "(18, 16)": 0.5850999355316162, "(20, 0)": 0.8242543935775757, "(20, 16)": 0.8242543935775757, "(22, 0)": 0.8242543935775757, "(22, 16)": 0.8242543935775757, "(24, 0)": 0.8242543935775757, "(24, 16)": 0.5850999355316162, "(26, 0)": 0.49417510628700256, "(26, 16)": 0.8242543935775757, "(28, 0)": 0.49417510628700256, "(28, 16)": 0.8242543935775757, "(30, 0)": 0.49417510628700256, "(30, 16)": 0.49417510628700256}, "r_span": [916, 1007], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0011248588562011719}}]}, {"id": "7155", "source_id": "14062", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 328, "end": 390, "text": "The wine shop is open Monday through Sunday from 12 pm to 8 pm", "meta": "EVIDENT CONFLICT\nOriginal: Monday to Sunday, 12 NN to 6 PM, except for Friday when it closes 5 PM. \nGenerative: \"The wine shop is open Monday through Sunday from 12 pm to 8 pm\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 392, "end": 424, "text": "with extended hours on weekends.", "meta": "EVIDENT CONFLICT\nOriginal: No extended hours on weekends. The operating hours are the same with weekdays.\nGenerative: \"... with extended hours on weekends.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Vino Divino:\n\nVino Divino is a locally owned wine shop located in Santa Barbara, California. With a total of 5 stars, the business offers a variety of services and amenities, including event planning, wine tastings, food, arts and entertainment, and more. The wine shop is open Monday through Sunday from 12 pm to 8 pm, with extended hours on weekends. The business provides free WiFi and has a welcoming atmosphere, making it a popular destination for special occasions and everyday visits alike. Customers have praised the friendly and knowledgeable staff, as well as the extensive selection of wines available. One customer even described it as their \"go-to spot\" for buying wine. Overall, Vino Divino appears to be a top-rated wine shop in Santa Barbara, offering a unique and enjoyable experience for its customers.", "response_spans": [[0, 84], [86, 596], [580, 892]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5930973291397095, "(0, 16)": 0.5930973291397095, "(2, 0)": 0.5930973291397095, "(2, 16)": 0.5930973291397095, "(4, 0)": 0.5930973291397095, "(4, 16)": 0.5930973291397095, "(6, 0)": 0.5930973291397095, "(6, 16)": 0.5981491804122925, "(8, 0)": 0.6353611946105957, "(8, 16)": 0.5930973291397095, "(10, 0)": 0.5981491804122925, "(10, 16)": 0.5981491804122925, "(12, 0)": 0.5507524609565735, "(12, 16)": 0.5981491804122925, "(14, 0)": 0.5930973291397095, "(14, 16)": 0.5981491804122925, "(16, 0)": 0.5981491804122925, "(16, 16)": 0.5981491804122925, "(18, 0)": 0.5981491804122925, "(18, 16)": 0.5981491804122925, "(20, 0)": 0.5981491804122925, "(20, 16)": 0.5930973291397095, "(22, 0)": 0.5981491804122925, "(22, 16)": 0.5981491804122925, "(24, 0)": 0.5930973291397095, "(24, 16)": 0.5981491804122925, "(26, 0)": 0.5981491804122925, "(26, 16)": 0.6353611946105957, "(28, 0)": 0.5981491804122925, "(28, 16)": 0.5930973291397095, "(30, 0)": 0.5981491804122925, "(30, 16)": 0.5981491804122925}, "r_span": [820, 841], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006225109100341797}}, {"prompt_attention_score": {"(0, 0)": 0.7907742857933044, "(0, 16)": 0.7907742857933044, "(2, 0)": 0.7907742857933044, "(2, 16)": 0.7907742857933044, "(4, 0)": 0.7907742857933044, "(4, 16)": 0.7907742857933044, "(6, 0)": 0.7907742857933044, "(6, 16)": 0.7723026871681213, "(8, 0)": 0.7907742857933044, "(8, 16)": 0.7907742857933044, "(10, 0)": 0.7907742857933044, "(10, 16)": 0.7907742857933044, "(12, 0)": 0.7907742857933044, "(12, 16)": 0.7723026871681213, "(14, 0)": 0.7907742857933044, "(14, 16)": 0.7723026871681213, "(16, 0)": 0.6709621548652649, "(16, 16)": 0.7907742857933044, "(18, 0)": 0.4113052487373352, "(18, 16)": 0.7723026871681213, "(20, 0)": 0.7723026871681213, "(20, 16)": 0.7907742857933044, "(22, 0)": 0.4113052487373352, "(22, 16)": 0.6709621548652649, "(24, 0)": 0.7907742857933044, "(24, 16)": 0.6709621548652649, "(26, 0)": 0.4113052487373352, "(26, 16)": 0.6709621548652649, "(28, 0)": 0.4113052487373352, "(28, 16)": 0.7907742857933044, "(30, 0)": 0.4113052487373352, "(30, 16)": 0.4113052487373352}, "r_span": [843, 958], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0003764629364013672}}, {"prompt_attention_score": {"(0, 0)": 0.905096173286438, "(0, 16)": 0.905096173286438, "(2, 0)": 0.905096173286438, "(2, 16)": 0.905096173286438, "(4, 0)": 0.905096173286438, "(4, 16)": 0.905096173286438, "(6, 0)": 0.905096173286438, "(6, 16)": 0.7495982646942139, "(8, 0)": 0.905096173286438, "(8, 16)": 0.905096173286438, "(10, 0)": 0.905096173286438, "(10, 16)": 0.905096173286438, "(12, 0)": 0.905096173286438, "(12, 16)": 0.905096173286438, "(14, 0)": 0.905096173286438, "(14, 16)": 0.905096173286438, "(16, 0)": 0.905096173286438, "(16, 16)": 0.41445213556289673, "(18, 0)": 0.41445213556289673, "(18, 16)": 0.6939132213592529, "(20, 0)": 0.905096173286438, "(20, 16)": 0.905096173286438, "(22, 0)": 0.41445213556289673, "(22, 16)": 0.6939132213592529, "(24, 0)": 0.905096173286438, "(24, 16)": 0.7495982646942139, "(26, 0)": 0.41445213556289673, "(26, 16)": 0.905096173286438, "(28, 0)": 0.41445213556289673, "(28, 16)": 0.905096173286438, "(30, 0)": 0.41445213556289673, "(30, 16)": 0.41445213556289673}, "r_span": [955, 1025], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00037401914596557617}}]}, {"id": "7161", "source_id": "14063", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 269, "end": 293, "text": "and intimate atmosphere.", "meta": "EVIDENT CONFLICT\nOriginal: \"intimate\": false\nGenerative: \"...and intimate atmosphere.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 659, "end": 675, "text": "around $20 each.", "meta": "EVIDENT CONFLICT\nOriginal: One review states, \"ended up paying 19 for one frose...\"\nGenerative: around $20 each", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 809, "end": 939, "text": "many customers have praised Santa Barbara Wine Therapy for its unique selection of wines and beers, as well as its cozy atmosphere", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No reviews about unique selection of wine and beers, also, no mention of cozy atmosphere. \nGenerative: \"...many customers have praised Santa Barbara Wine Therapy for its unique selection of wines and beers, as well as its cozy atmosphere.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Santa Barbara Wine Therapy:\n\nSanta Barbara Wine Therapy is a local wine bar located in downtown Santa Barbara, California. The business offers a variety of wines, beers, and cocktails in a relaxed and intimate atmosphere. According to customer reviews, the business has a rating of 4.0 out of 5 stars.\n\nOne customer left a negative review, stating that the door staff was rude and aggressively enforced the requirement for mask-wearing inside the establishment. Another customer noted that the prices have increased since the business moved to its new location, with some drinks costing around $20 each. A third customer expressed disappointment that the business was closed during their visit from Orange County.\n\nDespite these issues, many customers have praised Santa Barbara Wine Therapy for its unique selection of wines and beers, as well as its cozy atmosphere. The business also offers outdoor seating and free WiFi, making it a popular spot for both locals and tourists. Overall, Santa Barbara Wine Therapy appears to provide a enjoyable experience for those looking for a casual wine tasting or drink in downtown Santa Barbara.", "response_spans": [[0, 373], [375, 785], [787, 1209]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.44823306798934937, "(0, 16)": 0.44823306798934937, "(2, 0)": 0.44823306798934937, "(2, 16)": 0.513303279876709, "(4, 0)": 0.44823306798934937, "(4, 16)": 0.44823306798934937, "(6, 0)": 0.44823306798934937, "(6, 16)": 0.8007731437683105, "(8, 0)": 0.5319693684577942, "(8, 16)": 0.44823306798934937, "(10, 0)": 0.5319693684577942, "(10, 16)": 0.4523038864135742, "(12, 0)": 0.513303279876709, "(12, 16)": 0.8007731437683105, "(14, 0)": 0.44823306798934937, "(14, 16)": 0.8007731437683105, "(16, 0)": 0.4523038864135742, "(16, 16)": 0.44823306798934937, "(18, 0)": 0.44823306798934937, "(18, 16)": 0.8007731437683105, "(20, 0)": 0.8007731437683105, "(20, 16)": 0.44823306798934937, "(22, 0)": 0.4523038864135742, "(22, 16)": 0.8007731437683105, "(24, 0)": 0.44823306798934937, "(24, 16)": 0.8007731437683105, "(26, 0)": 0.4523038864135742, "(26, 16)": 0.8007731437683105, "(28, 0)": 0.4523038864135742, "(28, 16)": 0.44823306798934937, "(30, 0)": 0.4523038864135742, "(30, 16)": 0.4523038864135742}, "r_span": [746, 840], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0003624558448791504}}, {"prompt_attention_score": {"(0, 0)": 0.7639244198799133, "(0, 16)": 0.620003879070282, "(2, 0)": 0.7639244198799133, "(2, 16)": 0.7546900510787964, "(4, 0)": 0.7639244198799133, "(4, 16)": 0.7546900510787964, "(6, 0)": 0.7546900510787964, "(6, 16)": 0.5665897727012634, "(8, 0)": 0.7639244198799133, "(8, 16)": 0.7546900510787964, "(10, 0)": 0.7546900510787964, "(10, 16)": 0.7639244198799133, "(12, 0)": 0.7639244198799133, "(12, 16)": 0.7639244198799133, "(14, 0)": 0.7639244198799133, "(14, 16)": 0.7639244198799133, "(16, 0)": 0.7639244198799133, "(16, 16)": 0.4940320551395416, "(18, 0)": 0.620003879070282, "(18, 16)": 0.7639244198799133, "(20, 0)": 0.7639244198799133, "(20, 16)": 0.7639244198799133, "(22, 0)": 0.4940320551395416, "(22, 16)": 0.7639244198799133, "(24, 0)": 0.7639244198799133, "(24, 16)": 0.7639244198799133, "(26, 0)": 0.4940320551395416, "(26, 16)": 0.7639244198799133, "(28, 0)": 0.4940320551395416, "(28, 16)": 0.7639244198799133, "(30, 0)": 0.4940320551395416, "(30, 16)": 0.4940320551395416}, "r_span": [842, 921], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0026097893714904785}}, {"prompt_attention_score": {"(0, 0)": 0.44143354892730713, "(0, 16)": 0.7300248146057129, "(2, 0)": 0.44143354892730713, "(2, 16)": 0.44143354892730713, "(4, 0)": 0.44143354892730713, "(4, 16)": 0.49694377183914185, "(6, 0)": 0.44143354892730713, "(6, 16)": 0.7300248146057129, "(8, 0)": 0.44143354892730713, "(8, 16)": 0.44143354892730713, "(10, 0)": 0.568493127822876, "(10, 16)": 0.49694377183914185, "(12, 0)": 0.44143354892730713, "(12, 16)": 0.568493127822876, "(14, 0)": 0.44143354892730713, "(14, 16)": 0.49694377183914185, "(16, 0)": 0.44143354892730713, "(16, 16)": 0.44143354892730713, "(18, 0)": 0.44143354892730713, "(18, 16)": 0.7300248146057129, "(20, 0)": 0.568493127822876, "(20, 16)": 0.44143354892730713, "(22, 0)": 0.40064483880996704, "(22, 16)": 0.7300248146057129, "(24, 0)": 0.44143354892730713, "(24, 16)": 0.568493127822876, "(26, 0)": 0.40064483880996704, "(26, 16)": 0.568493127822876, "(28, 0)": 0.40064483880996704, "(28, 16)": 0.44143354892730713, "(30, 0)": 0.40064483880996704, "(30, 16)": 0.40064483880996704}, "r_span": [923, 1021], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001788020133972168}}]}, {"id": "7203", "source_id": "14070", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Valentino's Take N' Bake Pizza in Santa Barbara, California is a popular local business known for its delicious pizzas, sandwiches, and salads. With a rating of 4.5 stars, the restaurant has received glowing reviews from customers who praise the freshness of the ingredients, the quality of the food, and the convenience of taking pizzas home to bake. Reviewers particularly enjoy the Italian sub sandwich, which is described as \"amazing\" and \"perfectly made,\" and the pizzas, which are said to be \"freshly baked\" and \"perfectly cooked.\" Some customers have even raved about the excellent customer service, with one reviewer calling a particular employee, Shayre, an \"angel\" for her help with a large bulk order. Overall, Valentino's Take N' Bake Pizza is a must-visit destination for food lovers in the area.", "response_spans": [[0, 506], [487, 809]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6095767617225647, "(0, 16)": 0.728306233882904, "(2, 0)": 0.6095767617225647, "(2, 16)": 0.6095767617225647, "(4, 0)": 0.6095767617225647, "(4, 16)": 0.6095767617225647, "(6, 0)": 0.6095767617225647, "(6, 16)": 0.7867364883422852, "(8, 0)": 0.6095767617225647, "(8, 16)": 0.6095767617225647, "(10, 0)": 0.728306233882904, "(10, 16)": 0.6095767617225647, "(12, 0)": 0.6095767617225647, "(12, 16)": 0.7148449420928955, "(14, 0)": 0.6095767617225647, "(14, 16)": 0.46291500329971313, "(16, 0)": 0.5510632991790771, "(16, 16)": 0.6095767617225647, "(18, 0)": 0.6095767617225647, "(18, 16)": 0.7148449420928955, "(20, 0)": 0.6725777387619019, "(20, 16)": 0.6095767617225647, "(22, 0)": 0.6095767617225647, "(22, 16)": 0.7148449420928955, "(24, 0)": 0.6095767617225647, "(24, 16)": 0.6725777387619019, "(26, 0)": 0.48404818773269653, "(26, 16)": 0.6095767617225647, "(28, 0)": 0.48404818773269653, "(28, 16)": 0.6095767617225647, "(30, 0)": 0.48404818773269653, "(30, 16)": 0.48404818773269653}, "r_span": [1053, 1184], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001932382583618164}}, {"prompt_attention_score": {"(0, 0)": 0.7893494367599487, "(0, 16)": 0.7893494367599487, "(2, 0)": 0.7204247713088989, "(2, 16)": 0.7893494367599487, "(4, 0)": 0.7204247713088989, "(4, 16)": 0.7204247713088989, "(6, 0)": 0.7204247713088989, "(6, 16)": 0.7267293930053711, "(8, 0)": 0.7204247713088989, "(8, 16)": 0.7204247713088989, "(10, 0)": 0.7204247713088989, "(10, 16)": 0.7204247713088989, "(12, 0)": 0.7204247713088989, "(12, 16)": 0.7204247713088989, "(14, 0)": 0.7204247713088989, "(14, 16)": 0.7204247713088989, "(16, 0)": 0.7204247713088989, "(16, 16)": 0.7204247713088989, "(18, 0)": 0.7893494367599487, "(18, 16)": 0.7204247713088989, "(20, 0)": 0.7204247713088989, "(20, 16)": 0.7204247713088989, "(22, 0)": 0.7204247713088989, "(22, 16)": 0.7204247713088989, "(24, 0)": 0.7204247713088989, "(24, 16)": 0.7204247713088989, "(26, 0)": 0.5035497546195984, "(26, 16)": 0.7204247713088989, "(28, 0)": 0.5035497546195984, "(28, 16)": 0.7204247713088989, "(30, 0)": 0.5035497546195984, "(30, 16)": 0.5035497546195984}, "r_span": [1178, 1262], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006455183029174805}}]}, {"id": "7215", "source_id": "14072", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 305, "end": 325, "text": "and outdoor seating,", "meta": "EVIDENT CONFLICT\nOriginal: \"OutdoorSeating\": false\nGenerative: \"...has...outdoor seating...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 367, "end": 402, "text": "The ambiance is described as casual", "meta": "EVIDENT CONFLICT\nOriginal: \"casual\": false\nGenerative: \"The ambiance is described as casual...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "iGrill Korean BBQ is a popular restaurant located in Santa Barbara, California, that offers a variety of barbecue dishes with a Korean twist. Customers rave about the fresh and made-from-scratch food, with many giving the restaurant a perfect 5-star rating. The restaurant has free WiFi, takeout options, and outdoor seating, but does not offer valet or lot parking. The ambiance is described as casual and hipster-friendly, making it a great spot for groups and date nights. Despite some mixed reviews, iGrill Korean BBQ consistently impresses customers with its high-quality food and excellent service.", "response_spans": [[0, 510], [495, 604]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6349657773971558, "(0, 16)": 0.6349657773971558, "(2, 0)": 0.6349657773971558, "(2, 16)": 0.6349657773971558, "(4, 0)": 0.6349657773971558, "(4, 16)": 0.6349657773971558, "(6, 0)": 0.6349657773971558, "(6, 16)": 0.8185179233551025, "(8, 0)": 0.6349657773971558, "(8, 16)": 0.6349657773971558, "(10, 0)": 0.6433905363082886, "(10, 16)": 0.6433905363082886, "(12, 0)": 0.6349657773971558, "(12, 16)": 0.6433905363082886, "(14, 0)": 0.6349657773971558, "(14, 16)": 0.6433905363082886, "(16, 0)": 0.6433905363082886, "(16, 16)": 0.6349657773971558, "(18, 0)": 0.4501771926879883, "(18, 16)": 0.6433905363082886, "(20, 0)": 0.6433905363082886, "(20, 16)": 0.4501771926879883, "(22, 0)": 0.4501771926879883, "(22, 16)": 0.6433905363082886, "(24, 0)": 0.4501771926879883, "(24, 16)": 0.6433905363082886, "(26, 0)": 0.4501771926879883, "(26, 16)": 0.4501771926879883, "(28, 0)": 0.4501771926879883, "(28, 16)": 0.4501771926879883, "(30, 0)": 0.4501771926879883, "(30, 16)": 0.4501771926879883}, "r_span": [694, 819], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0020669102668762207}}, {"prompt_attention_score": {"(0, 0)": 0.7135146260261536, "(0, 16)": 0.7135146260261536, "(2, 0)": 0.7135146260261536, "(2, 16)": 0.7135146260261536, "(4, 0)": 0.7135146260261536, "(4, 16)": 0.7135146260261536, "(6, 0)": 0.7135146260261536, "(6, 16)": 0.6663553714752197, "(8, 0)": 0.7135146260261536, "(8, 16)": 0.7135146260261536, "(10, 0)": 0.7135146260261536, "(10, 16)": 0.7135146260261536, "(12, 0)": 0.4299708902835846, "(12, 16)": 0.7135146260261536, "(14, 0)": 0.7135146260261536, "(14, 16)": 0.6182621717453003, "(16, 0)": 0.7135146260261536, "(16, 16)": 0.4299708902835846, "(18, 0)": 0.4299708902835846, "(18, 16)": 0.6182621717453003, "(20, 0)": 0.6182621717453003, "(20, 16)": 0.4299708902835846, "(22, 0)": 0.4299708902835846, "(22, 16)": 0.6182621717453003, "(24, 0)": 0.4299708902835846, "(24, 16)": 0.6182621717453003, "(26, 0)": 0.4299708902835846, "(26, 16)": 0.4299708902835846, "(28, 0)": 0.4299708902835846, "(28, 16)": 0.4299708902835846, "(30, 0)": 0.4299708902835846, "(30, 16)": 0.4299708902835846}, "r_span": [815, 837], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006830096244812012}}]}, {"id": "7233", "source_id": "14076", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 310, "end": 321, "text": "and cheeses", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of cheese\nGenerative: \"...known for...and cheeses...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Eastside Deli is a popular restaurant located in Truckee, California, serving a variety of delicious sandwiches, desserts, and other menu items. With a rating of 5.0 stars, the business offers a cozy atmosphere and excellent customer service. According to reviews, the deli is known for its high-quality meats and cheeses, as well as its convenient location within an RV park. Reviewers have praised the business for its hidden gem status, great sandwiches, and friendly staff. While some have noted that the lack of gluten-free options may be a drawback for certain customers, overall Eastside Deli appears to be a must-visit destination for anyone in the area.", "response_spans": [[0, 508], [489, 662]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.651422381401062, "(0, 16)": 0.651422381401062, "(2, 0)": 0.651422381401062, "(2, 16)": 0.651422381401062, "(4, 0)": 0.651422381401062, "(4, 16)": 0.651422381401062, "(6, 0)": 0.651422381401062, "(6, 16)": 0.7593013048171997, "(8, 0)": 0.6912704706192017, "(8, 16)": 0.651422381401062, "(10, 0)": 0.651422381401062, "(10, 16)": 0.651422381401062, "(12, 0)": 0.651422381401062, "(12, 16)": 0.7593013048171997, "(14, 0)": 0.651422381401062, "(14, 16)": 0.651422381401062, "(16, 0)": 0.6220119595527649, "(16, 16)": 0.651422381401062, "(18, 0)": 0.651422381401062, "(18, 16)": 0.7593013048171997, "(20, 0)": 0.6220119595527649, "(20, 16)": 0.6912704706192017, "(22, 0)": 0.4305182099342346, "(22, 16)": 0.6220119595527649, "(24, 0)": 0.6912704706192017, "(24, 16)": 0.7593013048171997, "(26, 0)": 0.4305182099342346, "(26, 16)": 0.651422381401062, "(28, 0)": 0.4305182099342346, "(28, 16)": 0.651422381401062, "(30, 0)": 0.4305182099342346, "(30, 16)": 0.4305182099342346}, "r_span": [814, 931], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00042122602462768555}}, {"prompt_attention_score": {"(0, 0)": 0.542700469493866, "(0, 16)": 0.542700469493866, "(2, 0)": 0.542700469493866, "(2, 16)": 0.542700469493866, "(4, 0)": 0.542700469493866, "(4, 16)": 0.542700469493866, "(6, 0)": 0.542700469493866, "(6, 16)": 0.633152186870575, "(8, 0)": 0.7073206901550293, "(8, 16)": 0.542700469493866, "(10, 0)": 0.542700469493866, "(10, 16)": 0.542700469493866, "(12, 0)": 0.542700469493866, "(12, 16)": 0.7073206901550293, "(14, 0)": 0.7073206901550293, "(14, 16)": 0.7073206901550293, "(16, 0)": 0.7073206901550293, "(16, 16)": 0.542700469493866, "(18, 0)": 0.542700469493866, "(18, 16)": 0.7073206901550293, "(20, 0)": 0.7073206901550293, "(20, 16)": 0.7073206901550293, "(22, 0)": 0.43239301443099976, "(22, 16)": 0.7073206901550293, "(24, 0)": 0.7073206901550293, "(24, 16)": 0.7073206901550293, "(26, 0)": 0.43239301443099976, "(26, 16)": 0.7073206901550293, "(28, 0)": 0.43239301443099976, "(28, 16)": 0.542700469493866, "(30, 0)": 0.43239301443099976, "(30, 16)": 0.43239301443099976}, "r_span": [928, 967], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -6.663799285888672e-05}}]}, {"id": "7239", "source_id": "14077", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 317, "end": 359, "text": "7:00 AM to 10:30 PM from Monday to Sunday,", "meta": "EVIDENT CONFLICT\nOriginal: Monday-Tuesday: \"7:0-10:30\"\nWednesday-Sunday: \"17:0-21:30\"\nGenerated: 7:00 AM to 10:30 PM from Monday to Sunday", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 417, "end": 434, "text": "has valet parking", "meta": "EVIDENT CONFLICT\nOriginal: \"valet\": false,\nGenerated:  has valet parking", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 644, "end": 712, "text": "one reviewer praised the decor and ambiance, describing it as \"divey", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No reviews about the restaurant having a divey ambiance\nGenerative: \"...one reviewer praised the decor and ambiance, describing it as \"divey\"...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 618, "end": 633, "text": "long wait times", "meta": "LOW INTRODUCTION OF NEW INFORMATION\nIt was not mentioned in the structured data about a review on long wait times.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Outpost is a local restaurant located in Goleta, California, with a rating of 4.0 stars. The restaurant offers a variety of cuisines, including American (New), Bars, Nightlife, Seafood, Breakfast & Brunch, American (Traditional), Desserts, and Food. The business hours are from 7:00 AM to 10:30 PM from Monday to Sunday, and the restaurant provides free WiFi. The establishment has valet parking, but no garage or street parking available. The reviews suggest that while the menu is amazing, the service needs improvement, with some customers mentioning unprofessional staff and long wait times. However, one reviewer praised the decor and ambiance, describing it as \"divey\" but \"hipster\" and \"casual\". Another reviewer enjoyed their meal, particularly the burger and fries, but found the menu selection to be limited. Overall, Outpost seems to have mixed reviews, with some customers enjoying their dining experience but others feeling let down by the service.", "response_spans": [[0, 509], [491, 1000]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6320064663887024, "(0, 16)": 0.6320064663887024, "(2, 0)": 0.6121200323104858, "(2, 16)": 0.6121200323104858, "(4, 0)": 0.6320064663887024, "(4, 16)": 0.6320064663887024, "(6, 0)": 0.6320064663887024, "(6, 16)": 0.855868399143219, "(8, 0)": 0.855868399143219, "(8, 16)": 0.6320064663887024, "(10, 0)": 0.6277187466621399, "(10, 16)": 0.6320064663887024, "(12, 0)": 0.6320064663887024, "(12, 16)": 0.855868399143219, "(14, 0)": 0.6320064663887024, "(14, 16)": 0.855868399143219, "(16, 0)": 0.5693409442901611, "(16, 16)": 0.6320064663887024, "(18, 0)": 0.6320064663887024, "(18, 16)": 0.855868399143219, "(20, 0)": 0.855868399143219, "(20, 16)": 0.6320064663887024, "(22, 0)": 0.6320064663887024, "(22, 16)": 0.855868399143219, "(24, 0)": 0.6320064663887024, "(24, 16)": 0.855868399143219, "(26, 0)": 0.5693409442901611, "(26, 16)": 0.6330068707466125, "(28, 0)": 0.5693409442901611, "(28, 16)": 0.6320064663887024, "(30, 0)": 0.5693409442901611, "(30, 16)": 0.5693409442901611}, "r_span": [900, 1033], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012366771697998047}}, {"prompt_attention_score": {"(0, 0)": 0.7685803174972534, "(0, 16)": 0.7685803174972534, "(2, 0)": 0.7420618534088135, "(2, 16)": 0.7685803174972534, "(4, 0)": 0.7685803174972534, "(4, 16)": 0.7420618534088135, "(6, 0)": 0.7685803174972534, "(6, 16)": 0.8035302758216858, "(8, 0)": 0.7685803174972534, "(8, 16)": 0.7685803174972534, "(10, 0)": 0.7685803174972534, "(10, 16)": 0.7685803174972534, "(12, 0)": 0.7685803174972534, "(12, 16)": 0.6596056222915649, "(14, 0)": 0.7685803174972534, "(14, 16)": 0.7685803174972534, "(16, 0)": 0.7685803174972534, "(16, 16)": 0.7685803174972534, "(18, 0)": 0.7685803174972534, "(18, 16)": 0.8035302758216858, "(20, 0)": 0.8035302758216858, "(20, 16)": 0.7685803174972534, "(22, 0)": 0.7685803174972534, "(22, 16)": 0.8035302758216858, "(24, 0)": 0.7685803174972534, "(24, 16)": 0.7685803174972534, "(26, 0)": 0.5368502736091614, "(26, 16)": 0.7420618534088135, "(28, 0)": 0.5368502736091614, "(28, 16)": 0.7685803174972534, "(30, 0)": 0.5368502736091614, "(30, 16)": 0.5368502736091614}, "r_span": [1031, 1143], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009818673133850098}}]}, {"id": "7257", "source_id": "14080", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 286, "end": 308, "text": "offers outdoor seating", "meta": "EVIDENT CONFLICT\nOriginal: \"OutdoorSeating\": false,\nGenerated:  offers outdoor seating", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 310, "end": 314, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerated:  offers...", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Rusty's Pizza Parlor:\n\nRusty's Pizza Parlor is a local restaurant located in Santa Barbara, California, with a rating of 3.0 stars. The business has categories such as Restaurants, Pizza, Salad, Chicken Wings, and offers outdoor seating, WiFi, and restaurants takeout. According to customer reviews, the business has a mixed reputation, with some reviewers praising the quality of the food and others expressing disappointment with the delivery service. Specifically, one reviewer reported that their pizza was cold and a piece was missing upon delivery, while another reviewer had a positive experience with the restaurant for family dinners. Overall, Rusty's Pizza Parlor appears to have a good reputation among locals but may need to improve its delivery service to maintain customer satisfaction.", "response_spans": [[0, 93], [95, 603], [588, 872]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4674978256225586, "(0, 16)": 0.4674978256225586, "(2, 0)": 0.4674978256225586, "(2, 16)": 0.4674978256225586, "(4, 0)": 0.4674978256225586, "(4, 16)": 0.4674978256225586, "(6, 0)": 0.4674978256225586, "(6, 16)": 0.6350257992744446, "(8, 0)": 0.5410740375518799, "(8, 16)": 0.4674978256225586, "(10, 0)": 0.6350257992744446, "(10, 16)": 0.6350257992744446, "(12, 0)": 0.5234521627426147, "(12, 16)": 0.6350257992744446, "(14, 0)": 0.4674978256225586, "(14, 16)": 0.6350257992744446, "(16, 0)": 0.6350257992744446, "(16, 16)": 0.5234521627426147, "(18, 0)": 0.4674978256225586, "(18, 16)": 0.6350257992744446, "(20, 0)": 0.6350257992744446, "(20, 16)": 0.4674978256225586, "(22, 0)": 0.4674978256225586, "(22, 16)": 0.6350257992744446, "(24, 0)": 0.4674978256225586, "(24, 16)": 0.6350257992744446, "(26, 0)": 0.6350257992744446, "(26, 16)": 0.5410740375518799, "(28, 0)": 0.6350257992744446, "(28, 16)": 0.4674978256225586, "(30, 0)": 0.6350257992744446, "(30, 16)": 0.6350257992744446}, "r_span": [1022, 1048], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010085105895996094}}, {"prompt_attention_score": {"(0, 0)": 0.6043932437896729, "(0, 16)": 0.6043932437896729, "(2, 0)": 0.6043932437896729, "(2, 16)": 0.6819307804107666, "(4, 0)": 0.6043932437896729, "(4, 16)": 0.6043932437896729, "(6, 0)": 0.6043932437896729, "(6, 16)": 0.7965537309646606, "(8, 0)": 0.6254119873046875, "(8, 16)": 0.6043932437896729, "(10, 0)": 0.722366452217102, "(10, 16)": 0.6043932437896729, "(12, 0)": 0.6043932437896729, "(12, 16)": 0.7965537309646606, "(14, 0)": 0.6043932437896729, "(14, 16)": 0.7965537309646606, "(16, 0)": 0.5691065788269043, "(16, 16)": 0.6043932437896729, "(18, 0)": 0.722366452217102, "(18, 16)": 0.7965537309646606, "(20, 0)": 0.7965537309646606, "(20, 16)": 0.6043932437896729, "(22, 0)": 0.6043932437896729, "(22, 16)": 0.6254119873046875, "(24, 0)": 0.6043932437896729, "(24, 16)": 0.7965537309646606, "(26, 0)": 0.48793578147888184, "(26, 16)": 0.722366452217102, "(28, 0)": 0.48793578147888184, "(28, 16)": 0.6043932437896729, "(30, 0)": 0.48793578147888184, "(30, 16)": 0.48793578147888184}, "r_span": [1050, 1167], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00014328956604003906}}, {"prompt_attention_score": {"(0, 0)": 0.6533235311508179, "(0, 16)": 0.7470031976699829, "(2, 0)": 0.7269029021263123, "(2, 16)": 0.7269029021263123, "(4, 0)": 0.7269029021263123, "(4, 16)": 0.7269029021263123, "(6, 0)": 0.6533235311508179, "(6, 16)": 0.7470031976699829, "(8, 0)": 0.6533235311508179, "(8, 16)": 0.7269029021263123, "(10, 0)": 0.6533235311508179, "(10, 16)": 0.6533235311508179, "(12, 0)": 0.6533235311508179, "(12, 16)": 0.7103971242904663, "(14, 0)": 0.6533235311508179, "(14, 16)": 0.45519405603408813, "(16, 0)": 0.6533235311508179, "(16, 16)": 0.7269029021263123, "(18, 0)": 0.6533235311508179, "(18, 16)": 0.5217437744140625, "(20, 0)": 0.5217437744140625, "(20, 16)": 0.6533235311508179, "(22, 0)": 0.6533235311508179, "(22, 16)": 0.6533235311508179, "(24, 0)": 0.6533235311508179, "(24, 16)": 0.7470031976699829, "(26, 0)": 0.47842198610305786, "(26, 16)": 0.6533235311508179, "(28, 0)": 0.47842198610305786, "(28, 16)": 0.6533235311508179, "(30, 0)": 0.47842198610305786, "(30, 16)": 0.47842198610305786}, "r_span": [1164, 1221], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001001894474029541}}]}, {"id": "7263", "source_id": "14081", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 498, "end": 521, "text": "and takes reservations,", "meta": "EVIDENT CONFLICT\nOriginal: \"RestaurantsReservations\": false\nGenerative: \"...and takes reservations...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Little Alex's is a local restaurant located in Santa Barbara, California, serving Mexican cuisine. Despite its long history in the area, the business has faced criticism in recent years for the decline in quality of its food. Reviews suggest that the menu items are heavily Americanized, lacking in flavor, and made with frozen vegetables and dry chicken. However, some patrons still enjoy the chicken soup, which is affectionately referred to as \"sick soup.\" The restaurant offers outdoor seating and takes reservations, although the WiFi is unavailable. The business has received mixed reviews, with some customers praising the service and others expressing disappointment in the food. Overall, Little Alex's seems to be a casual, family-friendly establishment with potential for improvement in its culinary offerings.", "response_spans": [[0, 507], [490, 820]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6306014657020569, "(0, 16)": 0.6306014657020569, "(2, 0)": 0.6306014657020569, "(2, 16)": 0.6306014657020569, "(4, 0)": 0.6306014657020569, "(4, 16)": 0.6306014657020569, "(6, 0)": 0.6306014657020569, "(6, 16)": 0.7366960048675537, "(8, 0)": 0.6306014657020569, "(8, 16)": 0.6306014657020569, "(10, 0)": 0.6306014657020569, "(10, 16)": 0.6306014657020569, "(12, 0)": 0.6306014657020569, "(12, 16)": 0.6932555437088013, "(14, 0)": 0.6932555437088013, "(14, 16)": 0.6306014657020569, "(16, 0)": 0.6932555437088013, "(16, 16)": 0.6306014657020569, "(18, 0)": 0.5344412922859192, "(18, 16)": 0.6932555437088013, "(20, 0)": 0.6932555437088013, "(20, 16)": 0.6932555437088013, "(22, 0)": 0.6932555437088013, "(22, 16)": 0.6932555437088013, "(24, 0)": 0.6932555437088013, "(24, 16)": 0.6932555437088013, "(26, 0)": 0.4248404800891876, "(26, 16)": 0.6932555437088013, "(28, 0)": 0.4248404800891876, "(28, 16)": 0.6932555437088013, "(30, 0)": 0.4248404800891876, "(30, 16)": 0.4248404800891876}, "r_span": [835, 946], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0032155513763427734}}, {"prompt_attention_score": {"(0, 0)": 0.5938736200332642, "(0, 16)": 0.5938736200332642, "(2, 0)": 0.5938736200332642, "(2, 16)": 0.5938736200332642, "(4, 0)": 0.5938736200332642, "(4, 16)": 0.5938736200332642, "(6, 0)": 0.5938736200332642, "(6, 16)": 0.6650136709213257, "(8, 0)": 0.5938736200332642, "(8, 16)": 0.5938736200332642, "(10, 0)": 0.5938736200332642, "(10, 16)": 0.5938736200332642, "(12, 0)": 0.5938736200332642, "(12, 16)": 0.6650136709213257, "(14, 0)": 0.630515456199646, "(14, 16)": 0.4441544711589813, "(16, 0)": 0.5938736200332642, "(16, 16)": 0.5938736200332642, "(18, 0)": 0.46665433049201965, "(18, 16)": 0.606096088886261, "(20, 0)": 0.606096088886261, "(20, 16)": 0.630515456199646, "(22, 0)": 0.46665433049201965, "(22, 16)": 0.630515456199646, "(24, 0)": 0.630515456199646, "(24, 16)": 0.5938736200332642, "(26, 0)": 0.46665433049201965, "(26, 16)": 0.606096088886261, "(28, 0)": 0.46665433049201965, "(28, 16)": 0.46665433049201965, "(30, 0)": 0.46665433049201965, "(30, 16)": 0.46665433049201965}, "r_span": [943, 1012], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007384419441223145}}]}, {"id": "7281", "source_id": "14084", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Third Window Brewing is a popular local business in Santa Barbara, California that offers a unique blend of nightlife, beer gardens, breweries, food, beer, wine, and spirits. With a rating of 4.5 stars, the business boasts a cozy atmosphere and delicious offerings that have earned it rave reviews from customers. The brewery is known for its high-quality beers, including Smashburger, and its outdoor patio area, making it a great spot for both locals and visitors alike. Customers have praised the business for its friendly service, reasonable prices, and lively atmosphere, with one reviewer noting that it's a great spot for families. The business is conveniently located in The Mill, a complex that also houses a wine spot and restaurant, making it easy to pair a visit to Third Window with other activities in the area.", "response_spans": [[0, 512], [496, 825]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7643840909004211, "(0, 16)": 0.7643840909004211, "(2, 0)": 0.7643840909004211, "(2, 16)": 0.6247204542160034, "(4, 0)": 0.7643840909004211, "(4, 16)": 0.7643840909004211, "(6, 0)": 0.7643840909004211, "(6, 16)": 0.7880805730819702, "(8, 0)": 0.6182138919830322, "(8, 16)": 0.6247204542160034, "(10, 0)": 0.7643840909004211, "(10, 16)": 0.7643840909004211, "(12, 0)": 0.6247204542160034, "(12, 16)": 0.7880805730819702, "(14, 0)": 0.6247204542160034, "(14, 16)": 0.7880805730819702, "(16, 0)": 0.7880805730819702, "(16, 16)": 0.4186837077140808, "(18, 0)": 0.6182138919830322, "(18, 16)": 0.7880805730819702, "(20, 0)": 0.6182138919830322, "(20, 16)": 0.6247204542160034, "(22, 0)": 0.4186837077140808, "(22, 16)": 0.6182138919830322, "(24, 0)": 0.6247204542160034, "(24, 16)": 0.6182138919830322, "(26, 0)": 0.4186837077140808, "(26, 16)": 0.6182138919830322, "(28, 0)": 0.4186837077140808, "(28, 16)": 0.6247204542160034, "(30, 0)": 0.4186837077140808, "(30, 16)": 0.4186837077140808}, "r_span": [762, 889], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001624464988708496}}, {"prompt_attention_score": {"(0, 0)": 0.7797566652297974, "(0, 16)": 0.7797566652297974, "(2, 0)": 0.6723375916481018, "(2, 16)": 0.6723375916481018, "(4, 0)": 0.6723375916481018, "(4, 16)": 0.6723375916481018, "(6, 0)": 0.6723375916481018, "(6, 16)": 0.7797566652297974, "(8, 0)": 0.7797566652297974, "(8, 16)": 0.6723375916481018, "(10, 0)": 0.6723375916481018, "(10, 16)": 0.6723375916481018, "(12, 0)": 0.6723375916481018, "(12, 16)": 0.7797566652297974, "(14, 0)": 0.6723375916481018, "(14, 16)": 0.6723375916481018, "(16, 0)": 0.6723375916481018, "(16, 16)": 0.6723375916481018, "(18, 0)": 0.48200276494026184, "(18, 16)": 0.6192026138305664, "(20, 0)": 0.7797566652297974, "(20, 16)": 0.6723375916481018, "(22, 0)": 0.48200276494026184, "(22, 16)": 0.6192026138305664, "(24, 0)": 0.6723375916481018, "(24, 16)": 0.6192026138305664, "(26, 0)": 0.48200276494026184, "(26, 16)": 0.6723375916481018, "(28, 0)": 0.48200276494026184, "(28, 16)": 0.6723375916481018, "(30, 0)": 0.48200276494026184, "(30, 16)": 0.48200276494026184}, "r_span": [887, 955], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007456541061401367}}]}, {"id": "7293", "source_id": "14086", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 508, "end": 552, "text": "atmosphere is described as intimate, trendy,", "meta": "EVIDENT CONFLICT:\nAIGC: atmosphere is described as intimate, trendy,\nOriginal: \"intimate\": false,\"trendy\": false,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Opal Restaurant & Bar is a popular dining destination in Santa Barbara, California, offering a range of seafood and American cuisine. With an overall rating of 4.0 stars, the restaurant is known for its excellent food, great service, and cozy outdoor seating area. Customers have praised the restaurant's delicious menu options, including appetizers, salads, sandwiches, steaks, and desserts. The restaurant also offers takeout options and has free WiFi available. The atmosphere is described as intimate, trendy, and romantic, making it a great spot for date night or a special occasion. Additionally, the restaurant has a special events section where customers can host private events, such as weddings and receptions. The staff is friendly and accommodating, and the owner, Richard, is particularly commended for his exceptional customer service.", "response_spans": [[0, 507], [488, 888]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5925517678260803, "(0, 16)": 0.5925517678260803, "(2, 0)": 0.5925517678260803, "(2, 16)": 0.5925517678260803, "(4, 0)": 0.5925517678260803, "(4, 16)": 0.5925517678260803, "(6, 0)": 0.5925517678260803, "(6, 16)": 0.7817753553390503, "(8, 0)": 0.5925517678260803, "(8, 16)": 0.660965085029602, "(10, 0)": 0.5925517678260803, "(10, 16)": 0.5925517678260803, "(12, 0)": 0.5925517678260803, "(12, 16)": 0.7817753553390503, "(14, 0)": 0.660965085029602, "(14, 16)": 0.5925517678260803, "(16, 0)": 0.5514511466026306, "(16, 16)": 0.5925517678260803, "(18, 0)": 0.5925517678260803, "(18, 16)": 0.7817753553390503, "(20, 0)": 0.5812692642211914, "(20, 16)": 0.660965085029602, "(22, 0)": 0.660965085029602, "(22, 16)": 0.6231640577316284, "(24, 0)": 0.660965085029602, "(24, 16)": 0.5812692642211914, "(26, 0)": 0.5514511466026306, "(26, 16)": 0.660965085029602, "(28, 0)": 0.5514511466026306, "(28, 16)": 0.660965085029602, "(30, 0)": 0.5514511466026306, "(30, 16)": 0.5514511466026306}, "r_span": [1088, 1210], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -9.584426879882812e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7199816107749939, "(0, 16)": 0.7199816107749939, "(2, 0)": 0.7199816107749939, "(2, 16)": 0.7199816107749939, "(4, 0)": 0.7199816107749939, "(4, 16)": 0.7199816107749939, "(6, 0)": 0.7199816107749939, "(6, 16)": 0.6665458679199219, "(8, 0)": 0.7199816107749939, "(8, 16)": 0.683215320110321, "(10, 0)": 0.7199816107749939, "(10, 16)": 0.7199816107749939, "(12, 0)": 0.7199816107749939, "(12, 16)": 0.6665458679199219, "(14, 0)": 0.683215320110321, "(14, 16)": 0.683215320110321, "(16, 0)": 0.7199816107749939, "(16, 16)": 0.7199816107749939, "(18, 0)": 0.683215320110321, "(18, 16)": 0.6665458679199219, "(20, 0)": 0.6707323789596558, "(20, 16)": 0.683215320110321, "(22, 0)": 0.683215320110321, "(22, 16)": 0.6665458679199219, "(24, 0)": 0.683215320110321, "(24, 16)": 0.6665458679199219, "(26, 0)": 0.4850291609764099, "(26, 16)": 0.683215320110321, "(28, 0)": 0.4850291609764099, "(28, 16)": 0.683215320110321, "(30, 0)": 0.4850291609764099, "(30, 16)": 0.4850291609764099}, "r_span": [1206, 1288], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006683468818664551}}]}, {"id": "7299", "source_id": "14087", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "La Arcada Bistro is a locally owned restaurant located in Santa Barbara, California, serving coffee, tea, food, and American cuisine. With a rating of 3.5 stars, the business offers both indoor and outdoor seating and provides free WiFi to its customers. While some reviewers have had negative experiences with the service and availability of menu items, others have praised the quality of the food and friendly staff. Despite facing criticism, La Arcada Bistro has managed to maintain a loyal customer base and attract positive reviews overall.", "response_spans": [[0, 511], [494, 545]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5732540488243103, "(0, 16)": 0.5732540488243103, "(2, 0)": 0.5732540488243103, "(2, 16)": 0.5732540488243103, "(4, 0)": 0.5732540488243103, "(4, 16)": 0.5732540488243103, "(6, 0)": 0.5732540488243103, "(6, 16)": 0.7580713629722595, "(8, 0)": 0.5732540488243103, "(8, 16)": 0.5732540488243103, "(10, 0)": 0.5732540488243103, "(10, 16)": 0.5732540488243103, "(12, 0)": 0.5732540488243103, "(12, 16)": 0.7580713629722595, "(14, 0)": 0.5019459128379822, "(14, 16)": 0.42214256525039673, "(16, 0)": 0.523014485836029, "(16, 16)": 0.4396912455558777, "(18, 0)": 0.4396912455558777, "(18, 16)": 0.7580713629722595, "(20, 0)": 0.523014485836029, "(20, 16)": 0.5019459128379822, "(22, 0)": 0.4396912455558777, "(22, 16)": 0.523014485836029, "(24, 0)": 0.5019459128379822, "(24, 16)": 0.523014485836029, "(26, 0)": 0.4396912455558777, "(26, 16)": 0.4396912455558777, "(28, 0)": 0.4396912455558777, "(28, 16)": 0.5019459128379822, "(30, 0)": 0.4396912455558777, "(30, 16)": 0.4396912455558777}, "r_span": [722, 831], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0030020475387573242}}, {"prompt_attention_score": {"(0, 0)": 0.5568487644195557, "(0, 16)": 0.5568487644195557, "(2, 0)": 0.5568487644195557, "(2, 16)": 0.5568487644195557, "(4, 0)": 0.5568487644195557, "(4, 16)": 0.5568487644195557, "(6, 0)": 0.5412977933883667, "(6, 16)": 0.5345863103866577, "(8, 0)": 0.5568487644195557, "(8, 16)": 0.5568487644195557, "(10, 0)": 0.5568487644195557, "(10, 16)": 0.5568487644195557, "(12, 0)": 0.5345863103866577, "(12, 16)": 0.5568487644195557, "(14, 0)": 0.45778951048851013, "(14, 16)": 0.5470981597900391, "(16, 0)": 0.5568487644195557, "(16, 16)": 0.5345863103866577, "(18, 0)": 0.5345863103866577, "(18, 16)": 0.5412977933883667, "(20, 0)": 0.5412977933883667, "(20, 16)": 0.45778951048851013, "(22, 0)": 0.45778951048851013, "(22, 16)": 0.5412977933883667, "(24, 0)": 0.5345863103866577, "(24, 16)": 0.5412977933883667, "(26, 0)": 0.5345863103866577, "(26, 16)": 0.5345863103866577, "(28, 0)": 0.5345863103866577, "(28, 16)": 0.45778951048851013, "(30, 0)": 0.5345863103866577, "(30, 16)": 0.5345863103866577}, "r_span": [829, 836], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00027060508728027344}}]}, {"id": "7317", "source_id": "14090", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Brasil Arts Cafe is a local restaurant located in Santa Barbara, California, offering a unique blend of Brazilian cuisine and cultural experiences. With a rating of 4.0 stars, the business provides a cozy atmosphere, free WiFi, and outdoor seating. Customers have praised the restaurant for its delicious food, friendly prices, and hospitable staff. Reviewers have particularly enjoyed the menu options, including juice bars, smoothies, breakfast and brunch items, salads, acai bowls, and traditional Brazilian dishes. Some have also appreciated the restaurant's cultural ambiance, highlighting the festive atmosphere and live drumming classes offered in the past. Despite some minor issues with the building's appearance, customers have consistently recommended Brasil Arts Cafe for its high-quality food, friendly service, and welcoming environment.", "response_spans": [[0, 510], [501, 851]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6066271066665649, "(0, 16)": 0.6066271066665649, "(2, 0)": 0.6869276762008667, "(2, 16)": 0.6869276762008667, "(4, 0)": 0.6869276762008667, "(4, 16)": 0.6066271066665649, "(6, 0)": 0.6869276762008667, "(6, 16)": 0.7812395691871643, "(8, 0)": 0.705740213394165, "(8, 16)": 0.6869276762008667, "(10, 0)": 0.6869276762008667, "(10, 16)": 0.6869276762008667, "(12, 0)": 0.6066271066665649, "(12, 16)": 0.7812395691871643, "(14, 0)": 0.705740213394165, "(14, 16)": 0.6869276762008667, "(16, 0)": 0.7812395691871643, "(16, 16)": 0.6869276762008667, "(18, 0)": 0.41662806272506714, "(18, 16)": 0.7812395691871643, "(20, 0)": 0.7812395691871643, "(20, 16)": 0.705740213394165, "(22, 0)": 0.41662806272506714, "(22, 16)": 0.7812395691871643, "(24, 0)": 0.705740213394165, "(24, 16)": 0.705740213394165, "(26, 0)": 0.41662806272506714, "(26, 16)": 0.5897366404533386, "(28, 0)": 0.41662806272506714, "(28, 16)": 0.41662806272506714, "(30, 0)": 0.41662806272506714, "(30, 16)": 0.41662806272506714}, "r_span": [910, 1027], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011130571365356445}}, {"prompt_attention_score": {"(0, 0)": 0.6381694078445435, "(0, 16)": 0.6381694078445435, "(2, 0)": 0.7167676091194153, "(2, 16)": 0.7167676091194153, "(4, 0)": 0.7167676091194153, "(4, 16)": 0.7167676091194153, "(6, 0)": 0.7167676091194153, "(6, 16)": 0.8091892004013062, "(8, 0)": 0.7167676091194153, "(8, 16)": 0.7167676091194153, "(10, 0)": 0.7167676091194153, "(10, 16)": 0.7167676091194153, "(12, 0)": 0.7167676091194153, "(12, 16)": 0.8091892004013062, "(14, 0)": 0.8091892004013062, "(14, 16)": 0.8091892004013062, "(16, 0)": 0.7167676091194153, "(16, 16)": 0.7167676091194153, "(18, 0)": 0.44654470682144165, "(18, 16)": 0.7167676091194153, "(20, 0)": 0.8091892004013062, "(20, 16)": 0.8091892004013062, "(22, 0)": 0.44654470682144165, "(22, 16)": 0.7167676091194153, "(24, 0)": 0.8091892004013062, "(24, 16)": 0.8091892004013062, "(26, 0)": 0.44654470682144165, "(26, 16)": 0.8091892004013062, "(28, 0)": 0.44654470682144165, "(28, 16)": 0.44654470682144165, "(30, 0)": 0.44654470682144165, "(30, 16)": 0.44654470682144165}, "r_span": [1026, 1093], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002301633358001709}}]}, {"id": "7323", "source_id": "14091", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Pascucci is a popular Gelato, Food, Restaurant, Italian, Vegetarian, Gluten-Free establishment located in Santa Barbara, California. With a rating of 3.5 stars, the business offers a cozy atmosphere and outdoor seating, making it a great spot for a casual meal or snack. While some customers have reported slower service during COVID times, the Cr√®me Br√ªl√©e has been highly rated by many reviewers. However, some patrons have had negative experiences with unpleasant service, particularly from the hostess, which may deter them from returning. Despite these incidents, Pascucci remains a beloved local spot for its delectable menu items and inviting ambiance.", "response_spans": [[0, 512], [494, 659]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7015274167060852, "(0, 16)": 0.7015274167060852, "(2, 0)": 0.7015274167060852, "(2, 16)": 0.7015274167060852, "(4, 0)": 0.7015274167060852, "(4, 16)": 0.7015274167060852, "(6, 0)": 0.7015274167060852, "(6, 16)": 0.7540420293807983, "(8, 0)": 0.7015274167060852, "(8, 16)": 0.7015274167060852, "(10, 0)": 0.7015274167060852, "(10, 16)": 0.7015274167060852, "(12, 0)": 0.7015274167060852, "(12, 16)": 0.5872649550437927, "(14, 0)": 0.4614502191543579, "(14, 16)": 0.7540420293807983, "(16, 0)": 0.5872649550437927, "(16, 16)": 0.7015274167060852, "(18, 0)": 0.7015274167060852, "(18, 16)": 0.5872649550437927, "(20, 0)": 0.5872649550437927, "(20, 16)": 0.4614502191543579, "(22, 0)": 0.4614502191543579, "(22, 16)": 0.5872649550437927, "(24, 0)": 0.4614502191543579, "(24, 16)": 0.5872649550437927, "(26, 0)": 0.4044342339038849, "(26, 16)": 0.5872649550437927, "(28, 0)": 0.4044342339038849, "(28, 16)": 0.4614502191543579, "(30, 0)": 0.4044342339038849, "(30, 16)": 0.4044342339038849}, "r_span": [968, 1089], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0015901923179626465}}, {"prompt_attention_score": {"(0, 0)": 0.6891010403633118, "(0, 16)": 0.6891010403633118, "(2, 0)": 0.6891010403633118, "(2, 16)": 0.6891010403633118, "(4, 0)": 0.6891010403633118, "(4, 16)": 0.6891010403633118, "(6, 0)": 0.6891010403633118, "(6, 16)": 0.5709429383277893, "(8, 0)": 0.6891010403633118, "(8, 16)": 0.6891010403633118, "(10, 0)": 0.6891010403633118, "(10, 16)": 0.6891010403633118, "(12, 0)": 0.6891010403633118, "(12, 16)": 0.5505543947219849, "(14, 0)": 0.4835606515407562, "(14, 16)": 0.44595885276794434, "(16, 0)": 0.6891010403633118, "(16, 16)": 0.6891010403633118, "(18, 0)": 0.5367569327354431, "(18, 16)": 0.5142388343811035, "(20, 0)": 0.6891010403633118, "(20, 16)": 0.4835606515407562, "(22, 0)": 0.3769078254699707, "(22, 16)": 0.6891010403633118, "(24, 0)": 0.4835606515407562, "(24, 16)": 0.6891010403633118, "(26, 0)": 0.3769078254699707, "(26, 16)": 0.4835606515407562, "(28, 0)": 0.3769078254699707, "(28, 16)": 0.4835606515407562, "(30, 0)": 0.3769078254699707, "(30, 16)": 0.3769078254699707}, "r_span": [1085, 1123], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004590153694152832}}]}, {"id": "7449", "source_id": "14113", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 598, "end": 613, "text": "outdoor seating", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No specific information about the availability of outdoor seating. (outdoor seating is marked as null)\nGenerative: \"...offers...outdoor seating\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Fernando's Churros:\n\nFernando's Churros is a popular dessert spot located in Santa Barbara, California. With a 4.5-star rating and numerous positive reviews, this local business is known for its delicious churros, which are hot, fluffy, and crispy. Customers rave about the generous portion sizes and high quality of the churros, with some even calling them the best they've ever had. The business is family-owned and operated, and the owner, Fernando, is friendly and accommodating. Fernando's Churros offers both indoor and outdoor seating, as well as catering services for large events. Despite being a small, unassuming truck, Fernando's has gained a loyal following among locals and visitors alike, with many returning for their churro fix time and time again.", "response_spans": [[0, 91], [93, 597], [582, 837]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.49646517634391785, "(0, 16)": 0.6294009685516357, "(2, 0)": 0.49646517634391785, "(2, 16)": 0.49646517634391785, "(4, 0)": 0.49646517634391785, "(4, 16)": 0.49646517634391785, "(6, 0)": 0.6294009685516357, "(6, 16)": 0.6260584592819214, "(8, 0)": 0.49646517634391785, "(8, 16)": 0.6294009685516357, "(10, 0)": 0.6260584592819214, "(10, 16)": 0.6260584592819214, "(12, 0)": 0.5351667404174805, "(12, 16)": 0.6260584592819214, "(14, 0)": 0.6294009685516357, "(14, 16)": 0.6260584592819214, "(16, 0)": 0.6260584592819214, "(16, 16)": 0.6294009685516357, "(18, 0)": 0.6294009685516357, "(18, 16)": 0.6260584592819214, "(20, 0)": 0.6260584592819214, "(20, 16)": 0.560441792011261, "(22, 0)": 0.560441792011261, "(22, 16)": 0.6260584592819214, "(24, 0)": 0.6294009685516357, "(24, 16)": 0.6260584592819214, "(26, 0)": 0.6260584592819214, "(26, 16)": 0.6294009685516357, "(28, 0)": 0.6260584592819214, "(28, 16)": 0.6294009685516357, "(30, 0)": 0.6260584592819214, "(30, 16)": 0.6260584592819214}, "r_span": [1049, 1072], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00023853778839111328}}, {"prompt_attention_score": {"(0, 0)": 0.618674099445343, "(0, 16)": 0.618674099445343, "(2, 0)": 0.618674099445343, "(2, 16)": 0.7394986152648926, "(4, 0)": 0.618674099445343, "(4, 16)": 0.618674099445343, "(6, 0)": 0.618674099445343, "(6, 16)": 0.6518744230270386, "(8, 0)": 0.618674099445343, "(8, 16)": 0.618674099445343, "(10, 0)": 0.6518744230270386, "(10, 16)": 0.618674099445343, "(12, 0)": 0.7394986152648926, "(12, 16)": 0.6518744230270386, "(14, 0)": 0.6153093576431274, "(14, 16)": 0.6518744230270386, "(16, 0)": 0.6518744230270386, "(16, 16)": 0.41438692808151245, "(18, 0)": 0.7394986152648926, "(18, 16)": 0.6518744230270386, "(20, 0)": 0.6518744230270386, "(20, 16)": 0.6153093576431274, "(22, 0)": 0.41438692808151245, "(22, 16)": 0.6518744230270386, "(24, 0)": 0.7394986152648926, "(24, 16)": 0.6518744230270386, "(26, 0)": 0.41438692808151245, "(26, 16)": 0.6875823140144348, "(28, 0)": 0.41438692808151245, "(28, 16)": 0.7394986152648926, "(30, 0)": 0.41438692808151245, "(30, 16)": 0.41438692808151245}, "r_span": [1074, 1198], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001984238624572754}}, {"prompt_attention_score": {"(0, 0)": 0.6641240119934082, "(0, 16)": 0.6641240119934082, "(2, 0)": 0.6641240119934082, "(2, 16)": 0.6641240119934082, "(4, 0)": 0.6641240119934082, "(4, 16)": 0.6641240119934082, "(6, 0)": 0.6641240119934082, "(6, 16)": 0.6511775255203247, "(8, 0)": 0.6641240119934082, "(8, 16)": 0.6641240119934082, "(10, 0)": 0.6641240119934082, "(10, 16)": 0.6641240119934082, "(12, 0)": 0.7152290344238281, "(12, 16)": 0.6641240119934082, "(14, 0)": 0.6511775255203247, "(14, 16)": 0.6641240119934082, "(16, 0)": 0.6641240119934082, "(16, 16)": 0.7152290344238281, "(18, 0)": 0.7152290344238281, "(18, 16)": 0.6411991119384766, "(20, 0)": 0.6641240119934082, "(20, 16)": 0.6511775255203247, "(22, 0)": 0.43718457221984863, "(22, 16)": 0.6641240119934082, "(24, 0)": 0.7152290344238281, "(24, 16)": 0.6641240119934082, "(26, 0)": 0.43718457221984863, "(26, 16)": 0.7152290344238281, "(28, 0)": 0.43718457221984863, "(28, 16)": 0.7152290344238281, "(30, 0)": 0.43718457221984863, "(30, 16)": 0.43718457221984863}, "r_span": [1195, 1255], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -9.518861770629883e-05}}]}, {"id": "7509", "source_id": "14123", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 638, "end": 658, "text": "service can be slow.", "meta": "Original: No mention that the service can be slow", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Sushi GoGo:\n\nSushi GoGo is a popular sushi restaurant located in Santa Barbara, California, with a rating of 3.5 stars. The restaurant offers a variety of sushi options, including traditional rolls and hand rolls, as well as poke bowls. Customers have praised the freshness and quality of the food, with many mentioning their favorites being the rainbow roll and CA roll. The restaurant also has outdoor seating with a beautiful view of the harbor. However, some customers have noted that the atmosphere inside the restaurant is not particularly impressive, and the service can be slow. Despite these minor drawbacks, Sushi GoGo is a great option for those looking for fresh and affordable sushi in a convenient location.", "response_spans": [[0, 83], [85, 586], [576, 793]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5344933271408081, "(0, 16)": 0.5344933271408081, "(2, 0)": 0.5344933271408081, "(2, 16)": 0.4449225664138794, "(4, 0)": 0.5344933271408081, "(4, 16)": 0.4449225664138794, "(6, 0)": 0.5344933271408081, "(6, 16)": 0.6471354961395264, "(8, 0)": 0.5740084052085876, "(8, 16)": 0.4449225664138794, "(10, 0)": 0.6471354961395264, "(10, 16)": 0.6471354961395264, "(12, 0)": 0.5421286821365356, "(12, 16)": 0.6471354961395264, "(14, 0)": 0.5344933271408081, "(14, 16)": 0.6471354961395264, "(16, 0)": 0.6471354961395264, "(16, 16)": 0.6471354961395264, "(18, 0)": 0.5344933271408081, "(18, 16)": 0.6471354961395264, "(20, 0)": 0.6471354961395264, "(20, 16)": 0.5344933271408081, "(22, 0)": 0.5344933271408081, "(22, 16)": 0.6471354961395264, "(24, 0)": 0.5344933271408081, "(24, 16)": 0.6471354961395264, "(26, 0)": 0.6471354961395264, "(26, 16)": 0.6061858534812927, "(28, 0)": 0.6471354961395264, "(28, 16)": 0.5344933271408081, "(30, 0)": 0.6471354961395264, "(30, 16)": 0.6471354961395264}, "r_span": [764, 786], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006221532821655273}}, {"prompt_attention_score": {"(0, 0)": 0.6805101633071899, "(0, 16)": 0.6805101633071899, "(2, 0)": 0.6157918572425842, "(2, 16)": 0.6157918572425842, "(4, 0)": 0.6805101633071899, "(4, 16)": 0.6157918572425842, "(6, 0)": 0.6805101633071899, "(6, 16)": 0.7592946290969849, "(8, 0)": 0.6805101633071899, "(8, 16)": 0.6805101633071899, "(10, 0)": 0.6551553606987, "(10, 16)": 0.6805101633071899, "(12, 0)": 0.6805101633071899, "(12, 16)": 0.6805101633071899, "(14, 0)": 0.6805101633071899, "(14, 16)": 0.6805101633071899, "(16, 0)": 0.6805101633071899, "(16, 16)": 0.6805101633071899, "(18, 0)": 0.44052648544311523, "(18, 16)": 0.7592946290969849, "(20, 0)": 0.7592946290969849, "(20, 16)": 0.6805101633071899, "(22, 0)": 0.44052648544311523, "(22, 16)": 0.6551553606987, "(24, 0)": 0.6805101633071899, "(24, 16)": 0.6551553606987, "(26, 0)": 0.44052648544311523, "(26, 16)": 0.6805101633071899, "(28, 0)": 0.44052648544311523, "(28, 16)": 0.6805101633071899, "(30, 0)": 0.44052648544311523, "(30, 16)": 0.44052648544311523}, "r_span": [788, 903], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0015083551406860352}}, {"prompt_attention_score": {"(0, 0)": 0.6251359581947327, "(0, 16)": 0.6251359581947327, "(2, 0)": 0.582155704498291, "(2, 16)": 0.582155704498291, "(4, 0)": 0.582155704498291, "(4, 16)": 0.582155704498291, "(6, 0)": 0.6251359581947327, "(6, 16)": 0.6373454928398132, "(8, 0)": 0.6251359581947327, "(8, 16)": 0.6251359581947327, "(10, 0)": 0.6251359581947327, "(10, 16)": 0.6251359581947327, "(12, 0)": 0.6251359581947327, "(12, 16)": 0.6251359581947327, "(14, 0)": 0.6251359581947327, "(14, 16)": 0.6251359581947327, "(16, 0)": 0.6251359581947327, "(16, 16)": 0.582155704498291, "(18, 0)": 0.4750189185142517, "(18, 16)": 0.6171842217445374, "(20, 0)": 0.6251359581947327, "(20, 16)": 0.6251359581947327, "(22, 0)": 0.4750189185142517, "(22, 16)": 0.6251359581947327, "(24, 0)": 0.6251359581947327, "(24, 16)": 0.6251359581947327, "(26, 0)": 0.4750189185142517, "(26, 16)": 0.6251359581947327, "(28, 0)": 0.4750189185142517, "(28, 16)": 0.6251359581947327, "(30, 0)": 0.4750189185142517, "(30, 16)": 0.4750189185142517}, "r_span": [902, 949], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 3.4868717193603516e-05}}]}, {"id": "7581", "source_id": "14135", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 693, "end": 724, "text": "with extended hours on weekends", "meta": "EVIDENT CONFLICT\nOriginal: Monday to Sunday: \"9:0-21:0\" it has the same closing hours during weekends.\nGenerative: \"with extended hours on weekends\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Del Pueblo Cafe is a local Mexican restaurant located in Santa Barbara, California. The establishment has a rating of 4.0 out of 5 stars and offers both indoor and outdoor seating options. According to customer reviews, the restaurant serves authentic Mexican dishes with a cozy and comfortable atmosphere. However, some customers have reported issues with the quality of their orders, including cold food and lackluster drinks. Despite these complaints, many reviewers have praised the restaurant's ambiance and decor, as well as its unique offerings such as hot Mexican chocolate served in hearty mugs. The restaurant's hours of operation are Monday through Sunday from 9:00 AM to 21:00 PM, with extended hours on weekends.", "response_spans": [[0, 512], [500, 725]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.580117404460907, "(0, 16)": 0.580117404460907, "(2, 0)": 0.580117404460907, "(2, 16)": 0.580117404460907, "(4, 0)": 0.580117404460907, "(4, 16)": 0.580117404460907, "(6, 0)": 0.580117404460907, "(6, 16)": 0.7560383677482605, "(8, 0)": 0.580117404460907, "(8, 16)": 0.580117404460907, "(10, 0)": 0.6429334282875061, "(10, 16)": 0.580117404460907, "(12, 0)": 0.580117404460907, "(12, 16)": 0.6429334282875061, "(14, 0)": 0.6321448087692261, "(14, 16)": 0.4262295365333557, "(16, 0)": 0.5142223238945007, "(16, 16)": 0.580117404460907, "(18, 0)": 0.580117404460907, "(18, 16)": 0.7560383677482605, "(20, 0)": 0.7560383677482605, "(20, 16)": 0.6321448087692261, "(22, 0)": 0.6321448087692261, "(22, 16)": 0.5142223238945007, "(24, 0)": 0.6321448087692261, "(24, 16)": 0.6429334282875061, "(26, 0)": 0.40861791372299194, "(26, 16)": 0.6321448087692261, "(28, 0)": 0.40861791372299194, "(28, 16)": 0.6321448087692261, "(30, 0)": 0.40861791372299194, "(30, 16)": 0.40861791372299194}, "r_span": [1060, 1167], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001604914665222168}}, {"prompt_attention_score": {"(0, 0)": 0.5808756351470947, "(0, 16)": 0.5808756351470947, "(2, 0)": 0.5808756351470947, "(2, 16)": 0.5808756351470947, "(4, 0)": 0.5808756351470947, "(4, 16)": 0.5808756351470947, "(6, 0)": 0.5808756351470947, "(6, 16)": 0.6249822378158569, "(8, 0)": 0.5808756351470947, "(8, 16)": 0.5808756351470947, "(10, 0)": 0.5808756351470947, "(10, 16)": 0.5808756351470947, "(12, 0)": 0.5808756351470947, "(12, 16)": 0.6249822378158569, "(14, 0)": 0.6998290419578552, "(14, 16)": 0.6249822378158569, "(16, 0)": 0.5808756351470947, "(16, 16)": 0.5808756351470947, "(18, 0)": 0.6998290419578552, "(18, 16)": 0.6249822378158569, "(20, 0)": 0.6249822378158569, "(20, 16)": 0.6998290419578552, "(22, 0)": 0.6998290419578552, "(22, 16)": 0.6579552888870239, "(24, 0)": 0.6998290419578552, "(24, 16)": 0.6579552888870239, "(26, 0)": 0.41510793566703796, "(26, 16)": 0.6998290419578552, "(28, 0)": 0.41510793566703796, "(28, 16)": 0.6998290419578552, "(30, 0)": 0.41510793566703796, "(30, 16)": 0.41510793566703796}, "r_span": [1165, 1224], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -7.390975952148438e-05}}]}, {"id": "7599", "source_id": "14138", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 552, "end": 675, "text": "However, some customers have noted that the restaurant can be difficult to find parking near, especially during peak hours.", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the restaurant can be difficult to find parking near, especially during peak hours, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Jeannine's American Bakery Restaurant in Santa Barbara, CA:\n\nJeannine's American Bakery Restaurant is a popular breakfast and brunch spot located in the heart of Santa Barbara. With a rating of 4.0 stars, the restaurant offers a cozy atmosphere, free WiFi, and outdoor seating. Customers have praised the delicious food, excellent service, and relaxed ambiance. Particularly, the banana Kahlua French toast has been highly recommended, with one customer labeling it a \"must-try.\" However, some customers have noted that the restaurant can be difficult to find parking near, especially during peak hours. Overall, Jeannine's appears to be a great option for those looking for a tasty breakfast or brunch in a charming setting.", "response_spans": [[0, 131], [133, 639], [624, 797]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5787465572357178, "(0, 16)": 0.5787465572357178, "(2, 0)": 0.5362862348556519, "(2, 16)": 0.5787465572357178, "(4, 0)": 0.5362862348556519, "(4, 16)": 0.5362862348556519, "(6, 0)": 0.5362862348556519, "(6, 16)": 0.6408385634422302, "(8, 0)": 0.7310627102851868, "(8, 16)": 0.5787465572357178, "(10, 0)": 0.6408385634422302, "(10, 16)": 0.6408385634422302, "(12, 0)": 0.5362862348556519, "(12, 16)": 0.7310627102851868, "(14, 0)": 0.5787465572357178, "(14, 16)": 0.6408385634422302, "(16, 0)": 0.6408385634422302, "(16, 16)": 0.5173221230506897, "(18, 0)": 0.5362862348556519, "(18, 16)": 0.6408385634422302, "(20, 0)": 0.6408385634422302, "(20, 16)": 0.5362862348556519, "(22, 0)": 0.5362862348556519, "(22, 16)": 0.6408385634422302, "(24, 0)": 0.5362862348556519, "(24, 16)": 0.6408385634422302, "(26, 0)": 0.6408385634422302, "(26, 16)": 0.5362862348556519, "(28, 0)": 0.6408385634422302, "(28, 16)": 0.5362862348556519, "(30, 0)": 0.6408385634422302, "(30, 16)": 0.6408385634422302}, "r_span": [1072, 1105], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006146430969238281}}, {"prompt_attention_score": {"(0, 0)": 0.7855714559555054, "(0, 16)": 0.7855714559555054, "(2, 0)": 0.71030592918396, "(2, 16)": 0.71030592918396, "(4, 0)": 0.71030592918396, "(4, 16)": 0.71030592918396, "(6, 0)": 0.7855714559555054, "(6, 16)": 0.7093310356140137, "(8, 0)": 0.7855714559555054, "(8, 16)": 0.71030592918396, "(10, 0)": 0.7855714559555054, "(10, 16)": 0.7855714559555054, "(12, 0)": 0.7855714559555054, "(12, 16)": 0.5253691673278809, "(14, 0)": 0.71030592918396, "(14, 16)": 0.7855714559555054, "(16, 0)": 0.5253691673278809, "(16, 16)": 0.71030592918396, "(18, 0)": 0.7855714559555054, "(18, 16)": 0.5253691673278809, "(20, 0)": 0.5253691673278809, "(20, 16)": 0.71030592918396, "(22, 0)": 0.7855714559555054, "(22, 16)": 0.5253691673278809, "(24, 0)": 0.7855714559555054, "(24, 16)": 0.7469793558120728, "(26, 0)": 0.4159601926803589, "(26, 16)": 0.7855714559555054, "(28, 0)": 0.4159601926803589, "(28, 16)": 0.7855714559555054, "(30, 0)": 0.4159601926803589, "(30, 16)": 0.4159601926803589}, "r_span": [1107, 1227], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001081705093383789}}, {"prompt_attention_score": {"(0, 0)": 0.7801223397254944, "(0, 16)": 0.7801223397254944, "(2, 0)": 0.7068455219268799, "(2, 16)": 0.7801223397254944, "(4, 0)": 0.7068455219268799, "(4, 16)": 0.7068455219268799, "(6, 0)": 0.7801223397254944, "(6, 16)": 0.6503520607948303, "(8, 0)": 0.7801223397254944, "(8, 16)": 0.7068455219268799, "(10, 0)": 0.7801223397254944, "(10, 16)": 0.7801223397254944, "(12, 0)": 0.7801223397254944, "(12, 16)": 0.730237603187561, "(14, 0)": 0.7068455219268799, "(14, 16)": 0.7801223397254944, "(16, 0)": 0.730237603187561, "(16, 16)": 0.7068455219268799, "(18, 0)": 0.7801223397254944, "(18, 16)": 0.5329985618591309, "(20, 0)": 0.5329985618591309, "(20, 16)": 0.7068455219268799, "(22, 0)": 0.7801223397254944, "(22, 16)": 0.5329985618591309, "(24, 0)": 0.7801223397254944, "(24, 16)": 0.5329985618591309, "(26, 0)": 0.4320593476295471, "(26, 16)": 0.7801223397254944, "(28, 0)": 0.4320593476295471, "(28, 16)": 0.7801223397254944, "(30, 0)": 0.4320593476295471, "(30, 16)": 0.4320593476295471}, "r_span": [1224, 1266], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0004259943962097168}}]}, {"id": "7779", "source_id": "14169", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 83, "end": 154, "text": "some patrons have praised the restaurant's food quality and convenience", "meta": null, "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Domino's Pizza in Carpinteria, CA has received mixed reviews from customers. While some patrons have praised the restaurant's food quality and convenience, others have experienced disappointment with incorrect orders, poor customer service, and high prices. One reviewer noted that their cinnamon twist order often comes with only one icing despite requesting two, while another stated that their pizza was very bad and expensive. A third reviewer had a negative experience with the ordering process, as the price increased upon pickup despite being promised a special deal over the phone. Despite these issues, Domino's has been awarded 2.5 stars and is considered good for groups and takeout.", "response_spans": [[0, 507], [492, 694]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6619957685470581, "(0, 16)": 0.6619957685470581, "(2, 0)": 0.6619957685470581, "(2, 16)": 0.6619957685470581, "(4, 0)": 0.6619957685470581, "(4, 16)": 0.6619957685470581, "(6, 0)": 0.6619957685470581, "(6, 16)": 0.6314214468002319, "(8, 0)": 0.6619957685470581, "(8, 16)": 0.6619957685470581, "(10, 0)": 0.6257866621017456, "(10, 16)": 0.6257866621017456, "(12, 0)": 0.6619957685470581, "(12, 16)": 0.6314214468002319, "(14, 0)": 0.6619957685470581, "(14, 16)": 0.4143751561641693, "(16, 0)": 0.6314214468002319, "(16, 16)": 0.6619957685470581, "(18, 0)": 0.6619957685470581, "(18, 16)": 0.6257866621017456, "(20, 0)": 0.6257866621017456, "(20, 16)": 0.6619957685470581, "(22, 0)": 0.6619957685470581, "(22, 16)": 0.6257866621017456, "(24, 0)": 0.6619957685470581, "(24, 16)": 0.6257866621017456, "(26, 0)": 0.4481185972690582, "(26, 16)": 0.6314214468002319, "(28, 0)": 0.4481185972690582, "(28, 16)": 0.6619957685470581, "(30, 0)": 0.4481185972690582, "(30, 16)": 0.4481185972690582}, "r_span": [972, 1078], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002477705478668213}}, {"prompt_attention_score": {"(0, 0)": 0.6792908310890198, "(0, 16)": 0.6126837730407715, "(2, 0)": 0.6792908310890198, "(2, 16)": 0.6792908310890198, "(4, 0)": 0.6792908310890198, "(4, 16)": 0.6792908310890198, "(6, 0)": 0.6792908310890198, "(6, 16)": 0.5694454312324524, "(8, 0)": 0.6792908310890198, "(8, 16)": 0.6792908310890198, "(10, 0)": 0.6792908310890198, "(10, 16)": 0.6792908310890198, "(12, 0)": 0.6792908310890198, "(12, 16)": 0.7322516441345215, "(14, 0)": 0.6792908310890198, "(14, 16)": 0.46567821502685547, "(16, 0)": 0.6792908310890198, "(16, 16)": 0.6792908310890198, "(18, 0)": 0.6792908310890198, "(18, 16)": 0.6126837730407715, "(20, 0)": 0.7322516441345215, "(20, 16)": 0.6792908310890198, "(22, 0)": 0.6792908310890198, "(22, 16)": 0.7322516441345215, "(24, 0)": 0.6792908310890198, "(24, 16)": 0.7322516441345215, "(26, 0)": 0.4729517996311188, "(26, 16)": 0.6792908310890198, "(28, 0)": 0.4729517996311188, "(28, 16)": 0.6792908310890198, "(30, 0)": 0.4729517996311188, "(30, 16)": 0.4729517996311188}, "r_span": [1075, 1119], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005983114242553711}}]}, {"id": "7785", "source_id": "14171", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 557, "end": 578, "text": "good value for money.", "meta": "This might be true but it was not explicitly mentioned in the structured data\n", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Mesa Verde is a local business in Santa Barbara, California that offers a variety of services and products, including garage door services, restaurants, live/raw food, food, home services, Mediterranean cuisine, keys/locksmiths, burgers, vegetarian options, juice bars/smoothies, vegan options, and salads. The business has a rating of 4.5 stars and offers free WiFi. According to customer reviews, the business has a positive atmosphere, with some reviewers praising the fresh and delicious food, friendly staff, and good value for money. However, one reviewer found the food to be overpriced and not particularly flavorful, while another reviewer noted that the prices had increased since their last visit and the quality had decreased. Overall, Mesa Verde appears to offer a unique and enjoyable dining experience with a focus on fresh and innovative menu options.", "response_spans": [[0, 510], [498, 906]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6110174655914307, "(0, 16)": 0.6110174655914307, "(2, 0)": 0.6110174655914307, "(2, 16)": 0.6110174655914307, "(4, 0)": 0.5059733390808105, "(4, 16)": 0.6110174655914307, "(6, 0)": 0.6110174655914307, "(6, 16)": 0.8220012187957764, "(8, 0)": 0.6110174655914307, "(8, 16)": 0.6110174655914307, "(10, 0)": 0.6110174655914307, "(10, 16)": 0.6110174655914307, "(12, 0)": 0.6110174655914307, "(12, 16)": 0.8220012187957764, "(14, 0)": 0.41236060857772827, "(14, 16)": 0.8220012187957764, "(16, 0)": 0.5505874156951904, "(16, 16)": 0.6110174655914307, "(18, 0)": 0.6110174655914307, "(18, 16)": 0.8220012187957764, "(20, 0)": 0.8220012187957764, "(20, 16)": 0.41236060857772827, "(22, 0)": 0.41236060857772827, "(22, 16)": 0.8220012187957764, "(24, 0)": 0.41236060857772827, "(24, 16)": 0.8220012187957764, "(26, 0)": 0.5505874156951904, "(26, 16)": 0.6110174655914307, "(28, 0)": 0.5505874156951904, "(28, 16)": 0.41236060857772827, "(30, 0)": 0.5505874156951904, "(30, 16)": 0.5505874156951904}, "r_span": [1164, 1287], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00012570619583129883}}, {"prompt_attention_score": {"(0, 0)": 0.6761223077774048, "(0, 16)": 0.7117477655410767, "(2, 0)": 0.7117477655410767, "(2, 16)": 0.7117477655410767, "(4, 0)": 0.7117477655410767, "(4, 16)": 0.7117477655410767, "(6, 0)": 0.7117477655410767, "(6, 16)": 0.698958694934845, "(8, 0)": 0.6761223077774048, "(8, 16)": 0.7117477655410767, "(10, 0)": 0.7117477655410767, "(10, 16)": 0.7117477655410767, "(12, 0)": 0.7117477655410767, "(12, 16)": 0.7912902235984802, "(14, 0)": 0.5696272850036621, "(14, 16)": 0.5091735124588013, "(16, 0)": 0.7117477655410767, "(16, 16)": 0.7117477655410767, "(18, 0)": 0.6761223077774048, "(18, 16)": 0.698958694934845, "(20, 0)": 0.7117477655410767, "(20, 16)": 0.5696272850036621, "(22, 0)": 0.5696272850036621, "(22, 16)": 0.6761223077774048, "(24, 0)": 0.5696272850036621, "(24, 16)": 0.7117477655410767, "(26, 0)": 0.4782220721244812, "(26, 16)": 0.5696272850036621, "(28, 0)": 0.4782220721244812, "(28, 16)": 0.5696272850036621, "(30, 0)": 0.5696272850036621, "(30, 16)": 0.4782220721244812}, "r_span": [1285, 1372], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0016726255416870117}}]}, {"id": "7917", "source_id": "14194", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 627, "end": 664, "text": "The prices are considered reasonable,", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mantioned*\nGenerative: \"The prices are considered reasonable,\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Zen Yai Thai Cuisine is a local Thai restaurant located in Santa Barbara, California. The restaurant offers a variety of dishes including Thai, American New, Pop-Up Restaurants, and Asian Fusion. The business has a rating of 4.0 stars and the review information suggests that the quality of the food is somewhat inconsistent, with some reviewers finding it to be subpar and others enjoying it. The restaurant has good service, according to the reviews, and offers takeout options. The menu includes items such as pad thai, pineapple fried rice, egg rolls, and papaya salad, among others. The prices are considered reasonable, and the atmosphere is casual.", "response_spans": [[0, 510], [492, 694]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6328995227813721, "(0, 16)": 0.6328995227813721, "(2, 0)": 0.6328995227813721, "(2, 16)": 0.6328995227813721, "(4, 0)": 0.6328995227813721, "(4, 16)": 0.6328995227813721, "(6, 0)": 0.6847094297409058, "(6, 16)": 0.841902494430542, "(8, 0)": 0.6847094297409058, "(8, 16)": 0.6847094297409058, "(10, 0)": 0.6847094297409058, "(10, 16)": 0.6847094297409058, "(12, 0)": 0.6847094297409058, "(12, 16)": 0.841902494430542, "(14, 0)": 0.6847094297409058, "(14, 16)": 0.841902494430542, "(16, 0)": 0.5720950961112976, "(16, 16)": 0.6847094297409058, "(18, 0)": 0.6847094297409058, "(18, 16)": 0.841902494430542, "(20, 0)": 0.841902494430542, "(20, 16)": 0.6847094297409058, "(22, 0)": 0.6847094297409058, "(22, 16)": 0.841902494430542, "(24, 0)": 0.6847094297409058, "(24, 16)": 0.841902494430542, "(26, 0)": 0.5720950961112976, "(26, 16)": 0.6847094297409058, "(28, 0)": 0.5720950961112976, "(28, 16)": 0.6847094297409058, "(30, 0)": 0.5720950961112976, "(30, 16)": 0.5720950961112976}, "r_span": [918, 1034], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001618027687072754}}, {"prompt_attention_score": {"(0, 0)": 0.6941692233085632, "(0, 16)": 0.6941692233085632, "(2, 0)": 0.644986629486084, "(2, 16)": 0.644986629486084, "(4, 0)": 0.644986629486084, "(4, 16)": 0.644986629486084, "(6, 0)": 0.644986629486084, "(6, 16)": 0.7841001152992249, "(8, 0)": 0.6941692233085632, "(8, 16)": 0.6941692233085632, "(10, 0)": 0.6941692233085632, "(10, 16)": 0.644986629486084, "(12, 0)": 0.6941692233085632, "(12, 16)": 0.7841001152992249, "(14, 0)": 0.6941692233085632, "(14, 16)": 0.47085490822792053, "(16, 0)": 0.6941692233085632, "(16, 16)": 0.644986629486084, "(18, 0)": 0.6941692233085632, "(18, 16)": 0.7841001152992249, "(20, 0)": 0.7841001152992249, "(20, 16)": 0.6941692233085632, "(22, 0)": 0.6941692233085632, "(22, 16)": 0.7841001152992249, "(24, 0)": 0.6941692233085632, "(24, 16)": 0.7841001152992249, "(26, 0)": 0.42849206924438477, "(26, 16)": 0.6941692233085632, "(28, 0)": 0.42849206924438477, "(28, 16)": 0.6941692233085632, "(30, 0)": 0.42849206924438477, "(30, 16)": 0.42849206924438477}, "r_span": [1031, 1079], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0006653070449829102}}]}, {"id": "7953", "source_id": "14200", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 523, "end": 578, "text": "One reviewer highlighted the excellent customer service", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that a review said 'excellent customer service' which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Santa Barbara's Wood Fired Pizza:\n\nSanta Barbara's Wood Fired Pizza is a popular restaurant located in Santa Barbara, California, serving food, sandwiches, and pizza. With a rating of 4.0 out of 5 stars, the business has received positive reviews for its quality pizzas and late hours of operation. Some customers have reported issues with empty stores after placing online orders, while others have praised the light and delicious thin-crust pizzas. One reviewer highlighted the excellent customer service and recommended the pesto pizza, which is said to be addictive and of high quality. However, there have been some complaints regarding payment processing and food availability. Overall, Santa Barbara's Wood Fired Pizza appears to offer tasty and satisfying meals, but may need to improve upon its online ordering system and store operations.", "response_spans": [[0, 105], [107, 617], [599, 920]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5836872458457947, "(0, 16)": 0.5836872458457947, "(2, 0)": 0.5836872458457947, "(2, 16)": 0.5836872458457947, "(4, 0)": 0.5836872458457947, "(4, 16)": 0.5836872458457947, "(6, 0)": 0.5836872458457947, "(6, 16)": 0.6904569268226624, "(8, 0)": 0.4685847759246826, "(8, 16)": 0.5836872458457947, "(10, 0)": 0.6057077050209045, "(10, 16)": 0.6057077050209045, "(12, 0)": 0.5836872458457947, "(12, 16)": 0.6057077050209045, "(14, 0)": 0.5836872458457947, "(14, 16)": 0.6057077050209045, "(16, 0)": 0.6057077050209045, "(16, 16)": 0.5836872458457947, "(18, 0)": 0.5836872458457947, "(18, 16)": 0.6057077050209045, "(20, 0)": 0.6057077050209045, "(20, 16)": 0.5836872458457947, "(22, 0)": 0.5836872458457947, "(22, 16)": 0.6057077050209045, "(24, 0)": 0.5836872458457947, "(24, 16)": 0.6057077050209045, "(26, 0)": 0.6057077050209045, "(26, 16)": 0.5836872458457947, "(28, 0)": 0.6057077050209045, "(28, 16)": 0.5836872458457947, "(30, 0)": 0.6057077050209045, "(30, 16)": 0.6057077050209045}, "r_span": [728, 754], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 5.984306335449219e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7052617073059082, "(0, 16)": 0.7052617073059082, "(2, 0)": 0.7052617073059082, "(2, 16)": 0.7052617073059082, "(4, 0)": 0.7052617073059082, "(4, 16)": 0.7052617073059082, "(6, 0)": 0.7052617073059082, "(6, 16)": 0.7694641351699829, "(8, 0)": 0.7052617073059082, "(8, 16)": 0.7052617073059082, "(10, 0)": 0.5267219543457031, "(10, 16)": 0.7052617073059082, "(12, 0)": 0.7052617073059082, "(12, 16)": 0.7052617073059082, "(14, 0)": 0.7052617073059082, "(14, 16)": 0.7052617073059082, "(16, 0)": 0.7052617073059082, "(16, 16)": 0.7052617073059082, "(18, 0)": 0.4225350618362427, "(18, 16)": 0.7694641351699829, "(20, 0)": 0.7052617073059082, "(20, 16)": 0.7052617073059082, "(22, 0)": 0.7052617073059082, "(22, 16)": 0.7052617073059082, "(24, 0)": 0.7052617073059082, "(24, 16)": 0.7052617073059082, "(26, 0)": 0.4225350618362427, "(26, 16)": 0.7052617073059082, "(28, 0)": 0.4225350618362427, "(28, 16)": 0.7052617073059082, "(30, 0)": 0.4225350618362427, "(30, 16)": 0.4225350618362427}, "r_span": [756, 869], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.001477956771850586}}, {"prompt_attention_score": {"(0, 0)": 0.7542330026626587, "(0, 16)": 0.7542330026626587, "(2, 0)": 0.7542330026626587, "(2, 16)": 0.7542330026626587, "(4, 0)": 0.7542330026626587, "(4, 16)": 0.7542330026626587, "(6, 0)": 0.7542330026626587, "(6, 16)": 0.7042798399925232, "(8, 0)": 0.7542330026626587, "(8, 16)": 0.7542330026626587, "(10, 0)": 0.7240692973136902, "(10, 16)": 0.7542330026626587, "(12, 0)": 0.7542330026626587, "(12, 16)": 0.7542330026626587, "(14, 0)": 0.7542330026626587, "(14, 16)": 0.7542330026626587, "(16, 0)": 0.7542330026626587, "(16, 16)": 0.7542330026626587, "(18, 0)": 0.43935179710388184, "(18, 16)": 0.7542330026626587, "(20, 0)": 0.7542330026626587, "(20, 16)": 0.7542330026626587, "(22, 0)": 0.7542330026626587, "(22, 16)": 0.7542330026626587, "(24, 0)": 0.7542330026626587, "(24, 16)": 0.7542330026626587, "(26, 0)": 0.43935179710388184, "(26, 16)": 0.7542330026626587, "(28, 0)": 0.43935179710388184, "(28, 16)": 0.7542330026626587, "(30, 0)": 0.43935179710388184, "(30, 16)": 0.43935179710388184}, "r_span": [864, 934], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0033342838287353516}}]}, {"id": "7983", "source_id": "14205", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 241, "end": 245, "text": "five", "meta": "HIGH INTRO OF NEW INFO\nThe source information does not provide the number of reviews the rating was based off of.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Jay C's Place is a popular restaurant located in Isla Vista, California, serving a variety of Asian cuisines including Chinese, hot pot, pan-Asian, Szechuan, and chicken wings. The restaurant is highly rated with a 4.5-star rating, based on five reviews. Customers praise the friendly owner and delicious homemade dumplings, Chicken popcorn, Taiwanese sausage, pork belly bowl, special carts noodle, and lamp skewers. While some customers find the prices to be a bit high, overall, the restaurant is known for its excellent food quality and welcoming atmosphere.", "response_spans": [[0, 509], [497, 562]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6512938141822815, "(0, 16)": 0.6512938141822815, "(2, 0)": 0.6512938141822815, "(2, 16)": 0.6512938141822815, "(4, 0)": 0.6512938141822815, "(4, 16)": 0.6512938141822815, "(6, 0)": 0.6512938141822815, "(6, 16)": 0.728874683380127, "(8, 0)": 0.728874683380127, "(8, 16)": 0.6512938141822815, "(10, 0)": 0.6512938141822815, "(10, 16)": 0.728874683380127, "(12, 0)": 0.728874683380127, "(12, 16)": 0.728874683380127, "(14, 0)": 0.728874683380127, "(14, 16)": 0.728874683380127, "(16, 0)": 0.728874683380127, "(16, 16)": 0.6512938141822815, "(18, 0)": 0.728874683380127, "(18, 16)": 0.8053060173988342, "(20, 0)": 0.728874683380127, "(20, 16)": 0.728874683380127, "(22, 0)": 0.4220775365829468, "(22, 16)": 0.728874683380127, "(24, 0)": 0.728874683380127, "(24, 16)": 0.728874683380127, "(26, 0)": 0.4220775365829468, "(26, 16)": 0.8053060173988342, "(28, 0)": 0.4220775365829468, "(28, 16)": 0.728874683380127, "(30, 0)": 0.4220775365829468, "(30, 16)": 0.4220775365829468}, "r_span": [713, 848], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0002657771110534668}}, {"prompt_attention_score": {"(0, 0)": 0.6588936448097229, "(0, 16)": 0.6588936448097229, "(2, 0)": 0.6588936448097229, "(2, 16)": 0.6588936448097229, "(4, 0)": 0.6588936448097229, "(4, 16)": 0.6588936448097229, "(6, 0)": 0.6588936448097229, "(6, 16)": 0.6824077367782593, "(8, 0)": 0.6588936448097229, "(8, 16)": 0.6588936448097229, "(10, 0)": 0.6588936448097229, "(10, 16)": 0.6588936448097229, "(12, 0)": 0.3986680507659912, "(12, 16)": 0.6824077367782593, "(14, 0)": 0.6824077367782593, "(14, 16)": 0.46449053287506104, "(16, 0)": 0.6588936448097229, "(16, 16)": 0.6588936448097229, "(18, 0)": 0.3986680507659912, "(18, 16)": 0.6588936448097229, "(20, 0)": 0.6588936448097229, "(20, 16)": 0.6824077367782593, "(22, 0)": 0.3986680507659912, "(22, 16)": 0.6588936448097229, "(24, 0)": 0.6824077367782593, "(24, 16)": 0.6824077367782593, "(26, 0)": 0.3986680507659912, "(26, 16)": 0.6824077367782593, "(28, 0)": 0.3986680507659912, "(28, 16)": 0.6824077367782593, "(30, 0)": 0.3986680507659912, "(30, 16)": 0.3986680507659912}, "r_span": [846, 857], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00038045644760131836}}]}, {"id": "8055", "source_id": "14219", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 268, "end": 272, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\"\nGenerated: Wi-Fi", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 327, "end": 404, "text": "Monday to Friday from 0:00 to 20:30, Saturday and Sunday from 17:30 to 21:00.", "meta": "EVIDENT CONFLICT\nOriginal: \"Monday\": \"0:0-0:0\"\n\"Tuesday\": \"17:0-20:30\",\n\"Wednesday\": \"16:30-19:30\",\n\"Thursday\": \"17:30-20:0\",\n\"Friday\": \"17:30-20:0\",\n\"Saturday\": \"17:30-21:0\",\n\"Sunday\": \"17:0-20:30\"\nGenerated: Monday to Friday from 0:00 to 20:30, Saturday and Sunday from 17:30 to 21:00.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 432, "end": 443, "text": "parking lot", "meta": "EVIDENT CONFLICT\nOriginal: \"lot\": false\nGenerated: parking lot", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 857, "end": 869, "text": "cozy setting", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"cozy setting\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Petit Valentien:\n\nPetit Valentien is a Restaurant located in Santa Barbara, California, offering Ethiopian and French cuisine. The restaurant has a rating of 4.0 stars and offers outdoor seating, WiFi, and reservations. The business hours are as follows: Monday to Friday from 0:00 to 20:30, Saturday and Sunday from 17:30 to 21:00. The restaurant has a small parking lot, but validated parking is not available. The staff is known to be friendly and attentive, with one reviewer mentioning that the service was excellent. However, another reviewer experienced poor service, including long waits and rudeness from the waitstaff. One reviewer also noted that the restaurant is severely understaffed. Overall, Petit Valentien appears to offer delicious Ethiopian and French cuisine in a cozy setting, but inconsistent service may be a concern.", "response_spans": [[0, 88], [90, 594], [580, 913]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.41583940386772156, "(0, 16)": 0.41583940386772156, "(2, 0)": 0.3739142417907715, "(2, 16)": 0.41583940386772156, "(4, 0)": 0.3739142417907715, "(4, 16)": 0.3739142417907715, "(6, 0)": 0.3739142417907715, "(6, 16)": 0.6399816274642944, "(8, 0)": 0.41583940386772156, "(8, 16)": 0.5471529364585876, "(10, 0)": 0.6399816274642944, "(10, 16)": 0.41583940386772156, "(12, 0)": 0.41583940386772156, "(12, 16)": 0.6399816274642944, "(14, 0)": 0.3739142417907715, "(14, 16)": 0.6399816274642944, "(16, 0)": 0.6399816274642944, "(16, 16)": 0.5471529364585876, "(18, 0)": 0.3739142417907715, "(18, 16)": 0.6399816274642944, "(20, 0)": 0.6399816274642944, "(20, 16)": 0.3739142417907715, "(22, 0)": 0.3739142417907715, "(22, 16)": 0.6399816274642944, "(24, 0)": 0.3739142417907715, "(24, 16)": 0.6399816274642944, "(26, 0)": 0.6399816274642944, "(26, 16)": 0.3739142417907715, "(28, 0)": 0.5471529364585876, "(28, 16)": 0.3739142417907715, "(30, 0)": 0.3739142417907715, "(30, 16)": 0.6399816274642944}, "r_span": [1556, 1577], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007212162017822266}}, {"prompt_attention_score": {"(0, 0)": 0.6027408242225647, "(0, 16)": 0.6027408242225647, "(2, 0)": 0.6027408242225647, "(2, 16)": 0.6027408242225647, "(4, 0)": 0.6027408242225647, "(4, 16)": 0.6027408242225647, "(6, 0)": 0.6027408242225647, "(6, 16)": 0.8178775310516357, "(8, 0)": 0.6027408242225647, "(8, 16)": 0.552944540977478, "(10, 0)": 0.6027408242225647, "(10, 16)": 0.552944540977478, "(12, 0)": 0.6027408242225647, "(12, 16)": 0.8178775310516357, "(14, 0)": 0.552944540977478, "(14, 16)": 0.8178775310516357, "(16, 0)": 0.8178775310516357, "(16, 16)": 0.552944540977478, "(18, 0)": 0.552944540977478, "(18, 16)": 0.8178775310516357, "(20, 0)": 0.8178775310516357, "(20, 16)": 0.552944540977478, "(22, 0)": 0.552944540977478, "(22, 16)": 0.8178775310516357, "(24, 0)": 0.552944540977478, "(24, 16)": 0.8178775310516357, "(26, 0)": 0.4460371434688568, "(26, 16)": 0.552944540977478, "(28, 0)": 0.552944540977478, "(28, 16)": 0.552944540977478, "(30, 0)": 0.552944540977478, "(30, 16)": 0.4460371434688568}, "r_span": [1579, 1716], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00031757354736328125}}, {"prompt_attention_score": {"(0, 0)": 0.7395496964454651, "(0, 16)": 0.7828167080879211, "(2, 0)": 0.7828167080879211, "(2, 16)": 0.7395496964454651, "(4, 0)": 0.7828167080879211, "(4, 16)": 0.7828167080879211, "(6, 0)": 0.7395496964454651, "(6, 16)": 0.6724334955215454, "(8, 0)": 0.6701675057411194, "(8, 16)": 0.7395496964454651, "(10, 0)": 0.7828167080879211, "(10, 16)": 0.7828167080879211, "(12, 0)": 0.7395496964454651, "(12, 16)": 0.7395496964454651, "(14, 0)": 0.7395496964454651, "(14, 16)": 0.7395496964454651, "(16, 0)": 0.7395496964454651, "(16, 16)": 0.7828167080879211, "(18, 0)": 0.7395496964454651, "(18, 16)": 0.7828167080879211, "(20, 0)": 0.7395496964454651, "(20, 16)": 0.7395496964454651, "(22, 0)": 0.7395496964454651, "(22, 16)": 0.7395496964454651, "(24, 0)": 0.7395496964454651, "(24, 16)": 0.7395496964454651, "(26, 0)": 0.5094555616378784, "(26, 16)": 0.7395496964454651, "(28, 0)": 0.5094555616378784, "(28, 16)": 0.7395496964454651, "(30, 0)": 0.7395496964454651, "(30, 16)": 0.5094555616378784}, "r_span": [1714, 1789], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00026226043701171875}}]}, {"id": "8079", "source_id": "14223", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 272, "end": 345, "text": "Monday through Sunday from 11am to 22pm, with extended hours on weekends.", "meta": "EVIDENT CONFLICT\nOriginal: \"Monday\": \"0:0-0:0\",\n\"Tuesday\": \"16:0-21:0\"\nWednesday-Thursday, Sunday: \"11:0-21:0\"\nFriday-Saturday: \"11:0-22:0\"\nGenerated: Monday through Sunday from 11am to 22pm, with extended hours on weekends.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Bogo SB is a local business located in Santa Barbara, California, offering a variety of dining options including food delivery services, burgers, pizza, catering, event planning, and restaurant services. Their hours of operation are Monday through Sunday from 11am to 22pm, with extended hours on weekends. The business has a rating of 4.5 stars and receives positive reviews for its good food, easy ordering process, and friendly staff. Customers have also praised the value for money, with many mentioning the buy one get one free deals offered by the business. Some customers have noted that the business has improved since taking over the nearby restaurant, 1114. While some have expressed mixed opinions on the cakes and beer offered, the majority of reviews highlight the delicious pizzas and burgers at reasonable prices. Overall, Bogo SB appears to be a popular dining destination in Santa Barbara, known for its affordable menu and excellent customer service.", "response_spans": [[0, 508], [492, 998], [980, 1007]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6464401483535767, "(0, 16)": 0.6464401483535767, "(2, 0)": 0.5922645330429077, "(2, 16)": 0.6464401483535767, "(4, 0)": 0.6464401483535767, "(4, 16)": 0.5922645330429077, "(6, 0)": 0.6464401483535767, "(6, 16)": 0.8565136790275574, "(8, 0)": 0.6464401483535767, "(8, 16)": 0.5922645330429077, "(10, 0)": 0.6464401483535767, "(10, 16)": 0.6464401483535767, "(12, 0)": 0.6464401483535767, "(12, 16)": 0.8565136790275574, "(14, 0)": 0.5922645330429077, "(14, 16)": 0.8565136790275574, "(16, 0)": 0.5720426440238953, "(16, 16)": 0.5922645330429077, "(18, 0)": 0.6464401483535767, "(18, 16)": 0.8565136790275574, "(20, 0)": 0.8565136790275574, "(20, 16)": 0.5922645330429077, "(22, 0)": 0.5720426440238953, "(22, 16)": 0.6347863674163818, "(24, 0)": 0.5922645330429077, "(24, 16)": 0.8565136790275574, "(26, 0)": 0.5720426440238953, "(26, 16)": 0.6494433879852295, "(28, 0)": 0.5720426440238953, "(28, 16)": 0.5922645330429077, "(30, 0)": 0.5720426440238953, "(30, 16)": 0.5720426440238953}, "r_span": [1152, 1266], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012242794036865234}}, {"prompt_attention_score": {"(0, 0)": 0.7410710453987122, "(0, 16)": 0.7410710453987122, "(2, 0)": 0.7410710453987122, "(2, 16)": 0.7388912439346313, "(4, 0)": 0.7410710453987122, "(4, 16)": 0.7410710453987122, "(6, 0)": 0.7388912439346313, "(6, 16)": 0.760490894317627, "(8, 0)": 0.7410710453987122, "(8, 16)": 0.7388912439346313, "(10, 0)": 0.7410710453987122, "(10, 16)": 0.7410710453987122, "(12, 0)": 0.7410710453987122, "(12, 16)": 0.7388912439346313, "(14, 0)": 0.7388912439346313, "(14, 16)": 0.5109383463859558, "(16, 0)": 0.7388912439346313, "(16, 16)": 0.5162535905838013, "(18, 0)": 0.7388912439346313, "(18, 16)": 0.7410710453987122, "(20, 0)": 0.7388912439346313, "(20, 16)": 0.7388912439346313, "(22, 0)": 0.5162535905838013, "(22, 16)": 0.7300109267234802, "(24, 0)": 0.7388912439346313, "(24, 16)": 0.6838672757148743, "(26, 0)": 0.5162535905838013, "(26, 16)": 0.7410710453987122, "(28, 0)": 0.5162535905838013, "(28, 16)": 0.5162535905838013, "(30, 0)": 0.5162535905838013, "(30, 16)": 0.5162535905838013}, "r_span": [1263, 1370], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0033614039421081543}}, {"prompt_attention_score": {"(0, 0)": 0.5236625671386719, "(0, 16)": 0.4703277349472046, "(2, 0)": 0.4703277349472046, "(2, 16)": 0.4703277349472046, "(4, 0)": 0.4703277349472046, "(4, 16)": 0.4703277349472046, "(6, 0)": 0.4703277349472046, "(6, 16)": 0.5236625671386719, "(8, 0)": 0.4480096995830536, "(8, 16)": 0.4703277349472046, "(10, 0)": 0.5236625671386719, "(10, 16)": 0.5236625671386719, "(12, 0)": 0.3813244104385376, "(12, 16)": 0.5236625671386719, "(14, 0)": 0.4703277349472046, "(14, 16)": 0.49335724115371704, "(16, 0)": 0.5236625671386719, "(16, 16)": 0.3813244104385376, "(18, 0)": 0.4703277349472046, "(18, 16)": 0.4266555905342102, "(20, 0)": 0.4266555905342102, "(20, 16)": 0.4703277349472046, "(22, 0)": 0.4703277349472046, "(22, 16)": 0.5236625671386719, "(24, 0)": 0.4703277349472046, "(24, 16)": 0.3813244104385376, "(26, 0)": 0.3813244104385376, "(26, 16)": 0.4703277349472046, "(28, 0)": 0.3813244104385376, "(28, 16)": 0.3813244104385376, "(30, 0)": 0.3813244104385376, "(30, 16)": 0.3813244104385376}, "r_span": [1369, 1372], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 2.187490463256836e-05}}]}, {"id": "8151", "source_id": "14236", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 955, "end": 974, "text": "does not offer WiFi", "meta": "HIGH INTRO OF NEW INFO\nAIGC: does not offer WiFi\nOriginal: \"WiFi\": null,\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 978, "end": 994, "text": "outdoor seating,", "meta": "HIGH INTRO OF NEW INFO\nAIGC: does not outdoor seating\nOriginal: \"OutdoorSeating\": null,", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 1021, "end": 1080, "text": "the atmosphere is pleasant and ideal for special occasions.", "meta": "EVIDENT CONFLICT\nAIGC: atmosphere is pleasant and ideal for special occasions\nOriginal: \"Ambience\": null", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Montecito Confections:\n\nMontecito Confections is a local business located in Montecito, California, offering a variety of services including restaurants, bakeries, and food. The business has a rating of 4.5 stars and has received positive reviews from customers. The business is open Monday through Friday from 9:00 AM to 5:00 PM and offers free street parking.\n\nCustomers have praised the quality of the cakes and pastries at Montecito Confections, with one reviewer stating that their wedding cake was \"beyond perfect\" and another reviewer describing the owner, Katie Teall, as an \"angel\" who saved their wedding cake from being ruined. Customers have also praised the business's attention to detail and personalized service, with one reviewer mentioning that Katie Teall helped them decorate the cake and even gave them advice on how to work with the fondant.\n\nWhile the business does not offer WiFi or outdoor seating, customers have noted that the atmosphere is pleasant and ideal for special occasions. Overall, Montecito Confections appears to be a highly-recommended local business that excels in providing high-quality baked goods and exceptional customer service.", "response_spans": [[0, 433], [435, 934], [936, 1245]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5399330854415894, "(0, 16)": 0.5399330854415894, "(2, 0)": 0.4624600112438202, "(2, 16)": 0.5399330854415894, "(4, 0)": 0.4624600112438202, "(4, 16)": 0.4624600112438202, "(6, 0)": 0.5513797402381897, "(6, 16)": 0.7889214754104614, "(8, 0)": 0.5936353802680969, "(8, 16)": 0.4624600112438202, "(10, 0)": 0.4832514822483063, "(10, 16)": 0.5399330854415894, "(12, 0)": 0.41596975922584534, "(12, 16)": 0.7889214754104614, "(14, 0)": 0.4832514822483063, "(14, 16)": 0.7889214754104614, "(16, 0)": 0.4832514822483063, "(16, 16)": 0.4624600112438202, "(18, 0)": 0.5399330854415894, "(18, 16)": 0.7889214754104614, "(20, 0)": 0.7889214754104614, "(20, 16)": 0.5936353802680969, "(22, 0)": 0.4832514822483063, "(22, 16)": 0.7889214754104614, "(24, 0)": 0.5936353802680969, "(24, 16)": 0.7889214754104614, "(26, 0)": 0.4832514822483063, "(26, 16)": 0.7889214754104614, "(28, 0)": 0.4832514822483063, "(28, 16)": 0.4832514822483063, "(30, 0)": 0.4832514822483063, "(30, 16)": 0.4832514822483063}, "r_span": [1145, 1249], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000830531120300293}}, {"prompt_attention_score": {"(0, 0)": 0.7039943933486938, "(0, 16)": 0.7039943933486938, "(2, 0)": 0.7380350232124329, "(2, 16)": 0.7647563219070435, "(4, 0)": 0.7647563219070435, "(4, 16)": 0.7647563219070435, "(6, 0)": 0.7380350232124329, "(6, 16)": 0.8087732195854187, "(8, 0)": 0.7039943933486938, "(8, 16)": 0.7647563219070435, "(10, 0)": 0.7647563219070435, "(10, 16)": 0.7647563219070435, "(12, 0)": 0.7380350232124329, "(12, 16)": 0.8087732195854187, "(14, 0)": 0.7380350232124329, "(14, 16)": 0.8087732195854187, "(16, 0)": 0.8087732195854187, "(16, 16)": 0.45338255167007446, "(18, 0)": 0.7071589231491089, "(18, 16)": 0.8087732195854187, "(20, 0)": 0.8087732195854187, "(20, 16)": 0.7071589231491089, "(22, 0)": 0.45338255167007446, "(22, 16)": 0.8087732195854187, "(24, 0)": 0.7071589231491089, "(24, 16)": 0.7664715051651001, "(26, 0)": 0.45338255167007446, "(26, 16)": 0.45338255167007446, "(28, 0)": 0.45338255167007446, "(28, 16)": 0.45338255167007446, "(30, 0)": 0.45338255167007446, "(30, 16)": 0.45338255167007446}, "r_span": [1251, 1369], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0025574564933776855}}, {"prompt_attention_score": {"(0, 0)": 0.5682330131530762, "(0, 16)": 0.5682330131530762, "(2, 0)": 0.5265029668807983, "(2, 16)": 0.5265029668807983, "(4, 0)": 0.5913335084915161, "(4, 16)": 0.5265029668807983, "(6, 0)": 0.5265029668807983, "(6, 16)": 0.684382438659668, "(8, 0)": 0.5265029668807983, "(8, 16)": 0.5265029668807983, "(10, 0)": 0.5913335084915161, "(10, 16)": 0.5913335084915161, "(12, 0)": 0.5265029668807983, "(12, 16)": 0.684382438659668, "(14, 0)": 0.5265029668807983, "(14, 16)": 0.42229992151260376, "(16, 0)": 0.4766322672367096, "(16, 16)": 0.4766322672367096, "(18, 0)": 0.4766322672367096, "(18, 16)": 0.6317028403282166, "(20, 0)": 0.684382438659668, "(20, 16)": 0.6317028403282166, "(22, 0)": 0.4766322672367096, "(22, 16)": 0.684382438659668, "(24, 0)": 0.6317028403282166, "(24, 16)": 0.684382438659668, "(26, 0)": 0.4766322672367096, "(26, 16)": 0.4766322672367096, "(28, 0)": 0.4766322672367096, "(28, 16)": 0.4766322672367096, "(30, 0)": 0.4766322672367096, "(30, 16)": 0.4766322672367096}, "r_span": [1371, 1436], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0002709627151489258}}]}, {"id": "8217", "source_id": "14249", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Subway in Isla Vista, California:\n\nSubway is a popular restaurant located in Isla Vista, serving a variety of sandwiches and fast food options. The business has a rating of 2.5 stars and receives mixed reviews from customers. Some patrons praise the friendliness and helpfulness of the staff, while others express frustration with the cleanliness of the restrooms and the accuracy of orders. One reviewer mentions that two employees were not wearing masks during their visit, which caused them to feel uncomfortable and question the restaurant's commitment to hygiene. Despite these issues, Subway is known for its good service and occasional free cookies with delivery orders.", "response_spans": [[0, 105], [107, 617], [601, 749]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4954083561897278, "(0, 16)": 0.4954083561897278, "(2, 0)": 0.40497344732284546, "(2, 16)": 0.4954083561897278, "(4, 0)": 0.40497344732284546, "(4, 16)": 0.40497344732284546, "(6, 0)": 0.4954083561897278, "(6, 16)": 0.5957742929458618, "(8, 0)": 0.5296324491500854, "(8, 16)": 0.4954083561897278, "(10, 0)": 0.5957742929458618, "(10, 16)": 0.5957742929458618, "(12, 0)": 0.4954083561897278, "(12, 16)": 0.5957742929458618, "(14, 0)": 0.4954083561897278, "(14, 16)": 0.5957742929458618, "(16, 0)": 0.5957742929458618, "(16, 16)": 0.5957742929458618, "(18, 0)": 0.5957742929458618, "(18, 16)": 0.5957742929458618, "(20, 0)": 0.5957742929458618, "(20, 16)": 0.5296324491500854, "(22, 0)": 0.5296324491500854, "(22, 16)": 0.5957742929458618, "(24, 0)": 0.5296324491500854, "(24, 16)": 0.5957742929458618, "(26, 0)": 0.5957742929458618, "(26, 16)": 0.6600558757781982, "(28, 0)": 0.5957742929458618, "(28, 16)": 0.5296324491500854, "(30, 0)": 0.5957742929458618, "(30, 16)": 0.5957742929458618}, "r_span": [866, 892], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006020665168762207}}, {"prompt_attention_score": {"(0, 0)": 0.7438348531723022, "(0, 16)": 0.659877359867096, "(2, 0)": 0.7030448317527771, "(2, 16)": 0.7030448317527771, "(4, 0)": 0.6422139406204224, "(4, 16)": 0.6422139406204224, "(6, 0)": 0.7030448317527771, "(6, 16)": 0.659877359867096, "(8, 0)": 0.7438348531723022, "(8, 16)": 0.6422139406204224, "(10, 0)": 0.7030448317527771, "(10, 16)": 0.7030448317527771, "(12, 0)": 0.7030448317527771, "(12, 16)": 0.659877359867096, "(14, 0)": 0.7438348531723022, "(14, 16)": 0.7030448317527771, "(16, 0)": 0.7438348531723022, "(16, 16)": 0.4928377568721771, "(18, 0)": 0.4928377568721771, "(18, 16)": 0.687206506729126, "(20, 0)": 0.659877359867096, "(20, 16)": 0.7438348531723022, "(22, 0)": 0.7438348531723022, "(22, 16)": 0.6422139406204224, "(24, 0)": 0.7438348531723022, "(24, 16)": 0.7438348531723022, "(26, 0)": 0.4928377568721771, "(26, 16)": 0.659877359867096, "(28, 0)": 0.4928377568721771, "(28, 16)": 0.7438348531723022, "(30, 0)": 0.4928377568721771, "(30, 16)": 0.4928377568721771}, "r_span": [894, 1005], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00021404027938842773}}, {"prompt_attention_score": {"(0, 0)": 0.6402328014373779, "(0, 16)": 0.5682895183563232, "(2, 0)": 0.7716006636619568, "(2, 16)": 0.7716006636619568, "(4, 0)": 0.7716006636619568, "(4, 16)": 0.7716006636619568, "(6, 0)": 0.7716006636619568, "(6, 16)": 0.5810638666152954, "(8, 0)": 0.6402328014373779, "(8, 16)": 0.6402328014373779, "(10, 0)": 0.7716006636619568, "(10, 16)": 0.7716006636619568, "(12, 0)": 0.7716006636619568, "(12, 16)": 0.7716006636619568, "(14, 0)": 0.6402328014373779, "(14, 16)": 0.7716006636619568, "(16, 0)": 0.7716006636619568, "(16, 16)": 0.7716006636619568, "(18, 0)": 0.6402328014373779, "(18, 16)": 0.5682895183563232, "(20, 0)": 0.7716006636619568, "(20, 16)": 0.6402328014373779, "(22, 0)": 0.6402328014373779, "(22, 16)": 0.6402328014373779, "(24, 0)": 0.6402328014373779, "(24, 16)": 0.6402328014373779, "(26, 0)": 0.45868760347366333, "(26, 16)": 0.7716006636619568, "(28, 0)": 0.45868760347366333, "(28, 16)": 0.45868760347366333, "(30, 0)": 0.45868760347366333, "(30, 16)": 0.45868760347366333}, "r_span": [1002, 1033], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014330148696899414}}]}, {"id": "8241", "source_id": "14254", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 540, "end": 638, "text": "convenient location near the city's industrial area, making it a popular spot for lunchtime diners", "meta": "HIGH INTRO OF NEW INFO\nIt mentioned that the restaurant has convenient location near the city's industrial area, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the structured data provided, 101 Deli is a small, family-owned deli located in Santa Barbara, California. The business has a rating of 4.5 stars and offers a variety of dishes, including sandwiches, sushi, and Asian-inspired meals. According to customer reviews, the quality of the food is inconsistent, with some customers finding the meat to be lacking in flavor and the bread being older than expected. However, others have praised the friendly service and generous portion sizes. The deli is known for its outdoor seating and convenient location near the city's industrial area, making it a popular spot for lunchtime diners. While some customers have expressed disappointment with their experiences, overall, 101 Deli seems to offer a unique and satisfying dining experience for those looking for a taste of something different in Santa Barbara.", "response_spans": [[0, 511], [494, 860]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6087515354156494, "(0, 16)": 0.5832143425941467, "(2, 0)": 0.6087515354156494, "(2, 16)": 0.5832143425941467, "(4, 0)": 0.6087515354156494, "(4, 16)": 0.6087515354156494, "(6, 0)": 0.5832143425941467, "(6, 16)": 0.6256009340286255, "(8, 0)": 0.6087515354156494, "(8, 16)": 0.5832143425941467, "(10, 0)": 0.6256009340286255, "(10, 16)": 0.5832143425941467, "(12, 0)": 0.5832143425941467, "(12, 16)": 0.6256009340286255, "(14, 0)": 0.5832143425941467, "(14, 16)": 0.5382068753242493, "(16, 0)": 0.6256009340286255, "(16, 16)": 0.5382068753242493, "(18, 0)": 0.5832143425941467, "(18, 16)": 0.6256009340286255, "(20, 0)": 0.6256009340286255, "(20, 16)": 0.5832143425941467, "(22, 0)": 0.5382068753242493, "(22, 16)": 0.7434571981430054, "(24, 0)": 0.5832143425941467, "(24, 16)": 0.7434571981430054, "(26, 0)": 0.5382068753242493, "(26, 16)": 0.6784060001373291, "(28, 0)": 0.5382068753242493, "(28, 16)": 0.5832143425941467, "(30, 0)": 0.5382068753242493, "(30, 16)": 0.5382068753242493}, "r_span": [969, 1090], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00025272369384765625}}, {"prompt_attention_score": {"(0, 0)": 0.6453406810760498, "(0, 16)": 0.5812559127807617, "(2, 0)": 0.6240586042404175, "(2, 16)": 0.6240586042404175, "(4, 0)": 0.6240586042404175, "(4, 16)": 0.6240586042404175, "(6, 0)": 0.6240586042404175, "(6, 16)": 0.6617878675460815, "(8, 0)": 0.6453406810760498, "(8, 16)": 0.6240586042404175, "(10, 0)": 0.6240586042404175, "(10, 16)": 0.6240586042404175, "(12, 0)": 0.6240586042404175, "(12, 16)": 0.6984379291534424, "(14, 0)": 0.6240586042404175, "(14, 16)": 0.44964146614074707, "(16, 0)": 0.6984379291534424, "(16, 16)": 0.6240586042404175, "(18, 0)": 0.6240586042404175, "(18, 16)": 0.6984379291534424, "(20, 0)": 0.6984379291534424, "(20, 16)": 0.6240586042404175, "(22, 0)": 0.46609288454055786, "(22, 16)": 0.6984379291534424, "(24, 0)": 0.6240586042404175, "(24, 16)": 0.6984379291534424, "(26, 0)": 0.46609288454055786, "(26, 16)": 0.6195552349090576, "(28, 0)": 0.46609288454055786, "(28, 16)": 0.6240586042404175, "(30, 0)": 0.46609288454055786, "(30, 16)": 0.46609288454055786}, "r_span": [1087, 1161], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0009154081344604492}}]}, {"id": "8319", "source_id": "14268", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 1228, "end": 1376, "text": "However, there are mixed opinions about the ambiance of the establishment, with some describing it as divey and others finding it casual and trendy.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this from the reviews", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Kyle's Kitchen:\n\nKyle's Kitchen is a restaurant located in Goleta, California, offering a variety of dishes including burgers, salads, desserts, and more. The establishment has received mixed reviews from customers, with some praising the quality of their food and service, while others have had disappointing experiences.\n\nOne reviewer noted that the gift cards they received from their employer were unusable for online orders with delivery, and despite contacting the company, the issue remains unresolved. This raises concerns about the restaurant's integrity and leadership.\n\nOn the other hand, another reviewer enjoyed their meal, particularly the ahi salad, which they described as delicious. They also appreciated the cheerful and timely service.\n\nHowever, a third reviewer had a disappointing experience with their food, noting that their classic Kyle's burger was pink on the inside after waiting 40 minutes for it to be prepared. Additionally, their fries were floppy and greasy, which suggests that there may be inconsistencies in the quality of their food.\n\nThe restaurant's attributes include free WiFi, outdoor seating, and takeout options. However, there are mixed opinions about the ambiance of the establishment, with some describing it as divey and others finding it casual and trendy.\n\nOverall, Kyle's Kitchen seems to have a mixed reputation among its customers, with some enjoying their meals and others having disappointing experiences. Addressing the issues raised by one reviewer regarding the gift cards and food quality could help improve the restaurant's overall rating.", "response_spans": [[0, 394], [396, 826], [828, 1141], [1143, 1376], [1378, 1670]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6236704587936401, "(0, 16)": 0.6236704587936401, "(2, 0)": 0.6236704587936401, "(2, 16)": 0.6236704587936401, "(4, 0)": 0.6236704587936401, "(4, 16)": 0.6236704587936401, "(6, 0)": 0.6236704587936401, "(6, 16)": 0.7779452204704285, "(8, 0)": 0.6236704587936401, "(8, 16)": 0.6236704587936401, "(10, 0)": 0.6722118854522705, "(10, 16)": 0.6236704587936401, "(12, 0)": 0.6236704587936401, "(12, 16)": 0.7779452204704285, "(14, 0)": 0.6236704587936401, "(14, 16)": 0.7779452204704285, "(16, 0)": 0.4531767964363098, "(16, 16)": 0.6236704587936401, "(18, 0)": 0.4531767964363098, "(18, 16)": 0.7779452204704285, "(20, 0)": 0.7779452204704285, "(20, 16)": 0.6236704587936401, "(22, 0)": 0.4531767964363098, "(22, 16)": 0.7779452204704285, "(24, 0)": 0.6236704587936401, "(24, 16)": 0.7779452204704285, "(26, 0)": 0.4531767964363098, "(26, 16)": 0.7779452204704285, "(28, 0)": 0.4531767964363098, "(28, 16)": 0.6236704587936401, "(30, 0)": 0.4531767964363098, "(30, 16)": 0.4531767964363098}, "r_span": [828, 919], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010561943054199219}}, {"prompt_attention_score": {"(0, 0)": 0.7422739267349243, "(0, 16)": 0.7422739267349243, "(2, 0)": 0.7422739267349243, "(2, 16)": 0.7422739267349243, "(4, 0)": 0.7422739267349243, "(4, 16)": 0.7422739267349243, "(6, 0)": 0.7422739267349243, "(6, 16)": 0.8227203488349915, "(8, 0)": 0.7422739267349243, "(8, 16)": 0.7422739267349243, "(10, 0)": 0.8227203488349915, "(10, 16)": 0.8227203488349915, "(12, 0)": 0.7422739267349243, "(12, 16)": 0.8227203488349915, "(14, 0)": 0.7422739267349243, "(14, 16)": 0.7422739267349243, "(16, 0)": 0.8227203488349915, "(16, 16)": 0.7422739267349243, "(18, 0)": 0.5196195244789124, "(18, 16)": 0.8227203488349915, "(20, 0)": 0.8227203488349915, "(20, 16)": 0.8227203488349915, "(22, 0)": 0.5196195244789124, "(22, 16)": 0.8227203488349915, "(24, 0)": 0.7422739267349243, "(24, 16)": 0.8227203488349915, "(26, 0)": 0.5196195244789124, "(26, 16)": 0.6727026104927063, "(28, 0)": 0.5196195244789124, "(28, 16)": 0.5196195244789124, "(30, 0)": 0.5196195244789124, "(30, 16)": 0.5196195244789124}, "r_span": [921, 1011], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000723421573638916}}, {"prompt_attention_score": {"(0, 0)": 0.8736236095428467, "(0, 16)": 0.8736236095428467, "(2, 0)": 0.8736236095428467, "(2, 16)": 0.8736236095428467, "(4, 0)": 0.8736236095428467, "(4, 16)": 0.8736236095428467, "(6, 0)": 0.8736236095428467, "(6, 16)": 0.8736236095428467, "(8, 0)": 0.8736236095428467, "(8, 16)": 0.8736236095428467, "(10, 0)": 0.8736236095428467, "(10, 16)": 0.8736236095428467, "(12, 0)": 0.8736236095428467, "(12, 16)": 0.8736236095428467, "(14, 0)": 0.8736236095428467, "(14, 16)": 0.8736236095428467, "(16, 0)": 0.8736236095428467, "(16, 16)": 0.48381686210632324, "(18, 0)": 0.48381686210632324, "(18, 16)": 0.8736236095428467, "(20, 0)": 0.8736236095428467, "(20, 16)": 0.8736236095428467, "(22, 0)": 0.48381686210632324, "(22, 16)": 0.8736236095428467, "(24, 0)": 0.48381686210632324, "(24, 16)": 0.8736236095428467, "(26, 0)": 0.48381686210632324, "(26, 16)": 0.8736236095428467, "(28, 0)": 0.48381686210632324, "(28, 16)": 0.48381686210632324, "(30, 0)": 0.48381686210632324, "(30, 16)": 0.48381686210632324}, "r_span": [1013, 1085], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000810086727142334}}, {"prompt_attention_score": {"(0, 0)": 0.5740609765052795, "(0, 16)": 0.5740609765052795, "(2, 0)": 0.5740609765052795, "(2, 16)": 0.5740609765052795, "(4, 0)": 0.5740609765052795, "(4, 16)": 0.5740609765052795, "(6, 0)": 0.5740609765052795, "(6, 16)": 0.6360052824020386, "(8, 0)": 0.5740609765052795, "(8, 16)": 0.5740609765052795, "(10, 0)": 0.5999151468276978, "(10, 16)": 0.5740609765052795, "(12, 0)": 0.5740609765052795, "(12, 16)": 0.6360052824020386, "(14, 0)": 0.5740609765052795, "(14, 16)": 0.6360052824020386, "(16, 0)": 0.6360052824020386, "(16, 16)": 0.5740609765052795, "(18, 0)": 0.5740609765052795, "(18, 16)": 0.6360052824020386, "(20, 0)": 0.6360052824020386, "(20, 16)": 0.5740609765052795, "(22, 0)": 0.5209482312202454, "(22, 16)": 0.6360052824020386, "(24, 0)": 0.5740609765052795, "(24, 16)": 0.6360052824020386, "(26, 0)": 0.5209482312202454, "(26, 16)": 0.5999151468276978, "(28, 0)": 0.5209482312202454, "(28, 16)": 0.5209482312202454, "(30, 0)": 0.5209482312202454, "(30, 16)": 0.5209482312202454}, "r_span": [1087, 1140], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0005488395690917969}}, {"prompt_attention_score": {"(0, 0)": 0.7216724157333374, "(0, 16)": 0.6255022287368774, "(2, 0)": 0.7216724157333374, "(2, 16)": 0.7216724157333374, "(4, 0)": 0.7216724157333374, "(4, 16)": 0.7216724157333374, "(6, 0)": 0.7216724157333374, "(6, 16)": 0.8016164898872375, "(8, 0)": 0.7216724157333374, "(8, 16)": 0.7216724157333374, "(10, 0)": 0.8016164898872375, "(10, 16)": 0.8016164898872375, "(12, 0)": 0.7216724157333374, "(12, 16)": 0.8016164898872375, "(14, 0)": 0.7216724157333374, "(14, 16)": 0.48625046014785767, "(16, 0)": 0.49245014786720276, "(16, 16)": 0.49245014786720276, "(18, 0)": 0.49245014786720276, "(18, 16)": 0.8016164898872375, "(20, 0)": 0.8016164898872375, "(20, 16)": 0.7216724157333374, "(22, 0)": 0.49245014786720276, "(22, 16)": 0.8016164898872375, "(24, 0)": 0.7216724157333374, "(24, 16)": 0.8016164898872375, "(26, 0)": 0.49245014786720276, "(26, 16)": 0.7216724157333374, "(28, 0)": 0.49245014786720276, "(28, 16)": 0.49245014786720276, "(30, 0)": 0.49245014786720276, "(30, 16)": 0.49245014786720276}, "r_span": [1142, 1201], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009821653366088867}}]}, {"id": "8385", "source_id": "14282", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 366, "end": 399, "text": "WiFi available but not guaranteed", "meta": "Original: \"WiFi\": \"no\",", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Los Arroyos Mexican Restaurant & Take Out is a popular eatery located in Santa Barbara, California. With a rating of 4.0 stars, the restaurant offers a wide range of dining options, including Restaurants, Bars, Caterers, Mexican, Salad, Event Planning & Services, Desserts, Food, Nightlife. The restaurant is known for its outdoor seating and takeout services, with WiFi available but not guaranteed. Reviewers have praised the food quality, with one reviewer noting that their fajitas were full of flavor and a generous portion size, while another reviewer had a disappointing pickup experience. Despite this, a third reviewer enjoyed their meal, describing the tortillas as handmade and the salsas as delicious.", "response_spans": [[0, 511], [496, 713]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6231767535209656, "(0, 16)": 0.6231767535209656, "(2, 0)": 0.6231767535209656, "(2, 16)": 0.6231767535209656, "(4, 0)": 0.6231767535209656, "(4, 16)": 0.6231767535209656, "(6, 0)": 0.6231767535209656, "(6, 16)": 0.8130886554718018, "(8, 0)": 0.6033617258071899, "(8, 16)": 0.6231767535209656, "(10, 0)": 0.6231767535209656, "(10, 16)": 0.6231767535209656, "(12, 0)": 0.6231767535209656, "(12, 16)": 0.8130886554718018, "(14, 0)": 0.6033617258071899, "(14, 16)": 0.8130886554718018, "(16, 0)": 0.42291009426116943, "(16, 16)": 0.6231767535209656, "(18, 0)": 0.6231767535209656, "(18, 16)": 0.8130886554718018, "(20, 0)": 0.5454806089401245, "(20, 16)": 0.4966978430747986, "(22, 0)": 0.42291009426116943, "(22, 16)": 0.6033617258071899, "(24, 0)": 0.4966978430747986, "(24, 16)": 0.8130886554718018, "(26, 0)": 0.42291009426116943, "(26, 16)": 0.5454806089401245, "(28, 0)": 0.42291009426116943, "(28, 16)": 0.4966978430747986, "(30, 0)": 0.42291009426116943, "(30, 16)": 0.42291009426116943}, "r_span": [927, 1054], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0014791488647460938}}, {"prompt_attention_score": {"(0, 0)": 0.7509281039237976, "(0, 16)": 0.7509281039237976, "(2, 0)": 0.7509281039237976, "(2, 16)": 0.7509281039237976, "(4, 0)": 0.7509281039237976, "(4, 16)": 0.7509281039237976, "(6, 0)": 0.7509281039237976, "(6, 16)": 0.6933143734931946, "(8, 0)": 0.6266754865646362, "(8, 16)": 0.6266754865646362, "(10, 0)": 0.7509281039237976, "(10, 16)": 0.7509281039237976, "(12, 0)": 0.7509281039237976, "(12, 16)": 0.7509281039237976, "(14, 0)": 0.6266754865646362, "(14, 16)": 0.7509281039237976, "(16, 0)": 0.7509281039237976, "(16, 16)": 0.7509281039237976, "(18, 0)": 0.6266754865646362, "(18, 16)": 0.7509281039237976, "(20, 0)": 0.7509281039237976, "(20, 16)": 0.6266754865646362, "(22, 0)": 0.49007126688957214, "(22, 16)": 0.7509281039237976, "(24, 0)": 0.6266754865646362, "(24, 16)": 0.7509281039237976, "(26, 0)": 0.49007126688957214, "(26, 16)": 0.7509281039237976, "(28, 0)": 0.49007126688957214, "(28, 16)": 0.6266754865646362, "(30, 0)": 0.49007126688957214, "(30, 16)": 0.49007126688957214}, "r_span": [1050, 1099], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007172822952270508}}]}, {"id": "8421", "source_id": "14289", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 166, "end": 180, "text": "has free WiFi,", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: \"WiFi\": \"no\",\nGenerative: \"has free wifi\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 514, "end": 572, "text": "majority of reviewers have rated the restaurant positively", "meta": "EVIDENT CONFLICT\nOriginal: Out of the 3 reviews, 2 are negative\nGenerative: majority of reviewers have rated the restaurant positively", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Las Aves Cafe is a Mexican restaurant located in Santa Barbara, California, with a rating of 3.5 stars. The restaurant offers outdoor seating and takes reservations, has free WiFi, and is good for groups. While some customers have praised the staff and atmosphere, others have criticized the food quality and value for money. One reviewer found the flavors to be underwhelming and not seasoned well, while another was unhappy with the quantity and quality of their takeout order. Despite these mixed opinions, the majority of reviewers have rated the restaurant positively, citing friendly staff and a casual atmosphere.", "response_spans": [[0, 509], [494, 620]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.47974860668182373, "(0, 16)": 0.47974860668182373, "(2, 0)": 0.47974860668182373, "(2, 16)": 0.47974860668182373, "(4, 0)": 0.47974860668182373, "(4, 16)": 0.47974860668182373, "(6, 0)": 0.47974860668182373, "(6, 16)": 0.750765323638916, "(8, 0)": 0.47974860668182373, "(8, 16)": 0.47974860668182373, "(10, 0)": 0.6000205278396606, "(10, 16)": 0.6000205278396606, "(12, 0)": 0.6000205278396606, "(12, 16)": 0.750765323638916, "(14, 0)": 0.6000205278396606, "(14, 16)": 0.42954549193382263, "(16, 0)": 0.6000205278396606, "(16, 16)": 0.4322146773338318, "(18, 0)": 0.47974860668182373, "(18, 16)": 0.750765323638916, "(20, 0)": 0.750765323638916, "(20, 16)": 0.6000205278396606, "(22, 0)": 0.4322146773338318, "(22, 16)": 0.47974860668182373, "(24, 0)": 0.6000205278396606, "(24, 16)": 0.750765323638916, "(26, 0)": 0.4322146773338318, "(26, 16)": 0.5496150255203247, "(28, 0)": 0.4322146773338318, "(28, 16)": 0.5916332006454468, "(30, 0)": 0.4322146773338318, "(30, 16)": 0.4322146773338318}, "r_span": [899, 1013], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0003337860107421875}}, {"prompt_attention_score": {"(0, 0)": 0.38428372144699097, "(0, 16)": 0.6517395377159119, "(2, 0)": 0.38428372144699097, "(2, 16)": 0.38428372144699097, "(4, 0)": 0.38428372144699097, "(4, 16)": 0.38428372144699097, "(6, 0)": 0.38428372144699097, "(6, 16)": 0.6448293924331665, "(8, 0)": 0.38428372144699097, "(8, 16)": 0.38428372144699097, "(10, 0)": 0.6448293924331665, "(10, 16)": 0.38428372144699097, "(12, 0)": 0.41430702805519104, "(12, 16)": 0.6300711035728455, "(14, 0)": 0.6448293924331665, "(14, 16)": 0.43360960483551025, "(16, 0)": 0.6448293924331665, "(16, 16)": 0.41430702805519104, "(18, 0)": 0.41430702805519104, "(18, 16)": 0.6300711035728455, "(20, 0)": 0.6300711035728455, "(20, 16)": 0.6448293924331665, "(22, 0)": 0.41430702805519104, "(22, 16)": 0.6448293924331665, "(24, 0)": 0.6448293924331665, "(24, 16)": 0.6300711035728455, "(26, 0)": 0.41430702805519104, "(26, 16)": 0.41430702805519104, "(28, 0)": 0.41430702805519104, "(28, 16)": 0.6517395377159119, "(30, 0)": 0.41430702805519104, "(30, 16)": 0.41430702805519104}, "r_span": [1011, 1036], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00040084123611450195}}]}, {"id": "8463", "source_id": "14496", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Ming Dynasty Restaurant is a popular Chinese restaurant located in Goleta, California, offering a variety of dishes and a casual atmosphere. According to customer reviews, the restaurant has a rating of 3.0 stars, with mixed feedback regarding the quality of the food. Some patrons found the food to be salty and oily, while others enjoyed their meals. One reviewer noted that the service was excellent, but another mentioned being tricked into ordering an expensive dish when they initially just wanted a simple bowl of noodles. Despite these criticisms, many customers praised the restaurant's wide selection of dishes and good value. Unfortunately, the restaurant is set to close soon, according to one review, which may impact its reputation and future patronage.", "response_spans": [[0, 512], [497, 767]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6180102825164795, "(0, 16)": 0.6180102825164795, "(2, 0)": 0.6180102825164795, "(2, 16)": 0.6180102825164795, "(4, 0)": 0.6180102825164795, "(4, 16)": 0.6180102825164795, "(6, 0)": 0.6180102825164795, "(6, 16)": 0.7463793158531189, "(8, 0)": 0.6180102825164795, "(8, 16)": 0.6180102825164795, "(10, 0)": 0.7509876489639282, "(10, 16)": 0.6180102825164795, "(12, 0)": 0.6180102825164795, "(12, 16)": 0.7509876489639282, "(14, 0)": 0.6180102825164795, "(14, 16)": 0.6180102825164795, "(16, 0)": 0.7509876489639282, "(16, 16)": 0.6180102825164795, "(18, 0)": 0.6180102825164795, "(18, 16)": 0.7463793158531189, "(20, 0)": 0.7509876489639282, "(20, 16)": 0.6180102825164795, "(22, 0)": 0.4392474293708801, "(22, 16)": 0.7509876489639282, "(24, 0)": 0.6180102825164795, "(24, 16)": 0.7509876489639282, "(26, 0)": 0.4392474293708801, "(26, 16)": 0.7463793158531189, "(28, 0)": 0.4392474293708801, "(28, 16)": 0.6180102825164795, "(30, 0)": 0.4392474293708801, "(30, 16)": 0.4392474293708801}, "r_span": [779, 889], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008214116096496582}}, {"prompt_attention_score": {"(0, 0)": 0.7609390020370483, "(0, 16)": 0.7609390020370483, "(2, 0)": 0.7609390020370483, "(2, 16)": 0.7609390020370483, "(4, 0)": 0.7609390020370483, "(4, 16)": 0.7609390020370483, "(6, 0)": 0.7609390020370483, "(6, 16)": 0.7271031141281128, "(8, 0)": 0.7609390020370483, "(8, 16)": 0.7609390020370483, "(10, 0)": 0.7609390020370483, "(10, 16)": 0.7609390020370483, "(12, 0)": 0.7609390020370483, "(12, 16)": 0.7271031141281128, "(14, 0)": 0.7609390020370483, "(14, 16)": 0.7609390020370483, "(16, 0)": 0.7609390020370483, "(16, 16)": 0.7609390020370483, "(18, 0)": 0.5297216176986694, "(18, 16)": 0.7609390020370483, "(20, 0)": 0.7271031141281128, "(20, 16)": 0.7609390020370483, "(22, 0)": 0.7609390020370483, "(22, 16)": 0.7609390020370483, "(24, 0)": 0.7609390020370483, "(24, 16)": 0.7609390020370483, "(26, 0)": 0.5297216176986694, "(26, 16)": 0.7609390020370483, "(28, 0)": 0.5297216176986694, "(28, 16)": 0.5297216176986694, "(30, 0)": 0.5297216176986694, "(30, 16)": 0.5297216176986694}, "r_span": [887, 943], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0019555091857910156}}]}, {"id": "8475", "source_id": "14498", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 526, "end": 587, "text": "The restaurant offers both indoor and outdoor seating options", "meta": "Original: The restaurant's Outdoor Seating is marked as null.\nGenerative: \"The restaurant offers both indoor and outdoor seating options\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Your Place Thai Restaurant appears to be a popular spot for Thai cuisine in Santa Barbara, California. With a rating of 4.0 stars, the restaurant has generally positive reviews from customers. While some reviewers have complained about the price and portion size of certain dishes, many have praised the quality and taste of the food. Specifically, the yellow curry and coconut curries are highlighted as standout dishes, while the Pad Thai and soups are also enjoyed by many customers. The restaurant offers both indoor and outdoor seating options and has WiFi available. However, parking can be limited, and valet service is not offered. Despite some mixed reviews, Your Place Thai Restaurant seems to be a solid choice for those looking for authentic Thai cuisine in the area.", "response_spans": [[0, 509], [490, 818]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8365627527236938, "(0, 16)": 0.8365627527236938, "(2, 0)": 0.8365627527236938, "(2, 16)": 0.8365627527236938, "(4, 0)": 0.8365627527236938, "(4, 16)": 0.8365627527236938, "(6, 0)": 0.8365627527236938, "(6, 16)": 0.7805352210998535, "(8, 0)": 0.73748779296875, "(8, 16)": 0.8365627527236938, "(10, 0)": 0.8365627527236938, "(10, 16)": 0.8365627527236938, "(12, 0)": 0.8365627527236938, "(12, 16)": 0.73748779296875, "(14, 0)": 0.73748779296875, "(14, 16)": 0.5327737331390381, "(16, 0)": 0.73748779296875, "(16, 16)": 0.73748779296875, "(18, 0)": 0.5327737331390381, "(18, 16)": 0.5327737331390381, "(20, 0)": 0.73748779296875, "(20, 16)": 0.73748779296875, "(22, 0)": 0.73748779296875, "(22, 16)": 0.73748779296875, "(24, 0)": 0.73748779296875, "(24, 16)": 0.73748779296875, "(26, 0)": 0.5327737331390381, "(26, 16)": 0.73748779296875, "(28, 0)": 0.5327737331390381, "(28, 16)": 0.73748779296875, "(30, 0)": 0.5327737331390381, "(30, 16)": 0.5327737331390381}, "r_span": [788, 904], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001323103904724121}}, {"prompt_attention_score": {"(0, 0)": 0.7298454642295837, "(0, 16)": 0.7298454642295837, "(2, 0)": 0.7298454642295837, "(2, 16)": 0.7298454642295837, "(4, 0)": 0.7298454642295837, "(4, 16)": 0.7298454642295837, "(6, 0)": 0.7298454642295837, "(6, 16)": 0.7200087308883667, "(8, 0)": 0.7298454642295837, "(8, 16)": 0.7298454642295837, "(10, 0)": 0.7298454642295837, "(10, 16)": 0.7298454642295837, "(12, 0)": 0.6886168718338013, "(12, 16)": 0.7200087308883667, "(14, 0)": 0.6886168718338013, "(14, 16)": 0.7298454642295837, "(16, 0)": 0.6886168718338013, "(16, 16)": 0.7298454642295837, "(18, 0)": 0.48062413930892944, "(18, 16)": 0.7200087308883667, "(20, 0)": 0.7200087308883667, "(20, 16)": 0.6886168718338013, "(22, 0)": 0.48062413930892944, "(22, 16)": 0.7200087308883667, "(24, 0)": 0.6886168718338013, "(24, 16)": 0.7200087308883667, "(26, 0)": 0.48062413930892944, "(26, 16)": 0.6886168718338013, "(28, 0)": 0.48062413930892944, "(28, 16)": 0.6886168718338013, "(30, 0)": 0.48062413930892944, "(30, 16)": 0.48062413930892944}, "r_span": [901, 973], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008627772331237793}}]}, {"id": "8511", "source_id": "14504", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 276, "end": 304, "text": "and has a casual atmosphere.", "meta": "EVIDENT CONFLICT\nOriginal: \"casual\": false\nGenerative: \"... and has a casual atmosphere.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Alito's:\n\nAlito's is a New Mexican restaurant located in Santa Barbara, California, with a rating of 4 out of 5 stars. The restaurant offers a range of dining options, including takeout and reservations, and has a casual atmosphere. While some reviews praise the food quality and service, others have experienced poor service and subpar amenities. Reviews mention issues with the menu, such as typos and slow food preparation, but also highlight the restaurant's accommodation of large groups and exceptional service. Overall, Alito's appears to offer good quality Mexican cuisine, although there are some areas for improvement in terms of service and amenities.", "response_spans": [[0, 80], [82, 589], [581, 734]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.40380924940109253, "(0, 16)": 0.40380924940109253, "(2, 0)": 0.40380924940109253, "(2, 16)": 0.40380924940109253, "(4, 0)": 0.40380924940109253, "(4, 16)": 0.40380924940109253, "(6, 0)": 0.40380924940109253, "(6, 16)": 0.6448649168014526, "(8, 0)": 0.40380924940109253, "(8, 16)": 0.476209819316864, "(10, 0)": 0.6448649168014526, "(10, 16)": 0.6448649168014526, "(12, 0)": 0.563662052154541, "(12, 16)": 0.6448649168014526, "(14, 0)": 0.4319053590297699, "(14, 16)": 0.6448649168014526, "(16, 0)": 0.6448649168014526, "(16, 16)": 0.40380924940109253, "(18, 0)": 0.4319053590297699, "(18, 16)": 0.6448649168014526, "(20, 0)": 0.6448649168014526, "(20, 16)": 0.4319053590297699, "(22, 0)": 0.4319053590297699, "(22, 16)": 0.6448649168014526, "(24, 0)": 0.4319053590297699, "(24, 16)": 0.6448649168014526, "(26, 0)": 0.6448649168014526, "(26, 16)": 0.4319053590297699, "(28, 0)": 0.6448649168014526, "(28, 16)": 0.4319053590297699, "(30, 0)": 0.6448649168014526, "(30, 16)": 0.6448649168014526}, "r_span": [760, 781], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00024646520614624023}}, {"prompt_attention_score": {"(0, 0)": 0.6143521666526794, "(0, 16)": 0.6143521666526794, "(2, 0)": 0.6143521666526794, "(2, 16)": 0.6143521666526794, "(4, 0)": 0.6143521666526794, "(4, 16)": 0.6143521666526794, "(6, 0)": 0.6143521666526794, "(6, 16)": 0.7159460783004761, "(8, 0)": 0.6143521666526794, "(8, 16)": 0.6386774778366089, "(10, 0)": 0.6143521666526794, "(10, 16)": 0.6143521666526794, "(12, 0)": 0.6143521666526794, "(12, 16)": 0.5755541920661926, "(14, 0)": 0.5755541920661926, "(14, 16)": 0.5755541920661926, "(16, 0)": 0.6143521666526794, "(16, 16)": 0.6143521666526794, "(18, 0)": 0.5755541920661926, "(18, 16)": 0.7159460783004761, "(20, 0)": 0.5755541920661926, "(20, 16)": 0.5755541920661926, "(22, 0)": 0.5755541920661926, "(22, 16)": 0.5755541920661926, "(24, 0)": 0.5755541920661926, "(24, 16)": 0.5755541920661926, "(26, 0)": 0.42890989780426025, "(26, 16)": 0.5755541920661926, "(28, 0)": 0.42890989780426025, "(28, 16)": 0.5755541920661926, "(30, 0)": 0.42890989780426025, "(30, 16)": 0.42890989780426025}, "r_span": [783, 893], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.004974186420440674}}, {"prompt_attention_score": {"(0, 0)": 0.6328625679016113, "(0, 16)": 0.6328625679016113, "(2, 0)": 0.7437132000923157, "(2, 16)": 0.7437132000923157, "(4, 0)": 0.7437132000923157, "(4, 16)": 0.7437132000923157, "(6, 0)": 0.7437132000923157, "(6, 16)": 0.626742959022522, "(8, 0)": 0.6328625679016113, "(8, 16)": 0.7437132000923157, "(10, 0)": 0.6328625679016113, "(10, 16)": 0.7437132000923157, "(12, 0)": 0.4564591646194458, "(12, 16)": 0.7437132000923157, "(14, 0)": 0.5808197855949402, "(14, 16)": 0.4707339107990265, "(16, 0)": 0.4564591646194458, "(16, 16)": 0.7437132000923157, "(18, 0)": 0.5808197855949402, "(18, 16)": 0.5808197855949402, "(20, 0)": 0.5808197855949402, "(20, 16)": 0.5808197855949402, "(22, 0)": 0.4564591646194458, "(22, 16)": 0.5808197855949402, "(24, 0)": 0.5808197855949402, "(24, 16)": 0.5808197855949402, "(26, 0)": 0.4564591646194458, "(26, 16)": 0.5808197855949402, "(28, 0)": 0.4564591646194458, "(28, 16)": 0.4564591646194458, "(30, 0)": 0.4564591646194458, "(30, 16)": 0.4564591646194458}, "r_span": [892, 925], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005252957344055176}}]}, {"id": "8559", "source_id": "14513", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, Our Daily Bread is a local bakery and restaurant located in Santa Barbara, California. The business offers a variety of baked goods, sandwiches, and other dishes, including gluten-free options. Customers can enjoy their meals on site or take them to go. While the overall rating for the business is 3.5 stars, customer reviews suggest that the quality of the food and service can vary. Some patrons have praised the friendly service and delicious salads, while others have experienced long wait times and disappointing sandwiches. Despite these mixed reviews, Our Daily Bread appears to be a popular spot for casual lunches and breakfasts, with a cozy atmosphere and free WiFi.", "response_spans": [[0, 511], [494, 716]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6241481304168701, "(0, 16)": 0.6241481304168701, "(2, 0)": 0.6241481304168701, "(2, 16)": 0.6241481304168701, "(4, 0)": 0.6241481304168701, "(4, 16)": 0.6241481304168701, "(6, 0)": 0.6241481304168701, "(6, 16)": 0.8129971027374268, "(8, 0)": 0.6241481304168701, "(8, 16)": 0.6241481304168701, "(10, 0)": 0.6309303641319275, "(10, 16)": 0.6241481304168701, "(12, 0)": 0.6241481304168701, "(12, 16)": 0.8129971027374268, "(14, 0)": 0.6241481304168701, "(14, 16)": 0.5418931245803833, "(16, 0)": 0.6008806824684143, "(16, 16)": 0.6241481304168701, "(18, 0)": 0.6241481304168701, "(18, 16)": 0.8129971027374268, "(20, 0)": 0.8129971027374268, "(20, 16)": 0.6241481304168701, "(22, 0)": 0.6241481304168701, "(22, 16)": 0.8129971027374268, "(24, 0)": 0.6241481304168701, "(24, 16)": 0.8129971027374268, "(26, 0)": 0.5418931245803833, "(26, 16)": 0.6008806824684143, "(28, 0)": 0.5418931245803833, "(28, 16)": 0.6241481304168701, "(30, 0)": 0.5418931245803833, "(30, 16)": 0.5418931245803833}, "r_span": [855, 970], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0020546913146972656}}, {"prompt_attention_score": {"(0, 0)": 0.6261051297187805, "(0, 16)": 0.6261051297187805, "(2, 0)": 0.6261051297187805, "(2, 16)": 0.6261051297187805, "(4, 0)": 0.6261051297187805, "(4, 16)": 0.6261051297187805, "(6, 0)": 0.6557623147964478, "(6, 16)": 0.6557623147964478, "(8, 0)": 0.6261051297187805, "(8, 16)": 0.6261051297187805, "(10, 0)": 0.6261051297187805, "(10, 16)": 0.6261051297187805, "(12, 0)": 0.6261051297187805, "(12, 16)": 0.6557623147964478, "(14, 0)": 0.6261051297187805, "(14, 16)": 0.4703330397605896, "(16, 0)": 0.6056594848632812, "(16, 16)": 0.5432147979736328, "(18, 0)": 0.4351601302623749, "(18, 16)": 0.6056594848632812, "(20, 0)": 0.6477235555648804, "(20, 16)": 0.6261051297187805, "(22, 0)": 0.4351601302623749, "(22, 16)": 0.6477235555648804, "(24, 0)": 0.6261051297187805, "(24, 16)": 0.6056594848632812, "(26, 0)": 0.4351601302623749, "(26, 16)": 0.6261051297187805, "(28, 0)": 0.4351601302623749, "(28, 16)": 0.6261051297187805, "(30, 0)": 0.4351601302623749, "(30, 16)": 0.4351601302623749}, "r_span": [968, 1016], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002912282943725586}}]}, {"id": "8571", "source_id": "14515", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 104, "end": 176, "text": "While some have praised the restaurant's convenience and takeout options", "meta": "HIGH INTRO OF NEW INFO\nStructured data has no mention of customers praising these aspects. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 480, "end": 495, "text": "long wait times", "meta": "HIGH INTRO OF NEW INFO\nStructured data has no mention of how fast or slow their service is. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 519, "end": 594, "text": "the restaurant has been praised for its good value and convenient location.", "meta": "HIGH INTRO OF NEW INFO\nStructured data has no mention of the restaurant having positive interactions. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 674, "end": 762, "text": "it remains a popular choice for those looking for quick and easy meals in Santa Barbara.", "meta": "HIGH INTRO OF NEW INFO\nStructured data has no mention of this claim.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Domino's Pizza at 1808 Cliff Dr in Santa Barbara, California has received mixed reviews from customers. While some have praised the restaurant's convenience and takeout options, others have had disappointing experiences with their food and service. Some reviews mention poor quality food, including dry or burnt chicken, and missing or incorrect ingredients. Additionally, some customers have expressed frustration with the restaurant's customer service, including rude staff and long wait times. Despite these issues, the restaurant has been praised for its good value and convenient location. Overall, while Domino's Pizza may not be meeting some customers' expectations, it remains a popular choice for those looking for quick and easy meals in Santa Barbara.", "response_spans": [[0, 510], [497, 762]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6977152228355408, "(0, 16)": 0.6977152228355408, "(2, 0)": 0.6977152228355408, "(2, 16)": 0.6977152228355408, "(4, 0)": 0.6977152228355408, "(4, 16)": 0.6977152228355408, "(6, 0)": 0.6977152228355408, "(6, 16)": 0.7904539108276367, "(8, 0)": 0.6977152228355408, "(8, 16)": 0.6977152228355408, "(10, 0)": 0.6977152228355408, "(10, 16)": 0.6977152228355408, "(12, 0)": 0.6977152228355408, "(12, 16)": 0.7904539108276367, "(14, 0)": 0.6046597361564636, "(14, 16)": 0.43265190720558167, "(16, 0)": 0.6977152228355408, "(16, 16)": 0.6977152228355408, "(18, 0)": 0.45781487226486206, "(18, 16)": 0.5758804082870483, "(20, 0)": 0.7012762427330017, "(20, 16)": 0.7012762427330017, "(22, 0)": 0.7012762427330017, "(22, 16)": 0.7012762427330017, "(24, 0)": 0.7012762427330017, "(24, 16)": 0.7012762427330017, "(26, 0)": 0.45781487226486206, "(26, 16)": 0.5758804082870483, "(28, 0)": 0.45781487226486206, "(28, 16)": 0.6046597361564636, "(30, 0)": 0.45781487226486206, "(30, 16)": 0.45781487226486206}, "r_span": [860, 964], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00025594234466552734}}, {"prompt_attention_score": {"(0, 0)": 0.6359907388687134, "(0, 16)": 0.6359907388687134, "(2, 0)": 0.6359907388687134, "(2, 16)": 0.6359907388687134, "(4, 0)": 0.6359907388687134, "(4, 16)": 0.6359907388687134, "(6, 0)": 0.6359907388687134, "(6, 16)": 0.6947457790374756, "(8, 0)": 0.6359907388687134, "(8, 16)": 0.6253600120544434, "(10, 0)": 0.5795590877532959, "(10, 16)": 0.6359907388687134, "(12, 0)": 0.5795590877532959, "(12, 16)": 0.6359907388687134, "(14, 0)": 0.5795590877532959, "(14, 16)": 0.4658265709877014, "(16, 0)": 0.43994230031967163, "(16, 16)": 0.43994230031967163, "(18, 0)": 0.43994230031967163, "(18, 16)": 0.6947457790374756, "(20, 0)": 0.5654054880142212, "(20, 16)": 0.5795590877532959, "(22, 0)": 0.43994230031967163, "(22, 16)": 0.6947457790374756, "(24, 0)": 0.6253600120544434, "(24, 16)": 0.6947457790374756, "(26, 0)": 0.43994230031967163, "(26, 16)": 0.5654054880142212, "(28, 0)": 0.43994230031967163, "(28, 16)": 0.5795590877532959, "(30, 0)": 0.43994230031967163, "(30, 16)": 0.43994230031967163}, "r_span": [963, 1018], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.000943601131439209}}]}, {"id": "8625", "source_id": "14524", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 510, "end": 533, "text": "great option for groups", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: \"RestaurantsGoodForGroups\": null,\nGenerative: \"great option for groups\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 608, "end": 640, "text": "business parking or reservations", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal:\"BusinessParking\": null, \"RestaurantsReservations\": null, \nGenerative: \" does not offer business parking or reservations\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 649, "end": 663, "text": "Wifi available", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: \"WiFi\": null,\nGenerative: \"Wifi available\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Aksum Restaurant in Santa Barbara:\n\nAksum Restaurant is a highly-rated Ethiopian restaurant located in downtown Santa Barbara. Customers have praised the restaurant's friendly staff and delicious food, particularly the vegetable and meat combos which are popular choices among first-time visitors. The restaurant offers indoor seating and takeout options, and has a rating of 5.0 stars. Reviewers have also noted that the restaurant is a great option for groups and that the atmosphere is welcoming. While the restaurant does not offer business parking or reservations, it has Wifi available and allows takeout orders. Overall, Aksum Restaurant has received glowing reviews for its tasty Ethiopian cuisine and excellent customer service.", "response_spans": [[0, 106], [108, 616], [598, 809]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.563145101070404, "(0, 16)": 0.563145101070404, "(2, 0)": 0.563145101070404, "(2, 16)": 0.563145101070404, "(4, 0)": 0.563145101070404, "(4, 16)": 0.6128078699111938, "(6, 0)": 0.563145101070404, "(6, 16)": 0.6623671054840088, "(8, 0)": 0.6128078699111938, "(8, 16)": 0.563145101070404, "(10, 0)": 0.6623671054840088, "(10, 16)": 0.6623671054840088, "(12, 0)": 0.563145101070404, "(12, 16)": 0.6623671054840088, "(14, 0)": 0.6128078699111938, "(14, 16)": 0.6623671054840088, "(16, 0)": 0.6623671054840088, "(16, 16)": 0.6128078699111938, "(18, 0)": 0.563145101070404, "(18, 16)": 0.6623671054840088, "(20, 0)": 0.6623671054840088, "(20, 16)": 0.6128078699111938, "(22, 0)": 0.6128078699111938, "(22, 16)": 0.6623671054840088, "(24, 0)": 0.6128078699111938, "(24, 16)": 0.6623671054840088, "(26, 0)": 0.6623671054840088, "(26, 16)": 0.6128078699111938, "(28, 0)": 0.6623671054840088, "(28, 16)": 0.6128078699111938, "(30, 0)": 0.6623671054840088, "(30, 16)": 0.6623671054840088}, "r_span": [754, 780], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005321502685546875}}, {"prompt_attention_score": {"(0, 0)": 0.6856104135513306, "(0, 16)": 0.6856104135513306, "(2, 0)": 0.6856104135513306, "(2, 16)": 0.6856104135513306, "(4, 0)": 0.6856104135513306, "(4, 16)": 0.6856104135513306, "(6, 0)": 0.6856104135513306, "(6, 16)": 0.9059971570968628, "(8, 0)": 0.7521049380302429, "(8, 16)": 0.6856104135513306, "(10, 0)": 0.7521049380302429, "(10, 16)": 0.6856104135513306, "(12, 0)": 0.6856104135513306, "(12, 16)": 0.9059971570968628, "(14, 0)": 0.7521049380302429, "(14, 16)": 0.6856104135513306, "(16, 0)": 0.7521049380302429, "(16, 16)": 0.6856104135513306, "(18, 0)": 0.4632624387741089, "(18, 16)": 0.8073521852493286, "(20, 0)": 0.9059971570968628, "(20, 16)": 0.7521049380302429, "(22, 0)": 0.4632624387741089, "(22, 16)": 0.9059971570968628, "(24, 0)": 0.7521049380302429, "(24, 16)": 0.9059971570968628, "(26, 0)": 0.4632624387741089, "(26, 16)": 0.7521049380302429, "(28, 0)": 0.4632624387741089, "(28, 16)": 0.7521049380302429, "(30, 0)": 0.4632624387741089, "(30, 16)": 0.4632624387741089}, "r_span": [782, 892], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0007438063621520996}}, {"prompt_attention_score": {"(0, 0)": 0.6835954189300537, "(0, 16)": 0.6835954189300537, "(2, 0)": 0.6835954189300537, "(2, 16)": 0.6835954189300537, "(4, 0)": 0.6835954189300537, "(4, 16)": 0.6835954189300537, "(6, 0)": 0.6835954189300537, "(6, 16)": 0.7513176798820496, "(8, 0)": 0.7294822931289673, "(8, 16)": 0.6835954189300537, "(10, 0)": 0.6835954189300537, "(10, 16)": 0.6835954189300537, "(12, 0)": 0.6835954189300537, "(12, 16)": 0.7513176798820496, "(14, 0)": 0.7294822931289673, "(14, 16)": 0.6835954189300537, "(16, 0)": 0.7294822931289673, "(16, 16)": 0.6835954189300537, "(18, 0)": 0.4921067953109741, "(18, 16)": 0.7513176798820496, "(20, 0)": 0.7513176798820496, "(20, 16)": 0.7294822931289673, "(22, 0)": 0.4921067953109741, "(22, 16)": 0.7513176798820496, "(24, 0)": 0.7294822931289673, "(24, 16)": 0.7513176798820496, "(26, 0)": 0.4921067953109741, "(26, 16)": 0.7294822931289673, "(28, 0)": 0.4921067953109741, "(28, 16)": 0.7294822931289673, "(30, 0)": 0.4921067953109741, "(30, 16)": 0.4921067953109741}, "r_span": [890, 941], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0013278722763061523}}]}, {"id": "8661", "source_id": "14530", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Luna Grill:\n\nLuna Grill is a Mediterranean restaurant located in Santa Barbara, California. With a rating of 4.0 stars, the business offers fresh and flavorful food, excellent service, and ample parking. Although the restaurant can get busy and there may be a wait, customers have praised the quality of the food and the politeness of the staff. The business has both indoor and outdoor seating and offers free WiFi. While the salads are not particularly special, the gyro pita and fries are popular choices among customers. Overall, Luna Grill is a great option for those looking for delicious Mediterranean cuisine in a trendy and casual setting.", "response_spans": [[0, 83], [85, 596], [580, 720]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4841429591178894, "(0, 16)": 0.4841429591178894, "(2, 0)": 0.4841429591178894, "(2, 16)": 0.4841429591178894, "(4, 0)": 0.4841429591178894, "(4, 16)": 0.4841429591178894, "(6, 0)": 0.4841429591178894, "(6, 16)": 0.6051903367042542, "(8, 0)": 0.46716615557670593, "(8, 16)": 0.5276967287063599, "(10, 0)": 0.6051903367042542, "(10, 16)": 0.6051903367042542, "(12, 0)": 0.5276967287063599, "(12, 16)": 0.6051903367042542, "(14, 0)": 0.46716615557670593, "(14, 16)": 0.6051903367042542, "(16, 0)": 0.6051903367042542, "(16, 16)": 0.5276967287063599, "(18, 0)": 0.4841429591178894, "(18, 16)": 0.6051903367042542, "(20, 0)": 0.6051903367042542, "(20, 16)": 0.46716615557670593, "(22, 0)": 0.46716615557670593, "(22, 16)": 0.6051903367042542, "(24, 0)": 0.46716615557670593, "(24, 16)": 0.6051903367042542, "(26, 0)": 0.6051903367042542, "(26, 16)": 0.6066664457321167, "(28, 0)": 0.6051903367042542, "(28, 16)": 0.6051903367042542, "(30, 0)": 0.6051903367042542, "(30, 16)": 0.6051903367042542}, "r_span": [844, 865], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000548243522644043}}, {"prompt_attention_score": {"(0, 0)": 0.6303536295890808, "(0, 16)": 0.6303536295890808, "(2, 0)": 0.6303536295890808, "(2, 16)": 0.6303536295890808, "(4, 0)": 0.6303536295890808, "(4, 16)": 0.6303536295890808, "(6, 0)": 0.6303536295890808, "(6, 16)": 0.7754743695259094, "(8, 0)": 0.6535192728042603, "(8, 16)": 0.6303536295890808, "(10, 0)": 0.6303536295890808, "(10, 16)": 0.6303536295890808, "(12, 0)": 0.6303536295890808, "(12, 16)": 0.6303536295890808, "(14, 0)": 0.6535192728042603, "(14, 16)": 0.6303536295890808, "(16, 0)": 0.6303536295890808, "(16, 16)": 0.6303536295890808, "(18, 0)": 0.3749857544898987, "(18, 16)": 0.7754743695259094, "(20, 0)": 0.6303536295890808, "(20, 16)": 0.6535192728042603, "(22, 0)": 0.3749857544898987, "(22, 16)": 0.6303536295890808, "(24, 0)": 0.6535192728042603, "(24, 16)": 0.6535192728042603, "(26, 0)": 0.3749857544898987, "(26, 16)": 0.6787348985671997, "(28, 0)": 0.3749857544898987, "(28, 16)": 0.6535192728042603, "(30, 0)": 0.3749857544898987, "(30, 16)": 0.3749857544898987}, "r_span": [867, 983], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014522671699523926}}, {"prompt_attention_score": {"(0, 0)": 0.6510587334632874, "(0, 16)": 0.6510587334632874, "(2, 0)": 0.6510587334632874, "(2, 16)": 0.6510587334632874, "(4, 0)": 0.6510587334632874, "(4, 16)": 0.6510587334632874, "(6, 0)": 0.6636987924575806, "(6, 16)": 0.660439133644104, "(8, 0)": 0.6636987924575806, "(8, 16)": 0.6636987924575806, "(10, 0)": 0.6510587334632874, "(10, 16)": 0.6510587334632874, "(12, 0)": 0.6510587334632874, "(12, 16)": 0.6570412516593933, "(14, 0)": 0.6636987924575806, "(14, 16)": 0.4331319332122803, "(16, 0)": 0.37459033727645874, "(16, 16)": 0.37459033727645874, "(18, 0)": 0.37459033727645874, "(18, 16)": 0.6570412516593933, "(20, 0)": 0.6570412516593933, "(20, 16)": 0.6636987924575806, "(22, 0)": 0.37459033727645874, "(22, 16)": 0.660439133644104, "(24, 0)": 0.6636987924575806, "(24, 16)": 0.6570412516593933, "(26, 0)": 0.37459033727645874, "(26, 16)": 0.6636987924575806, "(28, 0)": 0.37459033727645874, "(28, 16)": 0.6636987924575806, "(30, 0)": 0.37459033727645874, "(30, 16)": 0.37459033727645874}, "r_span": [981, 1016], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003418922424316406}}]}, {"id": "8667", "source_id": "14531", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, The Tully is a cozy and welcoming local bar located in Santa Barbara, California. With a rating of 4.5 stars, it offers a range of amenities including outdoor seating, free WiFi, and a relaxed atmosphere. The bar has a loyal customer base, as evident from the positive reviews, with customers praising the friendly service, enjoyable atmosphere, and reasonable prices. The happy hour offerings are particularly noteworthy, with the bar offering discounted drinks until 7pm from Monday to Friday. While the bar may not have a fancy atmosphere, its nostalgic charm and down-to-earth vibe make it a popular spot for locals and visitors alike. Whether you're looking for a place to unwind with a drink or two or want to experience the local nightlife, The Tully is definitely worth checking out.", "response_spans": [[0, 511], [495, 830]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7031354904174805, "(0, 16)": 0.7031354904174805, "(2, 0)": 0.7031354904174805, "(2, 16)": 0.7031354904174805, "(4, 0)": 0.7031354904174805, "(4, 16)": 0.7031354904174805, "(6, 0)": 0.7031354904174805, "(6, 16)": 0.8065506815910339, "(8, 0)": 0.7031354904174805, "(8, 16)": 0.7031354904174805, "(10, 0)": 0.7031354904174805, "(10, 16)": 0.7031354904174805, "(12, 0)": 0.7031354904174805, "(12, 16)": 0.8065506815910339, "(14, 0)": 0.7031354904174805, "(14, 16)": 0.7031354904174805, "(16, 0)": 0.65313720703125, "(16, 16)": 0.7031354904174805, "(18, 0)": 0.7031354904174805, "(18, 16)": 0.6037560105323792, "(20, 0)": 0.8065506815910339, "(20, 16)": 0.7031354904174805, "(22, 0)": 0.7031354904174805, "(22, 16)": 0.8065506815910339, "(24, 0)": 0.7031354904174805, "(24, 16)": 0.65313720703125, "(26, 0)": 0.5034926533699036, "(26, 16)": 0.7031354904174805, "(28, 0)": 0.5034926533699036, "(28, 16)": 0.7031354904174805, "(30, 0)": 0.5034926533699036, "(30, 16)": 0.5034926533699036}, "r_span": [966, 1083], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008066296577453613}}, {"prompt_attention_score": {"(0, 0)": 0.6636469960212708, "(0, 16)": 0.6636469960212708, "(2, 0)": 0.6636469960212708, "(2, 16)": 0.6636469960212708, "(4, 0)": 0.6636469960212708, "(4, 16)": 0.6636469960212708, "(6, 0)": 0.6636469960212708, "(6, 16)": 0.6955404281616211, "(8, 0)": 0.6636469960212708, "(8, 16)": 0.6636469960212708, "(10, 0)": 0.6636469960212708, "(10, 16)": 0.6636469960212708, "(12, 0)": 0.6636469960212708, "(12, 16)": 0.6955404281616211, "(14, 0)": 0.6636469960212708, "(14, 16)": 0.6636469960212708, "(16, 0)": 0.6636469960212708, "(16, 16)": 0.6636469960212708, "(18, 0)": 0.6636469960212708, "(18, 16)": 0.5645525455474854, "(20, 0)": 0.6636469960212708, "(20, 16)": 0.6636469960212708, "(22, 0)": 0.6636469960212708, "(22, 16)": 0.6955404281616211, "(24, 0)": 0.6636469960212708, "(24, 16)": 0.5645525455474854, "(26, 0)": 0.4311524033546448, "(26, 16)": 0.6636469960212708, "(28, 0)": 0.4311524033546448, "(28, 16)": 0.6636469960212708, "(30, 0)": 0.4311524033546448, "(30, 16)": 0.4311524033546448}, "r_span": [1078, 1159], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00014477968215942383}}]}, {"id": "8673", "source_id": "14532", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 197, "end": 214, "text": "friendly service.", "meta": "Introduction of New Information\nNot mentioned in the structured data.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "El Pastorcito is a popular Mexican restaurant located in Santa Barbara, California. With a rating of 5.0 stars, the business has received positive reviews from customers for its delicious food and friendly service. The restaurant offers a variety of dishes, including mulitas de pastor, mulitas de pollo, tacos de birria, and pastor, all made fresh and served with large portions. Customers have praised the quality of the food, particularly the el pastor tacos and burritos, which are highly recommended. The business also offers a fun and lively atmosphere, with tables set up and lights, creating a enjoyable dining experience. Overall, El Pastorcito is a great option for those looking for authentic Mexican cuisine in Santa Barbara.", "response_spans": [[0, 509], [493, 737]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6514443159103394, "(0, 16)": 0.5606434941291809, "(2, 0)": 0.6514443159103394, "(2, 16)": 0.5606434941291809, "(4, 0)": 0.6514443159103394, "(4, 16)": 0.5606434941291809, "(6, 0)": 0.6514443159103394, "(6, 16)": 0.6754413843154907, "(8, 0)": 0.6514443159103394, "(8, 16)": 0.6514443159103394, "(10, 0)": 0.5606434941291809, "(10, 16)": 0.5606434941291809, "(12, 0)": 0.5606434941291809, "(12, 16)": 0.6754413843154907, "(14, 0)": 0.6514443159103394, "(14, 16)": 0.5606434941291809, "(16, 0)": 0.6754413843154907, "(16, 16)": 0.6514443159103394, "(18, 0)": 0.3698662519454956, "(18, 16)": 0.7235091924667358, "(20, 0)": 0.6754413843154907, "(20, 16)": 0.6514443159103394, "(22, 0)": 0.3698662519454956, "(22, 16)": 0.6754413843154907, "(24, 0)": 0.6514443159103394, "(24, 16)": 0.6754413843154907, "(26, 0)": 0.3698662519454956, "(26, 16)": 0.6514443159103394, "(28, 0)": 0.3698662519454956, "(28, 16)": 0.3698662519454956, "(30, 0)": 0.3698662519454956, "(30, 16)": 0.3698662519454956}, "r_span": [732, 848], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010530352592468262}}, {"prompt_attention_score": {"(0, 0)": 0.6707353591918945, "(0, 16)": 0.6707353591918945, "(2, 0)": 0.7191658020019531, "(2, 16)": 0.614567756652832, "(4, 0)": 0.7191658020019531, "(4, 16)": 0.614567756652832, "(6, 0)": 0.7191658020019531, "(6, 16)": 0.7191658020019531, "(8, 0)": 0.7191658020019531, "(8, 16)": 0.7191658020019531, "(10, 0)": 0.614567756652832, "(10, 16)": 0.614567756652832, "(12, 0)": 0.614567756652832, "(12, 16)": 0.7191658020019531, "(14, 0)": 0.43611016869544983, "(14, 16)": 0.4543699026107788, "(16, 0)": 0.6707353591918945, "(16, 16)": 0.614567756652832, "(18, 0)": 0.43611016869544983, "(18, 16)": 0.7191658020019531, "(20, 0)": 0.7191658020019531, "(20, 16)": 0.7191658020019531, "(22, 0)": 0.43611016869544983, "(22, 16)": 0.7191658020019531, "(24, 0)": 0.7191658020019531, "(24, 16)": 0.7191658020019531, "(26, 0)": 0.43611016869544983, "(26, 16)": 0.6707353591918945, "(28, 0)": 0.43611016869544983, "(28, 16)": 0.43611016869544983, "(30, 0)": 0.43611016869544983, "(30, 16)": 0.43611016869544983}, "r_span": [846, 897], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00010687112808227539}}]}, {"id": "8727", "source_id": "14541", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 603, "end": 608, "text": "Wi-Fi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\"\nGenerative: \"enjoy... the bar's Wi-Fi.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 772, "end": 797, "text": "validated parking options", "meta": "EVIDENT CONFLICT\nOriginal: \"validated\": false\nGenerative: \"validated parking options.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Tiburon Tavern:\n\nTiburon Tavern is a local dive bar located in Santa Barbara, California, offering a cozy atmosphere and a range of amenities. With a rating of 4.0 stars, the bar has gained a positive reputation among customers, who praise its friendly staff, cleanliness, and modern jukebox. While it may not be as lively as other bars in the area, Tiburon Tavern offers a unique experience for those seeking a more relaxed setting. Customers can enjoy a variety of beers, including craft options, and take advantage of the bar's Wi-Fi. The establishment is open seven days a week, with varying hours depending on the day of the week. While parking may be limited, the bar offers street parking and validated parking options. Overall, Tiburon Tavern is a great spot for locals and visitors alike, offering a welcoming atmosphere and quality drinks.", "response_spans": [[0, 87], [89, 596], [580, 921]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5051711201667786, "(0, 16)": 0.5051711201667786, "(2, 0)": 0.5280309319496155, "(2, 16)": 0.5051711201667786, "(4, 0)": 0.5280309319496155, "(4, 16)": 0.5280309319496155, "(6, 0)": 0.5051711201667786, "(6, 16)": 0.660137951374054, "(8, 0)": 0.5051711201667786, "(8, 16)": 0.5051711201667786, "(10, 0)": 0.660137951374054, "(10, 16)": 0.5051711201667786, "(12, 0)": 0.5051711201667786, "(12, 16)": 0.660137951374054, "(14, 0)": 0.5051711201667786, "(14, 16)": 0.660137951374054, "(16, 0)": 0.660137951374054, "(16, 16)": 0.5521812438964844, "(18, 0)": 0.5051711201667786, "(18, 16)": 0.660137951374054, "(20, 0)": 0.660137951374054, "(20, 16)": 0.5280309319496155, "(22, 0)": 0.5280309319496155, "(22, 16)": 0.660137951374054, "(24, 0)": 0.5280309319496155, "(24, 16)": 0.660137951374054, "(26, 0)": 0.660137951374054, "(26, 16)": 0.4706578552722931, "(28, 0)": 0.660137951374054, "(28, 16)": 0.5280309319496155, "(30, 0)": 0.660137951374054, "(30, 16)": 0.660137951374054}, "r_span": [1013, 1035], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007343292236328125}}, {"prompt_attention_score": {"(0, 0)": 0.7504462003707886, "(0, 16)": 0.7504462003707886, "(2, 0)": 0.7504462003707886, "(2, 16)": 0.7504462003707886, "(4, 0)": 0.7504462003707886, "(4, 16)": 0.7504462003707886, "(6, 0)": 0.7504462003707886, "(6, 16)": 0.7204664945602417, "(8, 0)": 0.6574879884719849, "(8, 16)": 0.7504462003707886, "(10, 0)": 0.7504462003707886, "(10, 16)": 0.7504462003707886, "(12, 0)": 0.7504462003707886, "(12, 16)": 0.7928777933120728, "(14, 0)": 0.6574879884719849, "(14, 16)": 0.7504462003707886, "(16, 0)": 0.49397581815719604, "(16, 16)": 0.7504462003707886, "(18, 0)": 0.7928777933120728, "(18, 16)": 0.7928777933120728, "(20, 0)": 0.7204664945602417, "(20, 16)": 0.6574879884719849, "(22, 0)": 0.426366925239563, "(22, 16)": 0.7928777933120728, "(24, 0)": 0.6574879884719849, "(24, 16)": 0.6069972515106201, "(26, 0)": 0.426366925239563, "(26, 16)": 0.6069972515106201, "(28, 0)": 0.426366925239563, "(28, 16)": 0.6574879884719849, "(30, 0)": 0.426366925239563, "(30, 16)": 0.426366925239563}, "r_span": [1037, 1157], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0016753673553466797}}, {"prompt_attention_score": {"(0, 0)": 0.6369302868843079, "(0, 16)": 0.6287456750869751, "(2, 0)": 0.6287456750869751, "(2, 16)": 0.6287456750869751, "(4, 0)": 0.6287456750869751, "(4, 16)": 0.6287456750869751, "(6, 0)": 0.6287456750869751, "(6, 16)": 0.7269033193588257, "(8, 0)": 0.6287456750869751, "(8, 16)": 0.6369302868843079, "(10, 0)": 0.6287456750869751, "(10, 16)": 0.6287456750869751, "(12, 0)": 0.6287456750869751, "(12, 16)": 0.7269033193588257, "(14, 0)": 0.6369302868843079, "(14, 16)": 0.6287456750869751, "(16, 0)": 0.6287456750869751, "(16, 16)": 0.6287456750869751, "(18, 0)": 0.7286754846572876, "(18, 16)": 0.7269033193588257, "(20, 0)": 0.7269033193588257, "(20, 16)": 0.6369302868843079, "(22, 0)": 0.43707263469696045, "(22, 16)": 0.7269033193588257, "(24, 0)": 0.6369302868843079, "(24, 16)": 0.5040943622589111, "(26, 0)": 0.43707263469696045, "(26, 16)": 0.5040943622589111, "(28, 0)": 0.43707263469696045, "(28, 16)": 0.6369302868843079, "(30, 0)": 0.43707263469696045, "(30, 16)": 0.43707263469696045}, "r_span": [1155, 1234], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0004303455352783203}}]}, {"id": "8733", "source_id": "14542", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 717, "end": 721, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerative: \"WiFi.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Three Pickles:\n\nThree Pickles is a locally-owned sandwich shop located in Goleta, California, with a second location in downtown Santa Barbara. The business offers a variety of sandwiches, including a popular signature sandwich called The Goucho, which has received rave reviews for its hot, messy, cheesy roast beef creation. Customers have praised the shop's friendly staff, quick service, and tasty offerings, with one reviewer describing their experience as a \"dream come true.\" The business has a rating of 4.0 stars and is open Monday through Friday from 10:30 am to 3 pm. While parking can be limited, the shop offers outdoor seating and WiFi.", "response_spans": [[0, 86], [88, 597], [581, 722]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4352399706840515, "(0, 16)": 0.4352399706840515, "(2, 0)": 0.4352399706840515, "(2, 16)": 0.4352399706840515, "(4, 0)": 0.4352399706840515, "(4, 16)": 0.5354148745536804, "(6, 0)": 0.4352399706840515, "(6, 16)": 0.6308602094650269, "(8, 0)": 0.4188423156738281, "(8, 16)": 0.4352399706840515, "(10, 0)": 0.6308602094650269, "(10, 16)": 0.6308602094650269, "(12, 0)": 0.5618586540222168, "(12, 16)": 0.6308602094650269, "(14, 0)": 0.4352399706840515, "(14, 16)": 0.6308602094650269, "(16, 0)": 0.6308602094650269, "(16, 16)": 0.5618586540222168, "(18, 0)": 0.4352399706840515, "(18, 16)": 0.6308602094650269, "(20, 0)": 0.6308602094650269, "(20, 16)": 0.4352399706840515, "(22, 0)": 0.4352399706840515, "(22, 16)": 0.6308602094650269, "(24, 0)": 0.4352399706840515, "(24, 16)": 0.6308602094650269, "(26, 0)": 0.6308602094650269, "(26, 16)": 0.5615900754928589, "(28, 0)": 0.6308602094650269, "(28, 16)": 0.4352399706840515, "(30, 0)": 0.6308602094650269, "(30, 16)": 0.6308602094650269}, "r_span": [951, 971], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003151893615722656}}, {"prompt_attention_score": {"(0, 0)": 0.6325578689575195, "(0, 16)": 0.6325578689575195, "(2, 0)": 0.6325578689575195, "(2, 16)": 0.6325578689575195, "(4, 0)": 0.6325578689575195, "(4, 16)": 0.6325578689575195, "(6, 0)": 0.6325578689575195, "(6, 16)": 0.5964264273643494, "(8, 0)": 0.6325578689575195, "(8, 16)": 0.6325578689575195, "(10, 0)": 0.6325578689575195, "(10, 16)": 0.6325578689575195, "(12, 0)": 0.6325578689575195, "(12, 16)": 0.7178797721862793, "(14, 0)": 0.6325578689575195, "(14, 16)": 0.6325578689575195, "(16, 0)": 0.7178797721862793, "(16, 16)": 0.6325578689575195, "(18, 0)": 0.6325578689575195, "(18, 16)": 0.5964264273643494, "(20, 0)": 0.5964264273643494, "(20, 16)": 0.6325578689575195, "(22, 0)": 0.6325578689575195, "(22, 16)": 0.5964264273643494, "(24, 0)": 0.6325578689575195, "(24, 16)": 0.7479070425033569, "(26, 0)": 0.43406787514686584, "(26, 16)": 0.5964264273643494, "(28, 0)": 0.43406787514686584, "(28, 16)": 0.6325578689575195, "(30, 0)": 0.43406787514686584, "(30, 16)": 0.43406787514686584}, "r_span": [973, 1096], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017033815383911133}}, {"prompt_attention_score": {"(0, 0)": 0.6255186200141907, "(0, 16)": 0.6255186200141907, "(2, 0)": 0.6255186200141907, "(2, 16)": 0.6255186200141907, "(4, 0)": 0.6255186200141907, "(4, 16)": 0.6255186200141907, "(6, 0)": 0.6255186200141907, "(6, 16)": 0.6130683422088623, "(8, 0)": 0.6255186200141907, "(8, 16)": 0.6255186200141907, "(10, 0)": 0.6255186200141907, "(10, 16)": 0.6255186200141907, "(12, 0)": 0.6255186200141907, "(12, 16)": 0.6130683422088623, "(14, 0)": 0.6255186200141907, "(14, 16)": 0.6255186200141907, "(16, 0)": 0.6255186200141907, "(16, 16)": 0.6255186200141907, "(18, 0)": 0.603042483329773, "(18, 16)": 0.6130683422088623, "(20, 0)": 0.6130683422088623, "(20, 16)": 0.6255186200141907, "(22, 0)": 0.6255186200141907, "(22, 16)": 0.6130683422088623, "(24, 0)": 0.6255186200141907, "(24, 16)": 0.6130683422088623, "(26, 0)": 0.4680301547050476, "(26, 16)": 0.6255186200141907, "(28, 0)": 0.4680301547050476, "(28, 16)": 0.6255186200141907, "(30, 0)": 0.4680301547050476, "(30, 16)": 0.4680301547050476}, "r_span": [1090, 1132], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0011129379272460938}}]}, {"id": "8757", "source_id": "14546", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 232, "end": 248, "text": "American cuisine", "meta": "HIGH INTRO OF NEW INFO \nOriginal: *not mentioned*\nGenerative: \"American cuisine...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Your Choice is a locally-owned Thai restaurant located in Santa Barbara, California. With a rating of 4.0 out of 5 stars, the restaurant offers a variety of dishes including Thai, Chinese, and American cuisine. Customers have praised the restaurant's quick and efficient service, delicious food, and friendly staff. One reviewer noted that the restaurant's take-out options are just as good as dining in, while another appreciated the restaurant's commitment to using fresh ingredients. However, some reviewers have experienced minor issues with their orders, such as spicy dishes, incorrect orders, and long delivery times. Despite these minor drawbacks, Your Choice has gained a loyal customer base and is highly recommended for those looking for a taste of authentic Thai cuisine in Santa Barbara.", "response_spans": [[0, 512], [498, 839]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7393044233322144, "(0, 16)": 0.7393044233322144, "(2, 0)": 0.6706401109695435, "(2, 16)": 0.6706401109695435, "(4, 0)": 0.6706401109695435, "(4, 16)": 0.6706401109695435, "(6, 0)": 0.6706401109695435, "(6, 16)": 0.7278560996055603, "(8, 0)": 0.7393044233322144, "(8, 16)": 0.6706401109695435, "(10, 0)": 0.7393044233322144, "(10, 16)": 0.7393044233322144, "(12, 0)": 0.7393044233322144, "(12, 16)": 0.7393044233322144, "(14, 0)": 0.7393044233322144, "(14, 16)": 0.7278560996055603, "(16, 0)": 0.6306284070014954, "(16, 16)": 0.7393044233322144, "(18, 0)": 0.5713478326797485, "(18, 16)": 0.7278560996055603, "(20, 0)": 0.6306284070014954, "(20, 16)": 0.7393044233322144, "(22, 0)": 0.5713478326797485, "(22, 16)": 0.7278560996055603, "(24, 0)": 0.7393044233322144, "(24, 16)": 0.7393044233322144, "(26, 0)": 0.5713478326797485, "(26, 16)": 0.6306284070014954, "(28, 0)": 0.5713478326797485, "(28, 16)": 0.7393044233322144, "(30, 0)": 0.5713478326797485, "(30, 16)": 0.5713478326797485}, "r_span": [828, 945], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0017403364181518555}}, {"prompt_attention_score": {"(0, 0)": 0.7604039907455444, "(0, 16)": 0.7604039907455444, "(2, 0)": 0.7390962243080139, "(2, 16)": 0.7604039907455444, "(4, 0)": 0.7390962243080139, "(4, 16)": 0.7390962243080139, "(6, 0)": 0.7604039907455444, "(6, 16)": 0.6724489331245422, "(8, 0)": 0.7604039907455444, "(8, 16)": 0.7604039907455444, "(10, 0)": 0.7604039907455444, "(10, 16)": 0.7390962243080139, "(12, 0)": 0.7604039907455444, "(12, 16)": 0.7390962243080139, "(14, 0)": 0.7604039907455444, "(14, 16)": 0.46872466802597046, "(16, 0)": 0.7390962243080139, "(16, 16)": 0.7390962243080139, "(18, 0)": 0.7604039907455444, "(18, 16)": 0.7390962243080139, "(20, 0)": 0.7390962243080139, "(20, 16)": 0.7604039907455444, "(22, 0)": 0.5022633671760559, "(22, 16)": 0.7390962243080139, "(24, 0)": 0.7604039907455444, "(24, 16)": 0.7390962243080139, "(26, 0)": 0.5022633671760559, "(26, 16)": 0.7390962243080139, "(28, 0)": 0.5022633671760559, "(28, 16)": 0.7604039907455444, "(30, 0)": 0.5022633671760559, "(30, 16)": 0.5022633671760559}, "r_span": [943, 1014], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010308027267456055}}]}, {"id": "8769", "source_id": "14548", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 745, "end": 781, "text": "does offer validated parking options", "meta": "EVIDENT CONFLICT\nOriginal: \"validated\": false\nGenerated: does offer validated parking options", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Radio Prophets:\n\nRadio Prophets is a locally owned business in Santa Barbara, California that offers a variety of services related to arts and entertainment, including live music performance, wedding planning, and event production. With a rating of 5.0 out of 5 stars, the business has received positive reviews from customers for its exceptional service, professionalism, and high-quality performances. Customers have praised the band for their ability to accommodate special requests and create a memorable atmosphere for their events. The business is open seven days a week and offers free WiFi to its customers. While parking may not be readily available, the business does offer validated parking options. Overall, Radio Prophets appears to be a reliable and talented choice for anyone looking for live music and event planning services in the Santa Barbara area.", "response_spans": [[0, 87], [89, 595], [581, 940]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.41971492767333984, "(0, 16)": 0.41971492767333984, "(2, 0)": 0.41971492767333984, "(2, 16)": 0.41971492767333984, "(4, 0)": 0.41971492767333984, "(4, 16)": 0.41971492767333984, "(6, 0)": 0.41971492767333984, "(6, 16)": 0.6058685779571533, "(8, 0)": 0.5292212963104248, "(8, 16)": 0.42422473430633545, "(10, 0)": 0.6058685779571533, "(10, 16)": 0.6058685779571533, "(12, 0)": 0.5381280183792114, "(12, 16)": 0.6058685779571533, "(14, 0)": 0.42422473430633545, "(14, 16)": 0.6058685779571533, "(16, 0)": 0.6058685779571533, "(16, 16)": 0.5381280183792114, "(18, 0)": 0.6058685779571533, "(18, 16)": 0.6058685779571533, "(20, 0)": 0.6058685779571533, "(20, 16)": 0.42422473430633545, "(22, 0)": 0.6058685779571533, "(22, 16)": 0.6058685779571533, "(24, 0)": 0.42422473430633545, "(24, 16)": 0.6058685779571533, "(26, 0)": 0.6058685779571533, "(26, 16)": 0.5062741637229919, "(28, 0)": 0.6058685779571533, "(28, 16)": 0.42422473430633545, "(30, 0)": 0.6058685779571533, "(30, 16)": 0.6058685779571533}, "r_span": [921, 942], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002561211585998535}}, {"prompt_attention_score": {"(0, 0)": 0.6024741530418396, "(0, 16)": 0.6024741530418396, "(2, 0)": 0.6024741530418396, "(2, 16)": 0.6024741530418396, "(4, 0)": 0.6024741530418396, "(4, 16)": 0.6024741530418396, "(6, 0)": 0.6024741530418396, "(6, 16)": 0.7629202604293823, "(8, 0)": 0.6807318925857544, "(8, 16)": 0.5979576706886292, "(10, 0)": 0.6024741530418396, "(10, 16)": 0.6024741530418396, "(12, 0)": 0.6024741530418396, "(12, 16)": 0.7629202604293823, "(14, 0)": 0.5979576706886292, "(14, 16)": 0.6024741530418396, "(16, 0)": 0.44919058680534363, "(16, 16)": 0.5979576706886292, "(18, 0)": 0.44919058680534363, "(18, 16)": 0.7629202604293823, "(20, 0)": 0.5197902917861938, "(20, 16)": 0.5979576706886292, "(22, 0)": 0.44919058680534363, "(22, 16)": 0.5197902917861938, "(24, 0)": 0.5979576706886292, "(24, 16)": 0.5197902917861938, "(26, 0)": 0.44919058680534363, "(26, 16)": 0.5979576706886292, "(28, 0)": 0.44919058680534363, "(28, 16)": 0.5979576706886292, "(30, 0)": 0.44919058680534363, "(30, 16)": 0.44919058680534363}, "r_span": [944, 1043], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017345547676086426}}, {"prompt_attention_score": {"(0, 0)": 0.6162580251693726, "(0, 16)": 0.6162580251693726, "(2, 0)": 0.6093139052391052, "(2, 16)": 0.6093139052391052, "(4, 0)": 0.6093139052391052, "(4, 16)": 0.6093139052391052, "(6, 0)": 0.6162580251693726, "(6, 16)": 0.7622692584991455, "(8, 0)": 0.6162580251693726, "(8, 16)": 0.6093139052391052, "(10, 0)": 0.6162580251693726, "(10, 16)": 0.6093139052391052, "(12, 0)": 0.6093139052391052, "(12, 16)": 0.5972636342048645, "(14, 0)": 0.6093139052391052, "(14, 16)": 0.6162580251693726, "(16, 0)": 0.46317195892333984, "(16, 16)": 0.6093139052391052, "(18, 0)": 0.46317195892333984, "(18, 16)": 0.5972636342048645, "(20, 0)": 0.5972636342048645, "(20, 16)": 0.6093139052391052, "(22, 0)": 0.46317195892333984, "(22, 16)": 0.5972636342048645, "(24, 0)": 0.6093139052391052, "(24, 16)": 0.5972636342048645, "(26, 0)": 0.46317195892333984, "(26, 16)": 0.6093139052391052, "(28, 0)": 0.46317195892333984, "(28, 16)": 0.6093139052391052, "(30, 0)": 0.46317195892333984, "(30, 16)": 0.46317195892333984}, "r_span": [1042, 1114], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0004755854606628418}}]}, {"id": "8781", "source_id": "14551", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Cabo's Baja Grill & Cantina:\n\nCabo's Baja Grill & Cantina is a Mexican restaurant located in Carpinteria, California. The restaurant has been renovated since its previous incarnation as Cabo's, with updates to the interior and bathrooms. However, the quality of the food has taken a hit, with reports of overcooked or raw food, high prices, and poorly mixed drinks. The restaurant has a casual atmosphere, with both indoor and outdoor seating, but the food does not seem to live up to the expectations of former patrons of Cabo's. While the service is generally good, the kitchen seems to be struggling to meet the standards of the restaurant's previous era. Overall, while the ambiance may be improved, the food at Cabo's Baja Grill & Cantina is underwhelming and may not be worth a visit for those who remember the quality of the food at its previous location.", "response_spans": [[0, 100], [102, 612], [595, 934]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.48587968945503235, "(0, 16)": 0.48587968945503235, "(2, 0)": 0.535602331161499, "(2, 16)": 0.48587968945503235, "(4, 0)": 0.48587968945503235, "(4, 16)": 0.543939471244812, "(6, 0)": 0.48587968945503235, "(6, 16)": 0.6840548515319824, "(8, 0)": 0.48587968945503235, "(8, 16)": 0.48587968945503235, "(10, 0)": 0.6300472021102905, "(10, 16)": 0.48587968945503235, "(12, 0)": 0.48587968945503235, "(12, 16)": 0.6300472021102905, "(14, 0)": 0.48587968945503235, "(14, 16)": 0.6300472021102905, "(16, 0)": 0.6300472021102905, "(16, 16)": 0.48587968945503235, "(18, 0)": 0.48587968945503235, "(18, 16)": 0.6300472021102905, "(20, 0)": 0.6300472021102905, "(20, 16)": 0.48587968945503235, "(22, 0)": 0.543939471244812, "(22, 16)": 0.6300472021102905, "(24, 0)": 0.543939471244812, "(24, 16)": 0.6300472021102905, "(26, 0)": 0.6300472021102905, "(26, 16)": 0.6300472021102905, "(28, 0)": 0.5330892205238342, "(28, 16)": 0.48587968945503235, "(30, 0)": 0.6300472021102905, "(30, 16)": 0.6300472021102905}, "r_span": [1428, 1456], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000844419002532959}}, {"prompt_attention_score": {"(0, 0)": 0.6065542101860046, "(0, 16)": 0.6065542101860046, "(2, 0)": 0.6065542101860046, "(2, 16)": 0.6065542101860046, "(4, 0)": 0.6065542101860046, "(4, 16)": 0.6065542101860046, "(6, 0)": 0.6065542101860046, "(6, 16)": 0.7106270790100098, "(8, 0)": 0.6155433654785156, "(8, 16)": 0.6065542101860046, "(10, 0)": 0.6352519392967224, "(10, 16)": 0.6065542101860046, "(12, 0)": 0.6065542101860046, "(12, 16)": 0.7106270790100098, "(14, 0)": 0.6065542101860046, "(14, 16)": 0.6065542101860046, "(16, 0)": 0.7106270790100098, "(16, 16)": 0.6065542101860046, "(18, 0)": 0.6065542101860046, "(18, 16)": 0.7106270790100098, "(20, 0)": 0.7106270790100098, "(20, 16)": 0.6065542101860046, "(22, 0)": 0.4039226770401001, "(22, 16)": 0.7106270790100098, "(24, 0)": 0.6338452100753784, "(24, 16)": 0.7106270790100098, "(26, 0)": 0.4039226770401001, "(26, 16)": 0.6338452100753784, "(28, 0)": 0.4039226770401001, "(28, 16)": 0.6065542101860046, "(30, 0)": 0.4039226770401001, "(30, 16)": 0.4039226770401001}, "r_span": [1458, 1585], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0032671689987182617}}, {"prompt_attention_score": {"(0, 0)": 0.6413424611091614, "(0, 16)": 0.7022291421890259, "(2, 0)": 0.7022291421890259, "(2, 16)": 0.6413424611091614, "(4, 0)": 0.7022291421890259, "(4, 16)": 0.7022291421890259, "(6, 0)": 0.7022291421890259, "(6, 16)": 0.7967753410339355, "(8, 0)": 0.7022291421890259, "(8, 16)": 0.6413424611091614, "(10, 0)": 0.7022291421890259, "(10, 16)": 0.7022291421890259, "(12, 0)": 0.7022291421890259, "(12, 16)": 0.7022291421890259, "(14, 0)": 0.7022291421890259, "(14, 16)": 0.47069668769836426, "(16, 0)": 0.7022291421890259, "(16, 16)": 0.7022291421890259, "(18, 0)": 0.6413424611091614, "(18, 16)": 0.7022291421890259, "(20, 0)": 0.7022291421890259, "(20, 16)": 0.7022291421890259, "(22, 0)": 0.472858190536499, "(22, 16)": 0.7022291421890259, "(24, 0)": 0.7341802716255188, "(24, 16)": 0.7967753410339355, "(26, 0)": 0.472858190536499, "(26, 16)": 0.7341802716255188, "(28, 0)": 0.472858190536499, "(28, 16)": 0.7022291421890259, "(30, 0)": 0.472858190536499, "(30, 16)": 0.472858190536499}, "r_span": [1579, 1659], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004799365997314453}}]}, {"id": "8787", "source_id": "14552", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 559, "end": 572, "text": "casual dining", "meta": "Conflict: Business Info tagged this as \" false\" therefore this is not available in the establishment.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Verde is a Spanish, tapas, and Mexican restaurant located in Santa Barbara, California. The establishment has received mixed reviews from customers, with some praising the bartender's skills and green chile sauce, while others have experienced poor service and subpar food. The restaurant offers outdoor seating and free WiFi, and takes reservations for parties of all sizes. Despite its potential, some customers have expressed concerns about the management and efficiency of the kitchen. Overall, Verde appears to be a decent option for those looking for a casual dining experience, but may not be worth visiting if quality and consistency are top priorities.", "response_spans": [[0, 512], [499, 661]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5346927642822266, "(0, 16)": 0.5346927642822266, "(2, 0)": 0.5346927642822266, "(2, 16)": 0.5346927642822266, "(4, 0)": 0.5346927642822266, "(4, 16)": 0.5346927642822266, "(6, 0)": 0.5346927642822266, "(6, 16)": 0.7321515083312988, "(8, 0)": 0.6371712684631348, "(8, 16)": 0.5346927642822266, "(10, 0)": 0.6371712684631348, "(10, 16)": 0.5346927642822266, "(12, 0)": 0.5346927642822266, "(12, 16)": 0.5435961484909058, "(14, 0)": 0.5346927642822266, "(14, 16)": 0.44456297159194946, "(16, 0)": 0.5435961484909058, "(16, 16)": 0.5346927642822266, "(18, 0)": 0.5346927642822266, "(18, 16)": 0.7321515083312988, "(20, 0)": 0.5435961484909058, "(20, 16)": 0.6371712684631348, "(22, 0)": 0.41687166690826416, "(22, 16)": 0.5346927642822266, "(24, 0)": 0.6371712684631348, "(24, 16)": 0.7321515083312988, "(26, 0)": 0.41687166690826416, "(26, 16)": 0.5435961484909058, "(28, 0)": 0.41687166690826416, "(28, 16)": 0.41687166690826416, "(30, 0)": 0.41687166690826416, "(30, 16)": 0.41687166690826416}, "r_span": [900, 1004], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0017572641372680664}}, {"prompt_attention_score": {"(0, 0)": 0.6268174648284912, "(0, 16)": 0.6268174648284912, "(2, 0)": 0.6268174648284912, "(2, 16)": 0.6268174648284912, "(4, 0)": 0.6268174648284912, "(4, 16)": 0.6268174648284912, "(6, 0)": 0.6268174648284912, "(6, 16)": 0.6308665871620178, "(8, 0)": 0.6268174648284912, "(8, 16)": 0.6268174648284912, "(10, 0)": 0.6268174648284912, "(10, 16)": 0.6268174648284912, "(12, 0)": 0.6268174648284912, "(12, 16)": 0.5911365747451782, "(14, 0)": 0.6308665871620178, "(14, 16)": 0.4896278977394104, "(16, 0)": 0.44423583149909973, "(16, 16)": 0.44423583149909973, "(18, 0)": 0.44423583149909973, "(18, 16)": 0.5911365747451782, "(20, 0)": 0.5911365747451782, "(20, 16)": 0.44423583149909973, "(22, 0)": 0.44423583149909973, "(22, 16)": 0.6268174648284912, "(24, 0)": 0.44423583149909973, "(24, 16)": 0.5568244457244873, "(26, 0)": 0.44423583149909973, "(26, 16)": 0.44423583149909973, "(28, 0)": 0.44423583149909973, "(28, 16)": 0.44423583149909973, "(30, 0)": 0.44423583149909973, "(30, 16)": 0.44423583149909973}, "r_span": [1002, 1037], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0021026134490966797}}]}, {"id": "8907", "source_id": "14575", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 375, "end": 406, "text": "all made with fresh ingredients", "meta": "HIGH INTRO OF NEW INFO\nStructured data has no mention of this claim. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 331, "end": 373, "text": "including pasta, seafood, and meat options", "meta": "LOW INTRO OF NEW INFO\nStructured data has no mention of these menu items but may stand to be accurate.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is an objective overview of Emilios Ristorante & Bar based on the provided structured data:\n\nEmilios Ristorante & Bar is a popular Italian restaurant located in Santa Barbara, California. With a rating of 3.5 stars, the restaurant offers a cozy atmosphere and excellent service. The menu features a variety of Italian dishes, including pasta, seafood, and meat options, all made with fresh ingredients. Customers have praised the restaurant for its delicious food, particularly the goat cheese salad and chicken dishes, as well as the friendly and attentive service. While some customers have noted that the restaurant may be a bit formal for a beachside location, overall Emilios Ristorante & Bar is a great choice for a fine dining experience.", "response_spans": [[0, 96], [98, 608], [593, 750]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5350114107131958, "(0, 16)": 0.5350114107131958, "(2, 0)": 0.5350114107131958, "(2, 16)": 0.5350114107131958, "(4, 0)": 0.5350114107131958, "(4, 16)": 0.5350114107131958, "(6, 0)": 0.5350114107131958, "(6, 16)": 0.6850544810295105, "(8, 0)": 0.632731556892395, "(8, 16)": 0.5350114107131958, "(10, 0)": 0.6850544810295105, "(10, 16)": 0.6850544810295105, "(12, 0)": 0.5645836591720581, "(12, 16)": 0.6850544810295105, "(14, 0)": 0.5350114107131958, "(14, 16)": 0.6850544810295105, "(16, 0)": 0.6850544810295105, "(16, 16)": 0.6850544810295105, "(18, 0)": 0.632731556892395, "(18, 16)": 0.6850544810295105, "(20, 0)": 0.6850544810295105, "(20, 16)": 0.5350114107131958, "(22, 0)": 0.6850544810295105, "(22, 16)": 0.6850544810295105, "(24, 0)": 0.5350114107131958, "(24, 16)": 0.6850544810295105, "(26, 0)": 0.6850544810295105, "(26, 16)": 0.6850544810295105, "(28, 0)": 0.6850544810295105, "(28, 16)": 0.6850544810295105, "(30, 0)": 0.6850544810295105, "(30, 16)": 0.6850544810295105}, "r_span": [640, 662], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008767843246459961}}, {"prompt_attention_score": {"(0, 0)": 0.6481044292449951, "(0, 16)": 0.6481044292449951, "(2, 0)": 0.6481044292449951, "(2, 16)": 0.6481044292449951, "(4, 0)": 0.6481044292449951, "(4, 16)": 0.6481044292449951, "(6, 0)": 0.6481044292449951, "(6, 16)": 0.7404062151908875, "(8, 0)": 0.6905680298805237, "(8, 16)": 0.6481044292449951, "(10, 0)": 0.6905680298805237, "(10, 16)": 0.6481044292449951, "(12, 0)": 0.6481044292449951, "(12, 16)": 0.6905680298805237, "(14, 0)": 0.6481044292449951, "(14, 16)": 0.6905680298805237, "(16, 0)": 0.6905680298805237, "(16, 16)": 0.6481044292449951, "(18, 0)": 0.6905680298805237, "(18, 16)": 0.7404062151908875, "(20, 0)": 0.6905680298805237, "(20, 16)": 0.6481044292449951, "(22, 0)": 0.4199921786785126, "(22, 16)": 0.6905680298805237, "(24, 0)": 0.6905680298805237, "(24, 16)": 0.6905680298805237, "(26, 0)": 0.4199921786785126, "(26, 16)": 0.4199921786785126, "(28, 0)": 0.4199921786785126, "(28, 16)": 0.6481044292449951, "(30, 0)": 0.4199921786785126, "(30, 16)": 0.4199921786785126}, "r_span": [664, 779], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005211234092712402}}, {"prompt_attention_score": {"(0, 0)": 0.6709273457527161, "(0, 16)": 0.6709273457527161, "(2, 0)": 0.6709273457527161, "(2, 16)": 0.6709273457527161, "(4, 0)": 0.6709273457527161, "(4, 16)": 0.6709273457527161, "(6, 0)": 0.6709273457527161, "(6, 16)": 0.6077097654342651, "(8, 0)": 0.6354966759681702, "(8, 16)": 0.6709273457527161, "(10, 0)": 0.6709273457527161, "(10, 16)": 0.6709273457527161, "(12, 0)": 0.6709273457527161, "(12, 16)": 0.6709273457527161, "(14, 0)": 0.6354966759681702, "(14, 16)": 0.6709273457527161, "(16, 0)": 0.6709273457527161, "(16, 16)": 0.4299609363079071, "(18, 0)": 0.6354966759681702, "(18, 16)": 0.6709273457527161, "(20, 0)": 0.6709273457527161, "(20, 16)": 0.6709273457527161, "(22, 0)": 0.4299609363079071, "(22, 16)": 0.6709273457527161, "(24, 0)": 0.6709273457527161, "(24, 16)": 0.6709273457527161, "(26, 0)": 0.4299609363079071, "(26, 16)": 0.6709273457527161, "(28, 0)": 0.4299609363079071, "(28, 16)": 0.4299609363079071, "(30, 0)": 0.4299609363079071, "(30, 16)": 0.4299609363079071}, "r_span": [777, 811], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0012981891632080078}}]}, {"id": "8937", "source_id": "14580", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 587, "end": 607, "text": "and catering orders.", "meta": "HIGH INTRO OF NEW INFO\nStructured data has no mention of catering services. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 558, "end": 576, "text": "takes reservations", "meta": "EVIDENT CONFLICT\nOriginal: \"RestaurantsReservations\": false,\nAIGC: takes reservations\n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 655, "end": 680, "text": "has a loyal customer base", "meta": "LOW INTRO OF NEW INFO\nStructured data has no mention of a loyal . customer base but may stand to be accurate ", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of The Daily Grind:\n\nThe Daily Grind is a popular restaurant located in Santa Barbara, California, serving a variety of cuisines such as Restaurants, Sandwiches, Breakfast & Brunch, Coffee & Tea, Food, Juice Bars & Smoothies. The business has a rating of 3.5 stars and receives positive reviews for its coffee and pastries, but some customers have had issues with the quality of their meals, including finding bugs in their salads. The restaurant offers free WiFi and outdoor seating, and takes reservations, takeout, and catering orders. Despite some negative reviews, The Daily Grind has a loyal customer base and is known for its friendly staff and pleasant atmosphere.", "response_spans": [[0, 88], [90, 599], [587, 741]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3817875385284424, "(0, 16)": 0.3817875385284424, "(2, 0)": 0.3817875385284424, "(2, 16)": 0.3817875385284424, "(4, 0)": 0.3817875385284424, "(4, 16)": 0.3817875385284424, "(6, 0)": 0.3817875385284424, "(6, 16)": 0.6266605854034424, "(8, 0)": 0.3817875385284424, "(8, 16)": 0.3817875385284424, "(10, 0)": 0.6266605854034424, "(10, 16)": 0.6266605854034424, "(12, 0)": 0.3817875385284424, "(12, 16)": 0.6266605854034424, "(14, 0)": 0.3817875385284424, "(14, 16)": 0.6266605854034424, "(16, 0)": 0.6266605854034424, "(16, 16)": 0.6266605854034424, "(18, 0)": 0.3817875385284424, "(18, 16)": 0.6266605854034424, "(20, 0)": 0.6266605854034424, "(20, 16)": 0.3817875385284424, "(22, 0)": 0.3817875385284424, "(22, 16)": 0.6266605854034424, "(24, 0)": 0.3817875385284424, "(24, 16)": 0.6266605854034424, "(26, 0)": 0.6266605854034424, "(26, 16)": 0.6266605854034424, "(28, 0)": 0.6266605854034424, "(28, 16)": 0.3817875385284424, "(30, 0)": 0.6266605854034424, "(30, 16)": 0.6266605854034424}, "r_span": [782, 803], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005232095718383789}}, {"prompt_attention_score": {"(0, 0)": 0.5342555642127991, "(0, 16)": 0.5342555642127991, "(2, 0)": 0.5342555642127991, "(2, 16)": 0.5342555642127991, "(4, 0)": 0.5342555642127991, "(4, 16)": 0.5342555642127991, "(6, 0)": 0.5342555642127991, "(6, 16)": 0.7934605479240417, "(8, 0)": 0.5342555642127991, "(8, 16)": 0.5342555642127991, "(10, 0)": 0.5342555642127991, "(10, 16)": 0.5342555642127991, "(12, 0)": 0.5342555642127991, "(12, 16)": 0.7934605479240417, "(14, 0)": 0.5342555642127991, "(14, 16)": 0.7934605479240417, "(16, 0)": 0.581899106502533, "(16, 16)": 0.5342555642127991, "(18, 0)": 0.5342555642127991, "(18, 16)": 0.7934605479240417, "(20, 0)": 0.7934605479240417, "(20, 16)": 0.5342555642127991, "(22, 0)": 0.5342555642127991, "(22, 16)": 0.6090657114982605, "(24, 0)": 0.5342555642127991, "(24, 16)": 0.581899106502533, "(26, 0)": 0.42825841903686523, "(26, 16)": 0.581899106502533, "(28, 0)": 0.42825841903686523, "(28, 16)": 0.5342555642127991, "(30, 0)": 0.42825841903686523, "(30, 16)": 0.42825841903686523}, "r_span": [805, 930], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0007674694061279297}}, {"prompt_attention_score": {"(0, 0)": 0.5783646106719971, "(0, 16)": 0.5783646106719971, "(2, 0)": 0.5783646106719971, "(2, 16)": 0.5783646106719971, "(4, 0)": 0.5783646106719971, "(4, 16)": 0.5783646106719971, "(6, 0)": 0.5783646106719971, "(6, 16)": 0.6833091974258423, "(8, 0)": 0.5783646106719971, "(8, 16)": 0.5783646106719971, "(10, 0)": 0.5783646106719971, "(10, 16)": 0.5783646106719971, "(12, 0)": 0.5783646106719971, "(12, 16)": 0.6833091974258423, "(14, 0)": 0.5783646106719971, "(14, 16)": 0.584218442440033, "(16, 0)": 0.5783646106719971, "(16, 16)": 0.5783646106719971, "(18, 0)": 0.41530123353004456, "(18, 16)": 0.584218442440033, "(20, 0)": 0.584218442440033, "(20, 16)": 0.5783646106719971, "(22, 0)": 0.41530123353004456, "(22, 16)": 0.6833091974258423, "(24, 0)": 0.5783646106719971, "(24, 16)": 0.6833091974258423, "(26, 0)": 0.41530123353004456, "(26, 16)": 0.5783646106719971, "(28, 0)": 0.41530123353004456, "(28, 16)": 0.5783646106719971, "(30, 0)": 0.41530123353004456, "(30, 16)": 0.41530123353004456}, "r_span": [927, 957], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00034803152084350586}}]}, {"id": "9003", "source_id": "14592", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Crushcakes & Co is a popular bakery and cafe located in Montecito, California, serving up delicious desserts and drinks. Customers rave about the mouthwatering cupcakes and lattes, with some even rating it as the best hamburger in town. The cozy atmosphere and free WiFi are added bonuses. Despite being small, the business boasts a high rating of 4.5 stars and a loyal customer base. Reviewers particularly enjoy the unique and playful offerings, such as chocolate cake burgers, making it a must-visit destination for sweet lovers.", "response_spans": [[0, 502], [487, 532]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6532764434814453, "(0, 16)": 0.6532764434814453, "(2, 0)": 0.6532764434814453, "(2, 16)": 0.6532764434814453, "(4, 0)": 0.6532764434814453, "(4, 16)": 0.6532764434814453, "(6, 0)": 0.6532764434814453, "(6, 16)": 0.7687172889709473, "(8, 0)": 0.6532764434814453, "(8, 16)": 0.6532764434814453, "(10, 0)": 0.6532764434814453, "(10, 16)": 0.5813128352165222, "(12, 0)": 0.6532764434814453, "(12, 16)": 0.6532764434814453, "(14, 0)": 0.6532764434814453, "(14, 16)": 0.6532764434814453, "(16, 0)": 0.6532764434814453, "(16, 16)": 0.6532764434814453, "(18, 0)": 0.5813128352165222, "(18, 16)": 0.7687172889709473, "(20, 0)": 0.7687172889709473, "(20, 16)": 0.5813128352165222, "(22, 0)": 0.4097079634666443, "(22, 16)": 0.5813128352165222, "(24, 0)": 0.5813128352165222, "(24, 16)": 0.5813128352165222, "(26, 0)": 0.4097079634666443, "(26, 16)": 0.5813128352165222, "(28, 0)": 0.4097079634666443, "(28, 16)": 0.5813128352165222, "(30, 0)": 0.4097079634666443, "(30, 16)": 0.4097079634666443}, "r_span": [638, 767], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0001423358917236328}}, {"prompt_attention_score": {"(0, 0)": 0.5651760101318359, "(0, 16)": 0.5651760101318359, "(2, 0)": 0.510265588760376, "(2, 16)": 0.510265588760376, "(4, 0)": 0.510265588760376, "(4, 16)": 0.510265588760376, "(6, 0)": 0.510265588760376, "(6, 16)": 0.5651760101318359, "(8, 0)": 0.5651760101318359, "(8, 16)": 0.510265588760376, "(10, 0)": 0.510265588760376, "(10, 16)": 0.510265588760376, "(12, 0)": 0.3742500841617584, "(12, 16)": 0.5651760101318359, "(14, 0)": 0.5651760101318359, "(14, 16)": 0.5651760101318359, "(16, 0)": 0.5651760101318359, "(16, 16)": 0.510265588760376, "(18, 0)": 0.3742500841617584, "(18, 16)": 0.5651760101318359, "(20, 0)": 0.5651760101318359, "(20, 16)": 0.5651760101318359, "(22, 0)": 0.3742500841617584, "(22, 16)": 0.5651760101318359, "(24, 0)": 0.5651760101318359, "(24, 16)": 0.5651760101318359, "(26, 0)": 0.3742500841617584, "(26, 16)": 0.5651760101318359, "(28, 0)": 0.3742500841617584, "(28, 16)": 0.5651760101318359, "(30, 0)": 0.3742500841617584, "(30, 16)": 0.3742500841617584}, "r_span": [762, 773], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00017917156219482422}}]}, {"id": "9069", "source_id": "14603", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 806, "end": 840, "text": "the service can sometimes be slow.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No reviews about the service being slow sometimes\nGenerative: \"...the service can sometimes be slow.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Modern Times Academy of Recreational Sciences is a popular local business in Santa Barbara, California that offers a unique blend of beer, breakfast, brunch, and vegan options. With a rating of 4.5 stars, the business has a loyal customer base who appreciate its welcoming atmosphere, friendly staff, and high-quality products. Customers particularly praise the business's selection of craft beers, including IPAs and barrel-aged stouts, as well as its vegan menu options, which are described as creative, indulgent, and delicious. The business's outdoor patio area is also a highlight, providing a cozy spot for customers to relax and enjoy their meals. While some customers have expressed appreciation for the business's knowledgeable staff, others have noted that the service can sometimes be slow. Nonetheless, Modern Times Academy of Recreational Sciences appears to be a top choice for locals and visitors alike looking for a fun and satisfying dining experience.", "response_spans": [[0, 511], [492, 996], [979, 1008]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6805221438407898, "(0, 16)": 0.6454693078994751, "(2, 0)": 0.6805221438407898, "(2, 16)": 0.6454693078994751, "(4, 0)": 0.6805221438407898, "(4, 16)": 0.6805221438407898, "(6, 0)": 0.6805221438407898, "(6, 16)": 0.8143439292907715, "(8, 0)": 0.6805221438407898, "(8, 16)": 0.6805221438407898, "(10, 0)": 0.6454693078994751, "(10, 16)": 0.6805221438407898, "(12, 0)": 0.6805221438407898, "(12, 16)": 0.8143439292907715, "(14, 0)": 0.6805221438407898, "(14, 16)": 0.5135670900344849, "(16, 0)": 0.5135670900344849, "(16, 16)": 0.6805221438407898, "(18, 0)": 0.6805221438407898, "(18, 16)": 0.8143439292907715, "(20, 0)": 0.8143439292907715, "(20, 16)": 0.6805221438407898, "(22, 0)": 0.6805221438407898, "(22, 16)": 0.8143439292907715, "(24, 0)": 0.6805221438407898, "(24, 16)": 0.8143439292907715, "(26, 0)": 0.5135670900344849, "(26, 16)": 0.6805221438407898, "(28, 0)": 0.5135670900344849, "(28, 16)": 0.6805221438407898, "(30, 0)": 0.5135670900344849, "(30, 16)": 0.5135670900344849}, "r_span": [975, 1090], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011568069458007812}}, {"prompt_attention_score": {"(0, 0)": 0.7169657349586487, "(0, 16)": 0.7169657349586487, "(2, 0)": 0.7084450125694275, "(2, 16)": 0.7084450125694275, "(4, 0)": 0.7169657349586487, "(4, 16)": 0.7084450125694275, "(6, 0)": 0.7169657349586487, "(6, 16)": 0.6841448545455933, "(8, 0)": 0.7169657349586487, "(8, 16)": 0.7169657349586487, "(10, 0)": 0.7084450125694275, "(10, 16)": 0.7084450125694275, "(12, 0)": 0.7169657349586487, "(12, 16)": 0.7084450125694275, "(14, 0)": 0.7169657349586487, "(14, 16)": 0.7169657349586487, "(16, 0)": 0.7084450125694275, "(16, 16)": 0.7169657349586487, "(18, 0)": 0.7169657349586487, "(18, 16)": 0.7084450125694275, "(20, 0)": 0.7084450125694275, "(20, 16)": 0.7169657349586487, "(22, 0)": 0.7169657349586487, "(22, 16)": 0.7169657349586487, "(24, 0)": 0.7169657349586487, "(24, 16)": 0.7084450125694275, "(26, 0)": 0.49665001034736633, "(26, 16)": 0.7169657349586487, "(28, 0)": 0.49665001034736633, "(28, 16)": 0.7169657349586487, "(30, 0)": 0.7169657349586487, "(30, 16)": 0.49665001034736633}, "r_span": [1086, 1193], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001232445240020752}}, {"prompt_attention_score": {"(0, 0)": 0.6451745629310608, "(0, 16)": 0.6451745629310608, "(2, 0)": 0.6468393206596375, "(2, 16)": 0.6451745629310608, "(4, 0)": 0.6451745629310608, "(4, 16)": 0.6468393206596375, "(6, 0)": 0.6451745629310608, "(6, 16)": 0.5887620449066162, "(8, 0)": 0.6451745629310608, "(8, 16)": 0.6451745629310608, "(10, 0)": 0.6468393206596375, "(10, 16)": 0.6468393206596375, "(12, 0)": 0.6451745629310608, "(12, 16)": 0.5215392112731934, "(14, 0)": 0.6451745629310608, "(14, 16)": 0.5215392112731934, "(16, 0)": 0.41496917605400085, "(16, 16)": 0.41496917605400085, "(18, 0)": 0.6451745629310608, "(18, 16)": 0.5736886262893677, "(20, 0)": 0.41496917605400085, "(20, 16)": 0.6451745629310608, "(22, 0)": 0.6451745629310608, "(22, 16)": 0.5736886262893677, "(24, 0)": 0.6451745629310608, "(24, 16)": 0.48119449615478516, "(26, 0)": 0.41496917605400085, "(26, 16)": 0.6451745629310608, "(28, 0)": 0.41496917605400085, "(28, 16)": 0.6451745629310608, "(30, 0)": 0.6451745629310608, "(30, 16)": 0.41496917605400085}, "r_span": [1191, 1195], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004450678825378418}}]}, {"id": "9075", "source_id": "14604", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 260, "end": 278, "text": "cakes, and cookies", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of cakes and cookies\nGenerative: \"...cakes, and cookies...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Xanadu Bakery:\n\nXanadu Bakery is a local bakery located in Santa Barbara, California, with a rating of 3.0 stars. The bakery offers a variety of delicious baked goods, including pastries, cakes, and cookies, as well as coffee and other beverages. Customers have praised the bakery's excellent products and friendly service, with many expressing their disappointment at its impending closure due to a greedy landlord. However, some reviewers have criticized the bakery's use of Crisco in their pastries and lack of transparency regarding their ingredients. Despite these issues, Xanadu Bakery remains a popular spot for locals and visitors alike, offering a cozy atmosphere and enjoyable dining experience.", "response_spans": [[0, 86], [88, 598], [583, 777]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.43249624967575073, "(0, 16)": 0.43249624967575073, "(2, 0)": 0.43249624967575073, "(2, 16)": 0.43249624967575073, "(4, 0)": 0.508167564868927, "(4, 16)": 0.43249624967575073, "(6, 0)": 0.43249624967575073, "(6, 16)": 0.6264258623123169, "(8, 0)": 0.4749549925327301, "(8, 16)": 0.43249624967575073, "(10, 0)": 0.6264258623123169, "(10, 16)": 0.6264258623123169, "(12, 0)": 0.5319079756736755, "(12, 16)": 0.6264258623123169, "(14, 0)": 0.4749549925327301, "(14, 16)": 0.6264258623123169, "(16, 0)": 0.6264258623123169, "(16, 16)": 0.5319079756736755, "(18, 0)": 0.43249624967575073, "(18, 16)": 0.6264258623123169, "(20, 0)": 0.6264258623123169, "(20, 16)": 0.4749549925327301, "(22, 0)": 0.4749549925327301, "(22, 16)": 0.6264258623123169, "(24, 0)": 0.4749549925327301, "(24, 16)": 0.6264258623123169, "(26, 0)": 0.6264258623123169, "(26, 16)": 0.6126173734664917, "(28, 0)": 0.6264258623123169, "(28, 16)": 0.4749549925327301, "(30, 0)": 0.6264258623123169, "(30, 16)": 0.6264258623123169}, "r_span": [881, 903], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005304217338562012}}, {"prompt_attention_score": {"(0, 0)": 0.6343874931335449, "(0, 16)": 0.6343874931335449, "(2, 0)": 0.5412408709526062, "(2, 16)": 0.5412408709526062, "(4, 0)": 0.5412408709526062, "(4, 16)": 0.5412408709526062, "(6, 0)": 0.5412408709526062, "(6, 16)": 0.760100245475769, "(8, 0)": 0.6290315985679626, "(8, 16)": 0.5412408709526062, "(10, 0)": 0.6290315985679626, "(10, 16)": 0.6343874931335449, "(12, 0)": 0.6343874931335449, "(12, 16)": 0.760100245475769, "(14, 0)": 0.6290315985679626, "(14, 16)": 0.6343874931335449, "(16, 0)": 0.760100245475769, "(16, 16)": 0.6343874931335449, "(18, 0)": 0.6290315985679626, "(18, 16)": 0.7866888046264648, "(20, 0)": 0.6290315985679626, "(20, 16)": 0.6290315985679626, "(22, 0)": 0.6290315985679626, "(22, 16)": 0.760100245475769, "(24, 0)": 0.6290315985679626, "(24, 16)": 0.6290315985679626, "(26, 0)": 0.43543770909309387, "(26, 16)": 0.6290315985679626, "(28, 0)": 0.43543770909309387, "(28, 16)": 0.6290315985679626, "(30, 0)": 0.6290315985679626, "(30, 16)": 0.43543770909309387}, "r_span": [905, 1033], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010721683502197266}}, {"prompt_attention_score": {"(0, 0)": 0.6315839886665344, "(0, 16)": 0.6315839886665344, "(2, 0)": 0.5573146939277649, "(2, 16)": 0.5573146939277649, "(4, 0)": 0.5573146939277649, "(4, 16)": 0.5573146939277649, "(6, 0)": 0.5573146939277649, "(6, 16)": 0.6940175890922546, "(8, 0)": 0.6315839886665344, "(8, 16)": 0.5573146939277649, "(10, 0)": 0.568759560585022, "(10, 16)": 0.6315839886665344, "(12, 0)": 0.5573146939277649, "(12, 16)": 0.568759560585022, "(14, 0)": 0.568759560585022, "(14, 16)": 0.6315839886665344, "(16, 0)": 0.6315839886665344, "(16, 16)": 0.5573146939277649, "(18, 0)": 0.568759560585022, "(18, 16)": 0.6315839886665344, "(20, 0)": 0.6315839886665344, "(20, 16)": 0.568759560585022, "(22, 0)": 0.568759560585022, "(22, 16)": 0.6315839886665344, "(24, 0)": 0.568759560585022, "(24, 16)": 0.568759560585022, "(26, 0)": 0.43405160307884216, "(26, 16)": 0.568759560585022, "(28, 0)": 0.43405160307884216, "(28, 16)": 0.568759560585022, "(30, 0)": 0.43405160307884216, "(30, 16)": 0.43405160307884216}, "r_span": [1030, 1072], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003883838653564453}}]}, {"id": "9081", "source_id": "14605", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 515, "end": 520, "text": "soups", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"...soups\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 561, "end": 600, "text": "with options for vegetarians and vegans", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"...with options for vegetarians and vegans\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 602, "end": 632, "text": "The business has a parking lot", "meta": "EVIDENT CONFLICT\nOriginal: \"lot\": false,\nGenerative: \"The business has a parking lot\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 602, "end": 648, "text": "The business has a parking lot, street parking", "meta": "EVIDENT CONFLICT\nOriginal: \"street\": false,\nGenerative: \"The business has a... street parking\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Angel Oak:\n\nAngel Oak is a restaurant located in Santa Barbara, California, offering a range of cuisines including Restaurants, Seafood, American (New), and Steakhouses. The establishment has a rating of 4.0 stars and offers free Wi-Fi. The business hours are as follows: Monday to Saturday from 17:00 to 22:00, and Sunday from 17:00 to 22:00. The restaurant provides outdoor seating and has a romantic ambiance. The menu includes appetizers, soups, salads, seafood, steaks, and desserts, with options for vegetarians and vegans. The business has a parking lot, street parking, and valet parking options. The staff is friendly, knowledgeable, and provides excellent service. The reviews mention that the food is delicious, especially the filet mignon, and the service is great. However, some reviewers noted that the menu lacks variety and the lighting is not ideal. Overall, Angel Oak is a great dining destination for those looking for high-quality food and exceptional service in a romantic setting.", "response_spans": [[0, 82], [84, 593], [574, 1074]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.41050291061401367, "(0, 16)": 0.41050291061401367, "(2, 0)": 0.41050291061401367, "(2, 16)": 0.41050291061401367, "(4, 0)": 0.41050291061401367, "(4, 16)": 0.41050291061401367, "(6, 0)": 0.41050291061401367, "(6, 16)": 0.6108568906784058, "(8, 0)": 0.5992322564125061, "(8, 16)": 0.5377488732337952, "(10, 0)": 0.6108568906784058, "(10, 16)": 0.6108568906784058, "(12, 0)": 0.5377488732337952, "(12, 16)": 0.6108568906784058, "(14, 0)": 0.3876881003379822, "(14, 16)": 0.6108568906784058, "(16, 0)": 0.6108568906784058, "(16, 16)": 0.5377488732337952, "(18, 0)": 0.41050291061401367, "(18, 16)": 0.6108568906784058, "(20, 0)": 0.6108568906784058, "(20, 16)": 0.3876881003379822, "(22, 0)": 0.3876881003379822, "(22, 16)": 0.6108568906784058, "(24, 0)": 0.3876881003379822, "(24, 16)": 0.6108568906784058, "(26, 0)": 0.6108568906784058, "(26, 16)": 0.34394571185112, "(28, 0)": 0.5377488732337952, "(28, 16)": 0.3876881003379822, "(30, 0)": 0.3876881003379822, "(30, 16)": 0.6108568906784058}, "r_span": [1250, 1269], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00015181303024291992}}, {"prompt_attention_score": {"(0, 0)": 0.5891939997673035, "(0, 16)": 0.5891939997673035, "(2, 0)": 0.5891939997673035, "(2, 16)": 0.5891939997673035, "(4, 0)": 0.5891939997673035, "(4, 16)": 0.5891939997673035, "(6, 0)": 0.5891939997673035, "(6, 16)": 0.7846981287002563, "(8, 0)": 0.7846981287002563, "(8, 16)": 0.5891939997673035, "(10, 0)": 0.5960568785667419, "(10, 16)": 0.5891939997673035, "(12, 0)": 0.559777021408081, "(12, 16)": 0.7846981287002563, "(14, 0)": 0.559777021408081, "(14, 16)": 0.7846981287002563, "(16, 0)": 0.7846981287002563, "(16, 16)": 0.5891939997673035, "(18, 0)": 0.5891939997673035, "(18, 16)": 0.7846981287002563, "(20, 0)": 0.7846981287002563, "(20, 16)": 0.559777021408081, "(22, 0)": 0.559777021408081, "(22, 16)": 0.7846981287002563, "(24, 0)": 0.559777021408081, "(24, 16)": 0.7846981287002563, "(26, 0)": 0.4222364127635956, "(26, 16)": 0.559777021408081, "(28, 0)": 0.4222364127635956, "(28, 16)": 0.559777021408081, "(30, 0)": 0.559777021408081, "(30, 16)": 0.4222364127635956}, "r_span": [1271, 1416], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0016331672668457031}}, {"prompt_attention_score": {"(0, 0)": 0.761101484298706, "(0, 16)": 0.761101484298706, "(2, 0)": 0.761101484298706, "(2, 16)": 0.761101484298706, "(4, 0)": 0.761101484298706, "(4, 16)": 0.761101484298706, "(6, 0)": 0.761101484298706, "(6, 16)": 0.674685001373291, "(8, 0)": 0.761101484298706, "(8, 16)": 0.761101484298706, "(10, 0)": 0.761101484298706, "(10, 16)": 0.761101484298706, "(12, 0)": 0.761101484298706, "(12, 16)": 0.761101484298706, "(14, 0)": 0.6675662994384766, "(14, 16)": 0.4646722078323364, "(16, 0)": 0.761101484298706, "(16, 16)": 0.761101484298706, "(18, 0)": 0.6675662994384766, "(18, 16)": 0.674685001373291, "(20, 0)": 0.674685001373291, "(20, 16)": 0.6675662994384766, "(22, 0)": 0.6675662994384766, "(22, 16)": 0.615839958190918, "(24, 0)": 0.6675662994384766, "(24, 16)": 0.615839958190918, "(26, 0)": 0.46768322587013245, "(26, 16)": 0.6675662994384766, "(28, 0)": 0.46768322587013245, "(28, 16)": 0.6675662994384766, "(30, 0)": 0.6675662994384766, "(30, 16)": 0.46768322587013245}, "r_span": [1412, 1523], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0036377906799316406}}]}, {"id": "9159", "source_id": "14618", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 846, "end": 865, "text": "intimate atmosphere", "meta": "HIGH INTRO OF NEW INFO\nAIGC: offering intimate atmosphere\nOriginal:\"intimate\": null,\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Wingman Rodeo - Milpas Street:\n\nWingman Rodeo - Milpas Street is a popular restaurant located in Santa Barbara, California, serving a variety of dishes including salads, sandwiches, chicken wings, and tenders. The establishment has a rating of 4.0 stars and offers outdoor seating, free WiFi, and takeout options. While some reviewers have praised the restaurant's atmosphere and food quality, others have expressed disappointment with the taste and portion size of their orders. Specifically, some reviewers have enjoyed the bourbon wings and sandwiches, while others have had issues with the dryness of the chicken wings and the balance of the burrito. Despite these mixed reviews, Wingman Rodeo remains a popular spot for locals and visitors alike, offering a trendy and intimate atmosphere.", "response_spans": [[0, 102], [104, 615], [598, 866]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.43966227769851685, "(0, 16)": 0.43966227769851685, "(2, 0)": 0.43966227769851685, "(2, 16)": 0.43966227769851685, "(4, 0)": 0.43966227769851685, "(4, 16)": 0.4956705570220947, "(6, 0)": 0.4956705570220947, "(6, 16)": 0.6938406229019165, "(8, 0)": 0.6938406229019165, "(8, 16)": 0.43966227769851685, "(10, 0)": 0.6021677851676941, "(10, 16)": 0.6021677851676941, "(12, 0)": 0.5305314660072327, "(12, 16)": 0.6021677851676941, "(14, 0)": 0.4956705570220947, "(14, 16)": 0.6021677851676941, "(16, 0)": 0.6021677851676941, "(16, 16)": 0.6021677851676941, "(18, 0)": 0.4956705570220947, "(18, 16)": 0.6021677851676941, "(20, 0)": 0.6021677851676941, "(20, 16)": 0.4956705570220947, "(22, 0)": 0.6021677851676941, "(22, 16)": 0.6021677851676941, "(24, 0)": 0.4956705570220947, "(24, 16)": 0.6021677851676941, "(26, 0)": 0.6021677851676941, "(26, 16)": 0.44384998083114624, "(28, 0)": 0.6021677851676941, "(28, 16)": 0.4956705570220947, "(30, 0)": 0.6021677851676941, "(30, 16)": 0.6021677851676941}, "r_span": [942, 968], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006579160690307617}}, {"prompt_attention_score": {"(0, 0)": 0.5889073610305786, "(0, 16)": 0.5889073610305786, "(2, 0)": 0.5889073610305786, "(2, 16)": 0.5889073610305786, "(4, 0)": 0.5889073610305786, "(4, 16)": 0.5889073610305786, "(6, 0)": 0.5889073610305786, "(6, 16)": 0.8160856366157532, "(8, 0)": 0.7007027864456177, "(8, 16)": 0.5889073610305786, "(10, 0)": 0.5889073610305786, "(10, 16)": 0.5889073610305786, "(12, 0)": 0.5889073610305786, "(12, 16)": 0.5887984037399292, "(14, 0)": 0.7007027864456177, "(14, 16)": 0.5889073610305786, "(16, 0)": 0.5887984037399292, "(16, 16)": 0.4291836619377136, "(18, 0)": 0.4291836619377136, "(18, 16)": 0.8160856366157532, "(20, 0)": 0.8160856366157532, "(20, 16)": 0.7007027864456177, "(22, 0)": 0.4291836619377136, "(22, 16)": 0.8160856366157532, "(24, 0)": 0.7007027864456177, "(24, 16)": 0.5887984037399292, "(26, 0)": 0.4291836619377136, "(26, 16)": 0.5666014552116394, "(28, 0)": 0.4291836619377136, "(28, 16)": 0.7007027864456177, "(30, 0)": 0.4291836619377136, "(30, 16)": 0.4291836619377136}, "r_span": [970, 1084], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.003336191177368164}}, {"prompt_attention_score": {"(0, 0)": 0.6762702465057373, "(0, 16)": 0.6762702465057373, "(2, 0)": 0.6762702465057373, "(2, 16)": 0.6762702465057373, "(4, 0)": 0.6762702465057373, "(4, 16)": 0.6762702465057373, "(6, 0)": 0.6418864727020264, "(6, 16)": 0.6527474522590637, "(8, 0)": 0.6418864727020264, "(8, 16)": 0.6762702465057373, "(10, 0)": 0.6762702465057373, "(10, 16)": 0.6762702465057373, "(12, 0)": 0.6762702465057373, "(12, 16)": 0.6762702465057373, "(14, 0)": 0.6418864727020264, "(14, 16)": 0.6762702465057373, "(16, 0)": 0.6762702465057373, "(16, 16)": 0.6762702465057373, "(18, 0)": 0.6418864727020264, "(18, 16)": 0.6762702465057373, "(20, 0)": 0.6250736117362976, "(20, 16)": 0.6418864727020264, "(22, 0)": 0.4170437455177307, "(22, 16)": 0.6762702465057373, "(24, 0)": 0.6418864727020264, "(24, 16)": 0.6762702465057373, "(26, 0)": 0.4170437455177307, "(26, 16)": 0.6762702465057373, "(28, 0)": 0.4170437455177307, "(28, 16)": 0.6418864727020264, "(30, 0)": 0.4170437455177307, "(30, 16)": 0.4170437455177307}, "r_span": [1080, 1142], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0014064311981201172}}]}, {"id": "9201", "source_id": "14625", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 678, "end": 730, "text": "including a private event room in a local restaurant", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of private event room in a local restaurant\nGenerative: \"...including a private event room in a local restaurant...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Pro Karaoke System Rentals:\n\nPro Karaoke System Rentals is a locally owned and operated business in Santa Barbara, California that offers karaoke rentals for events and parties. The business has received consistently high ratings for its excellent customer service, ease of use, and variety of song options. Customers have praised the owner, Mike, for his friendliness, expertise, and ability to make the experience simple and enjoyable. The business has a rating of 5.0 stars and has been recommended by multiple customers for its top-notch service. Pro Karaoke System Rentals offers a range of features, including a private event room in a local restaurant, a wide selection of songs, and the ability to adjust the key of the music and volume. Customers have also appreciated the availability of a songbook as a PDF, which makes it easier to search for songs and plan for their events. Overall, Pro Karaoke System Rentals is a reliable and enjoyable choice for those looking for karaoke rentals in the Santa Barbara area.", "response_spans": [[0, 99], [101, 603], [586, 1095]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5617467761039734, "(0, 16)": 0.5617467761039734, "(2, 0)": 0.5617467761039734, "(2, 16)": 0.5617467761039734, "(4, 0)": 0.5617467761039734, "(4, 16)": 0.5617467761039734, "(6, 0)": 0.5617467761039734, "(6, 16)": 0.6928561329841614, "(8, 0)": 0.6928561329841614, "(8, 16)": 0.5486539602279663, "(10, 0)": 0.605099618434906, "(10, 16)": 0.605099618434906, "(12, 0)": 0.500070333480835, "(12, 16)": 0.605099618434906, "(14, 0)": 0.5486539602279663, "(14, 16)": 0.605099618434906, "(16, 0)": 0.605099618434906, "(16, 16)": 0.5617467761039734, "(18, 0)": 0.5617467761039734, "(18, 16)": 0.605099618434906, "(20, 0)": 0.605099618434906, "(20, 16)": 0.5617467761039734, "(22, 0)": 0.605099618434906, "(22, 16)": 0.605099618434906, "(24, 0)": 0.5617467761039734, "(24, 16)": 0.605099618434906, "(26, 0)": 0.605099618434906, "(26, 16)": 0.605099618434906, "(28, 0)": 0.605099618434906, "(28, 16)": 0.5617467761039734, "(30, 0)": 0.605099618434906, "(30, 16)": 0.605099618434906}, "r_span": [883, 908], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0001131296157836914}}, {"prompt_attention_score": {"(0, 0)": 0.6997551918029785, "(0, 16)": 0.6997551918029785, "(2, 0)": 0.6184291839599609, "(2, 16)": 0.6184291839599609, "(4, 0)": 0.6997551918029785, "(4, 16)": 0.6997551918029785, "(6, 0)": 0.6997551918029785, "(6, 16)": 0.8122378587722778, "(8, 0)": 0.6997551918029785, "(8, 16)": 0.6997551918029785, "(10, 0)": 0.6997551918029785, "(10, 16)": 0.6997551918029785, "(12, 0)": 0.6997551918029785, "(12, 16)": 0.6680008172988892, "(14, 0)": 0.6184291839599609, "(14, 16)": 0.6997551918029785, "(16, 0)": 0.6680008172988892, "(16, 16)": 0.6997551918029785, "(18, 0)": 0.4492912292480469, "(18, 16)": 0.8122378587722778, "(20, 0)": 0.8122378587722778, "(20, 16)": 0.6997551918029785, "(22, 0)": 0.4492912292480469, "(22, 16)": 0.8122378587722778, "(24, 0)": 0.6997551918029785, "(24, 16)": 0.6680008172988892, "(26, 0)": 0.4492912292480469, "(26, 16)": 0.6997551918029785, "(28, 0)": 0.4492912292480469, "(28, 16)": 0.6184291839599609, "(30, 0)": 0.4492912292480469, "(30, 16)": 0.4492912292480469}, "r_span": [910, 1016], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0021840333938598633}}, {"prompt_attention_score": {"(0, 0)": 0.7102062702178955, "(0, 16)": 0.7102062702178955, "(2, 0)": 0.6325242519378662, "(2, 16)": 0.7102062702178955, "(4, 0)": 0.6325242519378662, "(4, 16)": 0.7102062702178955, "(6, 0)": 0.7102062702178955, "(6, 16)": 0.7306712865829468, "(8, 0)": 0.7102062702178955, "(8, 16)": 0.7102062702178955, "(10, 0)": 0.7102062702178955, "(10, 16)": 0.7102062702178955, "(12, 0)": 0.7102062702178955, "(12, 16)": 0.7306712865829468, "(14, 0)": 0.6325242519378662, "(14, 16)": 0.7102062702178955, "(16, 0)": 0.7102062702178955, "(16, 16)": 0.7102062702178955, "(18, 0)": 0.7102062702178955, "(18, 16)": 0.7306712865829468, "(20, 0)": 0.6196941137313843, "(20, 16)": 0.6325242519378662, "(22, 0)": 0.4720958471298218, "(22, 16)": 0.6196941137313843, "(24, 0)": 0.6325242519378662, "(24, 16)": 0.6196941137313843, "(26, 0)": 0.4720958471298218, "(26, 16)": 0.7102062702178955, "(28, 0)": 0.4720958471298218, "(28, 16)": 0.6325242519378662, "(30, 0)": 0.4720958471298218, "(30, 16)": 0.4720958471298218}, "r_span": [1014, 1128], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0019538402557373047}}]}, {"id": "9213", "source_id": "14627", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is an objective overview of 805 Kabob based on the structured data provided:\n\n805 Kabob is a Mediterranean restaurant located in Goleta, California, with a rating of 3.5 stars. The restaurant offers free WiFi, outdoor seating, and takeout options. While some reviewers praise the quality of the food, others have criticized the service and ambiance. One reviewer described the experience as \"dreary and stuffy\" inside, while another mentioned long wait times. However, one reviewer did appreciate the friendly and welcoming nature of the staff. Overall, 805 Kabob appears to offer decent Middle Eastern cuisine, but may need to improve its customer service and overall atmosphere to meet customer expectations.", "response_spans": [[0, 81], [83, 592], [577, 715]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.48826098442077637, "(0, 16)": 0.48826098442077637, "(2, 0)": 0.48826098442077637, "(2, 16)": 0.48826098442077637, "(4, 0)": 0.48826098442077637, "(4, 16)": 0.48826098442077637, "(6, 0)": 0.48826098442077637, "(6, 16)": 0.6292064189910889, "(8, 0)": 0.44923147559165955, "(8, 16)": 0.48826098442077637, "(10, 0)": 0.6292064189910889, "(10, 16)": 0.6292064189910889, "(12, 0)": 0.5553686618804932, "(12, 16)": 0.6292064189910889, "(14, 0)": 0.44923147559165955, "(14, 16)": 0.6292064189910889, "(16, 0)": 0.6292064189910889, "(16, 16)": 0.48826098442077637, "(18, 0)": 0.48826098442077637, "(18, 16)": 0.6292064189910889, "(20, 0)": 0.6292064189910889, "(20, 16)": 0.44923147559165955, "(22, 0)": 0.44923147559165955, "(22, 16)": 0.6292064189910889, "(24, 0)": 0.44923147559165955, "(24, 16)": 0.6292064189910889, "(26, 0)": 0.6292064189910889, "(26, 16)": 0.6292064189910889, "(28, 0)": 0.6292064189910889, "(28, 16)": 0.44923147559165955, "(30, 0)": 0.6292064189910889, "(30, 16)": 0.6292064189910889}, "r_span": [839, 860], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009216070175170898}}, {"prompt_attention_score": {"(0, 0)": 0.6475706100463867, "(0, 16)": 0.6475706100463867, "(2, 0)": 0.6475706100463867, "(2, 16)": 0.6475706100463867, "(4, 0)": 0.6475706100463867, "(4, 16)": 0.6475706100463867, "(6, 0)": 0.6475706100463867, "(6, 16)": 0.7385711669921875, "(8, 0)": 0.6324623823165894, "(8, 16)": 0.6475706100463867, "(10, 0)": 0.6324623823165894, "(10, 16)": 0.6475706100463867, "(12, 0)": 0.6324623823165894, "(12, 16)": 0.6218394041061401, "(14, 0)": 0.6324623823165894, "(14, 16)": 0.43816274404525757, "(16, 0)": 0.6475706100463867, "(16, 16)": 0.6475706100463867, "(18, 0)": 0.6324623823165894, "(18, 16)": 0.6218394041061401, "(20, 0)": 0.6218394041061401, "(20, 16)": 0.6324623823165894, "(22, 0)": 0.43468907475471497, "(22, 16)": 0.6475706100463867, "(24, 0)": 0.6324623823165894, "(24, 16)": 0.6475706100463867, "(26, 0)": 0.43468907475471497, "(26, 16)": 0.6324623823165894, "(28, 0)": 0.43468907475471497, "(28, 16)": 0.6324623823165894, "(30, 0)": 0.43468907475471497, "(30, 16)": 0.43468907475471497}, "r_span": [862, 984], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015451908111572266}}, {"prompt_attention_score": {"(0, 0)": 0.6500278115272522, "(0, 16)": 0.694701075553894, "(2, 0)": 0.694701075553894, "(2, 16)": 0.694701075553894, "(4, 0)": 0.694701075553894, "(4, 16)": 0.694701075553894, "(6, 0)": 0.6500278115272522, "(6, 16)": 0.4921819865703583, "(8, 0)": 0.6500278115272522, "(8, 16)": 0.6500278115272522, "(10, 0)": 0.6500278115272522, "(10, 16)": 0.694701075553894, "(12, 0)": 0.4626156687736511, "(12, 16)": 0.6500278115272522, "(14, 0)": 0.6500278115272522, "(14, 16)": 0.4813106656074524, "(16, 0)": 0.6500278115272522, "(16, 16)": 0.4626156687736511, "(18, 0)": 0.4626156687736511, "(18, 16)": 0.5904062986373901, "(20, 0)": 0.694701075553894, "(20, 16)": 0.6500278115272522, "(22, 0)": 0.6500278115272522, "(22, 16)": 0.694701075553894, "(24, 0)": 0.6500278115272522, "(24, 16)": 0.5904062986373901, "(26, 0)": 0.4626156687736511, "(26, 16)": 0.6500278115272522, "(28, 0)": 0.4626156687736511, "(28, 16)": 0.694701075553894, "(30, 0)": 0.6500278115272522, "(30, 16)": 0.4626156687736511}, "r_span": [982, 1007], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007807016372680664}}]}, {"id": "9525", "source_id": "14680", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 324, "end": 380, "text": "Customers can enjoy their drinks both inside and outside", "meta": "EVIDENT CONFLICT\nOriginal (2nd Review): \"There's no indoor seating...\"\nGenerative: \" Customers can enjoy their drinks both inside...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 459, "end": 484, "text": "it is suitable for groups", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"RestaurantsGoodForGroups\": null\nGenerative: \"it is suitable for groups\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Hustle & Grind Coffee Company:\n\nLocated in downtown Santa Barbara, California, Hustle & Grind Coffee Company is a popular destination for coffee and ice cream lovers. With a rating of 4.5 stars, the business offers a cozy atmosphere and quick service. Customers can enjoy their drinks both inside and outside, with free WiFi available. Although the business does not offer reservations, it is suitable for groups. While some customers have reported issues with the availability of almond milk, the quality of the coffee and ice cream has been consistently praised. Overall, Hustle & Grind Coffee Company is a great spot for those looking for a casual coffee or ice cream experience in a convenient location.", "response_spans": [[0, 102], [104, 614], [596, 779]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6003918647766113, "(0, 16)": 0.3914009630680084, "(2, 0)": 0.6003918647766113, "(2, 16)": 0.6003918647766113, "(4, 0)": 0.6003918647766113, "(4, 16)": 0.6003918647766113, "(6, 0)": 0.6003918647766113, "(6, 16)": 0.623961329460144, "(8, 0)": 0.5389108657836914, "(8, 16)": 0.3914009630680084, "(10, 0)": 0.622349739074707, "(10, 16)": 0.622349739074707, "(12, 0)": 0.6003918647766113, "(12, 16)": 0.622349739074707, "(14, 0)": 0.5389108657836914, "(14, 16)": 0.622349739074707, "(16, 0)": 0.622349739074707, "(16, 16)": 0.622349739074707, "(18, 0)": 0.5389108657836914, "(18, 16)": 0.622349739074707, "(20, 0)": 0.622349739074707, "(20, 16)": 0.5389108657836914, "(22, 0)": 0.622349739074707, "(22, 16)": 0.622349739074707, "(24, 0)": 0.5389108657836914, "(24, 16)": 0.622349739074707, "(26, 0)": 0.622349739074707, "(26, 16)": 0.622349739074707, "(28, 0)": 0.622349739074707, "(28, 16)": 0.622349739074707, "(30, 0)": 0.622349739074707, "(30, 16)": 0.622349739074707}, "r_span": [729, 756], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004825592041015625}}, {"prompt_attention_score": {"(0, 0)": 0.7795968055725098, "(0, 16)": 0.7795968055725098, "(2, 0)": 0.7795968055725098, "(2, 16)": 0.5715128183364868, "(4, 0)": 0.7795968055725098, "(4, 16)": 0.5715128183364868, "(6, 0)": 0.7795968055725098, "(6, 16)": 0.7987425923347473, "(8, 0)": 0.6278396844863892, "(8, 16)": 0.7795968055725098, "(10, 0)": 0.5715128183364868, "(10, 16)": 0.5715128183364868, "(12, 0)": 0.7795968055725098, "(12, 16)": 0.6278396844863892, "(14, 0)": 0.6278396844863892, "(14, 16)": 0.7795968055725098, "(16, 0)": 0.6278396844863892, "(16, 16)": 0.4435966908931732, "(18, 0)": 0.4435966908931732, "(18, 16)": 0.7987425923347473, "(20, 0)": 0.6278396844863892, "(20, 16)": 0.6278396844863892, "(22, 0)": 0.4435966908931732, "(22, 16)": 0.7987425923347473, "(24, 0)": 0.6278396844863892, "(24, 16)": 0.6278396844863892, "(26, 0)": 0.4435966908931732, "(26, 16)": 0.7795968055725098, "(28, 0)": 0.4435966908931732, "(28, 16)": 0.4435966908931732, "(30, 0)": 0.4435966908931732, "(30, 16)": 0.4435966908931732}, "r_span": [758, 873], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012516379356384277}}, {"prompt_attention_score": {"(0, 0)": 0.7651805281639099, "(0, 16)": 0.6912825703620911, "(2, 0)": 0.7651805281639099, "(2, 16)": 0.5049533843994141, "(4, 0)": 0.5049533843994141, "(4, 16)": 0.5049533843994141, "(6, 0)": 0.7651805281639099, "(6, 16)": 0.6912825703620911, "(8, 0)": 0.7651805281639099, "(8, 16)": 0.5049533843994141, "(10, 0)": 0.5049533843994141, "(10, 16)": 0.5049533843994141, "(12, 0)": 0.7651805281639099, "(12, 16)": 0.7651805281639099, "(14, 0)": 0.5915142893791199, "(14, 16)": 0.7651805281639099, "(16, 0)": 0.5915142893791199, "(16, 16)": 0.5915142893791199, "(18, 0)": 0.39360833168029785, "(18, 16)": 0.6912825703620911, "(20, 0)": 0.5915142893791199, "(20, 16)": 0.5915142893791199, "(22, 0)": 0.39360833168029785, "(22, 16)": 0.6912825703620911, "(24, 0)": 0.5915142893791199, "(24, 16)": 0.5915142893791199, "(26, 0)": 0.39360833168029785, "(26, 16)": 0.5915142893791199, "(28, 0)": 0.39360833168029785, "(28, 16)": 0.39360833168029785, "(30, 0)": 0.39360833168029785, "(30, 16)": 0.39360833168029785}, "r_span": [869, 913], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00039142370223999023}}]}, {"id": "9543", "source_id": "14683", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 486, "end": 513, "text": "the lack of parking options", "meta": "EVIDENT CONFLICT\nOriginal: \"garage\": true, \"street\": true, \"validated\": true\nGenerative: \"the lack of parking options\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is an objective overview of American Ale based on the provided structured data:\n\nAmerican Ale is a popular nightlife spot in Santa Barbara, California, offering a range of categories such as Nightlife, Pubs, Beer, Wine & Spirits, American (Traditional), Burgers, Bars, Food, and Restaurants. Although the business has received mixed reviews, it boasts a 4-star rating from customers. Some patrons have been disappointed with the closure of the original location on Cota Street and the lack of parking options, while others have enjoyed the taste of their food and drinks. One reviewer even expressed their longing for another bite of their delicious burgers. Despite some drawbacks, American Ale appears to have a loyal customer base and a cozy atmosphere. However, the cleanliness of the bathrooms has been identified as an area for improvement.", "response_spans": [[0, 84], [86, 594], [577, 851]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4449351131916046, "(0, 16)": 0.4449351131916046, "(2, 0)": 0.4449351131916046, "(2, 16)": 0.4449351131916046, "(4, 0)": 0.4449351131916046, "(4, 16)": 0.4449351131916046, "(6, 0)": 0.4449351131916046, "(6, 16)": 0.6118183135986328, "(8, 0)": 0.4449351131916046, "(8, 16)": 0.4449351131916046, "(10, 0)": 0.6118183135986328, "(10, 16)": 0.6118183135986328, "(12, 0)": 0.4449351131916046, "(12, 16)": 0.6118183135986328, "(14, 0)": 0.4449351131916046, "(14, 16)": 0.6118183135986328, "(16, 0)": 0.6118183135986328, "(16, 16)": 0.4449351131916046, "(18, 0)": 0.4449351131916046, "(18, 16)": 0.6118183135986328, "(20, 0)": 0.6118183135986328, "(20, 16)": 0.4449351131916046, "(22, 0)": 0.6118183135986328, "(22, 16)": 0.6118183135986328, "(24, 0)": 0.4449351131916046, "(24, 16)": 0.6118183135986328, "(26, 0)": 0.6118183135986328, "(26, 16)": 0.6118183135986328, "(28, 0)": 0.6118183135986328, "(28, 16)": 0.4449351131916046, "(30, 0)": 0.6118183135986328, "(30, 16)": 0.6118183135986328}, "r_span": [628, 645], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00030303001403808594}}, {"prompt_attention_score": {"(0, 0)": 0.5120059847831726, "(0, 16)": 0.5120059847831726, "(2, 0)": 0.5120059847831726, "(2, 16)": 0.5120059847831726, "(4, 0)": 0.5120059847831726, "(4, 16)": 0.5120059847831726, "(6, 0)": 0.5120059847831726, "(6, 16)": 0.7718345522880554, "(8, 0)": 0.5120059847831726, "(8, 16)": 0.5120059847831726, "(10, 0)": 0.5120059847831726, "(10, 16)": 0.5120059847831726, "(12, 0)": 0.5120059847831726, "(12, 16)": 0.7718345522880554, "(14, 0)": 0.5120059847831726, "(14, 16)": 0.7718345522880554, "(16, 0)": 0.7718345522880554, "(16, 16)": 0.5120059847831726, "(18, 0)": 0.5120059847831726, "(18, 16)": 0.7718345522880554, "(20, 0)": 0.7718345522880554, "(20, 16)": 0.5120059847831726, "(22, 0)": 0.4169386029243469, "(22, 16)": 0.6777257919311523, "(24, 0)": 0.5120059847831726, "(24, 16)": 0.7718345522880554, "(26, 0)": 0.4169386029243469, "(26, 16)": 0.7718345522880554, "(28, 0)": 0.4169386029243469, "(28, 16)": 0.5120059847831726, "(30, 0)": 0.4169386029243469, "(30, 16)": 0.4169386029243469}, "r_span": [647, 766], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0012214183807373047}}, {"prompt_attention_score": {"(0, 0)": 0.6902576684951782, "(0, 16)": 0.6902576684951782, "(2, 0)": 0.6902576684951782, "(2, 16)": 0.6902576684951782, "(4, 0)": 0.6902576684951782, "(4, 16)": 0.6902576684951782, "(6, 0)": 0.6902576684951782, "(6, 16)": 0.6324074268341064, "(8, 0)": 0.6902576684951782, "(8, 16)": 0.6902576684951782, "(10, 0)": 0.6902576684951782, "(10, 16)": 0.6902576684951782, "(12, 0)": 0.6902576684951782, "(12, 16)": 0.6902576684951782, "(14, 0)": 0.6902576684951782, "(14, 16)": 0.6902576684951782, "(16, 0)": 0.6902576684951782, "(16, 16)": 0.6902576684951782, "(18, 0)": 0.4351155161857605, "(18, 16)": 0.6902576684951782, "(20, 0)": 0.6902576684951782, "(20, 16)": 0.6902576684951782, "(22, 0)": 0.4351155161857605, "(22, 16)": 0.6902576684951782, "(24, 0)": 0.6902576684951782, "(24, 16)": 0.6902576684951782, "(26, 0)": 0.4351155161857605, "(26, 16)": 0.6902576684951782, "(28, 0)": 0.4351155161857605, "(28, 16)": 0.6902576684951782, "(30, 0)": 0.4351155161857605, "(30, 16)": 0.4351155161857605}, "r_span": [763, 821], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0029160380363464355}}]}, {"id": "9555", "source_id": "14685", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 150, "end": 154, "text": "WiFi", "meta": "HIGH INTRO OF NEW INFO\nAIGC:  offers WiFi\nOriginal: \"WiFi\": null,", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Old Town Tavern is a local dive bar located in Goleta, California, with a rating of 4.0 stars. The bar offers a cozy atmosphere, outdoor seating, and WiFi. While some patrons have reported inconsistent service, others have praised the friendly bartenders and extensive selection of liquor. One reviewer noted that the bar can be dead at times, while another described their interactions with the bartender, Matt, as an \"experience in itself.\" The karaoke DJ is also popular among regulars, who appreciate their attentiveness and willingness to play requests. Overall, Old Town Tavern appears to be a community-driven bar with a loyal following, despite occasional service issues.", "response_spans": [[0, 510], [494, 679]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7598593235015869, "(0, 16)": 0.7598593235015869, "(2, 0)": 0.7598593235015869, "(2, 16)": 0.7598593235015869, "(4, 0)": 0.7598593235015869, "(4, 16)": 0.7598593235015869, "(6, 0)": 0.7598593235015869, "(6, 16)": 0.7869877815246582, "(8, 0)": 0.5669921040534973, "(8, 16)": 0.7598593235015869, "(10, 0)": 0.7598593235015869, "(10, 16)": 0.7598593235015869, "(12, 0)": 0.7598593235015869, "(12, 16)": 0.7598593235015869, "(14, 0)": 0.5936128497123718, "(14, 16)": 0.7598593235015869, "(16, 0)": 0.7598593235015869, "(16, 16)": 0.7598593235015869, "(18, 0)": 0.4413105845451355, "(18, 16)": 0.7869877815246582, "(20, 0)": 0.5900556445121765, "(20, 16)": 0.5669921040534973, "(22, 0)": 0.4413105845451355, "(22, 16)": 0.7869877815246582, "(24, 0)": 0.5936128497123718, "(24, 16)": 0.7598593235015869, "(26, 0)": 0.4413105845451355, "(26, 16)": 0.5900556445121765, "(28, 0)": 0.4413105845451355, "(28, 16)": 0.5936128497123718, "(30, 0)": 0.4413105845451355, "(30, 16)": 0.4413105845451355}, "r_span": [843, 964], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00132673978805542}}, {"prompt_attention_score": {"(0, 0)": 0.7588960528373718, "(0, 16)": 0.7588960528373718, "(2, 0)": 0.7588960528373718, "(2, 16)": 0.7588960528373718, "(4, 0)": 0.7588960528373718, "(4, 16)": 0.7588960528373718, "(6, 0)": 0.7588960528373718, "(6, 16)": 0.6278339624404907, "(8, 0)": 0.6254414916038513, "(8, 16)": 0.6254414916038513, "(10, 0)": 0.7588960528373718, "(10, 16)": 0.7588960528373718, "(12, 0)": 0.6254414916038513, "(12, 16)": 0.6254414916038513, "(14, 0)": 0.6254414916038513, "(14, 16)": 0.4324854016304016, "(16, 0)": 0.6254414916038513, "(16, 16)": 0.42343220114707947, "(18, 0)": 0.42343220114707947, "(18, 16)": 0.6254414916038513, "(20, 0)": 0.6254414916038513, "(20, 16)": 0.6254414916038513, "(22, 0)": 0.42343220114707947, "(22, 16)": 0.6254414916038513, "(24, 0)": 0.6254414916038513, "(24, 16)": 0.6254414916038513, "(26, 0)": 0.42343220114707947, "(26, 16)": 0.6254414916038513, "(28, 0)": 0.42343220114707947, "(28, 16)": 0.6254414916038513, "(30, 0)": 0.42343220114707947, "(30, 16)": 0.42343220114707947}, "r_span": [963, 1001], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004748702049255371}}]}, {"id": "9579", "source_id": "14689", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 297, "end": 301, "text": "wine", "meta": "HIGH INTRO OF NEW INFO\nIt mentions the availability of wine, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is an objective overview of Night Lizard Brewing Company based on the provided structured data:\n\nNight Lizard Brewing Company is a popular local business located in Santa Barbara, California, with a rating of 4.5 stars. The brewery offers a variety of food and drink options, including beer, wine, and kombucha, as well as a cozy atmosphere for dining and socializing. Customers have praised the brewery's laid-back and relaxed vibe, as well as its excellent service and high-quality products. The brewery also offers outdoor seating and free WiFi, making it a great spot to unwind and enjoy a drink after work or on the weekends. Some customers have noted that the brewery has a fire pit and live music, adding to its ambiance. Overall, Night Lizard Brewing Company appears to be a great spot for both locals and visitors looking for a unique and enjoyable dining experience.", "response_spans": [[0, 100], [102, 610], [591, 881]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5306037068367004, "(0, 16)": 0.5306037068367004, "(2, 0)": 0.5306037068367004, "(2, 16)": 0.5306037068367004, "(4, 0)": 0.5306037068367004, "(4, 16)": 0.5306037068367004, "(6, 0)": 0.5306037068367004, "(6, 16)": 0.6121860146522522, "(8, 0)": 0.6371893286705017, "(8, 16)": 0.5306037068367004, "(10, 0)": 0.6121860146522522, "(10, 16)": 0.6121860146522522, "(12, 0)": 0.5270535349845886, "(12, 16)": 0.6121860146522522, "(14, 0)": 0.6371893286705017, "(14, 16)": 0.6121860146522522, "(16, 0)": 0.6121860146522522, "(16, 16)": 0.5306037068367004, "(18, 0)": 0.5306037068367004, "(18, 16)": 0.6121860146522522, "(20, 0)": 0.6121860146522522, "(20, 16)": 0.6371893286705017, "(22, 0)": 0.6371893286705017, "(22, 16)": 0.6121860146522522, "(24, 0)": 0.6371893286705017, "(24, 16)": 0.6121860146522522, "(26, 0)": 0.6121860146522522, "(26, 16)": 0.5378391146659851, "(28, 0)": 0.6121860146522522, "(28, 16)": 0.5306037068367004, "(30, 0)": 0.6121860146522522, "(30, 16)": 0.6121860146522522}, "r_span": [848, 870], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00010401010513305664}}, {"prompt_attention_score": {"(0, 0)": 0.6911904811859131, "(0, 16)": 0.6911904811859131, "(2, 0)": 0.6911904811859131, "(2, 16)": 0.6911904811859131, "(4, 0)": 0.6911904811859131, "(4, 16)": 0.6911904811859131, "(6, 0)": 0.6911904811859131, "(6, 16)": 0.7885569334030151, "(8, 0)": 0.7926335334777832, "(8, 16)": 0.6911904811859131, "(10, 0)": 0.7926335334777832, "(10, 16)": 0.6911904811859131, "(12, 0)": 0.7926335334777832, "(12, 16)": 0.6159082651138306, "(14, 0)": 0.7926335334777832, "(14, 16)": 0.6911904811859131, "(16, 0)": 0.6159082651138306, "(16, 16)": 0.6911904811859131, "(18, 0)": 0.4152434468269348, "(18, 16)": 0.7885569334030151, "(20, 0)": 0.6159082651138306, "(20, 16)": 0.7926335334777832, "(22, 0)": 0.4152434468269348, "(22, 16)": 0.7885569334030151, "(24, 0)": 0.7926335334777832, "(24, 16)": 0.6159082651138306, "(26, 0)": 0.4152434468269348, "(26, 16)": 0.6159082651138306, "(28, 0)": 0.4152434468269348, "(28, 16)": 0.6911904811859131, "(30, 0)": 0.4152434468269348, "(30, 16)": 0.4152434468269348}, "r_span": [872, 1000], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -1.4543533325195312e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7015913724899292, "(0, 16)": 0.7015913724899292, "(2, 0)": 0.7015913724899292, "(2, 16)": 0.7015913724899292, "(4, 0)": 0.7015913724899292, "(4, 16)": 0.7015913724899292, "(6, 0)": 0.7015913724899292, "(6, 16)": 0.8120973110198975, "(8, 0)": 0.7015913724899292, "(8, 16)": 0.7015913724899292, "(10, 0)": 0.8120973110198975, "(10, 16)": 0.7015913724899292, "(12, 0)": 0.7015913724899292, "(12, 16)": 0.8120973110198975, "(14, 0)": 0.8120973110198975, "(14, 16)": 0.7015913724899292, "(16, 0)": 0.6034387350082397, "(16, 16)": 0.3928874433040619, "(18, 0)": 0.3928874433040619, "(18, 16)": 0.6034387350082397, "(20, 0)": 0.6034387350082397, "(20, 16)": 0.8120973110198975, "(22, 0)": 0.3928874433040619, "(22, 16)": 0.8120973110198975, "(24, 0)": 0.8120973110198975, "(24, 16)": 0.6034387350082397, "(26, 0)": 0.3928874433040619, "(26, 16)": 0.8120973110198975, "(28, 0)": 0.3928874433040619, "(28, 16)": 0.7015913724899292, "(30, 0)": 0.3928874433040619, "(30, 16)": 0.3928874433040619}, "r_span": [997, 1063], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0021674036979675293}}]}, {"id": "9585", "source_id": "14690", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 212, "end": 226, "text": "WiFi available", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"WiFi\": null\nGenerative: \"WiFi available\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of the local business Sublime:\n\nSublime is a restaurant located in Santa Barbara, CA, offering American (New) cuisine with outdoor seating and WiFi available. Although the business has received mixed reviews, the restaurant appears to lack a clear brand identity, with some patrons finding the name to be unclear about the type of food served. Some reviewers have also noted issues with service, including slow and clueless servers, while others have appreciated the ambiance and quality of the food. One reviewer specifically criticized the use of Miracle Whip in the deviled eggs, which they found disappointing. Overall, Sublime appears to have potential, but may benefit from improvements in its branding and service to better meet customer expectations.", "response_spans": [[0, 99], [101, 610], [596, 827]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3757644295692444, "(0, 16)": 0.3757644295692444, "(2, 0)": 0.38326337933540344, "(2, 16)": 0.3757644295692444, "(4, 0)": 0.3757644295692444, "(4, 16)": 0.3757644295692444, "(6, 0)": 0.3757644295692444, "(6, 16)": 0.7107950448989868, "(8, 0)": 0.5175029039382935, "(8, 16)": 0.3757644295692444, "(10, 0)": 0.7107950448989868, "(10, 16)": 0.7107950448989868, "(12, 0)": 0.5497680902481079, "(12, 16)": 0.7107950448989868, "(14, 0)": 0.5175029039382935, "(14, 16)": 0.7107950448989868, "(16, 0)": 0.7107950448989868, "(16, 16)": 0.5497680902481079, "(18, 0)": 0.3757644295692444, "(18, 16)": 0.7107950448989868, "(20, 0)": 0.7107950448989868, "(20, 16)": 0.38326337933540344, "(22, 0)": 0.7107950448989868, "(22, 16)": 0.7107950448989868, "(24, 0)": 0.38326337933540344, "(24, 16)": 0.7107950448989868, "(26, 0)": 0.7107950448989868, "(26, 16)": 0.7107950448989868, "(28, 0)": 0.7107950448989868, "(28, 16)": 0.38326337933540344, "(30, 0)": 0.7107950448989868, "(30, 16)": 0.7107950448989868}, "r_span": [851, 873], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010820627212524414}}, {"prompt_attention_score": {"(0, 0)": 0.5404253005981445, "(0, 16)": 0.5404253005981445, "(2, 0)": 0.5404253005981445, "(2, 16)": 0.5404253005981445, "(4, 0)": 0.5404253005981445, "(4, 16)": 0.5404253005981445, "(6, 0)": 0.5404253005981445, "(6, 16)": 0.7319039106369019, "(8, 0)": 0.5802021026611328, "(8, 16)": 0.5802021026611328, "(10, 0)": 0.7410213947296143, "(10, 16)": 0.5404253005981445, "(12, 0)": 0.6984364986419678, "(12, 16)": 0.7319039106369019, "(14, 0)": 0.5802021026611328, "(14, 16)": 0.4889695346355438, "(16, 0)": 0.7410213947296143, "(16, 16)": 0.5404253005981445, "(18, 0)": 0.5404253005981445, "(18, 16)": 0.7410213947296143, "(20, 0)": 0.7319039106369019, "(20, 16)": 0.5802021026611328, "(22, 0)": 0.4889695346355438, "(22, 16)": 0.5802021026611328, "(24, 0)": 0.5802021026611328, "(24, 16)": 0.7319039106369019, "(26, 0)": 0.4889695346355438, "(26, 16)": 0.5802021026611328, "(28, 0)": 0.4889695346355438, "(28, 16)": 0.4889695346355438, "(30, 0)": 0.4889695346355438, "(30, 16)": 0.4889695346355438}, "r_span": [875, 978], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -1.7762184143066406e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6657662391662598, "(0, 16)": 0.6657662391662598, "(2, 0)": 0.6653116345405579, "(2, 16)": 0.6653116345405579, "(4, 0)": 0.6653116345405579, "(4, 16)": 0.6653116345405579, "(6, 0)": 0.6653116345405579, "(6, 16)": 0.6833060383796692, "(8, 0)": 0.6833060383796692, "(8, 16)": 0.6653116345405579, "(10, 0)": 0.6653116345405579, "(10, 16)": 0.6653116345405579, "(12, 0)": 0.6653116345405579, "(12, 16)": 0.6833060383796692, "(14, 0)": 0.6833060383796692, "(14, 16)": 0.5072222352027893, "(16, 0)": 0.6653116345405579, "(16, 16)": 0.5085030794143677, "(18, 0)": 0.5085030794143677, "(18, 16)": 0.7126704454421997, "(20, 0)": 0.6653116345405579, "(20, 16)": 0.6833060383796692, "(22, 0)": 0.5085030794143677, "(22, 16)": 0.6653116345405579, "(24, 0)": 0.6833060383796692, "(24, 16)": 0.6833060383796692, "(26, 0)": 0.5085030794143677, "(26, 16)": 0.6833060383796692, "(28, 0)": 0.5085030794143677, "(28, 16)": 0.5085030794143677, "(30, 0)": 0.5085030794143677, "(30, 16)": 0.5085030794143677}, "r_span": [976, 1024], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00036793947219848633}}]}, {"id": "9603", "source_id": "14694", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 611, "end": 678, "text": "Despite some criticism regarding the lack of a visible sign outside", "meta": "EVIDENT CONFLICT\nOriginal (3rd Review): \"The owners of this place should seriously consider investing in a good quality sign for out front.\"\nGenerative: \"Despite some criticism regarding the lack of a visible sign outside...\"\n(The review was more of a suggestion/recommendation not a criticism.)", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 344, "end": 359, "text": "outdoor seating", "meta": "EVIDENT CONFLICT\nOriginal: \"OutdoorSeating\": true\nGenerative: \"the restaurant does not offer... outdoor seating\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Javan's:\n\nJavan's is a locally owned sandwich shop located in Goleta, California. With a rating of 4.0 stars, the business has gained a positive reputation among customers for its high-quality food and friendly service. While the restaurant does not offer reservations or outdoor seating, it does provide free WiFi and is suitable for groups. Customers have praised the owners' attention to detail and commitment to using fresh, high-quality ingredients. The Tuna sandwich is particularly recommended for its delicious flavor combination. Despite some criticism regarding the lack of a visible sign outside, Javan's remains a popular destination for sandwich lovers in the area.", "response_spans": [[0, 80], [82, 590], [573, 750]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4344531297683716, "(0, 16)": 0.4344531297683716, "(2, 0)": 0.4344531297683716, "(2, 16)": 0.4344531297683716, "(4, 0)": 0.4344531297683716, "(4, 16)": 0.4344531297683716, "(6, 0)": 0.4344531297683716, "(6, 16)": 0.695151686668396, "(8, 0)": 0.5492911338806152, "(8, 16)": 0.4344531297683716, "(10, 0)": 0.695151686668396, "(10, 16)": 0.695151686668396, "(12, 0)": 0.6010211706161499, "(12, 16)": 0.695151686668396, "(14, 0)": 0.4344531297683716, "(14, 16)": 0.695151686668396, "(16, 0)": 0.695151686668396, "(16, 16)": 0.4344531297683716, "(18, 0)": 0.4344531297683716, "(18, 16)": 0.695151686668396, "(20, 0)": 0.695151686668396, "(20, 16)": 0.4344531297683716, "(22, 0)": 0.695151686668396, "(22, 16)": 0.695151686668396, "(24, 0)": 0.4344531297683716, "(24, 16)": 0.695151686668396, "(26, 0)": 0.695151686668396, "(26, 16)": 0.6239984035491943, "(28, 0)": 0.695151686668396, "(28, 16)": 0.4344531297683716, "(30, 0)": 0.695151686668396, "(30, 16)": 0.695151686668396}, "r_span": [739, 760], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00010836124420166016}}, {"prompt_attention_score": {"(0, 0)": 0.6394822001457214, "(0, 16)": 0.6394822001457214, "(2, 0)": 0.6394822001457214, "(2, 16)": 0.6394822001457214, "(4, 0)": 0.6394822001457214, "(4, 16)": 0.6394822001457214, "(6, 0)": 0.6394822001457214, "(6, 16)": 0.7398617267608643, "(8, 0)": 0.6394822001457214, "(8, 16)": 0.6394822001457214, "(10, 0)": 0.6394822001457214, "(10, 16)": 0.6394822001457214, "(12, 0)": 0.6394822001457214, "(12, 16)": 0.7398617267608643, "(14, 0)": 0.6394822001457214, "(14, 16)": 0.6394822001457214, "(16, 0)": 0.7398617267608643, "(16, 16)": 0.6394822001457214, "(18, 0)": 0.6394822001457214, "(18, 16)": 0.7398617267608643, "(20, 0)": 0.7398617267608643, "(20, 16)": 0.6394822001457214, "(22, 0)": 0.4717230200767517, "(22, 16)": 0.7398617267608643, "(24, 0)": 0.6394822001457214, "(24, 16)": 0.6352375149726868, "(26, 0)": 0.4717230200767517, "(26, 16)": 0.6302943825721741, "(28, 0)": 0.4717230200767517, "(28, 16)": 0.6394822001457214, "(30, 0)": 0.4717230200767517, "(30, 16)": 0.4717230200767517}, "r_span": [762, 875], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0006878972053527832}}, {"prompt_attention_score": {"(0, 0)": 0.7126275300979614, "(0, 16)": 0.7126275300979614, "(2, 0)": 0.7126275300979614, "(2, 16)": 0.7126275300979614, "(4, 0)": 0.7126275300979614, "(4, 16)": 0.7126275300979614, "(6, 0)": 0.7126275300979614, "(6, 16)": 0.6210533380508423, "(8, 0)": 0.7126275300979614, "(8, 16)": 0.7126275300979614, "(10, 0)": 0.7126275300979614, "(10, 16)": 0.7126275300979614, "(12, 0)": 0.7126275300979614, "(12, 16)": 0.7126275300979614, "(14, 0)": 0.7126275300979614, "(14, 16)": 0.7126275300979614, "(16, 0)": 0.7126275300979614, "(16, 16)": 0.7126275300979614, "(18, 0)": 0.39368653297424316, "(18, 16)": 0.7126275300979614, "(20, 0)": 0.7126275300979614, "(20, 16)": 0.7126275300979614, "(22, 0)": 0.39368653297424316, "(22, 16)": 0.7126275300979614, "(24, 0)": 0.7126275300979614, "(24, 16)": 0.6315131783485413, "(26, 0)": 0.39368653297424316, "(26, 16)": 0.6210533380508423, "(28, 0)": 0.39368653297424316, "(28, 16)": 0.7126275300979614, "(30, 0)": 0.39368653297424316, "(30, 16)": 0.39368653297424316}, "r_span": [872, 908], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002461850643157959}}]}, {"id": "9681", "source_id": "14710", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 426, "end": 448, "text": "and takes reservations", "meta": "EVIDENT CONFLICT\nOriginal: \"RestaurantsReservations\": false\nGenerative: \"...and takes reservations...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 516, "end": 552, "text": "there is validated parking available", "meta": "Original:  validated is mark as \"false\"\nGenerative: there is validated parking", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Sushi Tyme:\n\nSushi Tyme is a popular restaurant located in Santa Barbara, California, serving a variety of Japanese cuisine including sushi, seafood, and Asian fusion dishes. The restaurant has a 3.5-star rating and excellent reviews, with customers praising its delicious food, fair prices, and cozy atmosphere. The establishment offers outdoor seating and takes reservations, but does not provide Wi-Fi. While it does not have valet parking, there is validated parking available off the street and in a nearby garage. Overall, Sushi Tyme appears to be a well-liked and reliable dining option in the area.", "response_spans": [[0, 83], [85, 591], [572, 678]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6162934303283691, "(0, 16)": 0.6162934303283691, "(2, 0)": 0.6162934303283691, "(2, 16)": 0.6162934303283691, "(4, 0)": 0.6162934303283691, "(4, 16)": 0.6162934303283691, "(6, 0)": 0.6162934303283691, "(6, 16)": 0.6495711207389832, "(8, 0)": 0.5723316669464111, "(8, 16)": 0.6162934303283691, "(10, 0)": 0.6495711207389832, "(10, 16)": 0.6495711207389832, "(12, 0)": 0.5529217720031738, "(12, 16)": 0.6495711207389832, "(14, 0)": 0.6162934303283691, "(14, 16)": 0.6495711207389832, "(16, 0)": 0.6495711207389832, "(16, 16)": 0.6495711207389832, "(18, 0)": 0.5723316669464111, "(18, 16)": 0.6495711207389832, "(20, 0)": 0.6495711207389832, "(20, 16)": 0.5723316669464111, "(22, 0)": 0.6495711207389832, "(22, 16)": 0.6495711207389832, "(24, 0)": 0.5723316669464111, "(24, 16)": 0.6495711207389832, "(26, 0)": 0.6495711207389832, "(26, 16)": 0.6268597841262817, "(28, 0)": 0.6495711207389832, "(28, 16)": 0.6495711207389832, "(30, 0)": 0.6495711207389832, "(30, 16)": 0.6495711207389832}, "r_span": [695, 717], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009989738464355469}}, {"prompt_attention_score": {"(0, 0)": 0.7296720743179321, "(0, 16)": 0.7296720743179321, "(2, 0)": 0.7296720743179321, "(2, 16)": 0.7296720743179321, "(4, 0)": 0.7296720743179321, "(4, 16)": 0.7296720743179321, "(6, 0)": 0.7296720743179321, "(6, 16)": 0.7926422953605652, "(8, 0)": 0.5903212428092957, "(8, 16)": 0.7296720743179321, "(10, 0)": 0.7296720743179321, "(10, 16)": 0.7296720743179321, "(12, 0)": 0.5903212428092957, "(12, 16)": 0.7926422953605652, "(14, 0)": 0.5903212428092957, "(14, 16)": 0.7926422953605652, "(16, 0)": 0.5903212428092957, "(16, 16)": 0.7296720743179321, "(18, 0)": 0.4422982633113861, "(18, 16)": 0.7926422953605652, "(20, 0)": 0.7926422953605652, "(20, 16)": 0.5903212428092957, "(22, 0)": 0.4422982633113861, "(22, 16)": 0.7926422953605652, "(24, 0)": 0.5903212428092957, "(24, 16)": 0.7926422953605652, "(26, 0)": 0.4422982633113861, "(26, 16)": 0.5903212428092957, "(28, 0)": 0.4422982633113861, "(28, 16)": 0.4422982633113861, "(30, 0)": 0.4422982633113861, "(30, 16)": 0.4422982633113861}, "r_span": [719, 838], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003327608108520508}}, {"prompt_attention_score": {"(0, 0)": 0.7363885045051575, "(0, 16)": 0.7363885045051575, "(2, 0)": 0.7363885045051575, "(2, 16)": 0.7363885045051575, "(4, 0)": 0.7363885045051575, "(4, 16)": 0.7363885045051575, "(6, 0)": 0.7363885045051575, "(6, 16)": 0.663270115852356, "(8, 0)": 0.7363885045051575, "(8, 16)": 0.7363885045051575, "(10, 0)": 0.7363885045051575, "(10, 16)": 0.7363885045051575, "(12, 0)": 0.7363885045051575, "(12, 16)": 0.663270115852356, "(14, 0)": 0.5964006185531616, "(14, 16)": 0.7363885045051575, "(16, 0)": 0.7363885045051575, "(16, 16)": 0.7363885045051575, "(18, 0)": 0.4429984390735626, "(18, 16)": 0.663270115852356, "(20, 0)": 0.5964006185531616, "(20, 16)": 0.5964006185531616, "(22, 0)": 0.4429984390735626, "(22, 16)": 0.5964006185531616, "(24, 0)": 0.5964006185531616, "(24, 16)": 0.5964006185531616, "(26, 0)": 0.4429984390735626, "(26, 16)": 0.4429984390735626, "(28, 0)": 0.4429984390735626, "(28, 16)": 0.4429984390735626, "(30, 0)": 0.4429984390735626, "(30, 16)": 0.4429984390735626}, "r_span": [833, 863], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000573575496673584}}]}, {"id": "9729", "source_id": "14719", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 543, "end": 563, "text": "Restaurants Take Out", "meta": "EVIDENT CONFLICT\nOriginal: \"RestaurantsTakeOut\": false\nGenerated: Restaurants Take Out", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 533, "end": 537, "text": "WiFi", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: \"WiFi\": null\nGenerated: WiFi", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 618, "end": 624, "text": "casual", "meta": "EVIDENT CONFLICT\nOriginal: \"casual\": false\nGenerated: casual", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 581, "end": 642, "text": "it is a popular destination for both casual and formal dining", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"it is a popular destination for both casual and formal dining\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 812, "end": 835, "text": "Business Parking garage", "meta": "EVIDENT CONFLICT\nOriginal: \"garage\": false\nGenerated: Business Parking garage", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 853, "end": 870, "text": "validated parking", "meta": "EVIDENT CONFLICT\nOriginal: \"validated\": false\nGenerated: validated parking", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 876, "end": 897, "text": "valet parking options", "meta": "EVIDENT CONFLICT\nOriginal: \"valet\": false\nGenerated: valet parking options", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 977, "end": 1035, "text": "indicating that it is popular and often booked in advance.", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"indicating that it is popular and often booked in advance.\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Elements Restaurant and Bar in Santa Barbara, California:\n\nElements Restaurant and Bar is a Bars, Restaurants, American (New) establishment located in Santa Barbara, CA. The restaurant has received mixed reviews from customers, with some praising the ambiance, service, and food quality, while others have had disappointing experiences with poor management and sneaky gratuity charges.\n\nThe restaurant offers a variety of categories, including Outdoor Seating, WiFi, and Restaurants Take Out, suggesting that it is a popular destination for both casual and formal dining. However, some customers have noted that the restaurant can be quite loud, which may affect the overall dining experience.\n\nIn terms of attributes, the restaurant has a Business Parking garage, street parking, validated parking, and valet parking options available. Additionally, the restaurant has a Restaurants Reservations option, indicating that it is popular and often booked in advance.\n\nThe business has a 3.5-star rating, with some customers praising the excellent service, delicious food, and cozy atmosphere, while others have had disappointing experiences with poor management, sneaky gratuity charges, and subpar food quality. Overall, Elements Restaurant and Bar appears to be a mid-range establishment with potential for improvement in certain areas.", "response_spans": [[0, 457], [459, 765], [767, 1035], [1037, 1407]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.538585364818573, "(0, 16)": 0.538585364818573, "(2, 0)": 0.538585364818573, "(2, 16)": 0.538585364818573, "(4, 0)": 0.538585364818573, "(4, 16)": 0.5932583808898926, "(6, 0)": 0.538585364818573, "(6, 16)": 0.8325819969177246, "(8, 0)": 0.8325819969177246, "(8, 16)": 0.538585364818573, "(10, 0)": 0.5854300260543823, "(10, 16)": 0.538585364818573, "(12, 0)": 0.538585364818573, "(12, 16)": 0.8325819969177246, "(14, 0)": 0.538585364818573, "(14, 16)": 0.5400354862213135, "(16, 0)": 0.5400354862213135, "(16, 16)": 0.538585364818573, "(18, 0)": 0.538585364818573, "(18, 16)": 0.5400354862213135, "(20, 0)": 0.8325819969177246, "(20, 16)": 0.538585364818573, "(22, 0)": 0.538585364818573, "(22, 16)": 0.5854300260543823, "(24, 0)": 0.5854300260543823, "(24, 16)": 0.8325819969177246, "(26, 0)": 0.5400354862213135, "(26, 16)": 0.5932583808898926, "(28, 0)": 0.5400354862213135, "(28, 16)": 0.538585364818573, "(30, 0)": 0.5400354862213135, "(30, 16)": 0.5400354862213135}, "r_span": [1339, 1440], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001629948616027832}}, {"prompt_attention_score": {"(0, 0)": 0.6168003082275391, "(0, 16)": 0.6168003082275391, "(2, 0)": 0.6168003082275391, "(2, 16)": 0.6168003082275391, "(4, 0)": 0.6168003082275391, "(4, 16)": 0.6168003082275391, "(6, 0)": 0.6527905464172363, "(6, 16)": 0.699654221534729, "(8, 0)": 0.6527905464172363, "(8, 16)": 0.6168003082275391, "(10, 0)": 0.6445852518081665, "(10, 16)": 0.6168003082275391, "(12, 0)": 0.6527905464172363, "(12, 16)": 0.699654221534729, "(14, 0)": 0.6168003082275391, "(14, 16)": 0.5989596843719482, "(16, 0)": 0.699654221534729, "(16, 16)": 0.6168003082275391, "(18, 0)": 0.6527905464172363, "(18, 16)": 0.5989596843719482, "(20, 0)": 0.5989596843719482, "(20, 16)": 0.6168003082275391, "(22, 0)": 0.5090277194976807, "(22, 16)": 0.5989596843719482, "(24, 0)": 0.6168003082275391, "(24, 16)": 0.5989596843719482, "(26, 0)": 0.5090277194976807, "(26, 16)": 0.6527905464172363, "(28, 0)": 0.5090277194976807, "(28, 16)": 0.6168003082275391, "(30, 0)": 0.5090277194976807, "(30, 16)": 0.5090277194976807}, "r_span": [1442, 1505], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0001099705696105957}}, {"prompt_attention_score": {"(0, 0)": 0.5947390794754028, "(0, 16)": 0.5270302295684814, "(2, 0)": 0.5270302295684814, "(2, 16)": 0.5947390794754028, "(4, 0)": 0.5270302295684814, "(4, 16)": 0.5270302295684814, "(6, 0)": 0.5947390794754028, "(6, 16)": 0.6669396758079529, "(8, 0)": 0.5270302295684814, "(8, 16)": 0.5947390794754028, "(10, 0)": 0.5872458219528198, "(10, 16)": 0.5270302295684814, "(12, 0)": 0.6002042293548584, "(12, 16)": 0.6669396758079529, "(14, 0)": 0.5947390794754028, "(14, 16)": 0.6669396758079529, "(16, 0)": 0.61034095287323, "(16, 16)": 0.5270302295684814, "(18, 0)": 0.5947390794754028, "(18, 16)": 0.6669396758079529, "(20, 0)": 0.6669396758079529, "(20, 16)": 0.5270302295684814, "(22, 0)": 0.5084747076034546, "(22, 16)": 0.6669396758079529, "(24, 0)": 0.5872458219528198, "(24, 16)": 0.6669396758079529, "(26, 0)": 0.5084747076034546, "(26, 16)": 0.5947390794754028, "(28, 0)": 0.5084747076034546, "(28, 16)": 0.5270302295684814, "(30, 0)": 0.5947390794754028, "(30, 16)": 0.5084747076034546}, "r_span": [1507, 1565], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00038748979568481445}}, {"prompt_attention_score": {"(0, 0)": 0.7157434821128845, "(0, 16)": 0.7157434821128845, "(2, 0)": 0.6091201305389404, "(2, 16)": 0.6091201305389404, "(4, 0)": 0.6091201305389404, "(4, 16)": 0.6091201305389404, "(6, 0)": 0.7157434821128845, "(6, 16)": 0.8015120029449463, "(8, 0)": 0.6091201305389404, "(8, 16)": 0.6091201305389404, "(10, 0)": 0.7259458303451538, "(10, 16)": 0.6091201305389404, "(12, 0)": 0.6091201305389404, "(12, 16)": 0.6452991962432861, "(14, 0)": 0.6091201305389404, "(14, 16)": 0.49064943194389343, "(16, 0)": 0.7157434821128845, "(16, 16)": 0.5211896896362305, "(18, 0)": 0.7157434821128845, "(18, 16)": 0.7157434821128845, "(20, 0)": 0.6452991962432861, "(20, 16)": 0.6091201305389404, "(22, 0)": 0.5211896896362305, "(22, 16)": 0.7259458303451538, "(24, 0)": 0.6091201305389404, "(24, 16)": 0.7157434821128845, "(26, 0)": 0.5211896896362305, "(26, 16)": 0.7157434821128845, "(28, 0)": 0.5211896896362305, "(28, 16)": 0.6091201305389404, "(30, 0)": 0.5211896896362305, "(30, 16)": 0.5211896896362305}, "r_span": [1567, 1649], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005686283111572266}}]}, {"id": "9771", "source_id": "14726", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 302, "end": 378, "text": "Some patrons have had positive experiences with friendly and attentive staff", "meta": "HIGH INTRO OF NEW INFO\nOriginal:  No mentioned of positive experiences with staff\nGenerative:  Some patrons have had positive experiences with friendly and attentive staff\n\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 524, "end": 547, "text": "convenience of takeout.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: This specific info is not mentioned in any of the reviews.\nGenerative: appreciate the convenience of takeout.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 548, "end": 637, "text": "However, there have been some complaints regarding the availability of certain menu items", "meta": "HIGH INTRO OF NEW INFO\nOriginal: This specific info is not mentioned in any of the reviews.\nGenerative: However, there have been some complaints regarding the availability of certain menu items", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 646, "end": 670, "text": "lack of outdoor seating.", "meta": "EVIDENT CONFLICT:\nAIGC:   lack of outdoor seating.\nOriginal: there is outdoor seating. however, there is no review about it", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Kaptain's Firehouse BBQ is a local restaurant located in Isla Vista, California, offering a variety of food options including chicken wings, sandwiches, and barbecue dishes. According to reviews, the restaurant has a rating of 3.5 stars and provides good food, but customer service can be hit or miss. Some patrons have had positive experiences with friendly and attentive staff, while others have encountered rude and unhelpful service. Despite this inconsistency, many customers appreciate the quality of the food and the convenience of takeout. However, there have been some complaints regarding the availability of certain menu items and the lack of outdoor seating. Overall, Kaptain's Firehouse BBQ seems to offer decent food and service, although improvements could be made in these areas to enhance the overall dining experience.", "response_spans": [[0, 510], [492, 836]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6026724576950073, "(0, 16)": 0.6026724576950073, "(2, 0)": 0.6026724576950073, "(2, 16)": 0.6026724576950073, "(4, 0)": 0.6026724576950073, "(4, 16)": 0.6026724576950073, "(6, 0)": 0.6026724576950073, "(6, 16)": 0.7844647765159607, "(8, 0)": 0.5938106775283813, "(8, 16)": 0.6026724576950073, "(10, 0)": 0.5938106775283813, "(10, 16)": 0.5938106775283813, "(12, 0)": 0.6026724576950073, "(12, 16)": 0.7844647765159607, "(14, 0)": 0.6026724576950073, "(14, 16)": 0.7844647765159607, "(16, 0)": 0.5938106775283813, "(16, 16)": 0.6026724576950073, "(18, 0)": 0.6026724576950073, "(18, 16)": 0.7844647765159607, "(20, 0)": 0.7844647765159607, "(20, 16)": 0.6026724576950073, "(22, 0)": 0.6026724576950073, "(22, 16)": 0.5938106775283813, "(24, 0)": 0.6026724576950073, "(24, 16)": 0.7844647765159607, "(26, 0)": 0.4249042868614197, "(26, 16)": 0.6026724576950073, "(28, 0)": 0.4249042868614197, "(28, 16)": 0.6026724576950073, "(30, 0)": 0.4249042868614197, "(30, 16)": 0.4249042868614197}, "r_span": [825, 938], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0014522671699523926}}, {"prompt_attention_score": {"(0, 0)": 0.6811121702194214, "(0, 16)": 0.6811121702194214, "(2, 0)": 0.6811121702194214, "(2, 16)": 0.6811121702194214, "(4, 0)": 0.6811121702194214, "(4, 16)": 0.6811121702194214, "(6, 0)": 0.6811121702194214, "(6, 16)": 0.6767261028289795, "(8, 0)": 0.6811121702194214, "(8, 16)": 0.6811121702194214, "(10, 0)": 0.6811121702194214, "(10, 16)": 0.6811121702194214, "(12, 0)": 0.6811121702194214, "(12, 16)": 0.6811121702194214, "(14, 0)": 0.6811121702194214, "(14, 16)": 0.6811121702194214, "(16, 0)": 0.6811121702194214, "(16, 16)": 0.6811121702194214, "(18, 0)": 0.6811121702194214, "(18, 16)": 0.6811121702194214, "(20, 0)": 0.6811121702194214, "(20, 16)": 0.6811121702194214, "(22, 0)": 0.6811121702194214, "(22, 16)": 0.6811121702194214, "(24, 0)": 0.6811121702194214, "(24, 16)": 0.5382740497589111, "(26, 0)": 0.4743688106536865, "(26, 16)": 0.6811121702194214, "(28, 0)": 0.4743688106536865, "(28, 16)": 0.6811121702194214, "(30, 0)": 0.6811121702194214, "(30, 16)": 0.4743688106536865}, "r_span": [935, 1008], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0020412802696228027}}]}, {"id": "9777", "source_id": "14727", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 113, "end": 130, "text": "a cozy atmosphere", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"a cozy atmosphere\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 113, "end": 130, "text": "a cozy atmosphere", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"a cozy atmosphere\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}, {"start": 0, "end": 88, "text": "Nestled in the heart of Santa Barbara, California, Peabody's is a popular waterfront bar", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"Nestled in the heart of Santa Barbara, California, Peabody's is a popular waterfront bar\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Nestled in the heart of Santa Barbara, California, Peabody's is a popular waterfront bar and restaurant offering a cozy atmosphere and delicious American cuisine. With a rating of 3.5 stars, the establishment boasts a friendly and attentive staff, as shown in one customer's review where the bartender personally bought them a round of beers and shots of tequila after neglecting their table. However, another customer had a disappointing experience with slow service, despite enjoying their food. Overall, Peabody's appears to offer a welcoming and satisfying dining experience, although some visitors may encounter average service.", "response_spans": [[0, 506], [492, 633]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.638677716255188, "(0, 16)": 0.638677716255188, "(2, 0)": 0.638677716255188, "(2, 16)": 0.638677716255188, "(4, 0)": 0.638677716255188, "(4, 16)": 0.638677716255188, "(6, 0)": 0.638677716255188, "(6, 16)": 0.64280104637146, "(8, 0)": 0.638677716255188, "(8, 16)": 0.638677716255188, "(10, 0)": 0.638677716255188, "(10, 16)": 0.638677716255188, "(12, 0)": 0.638677716255188, "(12, 16)": 0.6297537088394165, "(14, 0)": 0.638677716255188, "(14, 16)": 0.4633086621761322, "(16, 0)": 0.638677716255188, "(16, 16)": 0.638677716255188, "(18, 0)": 0.638677716255188, "(18, 16)": 0.7527185678482056, "(20, 0)": 0.7527185678482056, "(20, 16)": 0.638677716255188, "(22, 0)": 0.638677716255188, "(22, 16)": 0.6297537088394165, "(24, 0)": 0.638677716255188, "(24, 16)": 0.6760377883911133, "(26, 0)": 0.4519491195678711, "(26, 16)": 0.638677716255188, "(28, 0)": 0.4519491195678711, "(28, 16)": 0.638677716255188, "(30, 0)": 0.4519491195678711, "(30, 16)": 0.4519491195678711}, "r_span": [1396, 1512], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005524754524230957}}, {"prompt_attention_score": {"(0, 0)": 0.6716191172599792, "(0, 16)": 0.6716191172599792, "(2, 0)": 0.6716191172599792, "(2, 16)": 0.6716191172599792, "(4, 0)": 0.6716191172599792, "(4, 16)": 0.6716191172599792, "(6, 0)": 0.6716191172599792, "(6, 16)": 0.5895326733589172, "(8, 0)": 0.6716191172599792, "(8, 16)": 0.6716191172599792, "(10, 0)": 0.6716191172599792, "(10, 16)": 0.6716191172599792, "(12, 0)": 0.6716191172599792, "(12, 16)": 0.6716191172599792, "(14, 0)": 0.6716191172599792, "(14, 16)": 0.5160654783248901, "(16, 0)": 0.6716191172599792, "(16, 16)": 0.6716191172599792, "(18, 0)": 0.6716191172599792, "(18, 16)": 0.6128026247024536, "(20, 0)": 0.6128026247024536, "(20, 16)": 0.6716191172599792, "(22, 0)": 0.6716191172599792, "(22, 16)": 0.6643509268760681, "(24, 0)": 0.6716191172599792, "(24, 16)": 0.4155254364013672, "(26, 0)": 0.4504378139972687, "(26, 16)": 0.6716191172599792, "(28, 0)": 0.4504378139972687, "(28, 16)": 0.6716191172599792, "(30, 0)": 0.4504378139972687, "(30, 16)": 0.4504378139972687}, "r_span": [1508, 1537], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00040727853775024414}}]}, {"id": "9837", "source_id": "14737", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 479, "end": 517, "text": "casual and intimate dining experiences", "meta": "EVIDENT CONFLICT\nOriginal: \"intimate\": false, \"casual\": false\nGenerative: \"casual and intimate dining experiences\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Khao Kaeng by Empty Bowl Gourmet Noodle Bar is a highly rated Thai and Taiwanese restaurant located in Montecito, California. With a rating of 4.5 stars, the restaurant offers a unique fusion of traditional Thai and Taiwanese cuisine with modern twists. The menu features a variety of dishes, including noodles, soups, and curries, all made with fresh and high-quality ingredients. The restaurant has a cozy atmosphere and offers outdoor seating, making it a great spot for both casual and intimate dining experiences. Unfortunately, the restaurant has closed, but fans of the cuisine can still visit the Empty Bowl location in Santa Barbara at the Public Market. Despite some issues with delivery service, the restaurant is highly recommended for its delicious food and excellent service.", "response_spans": [[0, 505], [486, 789]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6596291065216064, "(0, 16)": 0.6596291065216064, "(2, 0)": 0.6596291065216064, "(2, 16)": 0.6596291065216064, "(4, 0)": 0.7604038715362549, "(4, 16)": 0.7604038715362549, "(6, 0)": 0.7604038715362549, "(6, 16)": 0.8494516015052795, "(8, 0)": 0.7604038715362549, "(8, 16)": 0.7604038715362549, "(10, 0)": 0.7604038715362549, "(10, 16)": 0.7604038715362549, "(12, 0)": 0.6596291065216064, "(12, 16)": 0.8494516015052795, "(14, 0)": 0.7604038715362549, "(14, 16)": 0.8494516015052795, "(16, 0)": 0.8494516015052795, "(16, 16)": 0.7604038715362549, "(18, 0)": 0.4254518449306488, "(18, 16)": 0.8494516015052795, "(20, 0)": 0.703577995300293, "(20, 16)": 0.7604038715362549, "(22, 0)": 0.7604038715362549, "(22, 16)": 0.8494516015052795, "(24, 0)": 0.7604038715362549, "(24, 16)": 0.703577995300293, "(26, 0)": 0.4254518449306488, "(26, 16)": 0.7604038715362549, "(28, 0)": 0.4254518449306488, "(28, 16)": 0.7604038715362549, "(30, 0)": 0.4254518449306488, "(30, 16)": 0.4254518449306488}, "r_span": [786, 912], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.000821232795715332}}, {"prompt_attention_score": {"(0, 0)": 0.8454747200012207, "(0, 16)": 0.6018341779708862, "(2, 0)": 0.6121172308921814, "(2, 16)": 0.6121172308921814, "(4, 0)": 0.6121172308921814, "(4, 16)": 0.6121172308921814, "(6, 0)": 0.8454747200012207, "(6, 16)": 0.8454747200012207, "(8, 0)": 0.8454747200012207, "(8, 16)": 0.6121172308921814, "(10, 0)": 0.6121172308921814, "(10, 16)": 0.6121172308921814, "(12, 0)": 0.6121172308921814, "(12, 16)": 0.8454747200012207, "(14, 0)": 0.8454747200012207, "(14, 16)": 0.8454747200012207, "(16, 0)": 0.8454747200012207, "(16, 16)": 0.4523991048336029, "(18, 0)": 0.4523991048336029, "(18, 16)": 0.6018341779708862, "(20, 0)": 0.8454747200012207, "(20, 16)": 0.8454747200012207, "(22, 0)": 0.8454747200012207, "(22, 16)": 0.8454747200012207, "(24, 0)": 0.8454747200012207, "(24, 16)": 0.8454747200012207, "(26, 0)": 0.4523991048336029, "(26, 16)": 0.8454747200012207, "(28, 0)": 0.4523991048336029, "(28, 16)": 0.8454747200012207, "(30, 0)": 0.4523991048336029, "(30, 16)": 0.4523991048336029}, "r_span": [908, 965], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00188523530960083}}]}, {"id": "9843", "source_id": "14738", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 644, "end": 681, "text": "the restaurant does not serve alcohol", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the restaurant does not serve alcohol, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Itsuki is a Japanese restaurant located in Goleta, California, offering a variety of dishes including sushi, soups, and ramen. According to reviews, the restaurant has a rating of 3.0 out of 5 stars, with some customers expressing disappointment with the size of their orders and the quality of the food. One reviewer noted that the restaurant has permanently closed as of September 2021. Despite this, Itsuki has been praised for its ambiance, with one reviewer describing it as \"casual\" and another mentioning that it has outdoor seating. Reservations are available, and the restaurant offers takeout. However, the WiFi is not available, and the restaurant does not serve alcohol.", "response_spans": [[0, 511], [493, 682]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6018158793449402, "(0, 16)": 0.6018158793449402, "(2, 0)": 0.6018158793449402, "(2, 16)": 0.6018158793449402, "(4, 0)": 0.6018158793449402, "(4, 16)": 0.6018158793449402, "(6, 0)": 0.6018158793449402, "(6, 16)": 0.7051490545272827, "(8, 0)": 0.6018158793449402, "(8, 16)": 0.6018158793449402, "(10, 0)": 0.7758564949035645, "(10, 16)": 0.7758564949035645, "(12, 0)": 0.6018158793449402, "(12, 16)": 0.5735753774642944, "(14, 0)": 0.5735753774642944, "(14, 16)": 0.3997913599014282, "(16, 0)": 0.5735753774642944, "(16, 16)": 0.4277755618095398, "(18, 0)": 0.4277755618095398, "(18, 16)": 0.7051490545272827, "(20, 0)": 0.5735753774642944, "(20, 16)": 0.5735753774642944, "(22, 0)": 0.4277755618095398, "(22, 16)": 0.7051490545272827, "(24, 0)": 0.5735753774642944, "(24, 16)": 0.5735753774642944, "(26, 0)": 0.4277755618095398, "(26, 16)": 0.7051490545272827, "(28, 0)": 0.4277755618095398, "(28, 16)": 0.4277755618095398, "(30, 0)": 0.4277755618095398, "(30, 16)": 0.4277755618095398}, "r_span": [810, 933], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001563727855682373}}, {"prompt_attention_score": {"(0, 0)": 0.6600828170776367, "(0, 16)": 0.6168859004974365, "(2, 0)": 0.5430776476860046, "(2, 16)": 0.5430776476860046, "(4, 0)": 0.5430776476860046, "(4, 16)": 0.5430776476860046, "(6, 0)": 0.5430776476860046, "(6, 16)": 0.6821202039718628, "(8, 0)": 0.5430776476860046, "(8, 16)": 0.5430776476860046, "(10, 0)": 0.6821202039718628, "(10, 16)": 0.6821202039718628, "(12, 0)": 0.4907798767089844, "(12, 16)": 0.6821202039718628, "(14, 0)": 0.6821202039718628, "(14, 16)": 0.6821202039718628, "(16, 0)": 0.6821202039718628, "(16, 16)": 0.5430776476860046, "(18, 0)": 0.4907798767089844, "(18, 16)": 0.6821202039718628, "(20, 0)": 0.6168859004974365, "(20, 16)": 0.6821202039718628, "(22, 0)": 0.4907798767089844, "(22, 16)": 0.6168859004974365, "(24, 0)": 0.4907798767089844, "(24, 16)": 0.6821202039718628, "(26, 0)": 0.4907798767089844, "(26, 16)": 0.6821202039718628, "(28, 0)": 0.4907798767089844, "(28, 16)": 0.4907798767089844, "(30, 0)": 0.4907798767089844, "(30, 16)": 0.4907798767089844}, "r_span": [931, 972], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009188652038574219}}]}, {"id": "9873", "source_id": "14745", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 475, "end": 563, "text": "open from 10:00 AM to 8:30 PM from Monday to Saturday and 10:30 AM to 8:30 PM on Sunday,", "meta": "EVIDENT CONFLICT\nOriginal: \"Monday\": \"10:0-20:30\",\n\"Tuesday\": \"10:0-20:30\",\n\"Wednesday\": \"10:0-21:0\",\n\"Thursday\": \"10:0-20:30\",\n\"Friday\": \"10:0-20:30\",\n\"Saturday\": \"10:30-20:30\",\n\"Sunday\": \"10:30-19:0\"\nGenerative:  open from 10:00 AM to 8:30 PM from Monday to Saturday and 10:30 AM to 8:30 PM on Sunday,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Sam's To Go:\n\nSam's To Go is a local Sandwiches, Salad, Restaurant, Soup, Vegetarian, Local Flavor, Deli establishment located in Goleta, California. With an overall rating of 3.0 stars, the business offers simple and affordable sandwich options made with high-quality ingredients. While some customers have reported excellent service, others have experienced rudeness from the staff. The restaurant is open from 10:00 AM to 8:30 PM from Monday to Saturday and 10:30 AM to 8:30 PM on Sunday, providing flexible hours for customers. The business offers free WiFi and allows takeout orders, making it a convenient option for busy individuals. However, the atmosphere is casual and does not offer any special ambiance features such as romance, intimacy, classiness, hipness, diveyness, touristiness, trendiness, or upscaleness.", "response_spans": [[0, 84], [86, 592], [574, 896]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4809623956680298, "(0, 16)": 0.4809623956680298, "(2, 0)": 0.4809623956680298, "(2, 16)": 0.4809623956680298, "(4, 0)": 0.43574002385139465, "(4, 16)": 0.43574002385139465, "(6, 0)": 0.4809623956680298, "(6, 16)": 0.6833683848381042, "(8, 0)": 0.4809623956680298, "(8, 16)": 0.4809623956680298, "(10, 0)": 0.6833683848381042, "(10, 16)": 0.6833683848381042, "(12, 0)": 0.4809623956680298, "(12, 16)": 0.6833683848381042, "(14, 0)": 0.4809623956680298, "(14, 16)": 0.4809623956680298, "(16, 0)": 0.6833683848381042, "(16, 16)": 0.4809623956680298, "(18, 0)": 0.6833683848381042, "(18, 16)": 0.6833683848381042, "(20, 0)": 0.6833683848381042, "(20, 16)": 0.4809623956680298, "(22, 0)": 0.6833683848381042, "(22, 16)": 0.6833683848381042, "(24, 0)": 0.43574002385139465, "(24, 16)": 0.6833683848381042, "(26, 0)": 0.6833683848381042, "(26, 16)": 0.6196223497390747, "(28, 0)": 0.6833683848381042, "(28, 16)": 0.4809623956680298, "(30, 0)": 0.6833683848381042, "(30, 16)": 0.6833683848381042}, "r_span": [805, 827], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00044989585876464844}}, {"prompt_attention_score": {"(0, 0)": 0.6689654588699341, "(0, 16)": 0.6689654588699341, "(2, 0)": 0.6689654588699341, "(2, 16)": 0.6689654588699341, "(4, 0)": 0.6689654588699341, "(4, 16)": 0.6689654588699341, "(6, 0)": 0.6689654588699341, "(6, 16)": 0.7913141250610352, "(8, 0)": 0.6030972599983215, "(8, 16)": 0.6689654588699341, "(10, 0)": 0.6689654588699341, "(10, 16)": 0.6030972599983215, "(12, 0)": 0.6689654588699341, "(12, 16)": 0.7913141250610352, "(14, 0)": 0.6689654588699341, "(14, 16)": 0.7913141250610352, "(16, 0)": 0.7913141250610352, "(16, 16)": 0.6689654588699341, "(18, 0)": 0.4887106418609619, "(18, 16)": 0.7913141250610352, "(20, 0)": 0.7913141250610352, "(20, 16)": 0.6689654588699341, "(22, 0)": 0.4887106418609619, "(22, 16)": 0.7913141250610352, "(24, 0)": 0.6030972599983215, "(24, 16)": 0.7913141250610352, "(26, 0)": 0.4887106418609619, "(26, 16)": 0.6689654588699341, "(28, 0)": 0.4887106418609619, "(28, 16)": 0.4887106418609619, "(30, 0)": 0.4887106418609619, "(30, 16)": 0.4887106418609619}, "r_span": [829, 963], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007236003875732422}}, {"prompt_attention_score": {"(0, 0)": 0.5449728965759277, "(0, 16)": 0.5985079407691956, "(2, 0)": 0.5985079407691956, "(2, 16)": 0.5449728965759277, "(4, 0)": 0.5985079407691956, "(4, 16)": 0.5985079407691956, "(6, 0)": 0.5449728965759277, "(6, 16)": 0.671847403049469, "(8, 0)": 0.5449728965759277, "(8, 16)": 0.5449728965759277, "(10, 0)": 0.5985079407691956, "(10, 16)": 0.5985079407691956, "(12, 0)": 0.5985079407691956, "(12, 16)": 0.671847403049469, "(14, 0)": 0.5985079407691956, "(14, 16)": 0.671847403049469, "(16, 0)": 0.671847403049469, "(16, 16)": 0.5985079407691956, "(18, 0)": 0.537719190120697, "(18, 16)": 0.671847403049469, "(20, 0)": 0.671847403049469, "(20, 16)": 0.5449728965759277, "(22, 0)": 0.537719190120697, "(22, 16)": 0.671847403049469, "(24, 0)": 0.5449728965759277, "(24, 16)": 0.671847403049469, "(26, 0)": 0.537719190120697, "(26, 16)": 0.671847403049469, "(28, 0)": 0.537719190120697, "(28, 16)": 0.537719190120697, "(30, 0)": 0.537719190120697, "(30, 16)": 0.537719190120697}, "r_span": [961, 1035], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005876421928405762}}]}, {"id": "9879", "source_id": "14746", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 356, "end": 393, "text": "(until 10 PM from Monday to Saturday)", "meta": "EVIDENT CONFLICT\nOriginal: Monday to Sunday 7am to 12am\nGenerative: (until 10 PM from Monday to Saturday)", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 746, "end": 762, "text": "affordable meals", "meta": "LOW INTRODUCTION OF NEW INFORMATION \nGenerative: affordable meals", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Super Cucas:\n\nSuper Cucas is a locally-owned restaurant located in Isla Vista, California, serving a variety of Ethnic, Specialty, and Mexican cuisine. With a rating of 3.5 stars, the restaurant is popular among locals and visitors alike, particularly for its late hours of operation (until 10 PM from Monday to Saturday). The establishment is known for its generous portion sizes and vegetarian options, including veganized meats. While some reviewers have praised the quality of the food, others have experienced poor customer service, with instances of incorrect orders and rude staff behavior. Nonetheless, Super Cucas remains a popular spot for those seeking tasty and affordable meals in the area.", "response_spans": [[0, 84], [86, 591], [575, 775]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3942686915397644, "(0, 16)": 0.3942686915397644, "(2, 0)": 0.3942686915397644, "(2, 16)": 0.3942686915397644, "(4, 0)": 0.3942686915397644, "(4, 16)": 0.3942686915397644, "(6, 0)": 0.3942686915397644, "(6, 16)": 0.604044497013092, "(8, 0)": 0.3942686915397644, "(8, 16)": 0.3942686915397644, "(10, 0)": 0.604044497013092, "(10, 16)": 0.604044497013092, "(12, 0)": 0.3942686915397644, "(12, 16)": 0.604044497013092, "(14, 0)": 0.3942686915397644, "(14, 16)": 0.604044497013092, "(16, 0)": 0.604044497013092, "(16, 16)": 0.604044497013092, "(18, 0)": 0.3942686915397644, "(18, 16)": 0.604044497013092, "(20, 0)": 0.604044497013092, "(20, 16)": 0.3942686915397644, "(22, 0)": 0.604044497013092, "(22, 16)": 0.604044497013092, "(24, 0)": 0.3942686915397644, "(24, 16)": 0.604044497013092, "(26, 0)": 0.604044497013092, "(26, 16)": 0.5370601415634155, "(28, 0)": 0.604044497013092, "(28, 16)": 0.3942686915397644, "(30, 0)": 0.604044497013092, "(30, 16)": 0.604044497013092}, "r_span": [805, 826], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006224513053894043}}, {"prompt_attention_score": {"(0, 0)": 0.5382822155952454, "(0, 16)": 0.5382822155952454, "(2, 0)": 0.5382822155952454, "(2, 16)": 0.5382822155952454, "(4, 0)": 0.5382822155952454, "(4, 16)": 0.5382822155952454, "(6, 0)": 0.5382822155952454, "(6, 16)": 0.7937576770782471, "(8, 0)": 0.5382822155952454, "(8, 16)": 0.5382822155952454, "(10, 0)": 0.5382822155952454, "(10, 16)": 0.5382822155952454, "(12, 0)": 0.5382822155952454, "(12, 16)": 0.6540398001670837, "(14, 0)": 0.5382822155952454, "(14, 16)": 0.7937576770782471, "(16, 0)": 0.6540398001670837, "(16, 16)": 0.5382822155952454, "(18, 0)": 0.5382822155952454, "(18, 16)": 0.7937576770782471, "(20, 0)": 0.6540398001670837, "(20, 16)": 0.5382822155952454, "(22, 0)": 0.5382822155952454, "(22, 16)": 0.6540398001670837, "(24, 0)": 0.5382822155952454, "(24, 16)": 0.6540398001670837, "(26, 0)": 0.4066903293132782, "(26, 16)": 0.6055684089660645, "(28, 0)": 0.4066903293132782, "(28, 16)": 0.5382822155952454, "(30, 0)": 0.4066903293132782, "(30, 16)": 0.4066903293132782}, "r_span": [828, 942], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 5.841255187988281e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6949644088745117, "(0, 16)": 0.6949644088745117, "(2, 0)": 0.6949644088745117, "(2, 16)": 0.6949644088745117, "(4, 0)": 0.6949644088745117, "(4, 16)": 0.6949644088745117, "(6, 0)": 0.6949644088745117, "(6, 16)": 0.7153381109237671, "(8, 0)": 0.6949644088745117, "(8, 16)": 0.6949644088745117, "(10, 0)": 0.6949644088745117, "(10, 16)": 0.6949644088745117, "(12, 0)": 0.6949644088745117, "(12, 16)": 0.6949644088745117, "(14, 0)": 0.6949644088745117, "(14, 16)": 0.6949644088745117, "(16, 0)": 0.6949644088745117, "(16, 16)": 0.6949644088745117, "(18, 0)": 0.6949644088745117, "(18, 16)": 0.6949644088745117, "(20, 0)": 0.6949644088745117, "(20, 16)": 0.6949644088745117, "(22, 0)": 0.45920664072036743, "(22, 16)": 0.6949644088745117, "(24, 0)": 0.6949644088745117, "(24, 16)": 0.6471391320228577, "(26, 0)": 0.45920664072036743, "(26, 16)": 0.6949644088745117, "(28, 0)": 0.45920664072036743, "(28, 16)": 0.6949644088745117, "(30, 0)": 0.45920664072036743, "(30, 16)": 0.45920664072036743}, "r_span": [941, 983], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006734728813171387}}]}, {"id": "9915", "source_id": "14752", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 562, "end": 588, "text": "friendly and fast service.", "meta": "CONFLICT\nOriginal: female employees speaking...pretty loudly about us...how disgusting we were as customers\nGenerated: friendly and fast service.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Chopping Poke is a well-rated restaurant located in Goleta, California, providing delicious and healthy poke bowls to its customers. With a rating of 4.0 stars, the restaurant has received positive reviews from customers, praising the quality of the food and generous portion sizes. However, one reviewer experienced poor customer service, with an employee making derogatory comments about them after their meal. Despite this, the majority of customers have enjoyed their visits to Chopping Poke, highlighting the freshness and taste of the fish, as well as the friendly and fast service. At around $20 for a medium bowl, the restaurant may be a bit pricey, but customers agree it's worth splurging for a healthy and satisfying meal.", "response_spans": [[0, 509], [491, 733]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6223591566085815, "(0, 16)": 0.6223591566085815, "(2, 0)": 0.6223591566085815, "(2, 16)": 0.6223591566085815, "(4, 0)": 0.6223591566085815, "(4, 16)": 0.6223591566085815, "(6, 0)": 0.6223591566085815, "(6, 16)": 0.708476185798645, "(8, 0)": 0.6223591566085815, "(8, 16)": 0.6223591566085815, "(10, 0)": 0.6223591566085815, "(10, 16)": 0.6223591566085815, "(12, 0)": 0.6223591566085815, "(12, 16)": 0.7083848714828491, "(14, 0)": 0.6223591566085815, "(14, 16)": 0.42785781621932983, "(16, 0)": 0.708476185798645, "(16, 16)": 0.6223591566085815, "(18, 0)": 0.6223591566085815, "(18, 16)": 0.7518863081932068, "(20, 0)": 0.708476185798645, "(20, 16)": 0.7083848714828491, "(22, 0)": 0.7083848714828491, "(22, 16)": 0.564166784286499, "(24, 0)": 0.7083848714828491, "(24, 16)": 0.7518863081932068, "(26, 0)": 0.4316565692424774, "(26, 16)": 0.7518863081932068, "(28, 0)": 0.4316565692424774, "(28, 16)": 0.7083848714828491, "(30, 0)": 0.4316565692424774, "(30, 16)": 0.4316565692424774}, "r_span": [1203, 1313], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010434389114379883}}, {"prompt_attention_score": {"(0, 0)": 0.7834188938140869, "(0, 16)": 0.7834188938140869, "(2, 0)": 0.7834188938140869, "(2, 16)": 0.7834188938140869, "(4, 0)": 0.7834188938140869, "(4, 16)": 0.7834188938140869, "(6, 0)": 0.7304439544677734, "(6, 16)": 0.8306665420532227, "(8, 0)": 0.7834188938140869, "(8, 16)": 0.7834188938140869, "(10, 0)": 0.7834188938140869, "(10, 16)": 0.7834188938140869, "(12, 0)": 0.7834188938140869, "(12, 16)": 0.7834188938140869, "(14, 0)": 0.7304439544677734, "(14, 16)": 0.7834188938140869, "(16, 0)": 0.7834188938140869, "(16, 16)": 0.7834188938140869, "(18, 0)": 0.7304439544677734, "(18, 16)": 0.7834188938140869, "(20, 0)": 0.7834188938140869, "(20, 16)": 0.7304439544677734, "(22, 0)": 0.7304439544677734, "(22, 16)": 0.7834188938140869, "(24, 0)": 0.7304439544677734, "(24, 16)": 0.7834188938140869, "(26, 0)": 0.4345360994338989, "(26, 16)": 0.7834188938140869, "(28, 0)": 0.4345360994338989, "(28, 16)": 0.7304439544677734, "(30, 0)": 0.7304439544677734, "(30, 16)": 0.4345360994338989}, "r_span": [1309, 1370], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003599107265472412}}]}, {"id": "9921", "source_id": "14753", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 773, "end": 802, "text": "accommodating outdoor seating", "meta": "HIGH INTRODUCTION OF NEW INFORMATION \nOriginal: \"OutdoorSeating\": null\nGenerated: accommodating outdoor seating options", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of DJ Flamezz Entertainment:\n\nDJ Flamezz Entertainment is a reputable and highly-rated entertainment company in Santa Barbara, California. With a five-star rating and numerous positive reviews, the business has established itself as a go-to provider of DJ services, party equipment rentals, wedding planning, and event planning services. The company's attention to detail, flexibility, and ability to cater to diverse client needs have been consistently praised by customers. DJ Edu, one of the company's DJs, has received particularly high marks for his exceptional mixing skills and ability to create a memorable atmosphere at events. Additionally, the business's commitment to providing free WiFi and accommodating outdoor seating options further enhances its appeal. Overall, DJ Flamezz Entertainment appears to be a top choice for individuals and organizations seeking professional and enjoyable entertainment experiences.", "response_spans": [[0, 97], [99, 609], [592, 996]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4935641586780548, "(0, 16)": 0.4935641586780548, "(2, 0)": 0.4935641586780548, "(2, 16)": 0.4935641586780548, "(4, 0)": 0.4935641586780548, "(4, 16)": 0.4935641586780548, "(6, 0)": 0.4935641586780548, "(6, 16)": 0.6146174073219299, "(8, 0)": 0.6146174073219299, "(8, 16)": 0.4935641586780548, "(10, 0)": 0.6146174073219299, "(10, 16)": 0.6146174073219299, "(12, 0)": 0.5264045000076294, "(12, 16)": 0.6146174073219299, "(14, 0)": 0.4935641586780548, "(14, 16)": 0.6146174073219299, "(16, 0)": 0.6146174073219299, "(16, 16)": 0.6146174073219299, "(18, 0)": 0.6146174073219299, "(18, 16)": 0.6146174073219299, "(20, 0)": 0.6146174073219299, "(20, 16)": 0.4363390803337097, "(22, 0)": 0.6146174073219299, "(22, 16)": 0.6146174073219299, "(24, 0)": 0.4363390803337097, "(24, 16)": 0.6146174073219299, "(26, 0)": 0.6146174073219299, "(26, 16)": 0.6146174073219299, "(28, 0)": 0.6146174073219299, "(28, 16)": 0.6146174073219299, "(30, 0)": 0.6146174073219299, "(30, 16)": 0.6146174073219299}, "r_span": [822, 844], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008369088172912598}}, {"prompt_attention_score": {"(0, 0)": 0.6548101902008057, "(0, 16)": 0.6548101902008057, "(2, 0)": 0.6548101902008057, "(2, 16)": 0.6548101902008057, "(4, 0)": 0.6548101902008057, "(4, 16)": 0.6548101902008057, "(6, 0)": 0.6548101902008057, "(6, 16)": 0.765536904335022, "(8, 0)": 0.5494264364242554, "(8, 16)": 0.6548101902008057, "(10, 0)": 0.5494264364242554, "(10, 16)": 0.6548101902008057, "(12, 0)": 0.6548101902008057, "(12, 16)": 0.765536904335022, "(14, 0)": 0.5494264364242554, "(14, 16)": 0.765536904335022, "(16, 0)": 0.765536904335022, "(16, 16)": 0.6548101902008057, "(18, 0)": 0.42935672402381897, "(18, 16)": 0.765536904335022, "(20, 0)": 0.7040140628814697, "(20, 16)": 0.5494264364242554, "(22, 0)": 0.42935672402381897, "(22, 16)": 0.765536904335022, "(24, 0)": 0.5494264364242554, "(24, 16)": 0.765536904335022, "(26, 0)": 0.42935672402381897, "(26, 16)": 0.6548101902008057, "(28, 0)": 0.42935672402381897, "(28, 16)": 0.5494264364242554, "(30, 0)": 0.42935672402381897, "(30, 16)": 0.42935672402381897}, "r_span": [846, 956], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.002343416213989258}}, {"prompt_attention_score": {"(0, 0)": 0.7192478179931641, "(0, 16)": 0.7192478179931641, "(2, 0)": 0.7192478179931641, "(2, 16)": 0.692573070526123, "(4, 0)": 0.7192478179931641, "(4, 16)": 0.7192478179931641, "(6, 0)": 0.7192478179931641, "(6, 16)": 0.7099825143814087, "(8, 0)": 0.7192478179931641, "(8, 16)": 0.5803004503250122, "(10, 0)": 0.5803004503250122, "(10, 16)": 0.7192478179931641, "(12, 0)": 0.7192478179931641, "(12, 16)": 0.7099825143814087, "(14, 0)": 0.5803004503250122, "(14, 16)": 0.7192478179931641, "(16, 0)": 0.7099825143814087, "(16, 16)": 0.692573070526123, "(18, 0)": 0.4390948712825775, "(18, 16)": 0.7099825143814087, "(20, 0)": 0.7099825143814087, "(20, 16)": 0.5803004503250122, "(22, 0)": 0.4390948712825775, "(22, 16)": 0.7099825143814087, "(24, 0)": 0.5803004503250122, "(24, 16)": 0.7099825143814087, "(26, 0)": 0.4390948712825775, "(26, 16)": 0.7192478179931641, "(28, 0)": 0.4390948712825775, "(28, 16)": 0.4390948712825775, "(30, 0)": 0.4390948712825775, "(30, 16)": 0.4390948712825775}, "r_span": [955, 1028], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0004839897155761719}}]}, {"id": "9939", "source_id": "14756", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 250, "end": 255, "text": "WiFi,", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"WiFi\": null,\nGenerative: offers WiFi,", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}, {"start": 260, "end": 321, "text": "does not provide Business Parking or Restaurant Reservations.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"BusinessParking\": null, \"RestaurantsReservations\": null,\nGenerative: does not provide Business Parking or Restaurant Reservations.\n\n\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Cafe Lido:\n\nCafe Lido is an Italian, Mediterranean, and American restaurant located in Santa Barbara, California. With a rating of 3.5 stars, the cafe offers outdoor seating and WiFi, but does not provide Business Parking or Restaurant Reservations. Customers have praised the cafe's ambiance and service, with one reviewer noting that their server was friendly and efficient. However, another reviewer criticized the cafe's policy of adding a 20% service fee to bills without notice, which they felt was unfair. Additionally, some customers have complained about long wait times for service. Despite these issues, the cafe's breakfast options, including crispy Yukon grilled potatoes and a breakfast sandwich, have been praised for their taste and generous portions.", "response_spans": [[0, 82], [84, 584], [568, 839]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3746207356452942, "(0, 16)": 0.3746207356452942, "(2, 0)": 0.4939499795436859, "(2, 16)": 0.3746207356452942, "(4, 0)": 0.4939499795436859, "(4, 16)": 0.4939499795436859, "(6, 0)": 0.4939499795436859, "(6, 16)": 0.6551045775413513, "(8, 0)": 0.44386380910873413, "(8, 16)": 0.3746207356452942, "(10, 0)": 0.6551045775413513, "(10, 16)": 0.6551045775413513, "(12, 0)": 0.5441428422927856, "(12, 16)": 0.6551045775413513, "(14, 0)": 0.3746207356452942, "(14, 16)": 0.6551045775413513, "(16, 0)": 0.6551045775413513, "(16, 16)": 0.5441428422927856, "(18, 0)": 0.4939499795436859, "(18, 16)": 0.6551045775413513, "(20, 0)": 0.6551045775413513, "(20, 16)": 0.3746207356452942, "(22, 0)": 0.6551045775413513, "(22, 16)": 0.6551045775413513, "(24, 0)": 0.3746207356452942, "(24, 16)": 0.6551045775413513, "(26, 0)": 0.6551045775413513, "(26, 16)": 0.6551045775413513, "(28, 0)": 0.6551045775413513, "(28, 16)": 0.3746207356452942, "(30, 0)": 0.6551045775413513, "(30, 16)": 0.6551045775413513}, "r_span": [1059, 1080], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00038301944732666016}}, {"prompt_attention_score": {"(0, 0)": 0.5544562339782715, "(0, 16)": 0.5544562339782715, "(2, 0)": 0.40779802203178406, "(2, 16)": 0.40779802203178406, "(4, 0)": 0.40779802203178406, "(4, 16)": 0.5544562339782715, "(6, 0)": 0.5544562339782715, "(6, 16)": 0.7916743755340576, "(8, 0)": 0.6211237907409668, "(8, 16)": 0.40779802203178406, "(10, 0)": 0.5540238618850708, "(10, 16)": 0.40779802203178406, "(12, 0)": 0.5544562339782715, "(12, 16)": 0.7916743755340576, "(14, 0)": 0.40779802203178406, "(14, 16)": 0.7916743755340576, "(16, 0)": 0.6211237907409668, "(16, 16)": 0.40779802203178406, "(18, 0)": 0.40779802203178406, "(18, 16)": 0.7916743755340576, "(20, 0)": 0.7916743755340576, "(20, 16)": 0.40779802203178406, "(22, 0)": 0.43395379185676575, "(22, 16)": 0.6211237907409668, "(24, 0)": 0.40779802203178406, "(24, 16)": 0.7916743755340576, "(26, 0)": 0.43395379185676575, "(26, 16)": 0.5544562339782715, "(28, 0)": 0.43395379185676575, "(28, 16)": 0.40779802203178406, "(30, 0)": 0.43395379185676575, "(30, 16)": 0.43395379185676575}, "r_span": [1082, 1205], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00138169527053833}}, {"prompt_attention_score": {"(0, 0)": 0.7217655777931213, "(0, 16)": 0.7217655777931213, "(2, 0)": 0.5790024399757385, "(2, 16)": 0.7217655777931213, "(4, 0)": 0.5790024399757385, "(4, 16)": 0.5790024399757385, "(6, 0)": 0.7217655777931213, "(6, 16)": 0.8079965114593506, "(8, 0)": 0.7217655777931213, "(8, 16)": 0.5790024399757385, "(10, 0)": 0.7172409892082214, "(10, 16)": 0.7217655777931213, "(12, 0)": 0.7217655777931213, "(12, 16)": 0.8079965114593506, "(14, 0)": 0.5790024399757385, "(14, 16)": 0.8079965114593506, "(16, 0)": 0.8079965114593506, "(16, 16)": 0.7217655777931213, "(18, 0)": 0.7217655777931213, "(18, 16)": 0.8079965114593506, "(20, 0)": 0.8079965114593506, "(20, 16)": 0.5790024399757385, "(22, 0)": 0.49691158533096313, "(22, 16)": 0.8079965114593506, "(24, 0)": 0.5790024399757385, "(24, 16)": 0.8079965114593506, "(26, 0)": 0.49691158533096313, "(26, 16)": 0.8079965114593506, "(28, 0)": 0.49691158533096313, "(28, 16)": 0.5790024399757385, "(30, 0)": 0.49691158533096313, "(30, 16)": 0.49691158533096313}, "r_span": [1201, 1261], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -5.08427619934082e-05}}]}, {"id": "10005", "source_id": "14767", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Here is an objective overview of Mediterra Market and Cafe based on the structured data provided:\n\nMediterra Market and Cafe is a Mediterranean restaurant located in Goleta, California. With a rating of 4.0 out of 5 stars, the business has received positive reviews from customers for its excellent customer service and homemade-looking and tasting dishes. Although some customers have noted that the portions of meat on the combo plate could be improved, overall the quality of the food is considered to be good. The restaurant offers free WiFi and has an outdoor seating area, making it a popular spot for both casual and romantic dining. However, the parking lot is not particularly scenic, but the owners are accommodating. Reviewers have praised the friendliness of the staff and the authenticity of the food, including the gyro and falafel.", "response_spans": [[0, 97], [99, 607], [589, 846]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5135540962219238, "(0, 16)": 0.5135540962219238, "(2, 0)": 0.5135540962219238, "(2, 16)": 0.5135540962219238, "(4, 0)": 0.5135540962219238, "(4, 16)": 0.5135540962219238, "(6, 0)": 0.5135540962219238, "(6, 16)": 0.6523422002792358, "(8, 0)": 0.5425530672073364, "(8, 16)": 0.5135540962219238, "(10, 0)": 0.6523422002792358, "(10, 16)": 0.6523422002792358, "(12, 0)": 0.5623589754104614, "(12, 16)": 0.6523422002792358, "(14, 0)": 0.5135540962219238, "(14, 16)": 0.6523422002792358, "(16, 0)": 0.6523422002792358, "(16, 16)": 0.5135540962219238, "(18, 0)": 0.5135540962219238, "(18, 16)": 0.6523422002792358, "(20, 0)": 0.6523422002792358, "(20, 16)": 0.5135540962219238, "(22, 0)": 0.6523422002792358, "(22, 16)": 0.6523422002792358, "(24, 0)": 0.5135540962219238, "(24, 16)": 0.6523422002792358, "(26, 0)": 0.6523422002792358, "(26, 16)": 0.6523422002792358, "(28, 0)": 0.6523422002792358, "(28, 16)": 0.6523422002792358, "(30, 0)": 0.6523422002792358, "(30, 16)": 0.6523422002792358}, "r_span": [670, 691], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005287528038024902}}, {"prompt_attention_score": {"(0, 0)": 0.6455601453781128, "(0, 16)": 0.6455601453781128, "(2, 0)": 0.6455601453781128, "(2, 16)": 0.6455601453781128, "(4, 0)": 0.6455601453781128, "(4, 16)": 0.6455601453781128, "(6, 0)": 0.6455601453781128, "(6, 16)": 0.7774532437324524, "(8, 0)": 0.6455601453781128, "(8, 16)": 0.6455601453781128, "(10, 0)": 0.6455601453781128, "(10, 16)": 0.6455601453781128, "(12, 0)": 0.6455601453781128, "(12, 16)": 0.607952356338501, "(14, 0)": 0.6455601453781128, "(14, 16)": 0.6455601453781128, "(16, 0)": 0.6455601453781128, "(16, 16)": 0.6455601453781128, "(18, 0)": 0.607952356338501, "(18, 16)": 0.607952356338501, "(20, 0)": 0.607952356338501, "(20, 16)": 0.6455601453781128, "(22, 0)": 0.4428531527519226, "(22, 16)": 0.7774532437324524, "(24, 0)": 0.6455601453781128, "(24, 16)": 0.607952356338501, "(26, 0)": 0.4428531527519226, "(26, 16)": 0.7774532437324524, "(28, 0)": 0.4428531527519226, "(28, 16)": 0.6455601453781128, "(30, 0)": 0.4428531527519226, "(30, 16)": 0.4428531527519226}, "r_span": [693, 807], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009986162185668945}}, {"prompt_attention_score": {"(0, 0)": 0.7062737345695496, "(0, 16)": 0.7062737345695496, "(2, 0)": 0.7480494976043701, "(2, 16)": 0.7480494976043701, "(4, 0)": 0.7480494976043701, "(4, 16)": 0.7062737345695496, "(6, 0)": 0.7062737345695496, "(6, 16)": 0.7715817093849182, "(8, 0)": 0.7062737345695496, "(8, 16)": 0.7062737345695496, "(10, 0)": 0.7062737345695496, "(10, 16)": 0.7062737345695496, "(12, 0)": 0.7062737345695496, "(12, 16)": 0.7715817093849182, "(14, 0)": 0.7062737345695496, "(14, 16)": 0.7062737345695496, "(16, 0)": 0.7480494976043701, "(16, 16)": 0.474627822637558, "(18, 0)": 0.474627822637558, "(18, 16)": 0.7715817093849182, "(20, 0)": 0.7715817093849182, "(20, 16)": 0.7062737345695496, "(22, 0)": 0.474627822637558, "(22, 16)": 0.7480494976043701, "(24, 0)": 0.7062737345695496, "(24, 16)": 0.7715817093849182, "(26, 0)": 0.474627822637558, "(26, 16)": 0.7480494976043701, "(28, 0)": 0.474627822637558, "(28, 16)": 0.474627822637558, "(30, 0)": 0.474627822637558, "(30, 16)": 0.474627822637558}, "r_span": [804, 865], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0018176436424255371}}]}, {"id": "10017", "source_id": "14769", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "El Taco Tequila Taqueria is a local restaurant located in Santa Barbara, California, serving Mexican cuisine. According to the structured data, the restaurant has a rating of 3.5 stars and has received mixed reviews from customers. Some reviews praise the restaurant's delicious food and atmospheric ambiance, while others criticize poor customer service and food safety issues. One reviewer reported experiencing food poisoning after visiting the restaurant, while another had a negative encounter with the staff when trying to resolve an issue with their order. Despite these concerns, many patrons have enjoyed their dining experience at El Taco Tequila Taqueria, particularly during happy hour when they can take advantage of two-for-one margaritas. However, the restaurant could improve its customer service and ensure proper food safety protocols to enhance overall customer satisfaction.", "response_spans": [[0, 507], [489, 894]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.668869137763977, "(0, 16)": 0.668869137763977, "(2, 0)": 0.668869137763977, "(2, 16)": 0.668869137763977, "(4, 0)": 0.668869137763977, "(4, 16)": 0.668869137763977, "(6, 0)": 0.668869137763977, "(6, 16)": 0.7461010813713074, "(8, 0)": 0.668869137763977, "(8, 16)": 0.668869137763977, "(10, 0)": 0.668869137763977, "(10, 16)": 0.6463347673416138, "(12, 0)": 0.668869137763977, "(12, 16)": 0.7461010813713074, "(14, 0)": 0.668869137763977, "(14, 16)": 0.482165664434433, "(16, 0)": 0.668869137763977, "(16, 16)": 0.668869137763977, "(18, 0)": 0.668869137763977, "(18, 16)": 0.7461010813713074, "(20, 0)": 0.7461010813713074, "(20, 16)": 0.668869137763977, "(22, 0)": 0.482165664434433, "(22, 16)": 0.668869137763977, "(24, 0)": 0.668869137763977, "(24, 16)": 0.6463347673416138, "(26, 0)": 0.482165664434433, "(26, 16)": 0.668869137763977, "(28, 0)": 0.482165664434433, "(28, 16)": 0.668869137763977, "(30, 0)": 0.482165664434433, "(30, 16)": 0.482165664434433}, "r_span": [907, 1012], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001394510269165039}}, {"prompt_attention_score": {"(0, 0)": 0.6954324245452881, "(0, 16)": 0.6954324245452881, "(2, 0)": 0.6954324245452881, "(2, 16)": 0.6954324245452881, "(4, 0)": 0.6954324245452881, "(4, 16)": 0.6954324245452881, "(6, 0)": 0.6954324245452881, "(6, 16)": 0.6132478713989258, "(8, 0)": 0.6954324245452881, "(8, 16)": 0.6954324245452881, "(10, 0)": 0.6954324245452881, "(10, 16)": 0.6954324245452881, "(12, 0)": 0.6954324245452881, "(12, 16)": 0.6954324245452881, "(14, 0)": 0.6954324245452881, "(14, 16)": 0.4181443452835083, "(16, 0)": 0.6954324245452881, "(16, 16)": 0.6954324245452881, "(18, 0)": 0.7020015716552734, "(18, 16)": 0.6954324245452881, "(20, 0)": 0.6954324245452881, "(20, 16)": 0.6954324245452881, "(22, 0)": 0.4332560896873474, "(22, 16)": 0.6954324245452881, "(24, 0)": 0.6954324245452881, "(24, 16)": 0.7020015716552734, "(26, 0)": 0.4332560896873474, "(26, 16)": 0.6954324245452881, "(28, 0)": 0.4332560896873474, "(28, 16)": 0.6954324245452881, "(30, 0)": 0.4332560896873474, "(30, 16)": 0.4332560896873474}, "r_span": [1010, 1089], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003140568733215332}}]}, {"id": "10071", "source_id": "14778", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 435, "end": 457, "text": "offers outdoor seating", "meta": "EVIDENT CONFLICT:\nAIGC: offers outdoor seating \nOriginal: \"OutdoorSeating\": false,\n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 459, "end": 464, "text": "WiFi,", "meta": "EVIDENT CONFLICT:\nAIGC: offers wifi\nOriginal: \"WiFi\": \"no\",\n", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Itsuki Restaurant is a Japanese restaurant located in Santa Barbara, California. With a rating of 4.0 stars, the restaurant offers a casual dining experience with a variety of options including sushi, rolls, and entrees. While some customers have reported disappointment with the quantity of food and quality of fish, others have praised the restaurant's deliciousness and value for money. The restaurant has a convenient location and offers outdoor seating, WiFi, and reservations. However, parking can be limited, and the restaurant does not offer valet or validate parking. Despite some mixed reviews, Itsuki Restaurant appears to be a popular choice for those looking for authentic Japanese cuisine in the area.", "response_spans": [[0, 506], [492, 715]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6655542850494385, "(0, 16)": 0.6655542850494385, "(2, 0)": 0.6655542850494385, "(2, 16)": 0.6655542850494385, "(4, 0)": 0.6655542850494385, "(4, 16)": 0.6655542850494385, "(6, 0)": 0.6655542850494385, "(6, 16)": 0.7559078931808472, "(8, 0)": 0.5556333065032959, "(8, 16)": 0.5556333065032959, "(10, 0)": 0.6655542850494385, "(10, 16)": 0.6655542850494385, "(12, 0)": 0.5556333065032959, "(12, 16)": 0.7559078931808472, "(14, 0)": 0.5556333065032959, "(14, 16)": 0.4238581657409668, "(16, 0)": 0.6655542850494385, "(16, 16)": 0.5556333065032959, "(18, 0)": 0.5556333065032959, "(18, 16)": 0.7559078931808472, "(20, 0)": 0.7559078931808472, "(20, 16)": 0.5556333065032959, "(22, 0)": 0.5556333065032959, "(22, 16)": 0.7559078931808472, "(24, 0)": 0.5556333065032959, "(24, 16)": 0.7559078931808472, "(26, 0)": 0.4340778589248657, "(26, 16)": 0.6655542850494385, "(28, 0)": 0.4340778589248657, "(28, 16)": 0.5556333065032959, "(30, 0)": 0.4340778589248657, "(30, 16)": 0.4340778589248657}, "r_span": [916, 1029], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00028437376022338867}}, {"prompt_attention_score": {"(0, 0)": 0.6383694410324097, "(0, 16)": 0.6383694410324097, "(2, 0)": 0.6865594983100891, "(2, 16)": 0.6865594983100891, "(4, 0)": 0.6865594983100891, "(4, 16)": 0.6865594983100891, "(6, 0)": 0.6383694410324097, "(6, 16)": 0.68220055103302, "(8, 0)": 0.6865594983100891, "(8, 16)": 0.6865594983100891, "(10, 0)": 0.6865594983100891, "(10, 16)": 0.6383694410324097, "(12, 0)": 0.6865594983100891, "(12, 16)": 0.68220055103302, "(14, 0)": 0.6865594983100891, "(14, 16)": 0.41246283054351807, "(16, 0)": 0.68220055103302, "(16, 16)": 0.6865594983100891, "(18, 0)": 0.6865594983100891, "(18, 16)": 0.5905965566635132, "(20, 0)": 0.68220055103302, "(20, 16)": 0.6865594983100891, "(22, 0)": 0.6865594983100891, "(22, 16)": 0.68220055103302, "(24, 0)": 0.6865594983100891, "(24, 16)": 0.68220055103302, "(26, 0)": 0.4478823244571686, "(26, 16)": 0.6383694410324097, "(28, 0)": 0.4478823244571686, "(28, 16)": 0.6865594983100891, "(30, 0)": 0.4478823244571686, "(30, 16)": 0.4478823244571686}, "r_span": [1026, 1074], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006712675094604492}}]}, {"id": "10113", "source_id": "14785", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 613, "end": 658, "text": "may find the atmosphere to be either romantic", "meta": "EVIDENT CONFLICT\nOriginal: \"romantic\": false,\nGenerative: \"may find the atmosphere to be either romantic \"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 662, "end": 670, "text": "intimate", "meta": "EVIDENT CONFLICT\nOriginal: \"intimate\": false,\nGenerative: \"may find the atmosphere to be... intimate \"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Metropulos Fine Foods is a local restaurant located in Santa Barbara, California, offering a variety of dining experiences for customers. With a rating of 4.5 stars, the business provides excellent service and delicious food, including sandwiches, soups, and salads. Customers appreciate the reasonable prices and generous portion sizes, making it a great lunch spot. Although some customers have noted limited parking availability, the nearby parking option helps alleviate this issue. A few reviews mention the presence of dogs on the premises, but no incidents have been reported. Despite this, some customers may find the atmosphere to be either romantic or intimate, depending on their preferences. Overall, Metropulos Fine Foods is a fantastic choice for those seeking a tasty and convenient meal.", "response_spans": [[0, 512], [493, 803]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6006839275360107, "(0, 16)": 0.6006839275360107, "(2, 0)": 0.6006839275360107, "(2, 16)": 0.6006839275360107, "(4, 0)": 0.6006839275360107, "(4, 16)": 0.6006839275360107, "(6, 0)": 0.6006839275360107, "(6, 16)": 0.5471729040145874, "(8, 0)": 0.6006839275360107, "(8, 16)": 0.6006839275360107, "(10, 0)": 0.6635250449180603, "(10, 16)": 0.543897271156311, "(12, 0)": 0.6090759038925171, "(12, 16)": 0.5471729040145874, "(14, 0)": 0.6090759038925171, "(14, 16)": 0.45392099022865295, "(16, 0)": 0.5471729040145874, "(16, 16)": 0.6006839275360107, "(18, 0)": 0.6090759038925171, "(18, 16)": 0.8086195588111877, "(20, 0)": 0.5471729040145874, "(20, 16)": 0.6090759038925171, "(22, 0)": 0.4334619641304016, "(22, 16)": 0.5471729040145874, "(24, 0)": 0.6090759038925171, "(24, 16)": 0.8086195588111877, "(26, 0)": 0.4334619641304016, "(26, 16)": 0.5471729040145874, "(28, 0)": 0.4334619641304016, "(28, 16)": 0.6090759038925171, "(30, 0)": 0.4334619641304016, "(30, 16)": 0.4334619641304016}, "r_span": [1074, 1181], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0011330842971801758}}, {"prompt_attention_score": {"(0, 0)": 0.687397837638855, "(0, 16)": 0.687397837638855, "(2, 0)": 0.687397837638855, "(2, 16)": 0.687397837638855, "(4, 0)": 0.687397837638855, "(4, 16)": 0.687397837638855, "(6, 0)": 0.687397837638855, "(6, 16)": 0.616171658039093, "(8, 0)": 0.687397837638855, "(8, 16)": 0.687397837638855, "(10, 0)": 0.687397837638855, "(10, 16)": 0.6470350623130798, "(12, 0)": 0.6470350623130798, "(12, 16)": 0.616171658039093, "(14, 0)": 0.68354332447052, "(14, 16)": 0.4701592028141022, "(16, 0)": 0.687397837638855, "(16, 16)": 0.687397837638855, "(18, 0)": 0.68354332447052, "(18, 16)": 0.616171658039093, "(20, 0)": 0.616171658039093, "(20, 16)": 0.68354332447052, "(22, 0)": 0.44028133153915405, "(22, 16)": 0.6470350623130798, "(24, 0)": 0.68354332447052, "(24, 16)": 0.616171658039093, "(26, 0)": 0.44028133153915405, "(26, 16)": 0.68354332447052, "(28, 0)": 0.44028133153915405, "(28, 16)": 0.44028133153915405, "(30, 0)": 0.44028133153915405, "(30, 16)": 0.44028133153915405}, "r_span": [1179, 1247], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0027837157249450684}}]}, {"id": "10209", "source_id": "14802", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 458, "end": 466, "text": "and WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\"\nGenerative: \"...offers...and WiFi...\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 547, "end": 605, "text": "and the business is open during regular supermarket hours.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: \"hours\": null\nGenerative: \"...and the business is open during regular supermarket hours.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "Sanba IM is a popular bubble tea and sushi bar located inside Albertsons Supermarket in Goleta, CA. With a rating of 4.0 out of 5 stars, the business has received positive reviews for its high-quality boba and sushi, as well as its convenient location within a supermarket. Although the business is currently moving to a new location, customers have praised its unique offering of boba and sushi in an unexpected setting. The business offers outdoor seating and WiFi, but does not accept reservations or have valet parking. The ambiance is casual and the business is open during regular supermarket hours. Despite some disappointment from customers due to the move, Sanba IM has maintained a strong reputation among locals and visitors alike.", "response_spans": [[0, 508], [501, 742]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6796367168426514, "(0, 16)": 0.6796367168426514, "(2, 0)": 0.6796367168426514, "(2, 16)": 0.6796367168426514, "(4, 0)": 0.6796367168426514, "(4, 16)": 0.6796367168426514, "(6, 0)": 0.6796367168426514, "(6, 16)": 0.769989013671875, "(8, 0)": 0.6796367168426514, "(8, 16)": 0.6796367168426514, "(10, 0)": 0.6796367168426514, "(10, 16)": 0.6796367168426514, "(12, 0)": 0.6796367168426514, "(12, 16)": 0.557302713394165, "(14, 0)": 0.6796367168426514, "(14, 16)": 0.6796367168426514, "(16, 0)": 0.6796367168426514, "(16, 16)": 0.6796367168426514, "(18, 0)": 0.6796367168426514, "(18, 16)": 0.769989013671875, "(20, 0)": 0.769989013671875, "(20, 16)": 0.6796367168426514, "(22, 0)": 0.6796367168426514, "(22, 16)": 0.6796367168426514, "(24, 0)": 0.6796367168426514, "(24, 16)": 0.769989013671875, "(26, 0)": 0.4585401713848114, "(26, 16)": 0.6796367168426514, "(28, 0)": 0.4585401713848114, "(28, 16)": 0.6796367168426514, "(30, 0)": 0.4585401713848114, "(30, 16)": 0.4585401713848114}, "r_span": [630, 751], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009195804595947266}}, {"prompt_attention_score": {"(0, 0)": 0.5372155904769897, "(0, 16)": 0.5370872020721436, "(2, 0)": 0.5372155904769897, "(2, 16)": 0.5372155904769897, "(4, 0)": 0.5372155904769897, "(4, 16)": 0.5372155904769897, "(6, 0)": 0.5372155904769897, "(6, 16)": 0.6755920648574829, "(8, 0)": 0.5372155904769897, "(8, 16)": 0.5372155904769897, "(10, 0)": 0.5372155904769897, "(10, 16)": 0.5372155904769897, "(12, 0)": 0.5372155904769897, "(12, 16)": 0.5370872020721436, "(14, 0)": 0.5370872020721436, "(14, 16)": 0.5372155904769897, "(16, 0)": 0.5370872020721436, "(16, 16)": 0.5372155904769897, "(18, 0)": 0.5370872020721436, "(18, 16)": 0.5370872020721436, "(20, 0)": 0.5370872020721436, "(20, 16)": 0.5372155904769897, "(22, 0)": 0.4482156038284302, "(22, 16)": 0.5372155904769897, "(24, 0)": 0.5372155904769897, "(24, 16)": 0.5370872020721436, "(26, 0)": 0.4482156038284302, "(26, 16)": 0.5372155904769897, "(28, 0)": 0.4482156038284302, "(28, 16)": 0.5372155904769897, "(30, 0)": 0.4482156038284302, "(30, 16)": 0.4482156038284302}, "r_span": [750, 800], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -9.620189666748047e-05}}]}, {"id": "10335", "source_id": "14825", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, Casa Blanca Restaurant appears to be a popular Mexican restaurant located in Santa Barbara, California. With a rating of 3.5 stars, the restaurant offers a variety of dining options including Mexican cuisine, seafood, and has outdoor seating. Reviewers praise the restaurant's quick service, delicious food, and friendly staff. One reviewer noted that the menu could be more clear regarding the number of tacos included in the combination plate. Additionally, the restaurant offers free WiFi and has a casual atmosphere. Overall, Casa Blanca Restaurant seems to provide a great value for the price and is worth considering for dining in or taking out.", "response_spans": [[0, 502], [485, 690]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6353858709335327, "(0, 16)": 0.6353858709335327, "(2, 0)": 0.6353858709335327, "(2, 16)": 0.6353858709335327, "(4, 0)": 0.6353858709335327, "(4, 16)": 0.6353858709335327, "(6, 0)": 0.6889232397079468, "(6, 16)": 0.8031715750694275, "(8, 0)": 0.6353858709335327, "(8, 16)": 0.6889232397079468, "(10, 0)": 0.6889232397079468, "(10, 16)": 0.6353858709335327, "(12, 0)": 0.6889232397079468, "(12, 16)": 0.8031715750694275, "(14, 0)": 0.6889232397079468, "(14, 16)": 0.8031715750694275, "(16, 0)": 0.5101876258850098, "(16, 16)": 0.6889232397079468, "(18, 0)": 0.6889232397079468, "(18, 16)": 0.8031715750694275, "(20, 0)": 0.8031715750694275, "(20, 16)": 0.6889232397079468, "(22, 0)": 0.5101876258850098, "(22, 16)": 0.8031715750694275, "(24, 0)": 0.6889232397079468, "(24, 16)": 0.8031715750694275, "(26, 0)": 0.5101876258850098, "(26, 16)": 0.6505043506622314, "(28, 0)": 0.5101876258850098, "(28, 16)": 0.6889232397079468, "(30, 0)": 0.5101876258850098, "(30, 16)": 0.5101876258850098}, "r_span": [1048, 1159], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0012906193733215332}}, {"prompt_attention_score": {"(0, 0)": 0.6027557849884033, "(0, 16)": 0.708681046962738, "(2, 0)": 0.6027557849884033, "(2, 16)": 0.6027557849884033, "(4, 0)": 0.6027557849884033, "(4, 16)": 0.6027557849884033, "(6, 0)": 0.708681046962738, "(6, 16)": 0.6931155920028687, "(8, 0)": 0.6027557849884033, "(8, 16)": 0.708681046962738, "(10, 0)": 0.708681046962738, "(10, 16)": 0.6027557849884033, "(12, 0)": 0.708681046962738, "(12, 16)": 0.6085811853408813, "(14, 0)": 0.708681046962738, "(14, 16)": 0.46086031198501587, "(16, 0)": 0.708681046962738, "(16, 16)": 0.6027557849884033, "(18, 0)": 0.708681046962738, "(18, 16)": 0.6085811853408813, "(20, 0)": 0.618788480758667, "(20, 16)": 0.708681046962738, "(22, 0)": 0.708681046962738, "(22, 16)": 0.6085811853408813, "(24, 0)": 0.708681046962738, "(24, 16)": 0.618788480758667, "(26, 0)": 0.43789350986480713, "(26, 16)": 0.708681046962738, "(28, 0)": 0.43789350986480713, "(28, 16)": 0.708681046962738, "(30, 0)": 0.43789350986480713, "(30, 16)": 0.43789350986480713}, "r_span": [1157, 1201], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005186200141906738}}]}, {"id": "10353", "source_id": "14828", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Sandpiper Grill:\n\nSandpiper Grill is a restaurant located in Goleta, California, with a rating of 3.5 stars. The restaurant offers American (Traditional) cuisine and has a cozy atmosphere with outdoor seating. While some reviewers have praised the restaurant's view and food quality, others have experienced slow service, particularly during busy periods. The reviews mention that the carnitas quesadilla is a standout dish, but there have been instances of bones found in the pork. The restaurant is open to the public and does not require golfing attire to dine. Overall, Sandpiper Grill appears to offer decent food and drinks, but may benefit from improved service and efficiency.", "response_spans": [[0, 88], [90, 600], [581, 756]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.4656367897987366, "(0, 16)": 0.4656367897987366, "(2, 0)": 0.4656367897987366, "(2, 16)": 0.4656367897987366, "(4, 0)": 0.4656367897987366, "(4, 16)": 0.4656367897987366, "(6, 0)": 0.4656367897987366, "(6, 16)": 0.6224139332771301, "(8, 0)": 0.4656367897987366, "(8, 16)": 0.4656367897987366, "(10, 0)": 0.6224139332771301, "(10, 16)": 0.6224139332771301, "(12, 0)": 0.4656367897987366, "(12, 16)": 0.6224139332771301, "(14, 0)": 0.4656367897987366, "(14, 16)": 0.6224139332771301, "(16, 0)": 0.6224139332771301, "(16, 16)": 0.5544383525848389, "(18, 0)": 0.4656367897987366, "(18, 16)": 0.6224139332771301, "(20, 0)": 0.6224139332771301, "(20, 16)": 0.4478541910648346, "(22, 0)": 0.6224139332771301, "(22, 16)": 0.6224139332771301, "(24, 0)": 0.4478541910648346, "(24, 16)": 0.6224139332771301, "(26, 0)": 0.6224139332771301, "(26, 16)": 0.510308563709259, "(28, 0)": 0.6224139332771301, "(28, 16)": 0.4656367897987366, "(30, 0)": 0.6224139332771301, "(30, 16)": 0.6224139332771301}, "r_span": [891, 913], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000775456428527832}}, {"prompt_attention_score": {"(0, 0)": 0.5904463529586792, "(0, 16)": 0.5904463529586792, "(2, 0)": 0.5904463529586792, "(2, 16)": 0.5904463529586792, "(4, 0)": 0.5904463529586792, "(4, 16)": 0.5904463529586792, "(6, 0)": 0.5904463529586792, "(6, 16)": 0.7218155860900879, "(8, 0)": 0.5904463529586792, "(8, 16)": 0.5904463529586792, "(10, 0)": 0.5904463529586792, "(10, 16)": 0.5904463529586792, "(12, 0)": 0.5904463529586792, "(12, 16)": 0.6136001348495483, "(14, 0)": 0.5904463529586792, "(14, 16)": 0.5904463529586792, "(16, 0)": 0.534186840057373, "(16, 16)": 0.5904463529586792, "(18, 0)": 0.5904463529586792, "(18, 16)": 0.7218155860900879, "(20, 0)": 0.7218155860900879, "(20, 16)": 0.5904463529586792, "(22, 0)": 0.38194674253463745, "(22, 16)": 0.5851082801818848, "(24, 0)": 0.6136001348495483, "(24, 16)": 0.534186840057373, "(26, 0)": 0.38194674253463745, "(26, 16)": 0.534186840057373, "(28, 0)": 0.38194674253463745, "(28, 16)": 0.5904463529586792, "(30, 0)": 0.38194674253463745, "(30, 16)": 0.38194674253463745}, "r_span": [915, 1035], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00023430585861206055}}, {"prompt_attention_score": {"(0, 0)": 0.6430137157440186, "(0, 16)": 0.6430137157440186, "(2, 0)": 0.6430137157440186, "(2, 16)": 0.6430137157440186, "(4, 0)": 0.6430137157440186, "(4, 16)": 0.6430137157440186, "(6, 0)": 0.6430137157440186, "(6, 16)": 0.6374229192733765, "(8, 0)": 0.6430137157440186, "(8, 16)": 0.6430137157440186, "(10, 0)": 0.6430137157440186, "(10, 16)": 0.6430137157440186, "(12, 0)": 0.6430137157440186, "(12, 16)": 0.6430137157440186, "(14, 0)": 0.6430137157440186, "(14, 16)": 0.4830677807331085, "(16, 0)": 0.6430137157440186, "(16, 16)": 0.6430137157440186, "(18, 0)": 0.4298423230648041, "(18, 16)": 0.5941934585571289, "(20, 0)": 0.6430137157440186, "(20, 16)": 0.6430137157440186, "(22, 0)": 0.4298423230648041, "(22, 16)": 0.6624104976654053, "(24, 0)": 0.5822595357894897, "(24, 16)": 0.6430137157440186, "(26, 0)": 0.4298423230648041, "(26, 16)": 0.6430137157440186, "(28, 0)": 0.4298423230648041, "(28, 16)": 0.4298423230648041, "(30, 0)": 0.4298423230648041, "(30, 16)": 0.4298423230648041}, "r_span": [1032, 1071], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003966689109802246}}]}, {"id": "10365", "source_id": "14830", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 260, "end": 268, "text": "intimate", "meta": "HIGH INTRO OF NEW INFO\nAIGC: the atmosphere is  intimate\nOriginal: \"intimate\": null,\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": true}], "split": "test", "quality": "good", "response": "The Good Bar is a popular bar and restaurant located within the Kimpton Hotel in Goleta, California. With a rating of 4.0 stars, the bar offers a decent-sized full bar with plenty of seating, a Pool table, and free Wi-Fi. The atmosphere is classy, casual, and intimate, making it suitable for both groups and individuals. While the drinks are somewhat expensive, the service is generally good. However, there have been instances of poor staff management, particularly during busy periods, resulting in delayed orders and unpleasant experiences for some patrons. Despite this, many customers have praised the bar's ambiance, eclectic cocktail selection, and trivia nights, earning it a solid reputation in the area.\n\nHowever, one negative review stands out, detailing an unpleasant encounter with the bar's manager, Tyrell. A group of patrons were unwittingly kicked out of the bar after being invited in by the wedding guests, despite the bar's policy of allowing non-hotel guests inside. The manager's behavior was described as unprofessional and rude, leading the customers to boycott the establishment and file a complaint with the hotel front desk. Overall, while The Good Bar seems to offer a great experience for most customers, the occasional incidents of poor staff management raise concerns about the quality of service.", "response_spans": [[0, 509], [499, 714], [716, 1223], [1204, 1329]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5852594971656799, "(0, 16)": 0.5852594971656799, "(2, 0)": 0.5852594971656799, "(2, 16)": 0.5852594971656799, "(4, 0)": 0.5852594971656799, "(4, 16)": 0.5852594971656799, "(6, 0)": 0.5852594971656799, "(6, 16)": 0.7522197961807251, "(8, 0)": 0.7392759919166565, "(8, 16)": 0.5852594971656799, "(10, 0)": 0.6283389925956726, "(10, 16)": 0.6283389925956726, "(12, 0)": 0.5852594971656799, "(12, 16)": 0.7522197961807251, "(14, 0)": 0.5065150856971741, "(14, 16)": 0.4634966552257538, "(16, 0)": 0.7392759919166565, "(16, 16)": 0.5852594971656799, "(18, 0)": 0.5852594971656799, "(18, 16)": 0.7522197961807251, "(20, 0)": 0.7522197961807251, "(20, 16)": 0.5065150856971741, "(22, 0)": 0.44837868213653564, "(22, 16)": 0.7522197961807251, "(24, 0)": 0.5065150856971741, "(24, 16)": 0.7522197961807251, "(26, 0)": 0.44837868213653564, "(26, 16)": 0.7392759919166565, "(28, 0)": 0.44837868213653564, "(28, 16)": 0.5065150856971741, "(30, 0)": 0.44837868213653564, "(30, 16)": 0.44837868213653564}, "r_span": [1301, 1414], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00036394596099853516}}, {"prompt_attention_score": {"(0, 0)": 0.5876055955886841, "(0, 16)": 0.5876055955886841, "(2, 0)": 0.5876055955886841, "(2, 16)": 0.5876055955886841, "(4, 0)": 0.5876055955886841, "(4, 16)": 0.5876055955886841, "(6, 0)": 0.5876055955886841, "(6, 16)": 0.7307863831520081, "(8, 0)": 0.5891972780227661, "(8, 16)": 0.5891972780227661, "(10, 0)": 0.6815280914306641, "(10, 16)": 0.6815280914306641, "(12, 0)": 0.5891972780227661, "(12, 16)": 0.7307863831520081, "(14, 0)": 0.5891972780227661, "(14, 16)": 0.48182404041290283, "(16, 0)": 0.7307863831520081, "(16, 16)": 0.5876055955886841, "(18, 0)": 0.5891972780227661, "(18, 16)": 0.7307863831520081, "(20, 0)": 0.7307863831520081, "(20, 16)": 0.5891972780227661, "(22, 0)": 0.47173750400543213, "(22, 16)": 0.7307863831520081, "(24, 0)": 0.5891972780227661, "(24, 16)": 0.7307863831520081, "(26, 0)": 0.47173750400543213, "(26, 16)": 0.6694890260696411, "(28, 0)": 0.47173750400543213, "(28, 16)": 0.5891972780227661, "(30, 0)": 0.47173750400543213, "(30, 16)": 0.47173750400543213}, "r_span": [1413, 1465], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006301999092102051}}, {"prompt_attention_score": {"(0, 0)": 0.7803174257278442, "(0, 16)": 0.748552680015564, "(2, 0)": 0.748552680015564, "(2, 16)": 0.7803174257278442, "(4, 0)": 0.748552680015564, "(4, 16)": 0.748552680015564, "(6, 0)": 0.748552680015564, "(6, 16)": 0.6850200891494751, "(8, 0)": 0.7803174257278442, "(8, 16)": 0.7803174257278442, "(10, 0)": 0.748552680015564, "(10, 16)": 0.748552680015564, "(12, 0)": 0.7803174257278442, "(12, 16)": 0.7803174257278442, "(14, 0)": 0.7803174257278442, "(14, 16)": 0.748552680015564, "(16, 0)": 0.7803174257278442, "(16, 16)": 0.48750150203704834, "(18, 0)": 0.7803174257278442, "(18, 16)": 0.748552680015564, "(20, 0)": 0.748552680015564, "(20, 16)": 0.7803174257278442, "(22, 0)": 0.48750150203704834, "(22, 16)": 0.7803174257278442, "(24, 0)": 0.7803174257278442, "(24, 16)": 0.7803174257278442, "(26, 0)": 0.48750150203704834, "(26, 16)": 0.7803174257278442, "(28, 0)": 0.48750150203704834, "(28, 16)": 0.48750150203704834, "(30, 0)": 0.48750150203704834, "(30, 16)": 0.48750150203704834}, "r_span": [1467, 1583], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0019767284393310547}}, {"prompt_attention_score": {"(0, 0)": 0.49499502778053284, "(0, 16)": 0.4743679463863373, "(2, 0)": 0.4743679463863373, "(2, 16)": 0.4743679463863373, "(4, 0)": 0.4743679463863373, "(4, 16)": 0.4864802360534668, "(6, 0)": 0.4743679463863373, "(6, 16)": 0.4827349781990051, "(8, 0)": 0.49499502778053284, "(8, 16)": 0.4743679463863373, "(10, 0)": 0.5815693736076355, "(10, 16)": 0.4743679463863373, "(12, 0)": 0.4743679463863373, "(12, 16)": 0.424194872379303, "(14, 0)": 0.49499502778053284, "(14, 16)": 0.47616833448410034, "(16, 0)": 0.45115646719932556, "(16, 16)": 0.45115646719932556, "(18, 0)": 0.45115646719932556, "(18, 16)": 0.4743679463863373, "(20, 0)": 0.4743679463863373, "(20, 16)": 0.49499502778053284, "(22, 0)": 0.45115646719932556, "(22, 16)": 0.4743679463863373, "(24, 0)": 0.49499502778053284, "(24, 16)": 0.4743679463863373, "(26, 0)": 0.45115646719932556, "(26, 16)": 0.424194872379303, "(28, 0)": 0.45115646719932556, "(28, 16)": 0.45115646719932556, "(30, 0)": 0.45115646719932556, "(30, 16)": 0.45115646719932556}, "r_span": [1581, 1602], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0020468831062316895}}]}, {"id": "10461", "source_id": "14846", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 447, "end": 474, "text": "dairy products, baked goods", "meta": "HIGH INTRO OF NEW INFO\nNo mention of these products. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 596, "end": 618, "text": "Sunday from 9am to 5pm", "meta": "HIGH INTRO OF NEW INFO\nStructured data doesn't contain any hours for Sunday. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 620, "end": 650, "text": "The business offers free Wi-Fi", "meta": "EVIDENT CONFLICT\nOriginal: paid WiFi\nAIGC: free WiFi", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Gladden and Sons Produce:\n\nLocated in Santa Barbara, California, Gladden and Sons Produce is an organic store, farmers market, specialty food shop, sandwich restaurant, meat shop, deli, fruit and vegetable store, coffee and tea shop, grocery store, and restaurant. The business has a rating of 4.5 stars and offers a wide range of products, including organic produce, meats, dairy products, baked goods, and prepared foods. The business has a convenient hours of operation, open Monday through Saturday from 9am to 6pm, and Sunday from 9am to 5pm. The business offers free Wi-Fi and allows takeout orders, making it a great option for busy customers. While some customers have noted that the prices are a bit steep, many have praised the business for its high-quality products, friendly staff, and support for the local community during the COVID-19 pandemic.", "response_spans": [[0, 97], [99, 607], [592, 931]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5752473473548889, "(0, 16)": 0.5752473473548889, "(2, 0)": 0.5752473473548889, "(2, 16)": 0.5752473473548889, "(4, 0)": 0.5752473473548889, "(4, 16)": 0.5752473473548889, "(6, 0)": 0.5752473473548889, "(6, 16)": 0.6070677638053894, "(8, 0)": 0.41854342818260193, "(8, 16)": 0.5752473473548889, "(10, 0)": 0.6070677638053894, "(10, 16)": 0.6070677638053894, "(12, 0)": 0.5223034024238586, "(12, 16)": 0.6070677638053894, "(14, 0)": 0.5752473473548889, "(14, 16)": 0.587841808795929, "(16, 0)": 0.6070677638053894, "(16, 16)": 0.5752473473548889, "(18, 0)": 0.5752473473548889, "(18, 16)": 0.6070677638053894, "(20, 0)": 0.6070677638053894, "(20, 16)": 0.5752473473548889, "(22, 0)": 0.5752473473548889, "(22, 16)": 0.6070677638053894, "(24, 0)": 0.5752473473548889, "(24, 16)": 0.6070677638053894, "(26, 0)": 0.6070677638053894, "(26, 16)": 0.5752473473548889, "(28, 0)": 0.6070677638053894, "(28, 16)": 0.5752473473548889, "(30, 0)": 0.6070677638053894, "(30, 16)": 0.6070677638053894}, "r_span": [925, 949], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003617405891418457}}, {"prompt_attention_score": {"(0, 0)": 0.6867368817329407, "(0, 16)": 0.6867368817329407, "(2, 0)": 0.6867368817329407, "(2, 16)": 0.6867368817329407, "(4, 0)": 0.6867368817329407, "(4, 16)": 0.6867368817329407, "(6, 0)": 0.6867368817329407, "(6, 16)": 0.8377653956413269, "(8, 0)": 0.5066239833831787, "(8, 16)": 0.6867368817329407, "(10, 0)": 0.6867368817329407, "(10, 16)": 0.6867368817329407, "(12, 0)": 0.6867368817329407, "(12, 16)": 0.8377653956413269, "(14, 0)": 0.6867368817329407, "(14, 16)": 0.8377653956413269, "(16, 0)": 0.8377653956413269, "(16, 16)": 0.6867368817329407, "(18, 0)": 0.6867368817329407, "(18, 16)": 0.8377653956413269, "(20, 0)": 0.8377653956413269, "(20, 16)": 0.6867368817329407, "(22, 0)": 0.6867368817329407, "(22, 16)": 0.8377653956413269, "(24, 0)": 0.5066239833831787, "(24, 16)": 0.8377653956413269, "(26, 0)": 0.4103904664516449, "(26, 16)": 0.6867368817329407, "(28, 0)": 0.4103904664516449, "(28, 16)": 0.6867368817329407, "(30, 0)": 0.4103904664516449, "(30, 16)": 0.4103904664516449}, "r_span": [951, 1074], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0004900097846984863}}, {"prompt_attention_score": {"(0, 0)": 0.7486658096313477, "(0, 16)": 0.7486658096313477, "(2, 0)": 0.7486658096313477, "(2, 16)": 0.7486658096313477, "(4, 0)": 0.7486658096313477, "(4, 16)": 0.7486658096313477, "(6, 0)": 0.7486658096313477, "(6, 16)": 0.6986993551254272, "(8, 0)": 0.5652738809585571, "(8, 16)": 0.7486658096313477, "(10, 0)": 0.7486658096313477, "(10, 16)": 0.7486658096313477, "(12, 0)": 0.7486658096313477, "(12, 16)": 0.7321167588233948, "(14, 0)": 0.7486658096313477, "(14, 16)": 0.7486658096313477, "(16, 0)": 0.7321167588233948, "(16, 16)": 0.7486658096313477, "(18, 0)": 0.5652738809585571, "(18, 16)": 0.7321167588233948, "(20, 0)": 0.7321167588233948, "(20, 16)": 0.7486658096313477, "(22, 0)": 0.495327353477478, "(22, 16)": 0.7321167588233948, "(24, 0)": 0.5652738809585571, "(24, 16)": 0.7486658096313477, "(26, 0)": 0.495327353477478, "(26, 16)": 0.7486658096313477, "(28, 0)": 0.495327353477478, "(28, 16)": 0.7486658096313477, "(30, 0)": 0.495327353477478, "(30, 16)": 0.495327353477478}, "r_span": [1072, 1149], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.005110263824462891}}]}, {"id": "10545", "source_id": "14860", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 382, "end": 432, "text": ", the venue does have validated parking available.", "meta": "EVIDENT CONFLICT\nOriginal: \"validated\": false\nGenerative: \"...the venue does have validated parking available.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 284, "end": 314, "text": "a capacity of around 50 people", "meta": "The restaurant is good for groups, however, no mention of specific number of people.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Comedy Hideaway:\n\nComedy Hideaway is a local performing arts venue located in Santa Barbara, California. It offers a variety of comedy shows and events, including stand-up comedy, improv, and more. The venue has a capacity of around 50 people and is known for its intimate setting. While parking may be limited, the venue does have validated parking available. Customers have praised the affordable drinks and quality of the comedians, with some noting that it's a hidden gem worth experiencing before it moves to a larger location. Overall, Comedy Hideaway appears to be a popular spot for comedy lovers looking for a unique and affordable night out.", "response_spans": [[0, 88], [90, 594], [577, 723]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5428352952003479, "(0, 16)": 0.5428352952003479, "(2, 0)": 0.5428352952003479, "(2, 16)": 0.5428352952003479, "(4, 0)": 0.5428352952003479, "(4, 16)": 0.5428352952003479, "(6, 0)": 0.5428352952003479, "(6, 16)": 0.5879799127578735, "(8, 0)": 0.5428352952003479, "(8, 16)": 0.5428352952003479, "(10, 0)": 0.5879799127578735, "(10, 16)": 0.5879799127578735, "(12, 0)": 0.5428352952003479, "(12, 16)": 0.5879799127578735, "(14, 0)": 0.5428352952003479, "(14, 16)": 0.5879799127578735, "(16, 0)": 0.5879799127578735, "(16, 16)": 0.5879799127578735, "(18, 0)": 0.5428352952003479, "(18, 16)": 0.5879799127578735, "(20, 0)": 0.5879799127578735, "(20, 16)": 0.5428352952003479, "(22, 0)": 0.5879799127578735, "(22, 16)": 0.5879799127578735, "(24, 0)": 0.5428352952003479, "(24, 16)": 0.5879799127578735, "(26, 0)": 0.5879799127578735, "(26, 16)": 0.5879799127578735, "(28, 0)": 0.5879799127578735, "(28, 16)": 0.5879799127578735, "(30, 0)": 0.5879799127578735, "(30, 16)": 0.5879799127578735}, "r_span": [646, 668], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 3.68952751159668e-05}}, {"prompt_attention_score": {"(0, 0)": 0.5847470164299011, "(0, 16)": 0.5847470164299011, "(2, 0)": 0.5847470164299011, "(2, 16)": 0.5847470164299011, "(4, 0)": 0.5847470164299011, "(4, 16)": 0.5847470164299011, "(6, 0)": 0.5847470164299011, "(6, 16)": 0.7528845071792603, "(8, 0)": 0.5847470164299011, "(8, 16)": 0.5847470164299011, "(10, 0)": 0.5847470164299011, "(10, 16)": 0.5847470164299011, "(12, 0)": 0.5847470164299011, "(12, 16)": 0.5847470164299011, "(14, 0)": 0.5847470164299011, "(14, 16)": 0.5847470164299011, "(16, 0)": 0.5847470164299011, "(16, 16)": 0.5847470164299011, "(18, 0)": 0.5847470164299011, "(18, 16)": 0.7528845071792603, "(20, 0)": 0.5847470164299011, "(20, 16)": 0.5847470164299011, "(22, 0)": 0.38263219594955444, "(22, 16)": 0.46814993023872375, "(24, 0)": 0.5847470164299011, "(24, 16)": 0.5847470164299011, "(26, 0)": 0.38263219594955444, "(26, 16)": 0.38263219594955444, "(28, 0)": 0.38263219594955444, "(28, 16)": 0.5847470164299011, "(30, 0)": 0.38263219594955444, "(30, 16)": 0.38263219594955444}, "r_span": [670, 787], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0012166500091552734}}, {"prompt_attention_score": {"(0, 0)": 0.6477537751197815, "(0, 16)": 0.6477537751197815, "(2, 0)": 0.6477537751197815, "(2, 16)": 0.6477537751197815, "(4, 0)": 0.6477537751197815, "(4, 16)": 0.6477537751197815, "(6, 0)": 0.6477537751197815, "(6, 16)": 0.6735727787017822, "(8, 0)": 0.6477537751197815, "(8, 16)": 0.6477537751197815, "(10, 0)": 0.6477537751197815, "(10, 16)": 0.6477537751197815, "(12, 0)": 0.6477537751197815, "(12, 16)": 0.6477537751197815, "(14, 0)": 0.6477537751197815, "(14, 16)": 0.6477537751197815, "(16, 0)": 0.6477537751197815, "(16, 16)": 0.4016808271408081, "(18, 0)": 0.4016808271408081, "(18, 16)": 0.6477537751197815, "(20, 0)": 0.6477537751197815, "(20, 16)": 0.6477537751197815, "(22, 0)": 0.4016808271408081, "(22, 16)": 0.6477537751197815, "(24, 0)": 0.6477537751197815, "(24, 16)": 0.6477537751197815, "(26, 0)": 0.4016808271408081, "(26, 16)": 0.4016808271408081, "(28, 0)": 0.4016808271408081, "(28, 16)": 0.6477537751197815, "(30, 0)": 0.4016808271408081, "(30, 16)": 0.4016808271408081}, "r_span": [784, 817], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014518499374389648}}]}, {"id": "10713", "source_id": "14890", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of The New Black BBQ:\n\nThe New Black BBQ is a barbecue food truck located in Santa Barbara, California, with a rating of 3.5 stars. Although the business has a good reputation for serving tasty barbecue, there have been some complaints regarding their customer service and availability of options. One reviewer had a negative experience when the business cancelled their wedding catering without notice and refused to refund their deposit despite numerous attempts to contact them. Another reviewer appreciated the taste of their food but was disappointed with the limited selection, while a third reviewer found the staff to be unhelpful when they requested a spicier dish. Overall, while The New Black BBQ appears to serve decent barbecue, their customer service and menu variety may need improvement.", "response_spans": [[0, 90], [92, 603], [584, 872]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5379010438919067, "(0, 16)": 0.5379010438919067, "(2, 0)": 0.5379010438919067, "(2, 16)": 0.5379010438919067, "(4, 0)": 0.5379010438919067, "(4, 16)": 0.5379010438919067, "(6, 0)": 0.5379010438919067, "(6, 16)": 0.6205916404724121, "(8, 0)": 0.31991857290267944, "(8, 16)": 0.5379010438919067, "(10, 0)": 0.6205916404724121, "(10, 16)": 0.6205916404724121, "(12, 0)": 0.5371289849281311, "(12, 16)": 0.6205916404724121, "(14, 0)": 0.5379010438919067, "(14, 16)": 0.6205916404724121, "(16, 0)": 0.6205916404724121, "(16, 16)": 0.5371289849281311, "(18, 0)": 0.5379010438919067, "(18, 16)": 0.6205916404724121, "(20, 0)": 0.6205916404724121, "(20, 16)": 0.5379010438919067, "(22, 0)": 0.6205916404724121, "(22, 16)": 0.6205916404724121, "(24, 0)": 0.5379010438919067, "(24, 16)": 0.6205916404724121, "(26, 0)": 0.6205916404724121, "(26, 16)": 0.4940657615661621, "(28, 0)": 0.6205916404724121, "(28, 16)": 0.5379010438919067, "(30, 0)": 0.6205916404724121, "(30, 16)": 0.6205916404724121}, "r_span": [875, 897], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010085105895996094}}, {"prompt_attention_score": {"(0, 0)": 0.7098591923713684, "(0, 16)": 0.7098591923713684, "(2, 0)": 0.7098591923713684, "(2, 16)": 0.7098591923713684, "(4, 0)": 0.7098591923713684, "(4, 16)": 0.7098591923713684, "(6, 0)": 0.7098591923713684, "(6, 16)": 0.6561092734336853, "(8, 0)": 0.7098591923713684, "(8, 16)": 0.7098591923713684, "(10, 0)": 0.506648063659668, "(10, 16)": 0.7098591923713684, "(12, 0)": 0.7098591923713684, "(12, 16)": 0.6561092734336853, "(14, 0)": 0.7098591923713684, "(14, 16)": 0.6561092734336853, "(16, 0)": 0.6561092734336853, "(16, 16)": 0.7098591923713684, "(18, 0)": 0.7098591923713684, "(18, 16)": 0.7368987202644348, "(20, 0)": 0.6561092734336853, "(20, 16)": 0.7098591923713684, "(22, 0)": 0.47792983055114746, "(22, 16)": 0.6561092734336853, "(24, 0)": 0.7098591923713684, "(24, 16)": 0.6561092734336853, "(26, 0)": 0.47792983055114746, "(26, 16)": 0.7098591923713684, "(28, 0)": 0.47792983055114746, "(28, 16)": 0.7098591923713684, "(30, 0)": 0.47792983055114746, "(30, 16)": 0.47792983055114746}, "r_span": [899, 1005], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0019597411155700684}}, {"prompt_attention_score": {"(0, 0)": 0.7889336347579956, "(0, 16)": 0.7889336347579956, "(2, 0)": 0.7889336347579956, "(2, 16)": 0.7889336347579956, "(4, 0)": 0.7889336347579956, "(4, 16)": 0.7889336347579956, "(6, 0)": 0.7889336347579956, "(6, 16)": 0.6527478098869324, "(8, 0)": 0.7889336347579956, "(8, 16)": 0.7889336347579956, "(10, 0)": 0.7889336347579956, "(10, 16)": 0.7889336347579956, "(12, 0)": 0.7889336347579956, "(12, 16)": 0.7889336347579956, "(14, 0)": 0.7889336347579956, "(14, 16)": 0.7889336347579956, "(16, 0)": 0.7889336347579956, "(16, 16)": 0.5094506144523621, "(18, 0)": 0.5094506144523621, "(18, 16)": 0.7889336347579956, "(20, 0)": 0.7889336347579956, "(20, 16)": 0.7889336347579956, "(22, 0)": 0.5094506144523621, "(22, 16)": 0.7889336347579956, "(24, 0)": 0.7889336347579956, "(24, 16)": 0.7889336347579956, "(26, 0)": 0.5094506144523621, "(26, 16)": 0.7889336347579956, "(28, 0)": 0.5094506144523621, "(28, 16)": 0.7889336347579956, "(30, 0)": 0.5094506144523621, "(30, 16)": 0.5094506144523621}, "r_span": [1002, 1064], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015384554862976074}}]}, {"id": "10737", "source_id": "14894", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 116, "end": 136, "text": "other Italian dishes", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"other Italian dishes... \"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 483, "end": 531, "text": "While some reviewers have criticized the service", "meta": "LOW INTRODUCTION OF NEW INFORMATION \nOriginal: *not mentioned*\nGenerative: \"While some reviewers have criticized the service...\"", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Noemi Pizza Romana is a highly rated restaurant located in Santa Barbara, California, serving Roman-style pizza and other Italian dishes. According to customer reviews, the pizza here is exceptional, with a focus on high-quality ingredients and generous toppings. Reviewers particularly enjoy the crust, which is described as \"incredible\" and \"perfectly balanced\" with the toppings. The restaurant offers free WiFi and has ample parking, making it a convenient option for customers. While some reviewers have criticized the service, most customers have praised the friendly and helpful staff. Overall, Noemi Pizza Romana appears to be a must-try destination for pizza lovers in the area, with a rating of 4.5 stars out of 5.", "response_spans": [[0, 508], [489, 724]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5968462228775024, "(0, 16)": 0.6292297840118408, "(2, 0)": 0.5968462228775024, "(2, 16)": 0.5968462228775024, "(4, 0)": 0.5968462228775024, "(4, 16)": 0.5968462228775024, "(6, 0)": 0.5968462228775024, "(6, 16)": 0.7938162684440613, "(8, 0)": 0.6292297840118408, "(8, 16)": 0.5968462228775024, "(10, 0)": 0.6292297840118408, "(10, 16)": 0.6292297840118408, "(12, 0)": 0.6292297840118408, "(12, 16)": 0.7938162684440613, "(14, 0)": 0.5968462228775024, "(14, 16)": 0.4389871060848236, "(16, 0)": 0.662295937538147, "(16, 16)": 0.5968462228775024, "(18, 0)": 0.6292297840118408, "(18, 16)": 0.662295937538147, "(20, 0)": 0.7938162684440613, "(20, 16)": 0.5968462228775024, "(22, 0)": 0.44240516424179077, "(22, 16)": 0.662295937538147, "(24, 0)": 0.5769107937812805, "(24, 16)": 0.7938162684440613, "(26, 0)": 0.44240516424179077, "(26, 16)": 0.5968462228775024, "(28, 0)": 0.44240516424179077, "(28, 16)": 0.5968462228775024, "(30, 0)": 0.44240516424179077, "(30, 16)": 0.44240516424179077}, "r_span": [1000, 1116], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003423154354095459}}, {"prompt_attention_score": {"(0, 0)": 0.7059916257858276, "(0, 16)": 0.7244254350662231, "(2, 0)": 0.7059916257858276, "(2, 16)": 0.6452309489250183, "(4, 0)": 0.7059916257858276, "(4, 16)": 0.7059916257858276, "(6, 0)": 0.7244254350662231, "(6, 16)": 0.726800799369812, "(8, 0)": 0.7059916257858276, "(8, 16)": 0.7059916257858276, "(10, 0)": 0.67228102684021, "(10, 16)": 0.7244254350662231, "(12, 0)": 0.6452309489250183, "(12, 16)": 0.726800799369812, "(14, 0)": 0.7059916257858276, "(14, 16)": 0.47560346126556396, "(16, 0)": 0.726800799369812, "(16, 16)": 0.6452309489250183, "(18, 0)": 0.7244254350662231, "(18, 16)": 0.726800799369812, "(20, 0)": 0.726800799369812, "(20, 16)": 0.7059916257858276, "(22, 0)": 0.4641469419002533, "(22, 16)": 0.7244254350662231, "(24, 0)": 0.67228102684021, "(24, 16)": 0.726800799369812, "(26, 0)": 0.4641469419002533, "(26, 16)": 0.67228102684021, "(28, 0)": 0.4641469419002533, "(28, 16)": 0.4641469419002533, "(30, 0)": 0.4641469419002533, "(30, 16)": 0.4641469419002533}, "r_span": [1113, 1172], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0006785988807678223}}]}, {"id": "10803", "source_id": "14905", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 316, "end": 355, "text": "Fettuccine Alfredo stains on the floors", "meta": "HIGH INTRO OF NEW INFO\nIt mentions 'Fettuccine Alfredo stains on the floors' which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, Subway located in Goleta, CA has an overall rating of 1.5 stars. Customers have expressed disappointment with their experiences at this location, citing issues such as old and expired food, unfriendly staff, and poor cleanliness. One reviewer described the store as dirty with Fettuccine Alfredo stains on the floors, while another mentioned that the vegetables were almost gone upon their visit. Additionally, several reviewers have complained about the lack of friendliness from the staff, with one stating that they wouldn't return due to the poor service. Overall, this Subway location appears to have significant room for improvement in terms of customer satisfaction.", "response_spans": [[0, 501], [484, 712]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.741101861000061, "(0, 16)": 0.741101861000061, "(2, 0)": 0.7283853888511658, "(2, 16)": 0.7283853888511658, "(4, 0)": 0.741101861000061, "(4, 16)": 0.741101861000061, "(6, 0)": 0.7283853888511658, "(6, 16)": 0.6898961663246155, "(8, 0)": 0.7243022322654724, "(8, 16)": 0.7283853888511658, "(10, 0)": 0.741101861000061, "(10, 16)": 0.7283853888511658, "(12, 0)": 0.741101861000061, "(12, 16)": 0.7283853888511658, "(14, 0)": 0.7243022322654724, "(14, 16)": 0.741101861000061, "(16, 0)": 0.7283853888511658, "(16, 16)": 0.7283853888511658, "(18, 0)": 0.551668643951416, "(18, 16)": 0.551668643951416, "(20, 0)": 0.7283853888511658, "(20, 16)": 0.7243022322654724, "(22, 0)": 0.551668643951416, "(22, 16)": 0.7283853888511658, "(24, 0)": 0.7243022322654724, "(24, 16)": 0.7243022322654724, "(26, 0)": 0.551668643951416, "(26, 16)": 0.7283853888511658, "(28, 0)": 0.551668643951416, "(28, 16)": 0.551668643951416, "(30, 0)": 0.551668643951416, "(30, 16)": 0.551668643951416}, "r_span": [893, 1006], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005618929862976074}}, {"prompt_attention_score": {"(0, 0)": 0.6415002346038818, "(0, 16)": 0.6415002346038818, "(2, 0)": 0.7068032026290894, "(2, 16)": 0.7068032026290894, "(4, 0)": 0.7068032026290894, "(4, 16)": 0.7068032026290894, "(6, 0)": 0.7068032026290894, "(6, 16)": 0.7416908740997314, "(8, 0)": 0.7068032026290894, "(8, 16)": 0.7068032026290894, "(10, 0)": 0.7068032026290894, "(10, 16)": 0.7068032026290894, "(12, 0)": 0.7068032026290894, "(12, 16)": 0.6415002346038818, "(14, 0)": 0.7416908740997314, "(14, 16)": 0.505548357963562, "(16, 0)": 0.7068032026290894, "(16, 16)": 0.7068032026290894, "(18, 0)": 0.5152350664138794, "(18, 16)": 0.7416908740997314, "(20, 0)": 0.7416908740997314, "(20, 16)": 0.5152350664138794, "(22, 0)": 0.5152350664138794, "(22, 16)": 0.7068032026290894, "(24, 0)": 0.7416908740997314, "(24, 16)": 0.7416908740997314, "(26, 0)": 0.5152350664138794, "(26, 16)": 0.5152350664138794, "(28, 0)": 0.5152350664138794, "(28, 16)": 0.5152350664138794, "(30, 0)": 0.5152350664138794, "(30, 16)": 0.5152350664138794}, "r_span": [1003, 1048], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006212592124938965}}]}, {"id": "10815", "source_id": "14907", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 181, "end": 239, "text": "has a good reputation for providing fresh and quality food", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the restaurant has a good reputation for providing fresh and quality food, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 571, "end": 669, "text": "Maeda Restaurant remains a popular choice among locals and visitors due to its convenient location", "meta": "HIGH INTRO OF NEW INFO\nIt states that the restaurant is popular among locals and visitors due to its convenient location, which is also not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Maeda Restaurant is a local Japanese restaurant located in Santa Barbara, California. With a rating of 3.5 stars, the restaurant offers a variety of traditional Japanese dishes and has a good reputation for providing fresh and quality food. Although some customers have praised the restaurant's affordability and bento lunch combinations, others have expressed disappointment with the service and food quality. Specifically, some reviews mention poor communication between the waitstaff and customers, as well as subpar execution of certain dishes. Despite these issues, Maeda Restaurant remains a popular choice among locals and visitors due to its convenient location and reasonable prices.", "response_spans": [[0, 512], [502, 692]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5895007848739624, "(0, 16)": 0.5895007848739624, "(2, 0)": 0.5895007848739624, "(2, 16)": 0.5895007848739624, "(4, 0)": 0.5895007848739624, "(4, 16)": 0.5895007848739624, "(6, 0)": 0.5895007848739624, "(6, 16)": 0.8070953488349915, "(8, 0)": 0.5895007848739624, "(8, 16)": 0.5895007848739624, "(10, 0)": 0.640200138092041, "(10, 16)": 0.5722500085830688, "(12, 0)": 0.5722500085830688, "(12, 16)": 0.8070953488349915, "(14, 0)": 0.640200138092041, "(14, 16)": 0.4521435499191284, "(16, 0)": 0.8070953488349915, "(16, 16)": 0.5895007848739624, "(18, 0)": 0.5035370588302612, "(18, 16)": 0.8070953488349915, "(20, 0)": 0.8070953488349915, "(20, 16)": 0.640200138092041, "(22, 0)": 0.5035370588302612, "(22, 16)": 0.640200138092041, "(24, 0)": 0.640200138092041, "(24, 16)": 0.8070953488349915, "(26, 0)": 0.5035370588302612, "(26, 16)": 0.640200138092041, "(28, 0)": 0.5035370588302612, "(28, 16)": 0.5035370588302612, "(30, 0)": 0.5035370588302612, "(30, 16)": 0.5035370588302612}, "r_span": [795, 893], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001660168170928955}}, {"prompt_attention_score": {"(0, 0)": 0.6246403455734253, "(0, 16)": 0.6246403455734253, "(2, 0)": 0.6246403455734253, "(2, 16)": 0.6246403455734253, "(4, 0)": 0.6246403455734253, "(4, 16)": 0.6246403455734253, "(6, 0)": 0.6246403455734253, "(6, 16)": 0.6486649513244629, "(8, 0)": 0.6246403455734253, "(8, 16)": 0.6246403455734253, "(10, 0)": 0.6462633609771729, "(10, 16)": 0.6246403455734253, "(12, 0)": 0.4686732888221741, "(12, 16)": 0.6246403455734253, "(14, 0)": 0.6462633609771729, "(14, 16)": 0.5047752261161804, "(16, 0)": 0.6486649513244629, "(16, 16)": 0.6246403455734253, "(18, 0)": 0.4686732888221741, "(18, 16)": 0.6462633609771729, "(20, 0)": 0.6486649513244629, "(20, 16)": 0.6462633609771729, "(22, 0)": 0.4686732888221741, "(22, 16)": 0.6462633609771729, "(24, 0)": 0.6462633609771729, "(24, 16)": 0.6486649513244629, "(26, 0)": 0.4686732888221741, "(26, 16)": 0.6246403455734253, "(28, 0)": 0.4686732888221741, "(28, 16)": 0.4686732888221741, "(30, 0)": 0.4686732888221741, "(30, 16)": 0.4686732888221741}, "r_span": [891, 928], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0014927387237548828}}]}, {"id": "10821", "source_id": "14908", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 267, "end": 318, "text": "has a small parking lot with limited street parking", "meta": "LOW INTRODUCTION OF NEW INFORMATION\n\"has a small parking lot with limited street parking\" was not mentioned in the business info", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 279, "end": 290, "text": "parking lot", "meta": "EVIDENT CONFLICT\nOriginal: \"lot\": false\nGenerated: parking lot", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 304, "end": 318, "text": "street parking", "meta": "EVIDENT CONFLICT\nOriginal: \"street\": false\nGenerated: street parking", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Epic Bowl:\n\nEpic Bowl is a Specialty Food restaurant located in Santa Barbara, California, with a rating of 3.5 out of 5 stars. The business offers breakfast, brunch, and juice bar services, and has a small parking lot with limited street parking. According to customer reviews, the restaurant's atmosphere is casual and has outdoor seating, but the Wi-Fi is unavailable. While some customers have praised the variety of options and size of the bowls, others have criticized the lack of sweetness in their dishes and poor customer service. One customer even reported finding their forgotten purse at the location after leaving it behind. Despite these issues, some reviewers have appreciated the restaurant's helpful staff and unique juice offerings. Overall, Epic Bowl may benefit from improving its customer service and consistency in terms of menu items and availability.", "response_spans": [[0, 82], [84, 593], [578, 946]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3596073091030121, "(0, 16)": 0.3596073091030121, "(2, 0)": 0.3596073091030121, "(2, 16)": 0.3596073091030121, "(4, 0)": 0.3596073091030121, "(4, 16)": 0.3596073091030121, "(6, 0)": 0.3596073091030121, "(6, 16)": 0.6046426892280579, "(8, 0)": 0.3596073091030121, "(8, 16)": 0.3596073091030121, "(10, 0)": 0.6046426892280579, "(10, 16)": 0.3596073091030121, "(12, 0)": 0.3596073091030121, "(12, 16)": 0.6046426892280579, "(14, 0)": 0.3596073091030121, "(14, 16)": 0.6046426892280579, "(16, 0)": 0.6046426892280579, "(16, 16)": 0.5416431427001953, "(18, 0)": 0.3596073091030121, "(18, 16)": 0.6046426892280579, "(20, 0)": 0.6046426892280579, "(20, 16)": 0.36970385909080505, "(22, 0)": 0.36970385909080505, "(22, 16)": 0.6046426892280579, "(24, 0)": 0.36970385909080505, "(24, 16)": 0.6046426892280579, "(26, 0)": 0.6046426892280579, "(26, 16)": 0.4683573842048645, "(28, 0)": 0.6046426892280579, "(28, 16)": 0.6046426892280579, "(30, 0)": 0.6046426892280579, "(30, 16)": 0.6046426892280579}, "r_span": [1078, 1098], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011153221130371094}}, {"prompt_attention_score": {"(0, 0)": 0.4905819892883301, "(0, 16)": 0.4905819892883301, "(2, 0)": 0.4905819892883301, "(2, 16)": 0.4905819892883301, "(4, 0)": 0.4905819892883301, "(4, 16)": 0.4905819892883301, "(6, 0)": 0.4905819892883301, "(6, 16)": 0.5569260120391846, "(8, 0)": 0.4905819892883301, "(8, 16)": 0.4905819892883301, "(10, 0)": 0.4905819892883301, "(10, 16)": 0.4905819892883301, "(12, 0)": 0.4905819892883301, "(12, 16)": 0.5569260120391846, "(14, 0)": 0.5002743005752563, "(14, 16)": 0.7977403402328491, "(16, 0)": 0.6635520458221436, "(16, 16)": 0.4905819892883301, "(18, 0)": 0.4905819892883301, "(18, 16)": 0.7977403402328491, "(20, 0)": 0.7977403402328491, "(20, 16)": 0.5002743005752563, "(22, 0)": 0.5002743005752563, "(22, 16)": 0.6635520458221436, "(24, 0)": 0.5002743005752563, "(24, 16)": 0.7977403402328491, "(26, 0)": 0.45524483919143677, "(26, 16)": 0.5002743005752563, "(28, 0)": 0.45524483919143677, "(28, 16)": 0.45524483919143677, "(30, 0)": 0.45524483919143677, "(30, 16)": 0.45524483919143677}, "r_span": [1100, 1218], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.002575099468231201}}, {"prompt_attention_score": {"(0, 0)": 0.5725569128990173, "(0, 16)": 0.5725569128990173, "(2, 0)": 0.5725569128990173, "(2, 16)": 0.5725569128990173, "(4, 0)": 0.5725569128990173, "(4, 16)": 0.5725569128990173, "(6, 0)": 0.5725569128990173, "(6, 16)": 0.6662515997886658, "(8, 0)": 0.5725569128990173, "(8, 16)": 0.5725569128990173, "(10, 0)": 0.5725569128990173, "(10, 16)": 0.5725569128990173, "(12, 0)": 0.5725569128990173, "(12, 16)": 0.6662515997886658, "(14, 0)": 0.6662515997886658, "(14, 16)": 0.6662515997886658, "(16, 0)": 0.5725569128990173, "(16, 16)": 0.5725569128990173, "(18, 0)": 0.5725569128990173, "(18, 16)": 0.716989278793335, "(20, 0)": 0.6662515997886658, "(20, 16)": 0.6662515997886658, "(22, 0)": 0.6662515997886658, "(22, 16)": 0.6662515997886658, "(24, 0)": 0.6662515997886658, "(24, 16)": 0.6662515997886658, "(26, 0)": 0.4925655126571655, "(26, 16)": 0.6662515997886658, "(28, 0)": 0.4925655126571655, "(28, 16)": 0.4925655126571655, "(30, 0)": 0.4925655126571655, "(30, 16)": 0.4925655126571655}, "r_span": [1215, 1286], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002175450325012207}}]}, {"id": "10881", "source_id": "14918", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 208, "end": 254, "text": "offers both indoor and outdoor seating options", "meta": "EVIDENT CONFLICT\nOriginal: \"OutdoorSeating\": false\nGenerative: \"offers... outdoor seating options.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Chilangos:\n\nChilangos is a Mexican restaurant located in Santa Barbara, California. The business has a rating of 3.5 out of 5 stars and offers both indoor and outdoor seating options. According to customer reviews, the restaurant serves delicious food, including sweet potato fries and Telegraph beer on tap. However, there is a closing notice for the business as of April 18th, 2010. Customers have praised the late-night hours and healthier options available at Chilangos, making it a popular spot for college students and those looking for a casual dining experience. Some reviewers have also recommended trying the mole sauce, which is described as \"killer.\" Despite the closure notice, Chilangos has received positive feedback from customers throughout the years.", "response_spans": [[0, 82], [84, 592], [576, 840]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5000805854797363, "(0, 16)": 0.5000805854797363, "(2, 0)": 0.5000805854797363, "(2, 16)": 0.5000805854797363, "(4, 0)": 0.5000805854797363, "(4, 16)": 0.5000805854797363, "(6, 0)": 0.5000805854797363, "(6, 16)": 0.6359995603561401, "(8, 0)": 0.4747801423072815, "(8, 16)": 0.5000805854797363, "(10, 0)": 0.6359995603561401, "(10, 16)": 0.6359995603561401, "(12, 0)": 0.5000805854797363, "(12, 16)": 0.6359995603561401, "(14, 0)": 0.5000805854797363, "(14, 16)": 0.6359995603561401, "(16, 0)": 0.6359995603561401, "(16, 16)": 0.6359995603561401, "(18, 0)": 0.5000805854797363, "(18, 16)": 0.6359995603561401, "(20, 0)": 0.6359995603561401, "(20, 16)": 0.5000805854797363, "(22, 0)": 0.6359995603561401, "(22, 16)": 0.6359995603561401, "(24, 0)": 0.5000805854797363, "(24, 16)": 0.6359995603561401, "(26, 0)": 0.6359995603561401, "(26, 16)": 0.6359995603561401, "(28, 0)": 0.6359995603561401, "(28, 16)": 0.5000805854797363, "(30, 0)": 0.6359995603561401, "(30, 16)": 0.6359995603561401}, "r_span": [639, 660], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00013905763626098633}}, {"prompt_attention_score": {"(0, 0)": 0.7082489728927612, "(0, 16)": 0.7082489728927612, "(2, 0)": 0.7082489728927612, "(2, 16)": 0.7082489728927612, "(4, 0)": 0.7082489728927612, "(4, 16)": 0.7082489728927612, "(6, 0)": 0.7082489728927612, "(6, 16)": 0.6958320736885071, "(8, 0)": 0.6893265247344971, "(8, 16)": 0.7082489728927612, "(10, 0)": 0.6893265247344971, "(10, 16)": 0.7082489728927612, "(12, 0)": 0.7082489728927612, "(12, 16)": 0.6893265247344971, "(14, 0)": 0.7082489728927612, "(14, 16)": 0.6893265247344971, "(16, 0)": 0.6893265247344971, "(16, 16)": 0.4210664629936218, "(18, 0)": 0.7082489728927612, "(18, 16)": 0.6958320736885071, "(20, 0)": 0.6893265247344971, "(20, 16)": 0.7082489728927612, "(22, 0)": 0.4210664629936218, "(22, 16)": 0.6893265247344971, "(24, 0)": 0.7082489728927612, "(24, 16)": 0.6893265247344971, "(26, 0)": 0.4210664629936218, "(26, 16)": 0.7082489728927612, "(28, 0)": 0.4210664629936218, "(28, 16)": 0.7082489728927612, "(30, 0)": 0.4210664629936218, "(30, 16)": 0.4210664629936218}, "r_span": [662, 783], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0034128427505493164}}, {"prompt_attention_score": {"(0, 0)": 0.7958195805549622, "(0, 16)": 0.7958195805549622, "(2, 0)": 0.7958195805549622, "(2, 16)": 0.7958195805549622, "(4, 0)": 0.7958195805549622, "(4, 16)": 0.7958195805549622, "(6, 0)": 0.7958195805549622, "(6, 16)": 0.7958195805549622, "(8, 0)": 0.7958195805549622, "(8, 16)": 0.7958195805549622, "(10, 0)": 0.7958195805549622, "(10, 16)": 0.7958195805549622, "(12, 0)": 0.7958195805549622, "(12, 16)": 0.7958195805549622, "(14, 0)": 0.7958195805549622, "(14, 16)": 0.7958195805549622, "(16, 0)": 0.7958195805549622, "(16, 16)": 0.4347863793373108, "(18, 0)": 0.4347863793373108, "(18, 16)": 0.7958195805549622, "(20, 0)": 0.7958195805549622, "(20, 16)": 0.7958195805549622, "(22, 0)": 0.4347863793373108, "(22, 16)": 0.7958195805549622, "(24, 0)": 0.7958195805549622, "(24, 16)": 0.7958195805549622, "(26, 0)": 0.4347863793373108, "(26, 16)": 0.7958195805549622, "(28, 0)": 0.4347863793373108, "(28, 16)": 0.7958195805549622, "(30, 0)": 0.4347863793373108, "(30, 16)": 0.4347863793373108}, "r_span": [782, 833], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00015783309936523438}}]}, {"id": "11103", "source_id": "14958", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 408, "end": 437, "text": "international-inspired dishes", "meta": "HIGH INTRO OF NEW INFO\nIt mentions that the deli offers international-inspired dishes and breakfast sandwiches, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is an objective overview of the local business \"805 Deli\" based on the provided structured data:\n\n805 Deli is a popular restaurant located in Santa Barbara, California, offering a variety of sandwiches, soups, and other dishes. The business has a rating of 4.0 stars and provides free WiFi to its customers. The deli is known for its unique and creative menu options, including breakfast sandwiches and international-inspired dishes. The business has both indoor and outdoor seating and offers catering services. While some customers have noted difficulty communicating with the cashier due to their accent, overall the quality of the food and service is highly rated. Reviewers have praised the portion sizes, price, and atmosphere of the deli, making it a great destination for both locals and travelers.", "response_spans": [[0, 101], [103, 612], [596, 811]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5021710395812988, "(0, 16)": 0.5021710395812988, "(2, 0)": 0.5021710395812988, "(2, 16)": 0.5021710395812988, "(4, 0)": 0.5021710395812988, "(4, 16)": 0.5021710395812988, "(6, 0)": 0.5021710395812988, "(6, 16)": 0.7062483429908752, "(8, 0)": 0.5086688995361328, "(8, 16)": 0.5021710395812988, "(10, 0)": 0.7062483429908752, "(10, 16)": 0.7062483429908752, "(12, 0)": 0.5326436758041382, "(12, 16)": 0.7062483429908752, "(14, 0)": 0.5021710395812988, "(14, 16)": 0.7062483429908752, "(16, 0)": 0.7062483429908752, "(16, 16)": 0.5021710395812988, "(18, 0)": 0.5086688995361328, "(18, 16)": 0.7062483429908752, "(20, 0)": 0.7062483429908752, "(20, 16)": 0.5021710395812988, "(22, 0)": 0.5021710395812988, "(22, 16)": 0.7062483429908752, "(24, 0)": 0.5021710395812988, "(24, 16)": 0.7062483429908752, "(26, 0)": 0.7062483429908752, "(26, 16)": 0.5086688995361328, "(28, 0)": 0.7062483429908752, "(28, 16)": 0.5021710395812988, "(30, 0)": 0.7062483429908752, "(30, 16)": 0.7062483429908752}, "r_span": [846, 871], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 5.811452865600586e-05}}, {"prompt_attention_score": {"(0, 0)": 0.5760205388069153, "(0, 16)": 0.5760205388069153, "(2, 0)": 0.5760205388069153, "(2, 16)": 0.5760205388069153, "(4, 0)": 0.5760205388069153, "(4, 16)": 0.5760205388069153, "(6, 0)": 0.5760205388069153, "(6, 16)": 0.7531256675720215, "(8, 0)": 0.5548517107963562, "(8, 16)": 0.5760205388069153, "(10, 0)": 0.5760205388069153, "(10, 16)": 0.5760205388069153, "(12, 0)": 0.5760205388069153, "(12, 16)": 0.5548517107963562, "(14, 0)": 0.5760205388069153, "(14, 16)": 0.5760205388069153, "(16, 0)": 0.7531256675720215, "(16, 16)": 0.5760205388069153, "(18, 0)": 0.5760205388069153, "(18, 16)": 0.7531256675720215, "(20, 0)": 0.7531256675720215, "(20, 16)": 0.5760205388069153, "(22, 0)": 0.5760205388069153, "(22, 16)": 0.7531256675720215, "(24, 0)": 0.5760205388069153, "(24, 16)": 0.49538537859916687, "(26, 0)": 0.4369216561317444, "(26, 16)": 0.5760205388069153, "(28, 0)": 0.4369216561317444, "(28, 16)": 0.5760205388069153, "(30, 0)": 0.5760205388069153, "(30, 16)": 0.4369216561317444}, "r_span": [873, 989], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0019565820693969727}}, {"prompt_attention_score": {"(0, 0)": 0.754895031452179, "(0, 16)": 0.754895031452179, "(2, 0)": 0.754895031452179, "(2, 16)": 0.754895031452179, "(4, 0)": 0.754895031452179, "(4, 16)": 0.754895031452179, "(6, 0)": 0.754895031452179, "(6, 16)": 0.6987059116363525, "(8, 0)": 0.754895031452179, "(8, 16)": 0.754895031452179, "(10, 0)": 0.754895031452179, "(10, 16)": 0.754895031452179, "(12, 0)": 0.754895031452179, "(12, 16)": 0.6987059116363525, "(14, 0)": 0.754895031452179, "(14, 16)": 0.754895031452179, "(16, 0)": 0.754895031452179, "(16, 16)": 0.4907819330692291, "(18, 0)": 0.4907819330692291, "(18, 16)": 0.6987059116363525, "(20, 0)": 0.6987059116363525, "(20, 16)": 0.754895031452179, "(22, 0)": 0.754895031452179, "(22, 16)": 0.6987059116363525, "(24, 0)": 0.754895031452179, "(24, 16)": 0.754895031452179, "(26, 0)": 0.4907819330692291, "(26, 16)": 0.754895031452179, "(28, 0)": 0.4907819330692291, "(28, 16)": 0.754895031452179, "(30, 0)": 0.4907819330692291, "(30, 16)": 0.4907819330692291}, "r_span": [985, 1032], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004087090492248535}}]}, {"id": "11181", "source_id": "14972", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 159, "end": 178, "text": "intimate atmosphere", "meta": "EVIDENT CONFLICT\nOriginal: \"intimate\": false,\nGenerative: \"intimate atmosphere....\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Due Lune Cucina is a highly rated Italian restaurant located in Santa Barbara, California. With a rating of 4.0 out of 5 stars, the business offers a cozy and intimate atmosphere, free WiFi, and excellent food and service. Customers have praised the restaurant's delicious pasta dishes and friendly staff, making it a standout in the area. While some reviews have noted that the restaurant is no longer open for business, the majority of customers have had positive experiences at Due Lune Cucina.", "response_spans": [[0, 497]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6537141799926758, "(0, 16)": 0.6537141799926758, "(2, 0)": 0.6537141799926758, "(2, 16)": 0.6537141799926758, "(4, 0)": 0.6537141799926758, "(4, 16)": 0.6537141799926758, "(6, 0)": 0.6537141799926758, "(6, 16)": 0.7834944128990173, "(8, 0)": 0.6537141799926758, "(8, 16)": 0.6537141799926758, "(10, 0)": 0.6537141799926758, "(10, 16)": 0.6537141799926758, "(12, 0)": 0.6537141799926758, "(12, 16)": 0.617728590965271, "(14, 0)": 0.6537141799926758, "(14, 16)": 0.6537141799926758, "(16, 0)": 0.6537141799926758, "(16, 16)": 0.6537141799926758, "(18, 0)": 0.43512415885925293, "(18, 16)": 0.7834944128990173, "(20, 0)": 0.7834944128990173, "(20, 16)": 0.6537141799926758, "(22, 0)": 0.6537141799926758, "(22, 16)": 0.7016305923461914, "(24, 0)": 0.6537141799926758, "(24, 16)": 0.7834944128990173, "(26, 0)": 0.43512415885925293, "(26, 16)": 0.6537141799926758, "(28, 0)": 0.43512415885925293, "(28, 16)": 0.6537141799926758, "(30, 0)": 0.43512415885925293, "(30, 16)": 0.43512415885925293}, "r_span": [830, 945], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00044798851013183594}}]}, {"id": "11193", "source_id": "14974", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 551, "end": 555, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerative:provides Wifi", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "La Hacienda Mexican Restaurant is a popular dining destination in Goleta, California, known for its delicious Mexican cuisine and exceptional customer service. With a rating of 4.0 stars, the restaurant has received positive reviews from customers who have praised the quality of their meals and the friendly service provided by the staff. The restaurant offers a variety of options, including a lunch special, chili verde, and chicken tortilla soup, all of which have been well-received by customers. The restaurant also provides outdoor seating and WiFi, making it a convenient and comfortable dining experience. The servers, particularly Luz and Juanita, have been commended for their excellent service and hospitality. Overall, La Hacienda Mexican Restaurant appears to be a great choice for those looking for authentic Mexican cuisine in a welcoming atmosphere.", "response_spans": [[0, 505], [488, 866]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6006954908370972, "(0, 16)": 0.6006954908370972, "(2, 0)": 0.6006954908370972, "(2, 16)": 0.6006954908370972, "(4, 0)": 0.6006954908370972, "(4, 16)": 0.6006954908370972, "(6, 0)": 0.6006954908370972, "(6, 16)": 0.7183321714401245, "(8, 0)": 0.6322582960128784, "(8, 16)": 0.6006954908370972, "(10, 0)": 0.6006954908370972, "(10, 16)": 0.6322582960128784, "(12, 0)": 0.6006954908370972, "(12, 16)": 0.6322582960128784, "(14, 0)": 0.5919985771179199, "(14, 16)": 0.37324053049087524, "(16, 0)": 0.5919985771179199, "(16, 16)": 0.6006954908370972, "(18, 0)": 0.5919985771179199, "(18, 16)": 0.7183321714401245, "(20, 0)": 0.5919985771179199, "(20, 16)": 0.5919985771179199, "(22, 0)": 0.37324053049087524, "(22, 16)": 0.6322582960128784, "(24, 0)": 0.5919985771179199, "(24, 16)": 0.6322582960128784, "(26, 0)": 0.37324053049087524, "(26, 16)": 0.5919985771179199, "(28, 0)": 0.37324053049087524, "(28, 16)": 0.5919985771179199, "(30, 0)": 0.37324053049087524, "(30, 16)": 0.37324053049087524}, "r_span": [786, 898], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007749199867248535}}, {"prompt_attention_score": {"(0, 0)": 0.6933100819587708, "(0, 16)": 0.661904513835907, "(2, 0)": 0.661904513835907, "(2, 16)": 0.661904513835907, "(4, 0)": 0.661904513835907, "(4, 16)": 0.661904513835907, "(6, 0)": 0.661904513835907, "(6, 16)": 0.669047474861145, "(8, 0)": 0.661904513835907, "(8, 16)": 0.661904513835907, "(10, 0)": 0.661904513835907, "(10, 16)": 0.661904513835907, "(12, 0)": 0.661904513835907, "(12, 16)": 0.6933100819587708, "(14, 0)": 0.6278780698776245, "(14, 16)": 0.4262233376502991, "(16, 0)": 0.661904513835907, "(16, 16)": 0.661904513835907, "(18, 0)": 0.42033088207244873, "(18, 16)": 0.669047474861145, "(20, 0)": 0.6933100819587708, "(20, 16)": 0.6278780698776245, "(22, 0)": 0.42033088207244873, "(22, 16)": 0.6933100819587708, "(24, 0)": 0.6278780698776245, "(24, 16)": 0.6933100819587708, "(26, 0)": 0.42033088207244873, "(26, 16)": 0.6278780698776245, "(28, 0)": 0.42033088207244873, "(28, 16)": 0.42033088207244873, "(30, 0)": 0.42033088207244873, "(30, 16)": 0.42033088207244873}, "r_span": [895, 973], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 1.2814998626708984e-05}}]}, {"id": "11289", "source_id": "14990", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 0, "end": 38, "text": "Nestled in the heart of Santa Barbara,", "meta": "LOW INTRO OF NEW INFO\nNo mention of this detail but may stand to be true. ", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Nestled in the heart of Santa Barbara, Crocodile Restaurant & Bar is a popular hotspot for travelers and locals alike. With a cozy atmosphere and delicious menu options, including pizza, breakfast, brunch, and American and Italian cuisine, this establishment is a must-visit for anyone looking for a satisfying dining experience. The restaurant boasts a tranquil outdoor seating area, making it perfect for relaxation after a long day. Additionally, free WiFi is available, ensuring guests can stay connected during their visit. While some reviewers have noted issues with service, the majority of patrons have praised the friendly and accommodating staff. Despite one reviewer expressing disappointment with the hand sanitizer availability, most visitors have enjoyed their experience at Crocodile Restaurant & Bar.", "response_spans": [[0, 508], [490, 816]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5516173243522644, "(0, 16)": 0.5516173243522644, "(2, 0)": 0.5516173243522644, "(2, 16)": 0.5516173243522644, "(4, 0)": 0.5516173243522644, "(4, 16)": 0.5516173243522644, "(6, 0)": 0.5516173243522644, "(6, 16)": 0.808343768119812, "(8, 0)": 0.808343768119812, "(8, 16)": 0.5516173243522644, "(10, 0)": 0.5516173243522644, "(10, 16)": 0.5516173243522644, "(12, 0)": 0.5516173243522644, "(12, 16)": 0.808343768119812, "(14, 0)": 0.5561394691467285, "(14, 16)": 0.808343768119812, "(16, 0)": 0.5988407731056213, "(16, 16)": 0.5516173243522644, "(18, 0)": 0.5060586333274841, "(18, 16)": 0.808343768119812, "(20, 0)": 0.808343768119812, "(20, 16)": 0.5060586333274841, "(22, 0)": 0.4288169741630554, "(22, 16)": 0.808343768119812, "(24, 0)": 0.5060586333274841, "(24, 16)": 0.808343768119812, "(26, 0)": 0.4288169741630554, "(26, 16)": 0.5561394691467285, "(28, 0)": 0.4288169741630554, "(28, 16)": 0.4288169741630554, "(30, 0)": 0.4288169741630554, "(30, 16)": 0.4288169741630554}, "r_span": [1226, 1343], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0011719465255737305}}, {"prompt_attention_score": {"(0, 0)": 0.6211128234863281, "(0, 16)": 0.6211128234863281, "(2, 0)": 0.6211128234863281, "(2, 16)": 0.6211128234863281, "(4, 0)": 0.6211128234863281, "(4, 16)": 0.6211128234863281, "(6, 0)": 0.6211128234863281, "(6, 16)": 0.6684710383415222, "(8, 0)": 0.6211128234863281, "(8, 16)": 0.6211128234863281, "(10, 0)": 0.6211128234863281, "(10, 16)": 0.6211128234863281, "(12, 0)": 0.6211128234863281, "(12, 16)": 0.6684710383415222, "(14, 0)": 0.5432432889938354, "(14, 16)": 0.6211128234863281, "(16, 0)": 0.6684710383415222, "(16, 16)": 0.6211128234863281, "(18, 0)": 0.5432432889938354, "(18, 16)": 0.6684710383415222, "(20, 0)": 0.6684710383415222, "(20, 16)": 0.5432432889938354, "(22, 0)": 0.4561064839363098, "(22, 16)": 0.6684710383415222, "(24, 0)": 0.5432432889938354, "(24, 16)": 0.6684710383415222, "(26, 0)": 0.4561064839363098, "(26, 16)": 0.6684710383415222, "(28, 0)": 0.4561064839363098, "(28, 16)": 0.4561064839363098, "(30, 0)": 0.4561064839363098, "(30, 16)": 0.4561064839363098}, "r_span": [1341, 1405], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0016033053398132324}}]}, {"id": "11295", "source_id": "14991", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 464, "end": 481, "text": "artisanal cheeses", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this menu item. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 744, "end": 764, "text": "intimate atmosphere.", "meta": "EVIDENT CONFLICT\nOriginal: false for intimate ambiance\nAIGC: intimate atmosphere", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Pierre Lafond Wine Bistro:\n\nPierre Lafond Wine Bistro is a popular eatery located in Santa Barbara, California, offering a range of delicious dishes and drinks. With a cozy atmosphere and outdoor seating, the bistro is perfect for a relaxed evening out or a casual dinner with friends. The menu features a variety of options, including vegetarian and vegan choices, as well as a selection of artisanal cheeses and wines. While the State Street location has closed, the Montecito branch remains open and continues to receive positive reviews for its food quality and friendly service. Customers appreciate the fresh, organic ingredients used in the dishes and the relaxed, intimate atmosphere.", "response_spans": [[0, 98], [100, 604], [585, 764]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5073973536491394, "(0, 16)": 0.5073973536491394, "(2, 0)": 0.5073973536491394, "(2, 16)": 0.5073973536491394, "(4, 0)": 0.5073973536491394, "(4, 16)": 0.5073973536491394, "(6, 0)": 0.5073973536491394, "(6, 16)": 0.5933218002319336, "(8, 0)": 0.5073973536491394, "(8, 16)": 0.5073973536491394, "(10, 0)": 0.5933218002319336, "(10, 16)": 0.5933218002319336, "(12, 0)": 0.5073973536491394, "(12, 16)": 0.5933218002319336, "(14, 0)": 0.5933218002319336, "(14, 16)": 0.5933218002319336, "(16, 0)": 0.5933218002319336, "(16, 16)": 0.5933218002319336, "(18, 0)": 0.5933218002319336, "(18, 16)": 0.5933218002319336, "(20, 0)": 0.5933218002319336, "(20, 16)": 0.4085008502006531, "(22, 0)": 0.5933218002319336, "(22, 16)": 0.5933218002319336, "(24, 0)": 0.4085008502006531, "(24, 16)": 0.5933218002319336, "(26, 0)": 0.5933218002319336, "(26, 16)": 0.4085008502006531, "(28, 0)": 0.5933218002319336, "(28, 16)": 0.5933218002319336, "(30, 0)": 0.5933218002319336, "(30, 16)": 0.5933218002319336}, "r_span": [809, 834], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005561709403991699}}, {"prompt_attention_score": {"(0, 0)": 0.6261017918586731, "(0, 16)": 0.6261017918586731, "(2, 0)": 0.6261017918586731, "(2, 16)": 0.6261017918586731, "(4, 0)": 0.6261017918586731, "(4, 16)": 0.6261017918586731, "(6, 0)": 0.6261017918586731, "(6, 16)": 0.7983096837997437, "(8, 0)": 0.6261017918586731, "(8, 16)": 0.6261017918586731, "(10, 0)": 0.6261017918586731, "(10, 16)": 0.6261017918586731, "(12, 0)": 0.6261017918586731, "(12, 16)": 0.6601283550262451, "(14, 0)": 0.6601283550262451, "(14, 16)": 0.6261017918586731, "(16, 0)": 0.7983096837997437, "(16, 16)": 0.6261017918586731, "(18, 0)": 0.3943699598312378, "(18, 16)": 0.7983096837997437, "(20, 0)": 0.6601283550262451, "(20, 16)": 0.6601283550262451, "(22, 0)": 0.3943699598312378, "(22, 16)": 0.6601283550262451, "(24, 0)": 0.6601283550262451, "(24, 16)": 0.6601283550262451, "(26, 0)": 0.3943699598312378, "(26, 16)": 0.6601283550262451, "(28, 0)": 0.3943699598312378, "(28, 16)": 0.6601283550262451, "(30, 0)": 0.3943699598312378, "(30, 16)": 0.3943699598312378}, "r_span": [836, 948], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0003313422203063965}}, {"prompt_attention_score": {"(0, 0)": 0.6979643106460571, "(0, 16)": 0.6979643106460571, "(2, 0)": 0.6979643106460571, "(2, 16)": 0.6979643106460571, "(4, 0)": 0.6979643106460571, "(4, 16)": 0.6979643106460571, "(6, 0)": 0.6979643106460571, "(6, 16)": 0.6189086437225342, "(8, 0)": 0.6979643106460571, "(8, 16)": 0.6979643106460571, "(10, 0)": 0.6979643106460571, "(10, 16)": 0.6979643106460571, "(12, 0)": 0.6979643106460571, "(12, 16)": 0.6189086437225342, "(14, 0)": 0.6189086437225342, "(14, 16)": 0.6979643106460571, "(16, 0)": 0.6979643106460571, "(16, 16)": 0.6979643106460571, "(18, 0)": 0.6189086437225342, "(18, 16)": 0.6189086437225342, "(20, 0)": 0.6189086437225342, "(20, 16)": 0.6189086437225342, "(22, 0)": 0.5218900442123413, "(22, 16)": 0.6189086437225342, "(24, 0)": 0.6189086437225342, "(24, 16)": 0.6189086437225342, "(26, 0)": 0.5218900442123413, "(26, 16)": 0.6979643106460571, "(28, 0)": 0.5218900442123413, "(28, 16)": 0.6189086437225342, "(30, 0)": 0.5218900442123413, "(30, 16)": 0.5218900442123413}, "r_span": [946, 982], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0018295645713806152}}]}, {"id": "11445", "source_id": "15018", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 245, "end": 303, "text": "Hours: Monday - Saturday: 16:00-20:30, Sunday: 16:00-20:30", "meta": "EVIDENT CONFLICT\nOriginal: Monday (close), 4PM-8:30PM (Tuesday-Thursday and Sunday), 4:30PM-9:30PM (Friday), 4PM-9:30PM (Saturday)\nGenerative: Monday - Saturday: 16:00-20:30", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 485, "end": 541, "text": "Music: DJ, live music occasionally, karaoke occasionally", "meta": "EVIDENT CONFLICT\nOriginal: \"Music\": \"{dj: None, live: False, jkebox: False, video: False, backgrond_msic: False, karaoke: None, no_msic: False}\",\nGenerative: live music occasionally,", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Ca' Dario:\n\nLocation: Ca' Dario is located in Santa Barbara, California at 37 E Victoria St.\n\nCategories: Tuscan, Seafood, Wine Bars, Restaurants, Bars, Nightlife, Italian\n\nHours: Monday - Saturday: 16:00-20:30, Sunday: 16:00-20:30\n\nAttributes: BusinessParking: Garage, street parking available; RestaurantsReservations: Yes; OutdoorSeating: Yes; WiFi: No; RestaurantsTakeOut: Yes; RestaurantsGoodForGroups: Yes; Music: DJ, live music occasionally, karaoke occasionally\n\nAmbiance: Not touristy, hipster, romantic, or divey; classy and casual\n\nBusiness Stars: 4.0\n\nReviews:\n\n* Review 1 (2.0 stars): Disappointing meals with lackluster ingredients and poor service.\n* Review 2 (3.0 stars): Ordinary food with overcooked pasta and unspectacular sauces, but good wine choices.\n* Review 3 (5.0 stars): Delicious food, particularly the ravioli with sage and brown butter, and great service.\n\nOverall, Ca' Dario seems to have a mixed reputation, with some reviewers enjoying their meals and others finding them to be disappointing. While some appreciate the restaurant's atmosphere and wine selection, others feel that the food is ordinary and overpriced.", "response_spans": [[0, 303], [305, 644], [636, 956], [958, 1220]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6837174296379089, "(0, 16)": 0.6837174296379089, "(2, 0)": 0.6837174296379089, "(2, 16)": 0.6837174296379089, "(4, 0)": 0.6837174296379089, "(4, 16)": 0.5241131782531738, "(6, 0)": 0.6837174296379089, "(6, 16)": 0.8245978951454163, "(8, 0)": 0.8245978951454163, "(8, 16)": 0.6837174296379089, "(10, 0)": 0.6837174296379089, "(10, 16)": 0.6837174296379089, "(12, 0)": 0.6837174296379089, "(12, 16)": 0.8245978951454163, "(14, 0)": 0.6837174296379089, "(14, 16)": 0.8245978951454163, "(16, 0)": 0.8245978951454163, "(16, 16)": 0.6837174296379089, "(18, 0)": 0.6837174296379089, "(18, 16)": 0.8245978951454163, "(20, 0)": 0.8245978951454163, "(20, 16)": 0.6837174296379089, "(22, 0)": 0.6837174296379089, "(22, 16)": 0.8245978951454163, "(24, 0)": 0.6837174296379089, "(24, 16)": 0.8245978951454163, "(26, 0)": 0.4711380898952484, "(26, 16)": 0.6837174296379089, "(28, 0)": 0.4711380898952484, "(28, 16)": 0.6837174296379089, "(30, 0)": 0.4711380898952484, "(30, 16)": 0.4711380898952484}, "r_span": [1305, 1414], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008955001831054688}}, {"prompt_attention_score": {"(0, 0)": 0.5753976106643677, "(0, 16)": 0.5753976106643677, "(2, 0)": 0.5834925770759583, "(2, 16)": 0.5834925770759583, "(4, 0)": 0.5834925770759583, "(4, 16)": 0.5834925770759583, "(6, 0)": 0.5834925770759583, "(6, 16)": 0.7437927722930908, "(8, 0)": 0.7437927722930908, "(8, 16)": 0.5834925770759583, "(10, 0)": 0.5834925770759583, "(10, 16)": 0.5834925770759583, "(12, 0)": 0.5834925770759583, "(12, 16)": 0.7437927722930908, "(14, 0)": 0.5834925770759583, "(14, 16)": 0.7437927722930908, "(16, 0)": 0.7437927722930908, "(16, 16)": 0.5834925770759583, "(18, 0)": 0.5753976106643677, "(18, 16)": 0.7437927722930908, "(20, 0)": 0.7437927722930908, "(20, 16)": 0.5834925770759583, "(22, 0)": 0.6010196208953857, "(22, 16)": 0.7437927722930908, "(24, 0)": 0.5834925770759583, "(24, 16)": 0.7437927722930908, "(26, 0)": 0.6010196208953857, "(26, 16)": 0.5834925770759583, "(28, 0)": 0.6010196208953857, "(28, 16)": 0.5834925770759583, "(30, 0)": 0.6010196208953857, "(30, 16)": 0.6010196208953857}, "r_span": [1416, 1523], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0019869208335876465}}, {"prompt_attention_score": {"(0, 0)": 0.6959447860717773, "(0, 16)": 0.6959447860717773, "(2, 0)": 0.7614489197731018, "(2, 16)": 0.6959447860717773, "(4, 0)": 0.7614489197731018, "(4, 16)": 0.7614489197731018, "(6, 0)": 0.7614489197731018, "(6, 16)": 0.7703587412834167, "(8, 0)": 0.7614489197731018, "(8, 16)": 0.7614489197731018, "(10, 0)": 0.6959447860717773, "(10, 16)": 0.7614489197731018, "(12, 0)": 0.7614489197731018, "(12, 16)": 0.7614489197731018, "(14, 0)": 0.7614489197731018, "(14, 16)": 0.7614489197731018, "(16, 0)": 0.7614489197731018, "(16, 16)": 0.7614489197731018, "(18, 0)": 0.7614489197731018, "(18, 16)": 0.7703587412834167, "(20, 0)": 0.7703587412834167, "(20, 16)": 0.7614489197731018, "(22, 0)": 0.4892626702785492, "(22, 16)": 0.7614489197731018, "(24, 0)": 0.7614489197731018, "(24, 16)": 0.7703587412834167, "(26, 0)": 0.4892626702785492, "(26, 16)": 0.7614489197731018, "(28, 0)": 0.4892626702785492, "(28, 16)": 0.7614489197731018, "(30, 0)": 0.4892626702785492, "(30, 16)": 0.4892626702785492}, "r_span": [1520, 1617], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007584691047668457}}, {"prompt_attention_score": {"(0, 0)": 0.7576252818107605, "(0, 16)": 0.7576252818107605, "(2, 0)": 0.7576252818107605, "(2, 16)": 0.7331344485282898, "(4, 0)": 0.7331344485282898, "(4, 16)": 0.7331344485282898, "(6, 0)": 0.7331344485282898, "(6, 16)": 0.7396522164344788, "(8, 0)": 0.7331344485282898, "(8, 16)": 0.7331344485282898, "(10, 0)": 0.7576252818107605, "(10, 16)": 0.7576252818107605, "(12, 0)": 0.7331344485282898, "(12, 16)": 0.7576252818107605, "(14, 0)": 0.7331344485282898, "(14, 16)": 0.4777236580848694, "(16, 0)": 0.7331344485282898, "(16, 16)": 0.46858394145965576, "(18, 0)": 0.7331344485282898, "(18, 16)": 0.7331344485282898, "(20, 0)": 0.7396522164344788, "(20, 16)": 0.7331344485282898, "(22, 0)": 0.46858394145965576, "(22, 16)": 0.7331344485282898, "(24, 0)": 0.7331344485282898, "(24, 16)": 0.7711077332496643, "(26, 0)": 0.46858394145965576, "(26, 16)": 0.46858394145965576, "(28, 0)": 0.46858394145965576, "(28, 16)": 0.7210467457771301, "(30, 0)": 0.46858394145965576, "(30, 16)": 0.46858394145965576}, "r_span": [1619, 1675], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 1.5854835510253906e-05}}]}, {"id": "11451", "source_id": "15019", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 420, "end": 444, "text": "street parking available", "meta": "EVIDENT CONFLICT\nOriginal:\"street\": false, \nGenerative: there is street parking available", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "El Rincon Bohemio-Goleta is a Mexican restaurant located in Goleta, California, with a rating of 3.5 stars. The restaurant offers outdoor seating, free WiFi, and takeout options. Reviewers have mixed opinions about the quality of the food, with some finding it average and others enjoying it. The wait staff and hostess are praised for being friendly and fun. While the restaurant does not offer valet parking, there is street parking available. Overall, El Rincon Bohemio-Goleta is a casual dining spot with a cozy atmosphere and good service, although the quality of the food may vary.", "response_spans": [[0, 510], [492, 587]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6647347211837769, "(0, 16)": 0.6647347211837769, "(2, 0)": 0.6647347211837769, "(2, 16)": 0.6647347211837769, "(4, 0)": 0.6647347211837769, "(4, 16)": 0.6647347211837769, "(6, 0)": 0.6837654709815979, "(6, 16)": 0.7556560039520264, "(8, 0)": 0.6837654709815979, "(8, 16)": 0.6647347211837769, "(10, 0)": 0.6837654709815979, "(10, 16)": 0.6837654709815979, "(12, 0)": 0.6647347211837769, "(12, 16)": 0.7556560039520264, "(14, 0)": 0.6837654709815979, "(14, 16)": 0.418243944644928, "(16, 0)": 0.6692091226577759, "(16, 16)": 0.41527819633483887, "(18, 0)": 0.6692091226577759, "(18, 16)": 0.7556560039520264, "(20, 0)": 0.7556560039520264, "(20, 16)": 0.6837654709815979, "(22, 0)": 0.41527819633483887, "(22, 16)": 0.6837654709815979, "(24, 0)": 0.6837654709815979, "(24, 16)": 0.7556560039520264, "(26, 0)": 0.41527819633483887, "(26, 16)": 0.7556560039520264, "(28, 0)": 0.41527819633483887, "(28, 16)": 0.41527819633483887, "(30, 0)": 0.41527819633483887, "(30, 16)": 0.41527819633483887}, "r_span": [788, 917], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.000647425651550293}}, {"prompt_attention_score": {"(0, 0)": 0.5908054113388062, "(0, 16)": 0.5908054113388062, "(2, 0)": 0.5908054113388062, "(2, 16)": 0.5908054113388062, "(4, 0)": 0.5908054113388062, "(4, 16)": 0.5908054113388062, "(6, 0)": 0.5890332460403442, "(6, 16)": 0.5890332460403442, "(8, 0)": 0.5890332460403442, "(8, 16)": 0.5908054113388062, "(10, 0)": 0.5890332460403442, "(10, 16)": 0.5908054113388062, "(12, 0)": 0.4324285387992859, "(12, 16)": 0.5890332460403442, "(14, 0)": 0.5890332460403442, "(14, 16)": 0.48943936824798584, "(16, 0)": 0.5890332460403442, "(16, 16)": 0.5908054113388062, "(18, 0)": 0.5537949204444885, "(18, 16)": 0.5537949204444885, "(20, 0)": 0.5537949204444885, "(20, 16)": 0.5890332460403442, "(22, 0)": 0.4324285387992859, "(22, 16)": 0.5537949204444885, "(24, 0)": 0.5890332460403442, "(24, 16)": 0.5537949204444885, "(26, 0)": 0.4324285387992859, "(26, 16)": 0.5908054113388062, "(28, 0)": 0.4324285387992859, "(28, 16)": 0.4324285387992859, "(30, 0)": 0.4324285387992859, "(30, 16)": 0.4324285387992859}, "r_span": [913, 933], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002776980400085449}}]}, {"id": "11457", "source_id": "15020", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 380, "end": 421, "text": "Monday through Sunday from 17:00 to 22:00", "meta": "EVIDENT CONFLICT\nOriginal: closed on Monday, open from Tuesday to Thursday, and Sunday from 5pm to 9pm and Friday to Saturday from 5pm to 10pm\nGenerated: Monday through Sunday from 17:00 to 22:00", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 423, "end": 455, "text": "with validated parking available", "meta": "EVIDENT CONFLICT\nOriginal: \"validated\": false,\nGenerated: with validated parking available", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of The Lark:\n\nThe Lark is a popular nightlife spot located in the heart of Santa Barbara's Funk Zone. With categories such as Nightlife, Bars, Cocktail Bars, Food, American (New), Desserts, and Restaurants, The Lark offers a unique shared dining experience for groups of all sizes. Their hours of operation are Monday through Sunday from 17:00 to 22:00, with validated parking available off-street and street parking nearby.\n\nAccording to customer reviews, the quality of the food at The Lark is consistently high, with standout dishes including crispy Brussels sprouts, winter beets marinated in balsamic vinegar, caramelized cauliflower, cast iron Morro Bay black cod, creekstone prime hanger steak, and buttermilk fried chicken. Wine enthusiasts will appreciate the extensive selection of wine-by-the-glass options, including Grimm's Bluff, Happy Canyon, and Rose of Cabernet Sauvignon.\n\nHowever, some customers have reported issues with the service at The Lark, including a lack of attentiveness from servers and confusion with regard to reservations. Despite these minor drawbacks, the majority of customers have praised The Lark for its cozy atmosphere, excellent food, and exceptional service. One reviewer even noted that their server, Laurel, went above and beyond to ensure a special night, earning a 5-star rating for service. Overall, The Lark appears to be a top choice for dinner and drinks in Santa Barbara, offering a memorable dining experience for visitors and locals alike.", "response_spans": [[0, 493], [495, 958], [960, 1466], [1452, 1561]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5210003852844238, "(0, 16)": 0.5210003852844238, "(2, 0)": 0.5210003852844238, "(2, 16)": 0.5210003852844238, "(4, 0)": 0.5210003852844238, "(4, 16)": 0.5210003852844238, "(6, 0)": 0.5210003852844238, "(6, 16)": 0.8175430297851562, "(8, 0)": 0.6478299498558044, "(8, 16)": 0.5210003852844238, "(10, 0)": 0.6510764956474304, "(10, 16)": 0.5006810426712036, "(12, 0)": 0.5210003852844238, "(12, 16)": 0.8175430297851562, "(14, 0)": 0.5210003852844238, "(14, 16)": 0.8175430297851562, "(16, 0)": 0.4643007516860962, "(16, 16)": 0.5210003852844238, "(18, 0)": 0.5064797401428223, "(18, 16)": 0.8175430297851562, "(20, 0)": 0.8175430297851562, "(20, 16)": 0.5391603112220764, "(22, 0)": 0.5210003852844238, "(22, 16)": 0.8175430297851562, "(24, 0)": 0.5391603112220764, "(24, 16)": 0.8175430297851562, "(26, 0)": 0.4643007516860962, "(26, 16)": 0.6478299498558044, "(28, 0)": 0.4643007516860962, "(28, 16)": 0.5210003852844238, "(30, 0)": 0.4643007516860962, "(30, 16)": 0.4643007516860962}, "r_span": [1363, 1493], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0023952126502990723}}, {"prompt_attention_score": {"(0, 0)": 0.63393634557724, "(0, 16)": 0.63393634557724, "(2, 0)": 0.63393634557724, "(2, 16)": 0.63393634557724, "(4, 0)": 0.63393634557724, "(4, 16)": 0.63393634557724, "(6, 0)": 0.63393634557724, "(6, 16)": 0.7551273703575134, "(8, 0)": 0.7551273703575134, "(8, 16)": 0.63393634557724, "(10, 0)": 0.5871759653091431, "(10, 16)": 0.63393634557724, "(12, 0)": 0.63393634557724, "(12, 16)": 0.7551273703575134, "(14, 0)": 0.63393634557724, "(14, 16)": 0.7551273703575134, "(16, 0)": 0.7551273703575134, "(16, 16)": 0.63393634557724, "(18, 0)": 0.5873120427131653, "(18, 16)": 0.7551273703575134, "(20, 0)": 0.7551273703575134, "(20, 16)": 0.63393634557724, "(22, 0)": 0.409696489572525, "(22, 16)": 0.7551273703575134, "(24, 0)": 0.5873120427131653, "(24, 16)": 0.7551273703575134, "(26, 0)": 0.409696489572525, "(26, 16)": 0.7551273703575134, "(28, 0)": 0.409696489572525, "(28, 16)": 0.63393634557724, "(30, 0)": 0.409696489572525, "(30, 16)": 0.409696489572525}, "r_span": [1495, 1624], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0025449395179748535}}, {"prompt_attention_score": {"(0, 0)": 0.6861612200737, "(0, 16)": 0.6861612200737, "(2, 0)": 0.6861612200737, "(2, 16)": 0.6861612200737, "(4, 0)": 0.6894201040267944, "(4, 16)": 0.6861612200737, "(6, 0)": 0.6861612200737, "(6, 16)": 0.7924342155456543, "(8, 0)": 0.6877028346061707, "(8, 16)": 0.6861612200737, "(10, 0)": 0.7021958231925964, "(10, 16)": 0.7021958231925964, "(12, 0)": 0.7021958231925964, "(12, 16)": 0.7924342155456543, "(14, 0)": 0.6861612200737, "(14, 16)": 0.7021958231925964, "(16, 0)": 0.7021958231925964, "(16, 16)": 0.489634245634079, "(18, 0)": 0.6861612200737, "(18, 16)": 0.7231287956237793, "(20, 0)": 0.7231287956237793, "(20, 16)": 0.7261220812797546, "(22, 0)": 0.489634245634079, "(22, 16)": 0.7021958231925964, "(24, 0)": 0.6861612200737, "(24, 16)": 0.7261220812797546, "(26, 0)": 0.489634245634079, "(26, 16)": 0.6861612200737, "(28, 0)": 0.489634245634079, "(28, 16)": 0.6877028346061707, "(30, 0)": 0.489634245634079, "(30, 16)": 0.489634245634079}, "r_span": [1626, 1739], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012329816818237305}}, {"prompt_attention_score": {"(0, 0)": 0.5118314027786255, "(0, 16)": 0.5118314027786255, "(2, 0)": 0.5118314027786255, "(2, 16)": 0.525942325592041, "(4, 0)": 0.5118314027786255, "(4, 16)": 0.5118314027786255, "(6, 0)": 0.690453052520752, "(6, 16)": 0.690453052520752, "(8, 0)": 0.690453052520752, "(8, 16)": 0.5032285451889038, "(10, 0)": 0.6502218842506409, "(10, 16)": 0.5517269372940063, "(12, 0)": 0.5032285451889038, "(12, 16)": 0.6502218842506409, "(14, 0)": 0.5118314027786255, "(14, 16)": 0.4158497154712677, "(16, 0)": 0.38059985637664795, "(16, 16)": 0.5118314027786255, "(18, 0)": 0.5118314027786255, "(18, 16)": 0.477148175239563, "(20, 0)": 0.477148175239563, "(20, 16)": 0.5118314027786255, "(22, 0)": 0.5118314027786255, "(22, 16)": 0.6502218842506409, "(24, 0)": 0.5032285451889038, "(24, 16)": 0.5517269372940063, "(26, 0)": 0.38059985637664795, "(26, 16)": 0.5118314027786255, "(28, 0)": 0.38059985637664795, "(28, 16)": 0.690453052520752, "(30, 0)": 0.38059985637664795, "(30, 16)": 0.38059985637664795}, "r_span": [1737, 1760], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006892085075378418}}]}, {"id": "11487", "source_id": "15025", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 430, "end": 434, "text": "WiFi", "meta": "EVIDENT CONFLICT\nOriginal: \"WiFi\": \"no\",\nGenerative: offers Wi-Fi, ", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided structured data, here is an objective overview of Cafe del Sol:\n\nLocated in Santa Barbara, California, Cafe del Sol is a restaurant that offers American (Traditional), American (New), and Mexican cuisine. The establishment has a rating of 3.5 stars and receives positive reviews for its atmosphere, with customers describing it as casual and inviting. The business has a full bar and offers outdoor seating, WiFi, and restaurants takeout options. However, their liquor license is currently suspended, which may be of concern to some customers.\n\nReviews for the food vary, with some customers praising the delicious chicken enchilada and generous tostada portions, while others have criticized the quality of the food, particularly the high prices compared to the portion sizes. Some customers have also mentioned that the menu items are not value-for-money. Despite this, many customers have praised the friendliness of the staff and the overall experience at the cafe.\n\nIn summary, Cafe del Sol seems to have a mixed reputation, with both positive and negative feedback from customers regarding the quality of the food and services. While some customers enjoy the ambiance and customer service, others are disappointed with the food value and quality.", "response_spans": [[0, 85], [87, 565], [567, 991], [993, 1274]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.49655136466026306, "(0, 16)": 0.4787920117378235, "(2, 0)": 0.49655136466026306, "(2, 16)": 0.49655136466026306, "(4, 0)": 0.49655136466026306, "(4, 16)": 0.49655136466026306, "(6, 0)": 0.49655136466026306, "(6, 16)": 0.6319891214370728, "(8, 0)": 0.5247605443000793, "(8, 16)": 0.49655136466026306, "(10, 0)": 0.6319891214370728, "(10, 16)": 0.6319891214370728, "(12, 0)": 0.541378378868103, "(12, 16)": 0.6319891214370728, "(14, 0)": 0.6319891214370728, "(14, 16)": 0.6319891214370728, "(16, 0)": 0.6319891214370728, "(16, 16)": 0.6319891214370728, "(18, 0)": 0.6319891214370728, "(18, 16)": 0.6319891214370728, "(20, 0)": 0.6319891214370728, "(20, 16)": 0.5247605443000793, "(22, 0)": 0.6319891214370728, "(22, 16)": 0.6319891214370728, "(24, 0)": 0.5247605443000793, "(24, 16)": 0.6319891214370728, "(26, 0)": 0.6319891214370728, "(26, 16)": 0.5247605443000793, "(28, 0)": 0.6319891214370728, "(28, 16)": 0.6319891214370728, "(30, 0)": 0.6319891214370728, "(30, 16)": 0.6319891214370728}, "r_span": [802, 823], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001284778118133545}}, {"prompt_attention_score": {"(0, 0)": 0.5576319694519043, "(0, 16)": 0.5738927125930786, "(2, 0)": 0.5576319694519043, "(2, 16)": 0.5576319694519043, "(4, 0)": 0.5576319694519043, "(4, 16)": 0.5576319694519043, "(6, 0)": 0.5576319694519043, "(6, 16)": 0.723554253578186, "(8, 0)": 0.5576319694519043, "(8, 16)": 0.5576319694519043, "(10, 0)": 0.5660355687141418, "(10, 16)": 0.5738927125930786, "(12, 0)": 0.4256748557090759, "(12, 16)": 0.723554253578186, "(14, 0)": 0.5576319694519043, "(14, 16)": 0.723554253578186, "(16, 0)": 0.723554253578186, "(16, 16)": 0.5576319694519043, "(18, 0)": 0.4256748557090759, "(18, 16)": 0.723554253578186, "(20, 0)": 0.723554253578186, "(20, 16)": 0.5140129923820496, "(22, 0)": 0.4256748557090759, "(22, 16)": 0.723554253578186, "(24, 0)": 0.5660355687141418, "(24, 16)": 0.723554253578186, "(26, 0)": 0.4256748557090759, "(26, 16)": 0.5660355687141418, "(28, 0)": 0.4256748557090759, "(28, 16)": 0.5140129923820496, "(30, 0)": 0.4256748557090759, "(30, 16)": 0.4256748557090759}, "r_span": [825, 931], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0017493367195129395}}, {"prompt_attention_score": {"(0, 0)": 0.8155421614646912, "(0, 16)": 0.7207961082458496, "(2, 0)": 0.8155421614646912, "(2, 16)": 0.8155421614646912, "(4, 0)": 0.8155421614646912, "(4, 16)": 0.8155421614646912, "(6, 0)": 0.7800101637840271, "(6, 16)": 0.7800101637840271, "(8, 0)": 0.8155421614646912, "(8, 16)": 0.8155421614646912, "(10, 0)": 0.7207961082458496, "(10, 16)": 0.8155421614646912, "(12, 0)": 0.8155421614646912, "(12, 16)": 0.7800101637840271, "(14, 0)": 0.7800101637840271, "(14, 16)": 0.8155421614646912, "(16, 0)": 0.7800101637840271, "(16, 16)": 0.4916817545890808, "(18, 0)": 0.4916817545890808, "(18, 16)": 0.7800101637840271, "(20, 0)": 0.7800101637840271, "(20, 16)": 0.8155421614646912, "(22, 0)": 0.4916817545890808, "(22, 16)": 0.8155421614646912, "(24, 0)": 0.7800101637840271, "(24, 16)": 0.8155421614646912, "(26, 0)": 0.4916817545890808, "(26, 16)": 0.7800101637840271, "(28, 0)": 0.4916817545890808, "(28, 16)": 0.4916817545890808, "(30, 0)": 0.4916817545890808, "(30, 16)": 0.4916817545890808}, "r_span": [933, 1026], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018208622932434082}}, {"prompt_attention_score": {"(0, 0)": 0.6546499729156494, "(0, 16)": 0.6245150566101074, "(2, 0)": 0.6546499729156494, "(2, 16)": 0.6546499729156494, "(4, 0)": 0.6546499729156494, "(4, 16)": 0.6546499729156494, "(6, 0)": 0.6546499729156494, "(6, 16)": 0.639893651008606, "(8, 0)": 0.6546499729156494, "(8, 16)": 0.6546499729156494, "(10, 0)": 0.6245150566101074, "(10, 16)": 0.6307016611099243, "(12, 0)": 0.6546499729156494, "(12, 16)": 0.6307016611099243, "(14, 0)": 0.6546499729156494, "(14, 16)": 0.4759097993373871, "(16, 0)": 0.46920067071914673, "(16, 16)": 0.46920067071914673, "(18, 0)": 0.46920067071914673, "(18, 16)": 0.6468333005905151, "(20, 0)": 0.6468333005905151, "(20, 16)": 0.6468333005905151, "(22, 0)": 0.46920067071914673, "(22, 16)": 0.6468333005905151, "(24, 0)": 0.6546499729156494, "(24, 16)": 0.6546499729156494, "(26, 0)": 0.46920067071914673, "(26, 16)": 0.6468333005905151, "(28, 0)": 0.46920067071914673, "(28, 16)": 0.46920067071914673, "(30, 0)": 0.46920067071914673, "(30, 16)": 0.46920067071914673}, "r_span": [1028, 1081], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003312230110168457}}]}, {"id": "11523", "source_id": "15031", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided structured data, The Spot is a popular restaurant located in Carpinteria, California, serving a variety of cuisines including Mexican, American (Traditional), and Burgers. The establishment has a rating of 3.5 stars and offers both indoor and outdoor seating. While the restaurant does not accept credit cards, there is an ATM available on site. Reviewers have praised The Spot for its quick service and delicious food, particularly its onion rings and burgers. One reviewer even described it as \"top-tier.\" Another reviewer noted that the clam chowder is the real deal, and there are plenty of options available, including American, seafood, and Mexican dishes. Overall, The Spot appears to be a great spot for casual dining near the beach.", "response_spans": [[0, 511], [497, 763]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6531600952148438, "(0, 16)": 0.6531600952148438, "(2, 0)": 0.6531600952148438, "(2, 16)": 0.6531600952148438, "(4, 0)": 0.6531600952148438, "(4, 16)": 0.6531600952148438, "(6, 0)": 0.6531600952148438, "(6, 16)": 0.7761145830154419, "(8, 0)": 0.6531600952148438, "(8, 16)": 0.6531600952148438, "(10, 0)": 0.6531600952148438, "(10, 16)": 0.6531600952148438, "(12, 0)": 0.6531600952148438, "(12, 16)": 0.6531600952148438, "(14, 0)": 0.6531600952148438, "(14, 16)": 0.6531600952148438, "(16, 0)": 0.6531600952148438, "(16, 16)": 0.6531600952148438, "(18, 0)": 0.6531600952148438, "(18, 16)": 0.7761145830154419, "(20, 0)": 0.6463876366615295, "(20, 16)": 0.6531600952148438, "(22, 0)": 0.6531600952148438, "(22, 16)": 0.7761145830154419, "(24, 0)": 0.6531600952148438, "(24, 16)": 0.7761145830154419, "(26, 0)": 0.5241549611091614, "(26, 16)": 0.6531600952148438, "(28, 0)": 0.5241549611091614, "(28, 16)": 0.6531600952148438, "(30, 0)": 0.5241549611091614, "(30, 16)": 0.5241549611091614}, "r_span": [705, 821], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017739534378051758}}, {"prompt_attention_score": {"(0, 0)": 0.7959877252578735, "(0, 16)": 0.7959877252578735, "(2, 0)": 0.7959877252578735, "(2, 16)": 0.7959877252578735, "(4, 0)": 0.7959877252578735, "(4, 16)": 0.7959877252578735, "(6, 0)": 0.7959877252578735, "(6, 16)": 0.7959877252578735, "(8, 0)": 0.7959877252578735, "(8, 16)": 0.7959877252578735, "(10, 0)": 0.7959877252578735, "(10, 16)": 0.7959877252578735, "(12, 0)": 0.7959877252578735, "(12, 16)": 0.7959877252578735, "(14, 0)": 0.7959877252578735, "(14, 16)": 0.7959877252578735, "(16, 0)": 0.7959877252578735, "(16, 16)": 0.7959877252578735, "(18, 0)": 0.7959877252578735, "(18, 16)": 0.7959877252578735, "(20, 0)": 0.7959877252578735, "(20, 16)": 0.7959877252578735, "(22, 0)": 0.7959877252578735, "(22, 16)": 0.7959877252578735, "(24, 0)": 0.7959877252578735, "(24, 16)": 0.7959877252578735, "(26, 0)": 0.4326079487800598, "(26, 16)": 0.7959877252578735, "(28, 0)": 0.4326079487800598, "(28, 16)": 0.7959877252578735, "(30, 0)": 0.4326079487800598, "(30, 16)": 0.4326079487800598}, "r_span": [820, 886], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008513331413269043}}]}, {"id": "11907", "source_id": "14300", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is the answer to the question:\n\nHow do automotive technicians get paid?\n\nThe payment structure for automotive technicians varies depending on factors such as location, employer, and job specialty. According to passage 1, technicians who are paid on a flat-rate or flag-rate basis are entitled to overtime under the Fair Labor Standards Act (FLSA). However, the passage does not provide specific information on the average hourly rate or salary range for automotive technicians.\n\nPassage 2 mentions that automotive technicians in Alaska have the highest average pay among all states, with an average hourly rate of around $23.70 and an annual salary of approximately $49,400. Passage 3 provides information on the varying pay structures among different companies, with some offering hourly and commission pay rates, while others may use a combination of both. However, the passage does not provide specific data on the average hourly rate or salary range for automotive technicians.\n\nTherefore, based on the provided passages, it is unable to answer the question with confidence.", "response_spans": [[0, 108], [110, 514], [516, 1018], [1020, 1115]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6422874927520752, "(0, 16)": 0.6422874927520752, "(2, 0)": 0.6422874927520752, "(2, 16)": 0.6422874927520752, "(4, 0)": 0.6422874927520752, "(4, 16)": 0.6422874927520752, "(6, 0)": 0.580166220664978, "(6, 16)": 0.8963749408721924, "(8, 0)": 0.6946678161621094, "(8, 16)": 0.580166220664978, "(10, 0)": 0.580166220664978, "(10, 16)": 0.580166220664978, "(12, 0)": 0.580166220664978, "(12, 16)": 0.8963749408721924, "(14, 0)": 0.8963749408721924, "(14, 16)": 0.580166220664978, "(16, 0)": 0.8963749408721924, "(16, 16)": 0.6422874927520752, "(18, 0)": 0.580166220664978, "(18, 16)": 0.8963749408721924, "(20, 0)": 0.8963749408721924, "(20, 16)": 0.8963749408721924, "(22, 0)": 0.8963749408721924, "(22, 16)": 0.8963749408721924, "(24, 0)": 0.7539803981781006, "(24, 16)": 0.8963749408721924, "(26, 0)": 0.8963749408721924, "(26, 16)": 0.8963749408721924, "(28, 0)": 0.580166220664978, "(28, 16)": 0.8963749408721924, "(30, 0)": 0.8963749408721924, "(30, 16)": 0.8963749408721924}, "r_span": [497, 525], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00031441450119018555}}, {"prompt_attention_score": {"(0, 0)": 0.7080013155937195, "(0, 16)": 0.6401325464248657, "(2, 0)": 0.6401325464248657, "(2, 16)": 0.6401325464248657, "(4, 0)": 0.6401325464248657, "(4, 16)": 0.6401325464248657, "(6, 0)": 0.6401325464248657, "(6, 16)": 0.842261552810669, "(8, 0)": 0.7080013155937195, "(8, 16)": 0.6401325464248657, "(10, 0)": 0.7080013155937195, "(10, 16)": 0.842261552810669, "(12, 0)": 0.6401325464248657, "(12, 16)": 0.842261552810669, "(14, 0)": 0.7080013155937195, "(14, 16)": 0.842261552810669, "(16, 0)": 0.842261552810669, "(16, 16)": 0.7643639445304871, "(18, 0)": 0.7643639445304871, "(18, 16)": 0.842261552810669, "(20, 0)": 0.842261552810669, "(20, 16)": 0.7080013155937195, "(22, 0)": 0.7643639445304871, "(22, 16)": 0.842261552810669, "(24, 0)": 0.7080013155937195, "(24, 16)": 0.842261552810669, "(26, 0)": 0.7643639445304871, "(26, 16)": 0.7643639445304871, "(28, 0)": 0.7643639445304871, "(28, 16)": 0.7643639445304871, "(30, 0)": 0.7643639445304871, "(30, 16)": 0.7643639445304871}, "r_span": [527, 616], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001410841941833496}}, {"prompt_attention_score": {"(0, 0)": 0.8720787763595581, "(0, 16)": 0.8720787763595581, "(2, 0)": 0.6270480155944824, "(2, 16)": 0.8720787763595581, "(4, 0)": 0.6270480155944824, "(4, 16)": 0.6270480155944824, "(6, 0)": 0.8720787763595581, "(6, 16)": 0.8720787763595581, "(8, 0)": 0.8720787763595581, "(8, 16)": 0.8720787763595581, "(10, 0)": 0.8720787763595581, "(10, 16)": 0.6270480155944824, "(12, 0)": 0.8720787763595581, "(12, 16)": 0.8720787763595581, "(14, 0)": 0.8720787763595581, "(14, 16)": 0.8720787763595581, "(16, 0)": 0.8720787763595581, "(16, 16)": 0.7284791469573975, "(18, 0)": 0.7284791469573975, "(18, 16)": 0.6270480155944824, "(20, 0)": 0.8720787763595581, "(20, 16)": 0.8720787763595581, "(22, 0)": 0.7284791469573975, "(22, 16)": 0.6270480155944824, "(24, 0)": 0.8720787763595581, "(24, 16)": 0.6270480155944824, "(26, 0)": 0.7284791469573975, "(26, 16)": 0.7284791469573975, "(28, 0)": 0.7284791469573975, "(28, 16)": 0.7284791469573975, "(30, 0)": 0.7284791469573975, "(30, 16)": 0.7284791469573975}, "r_span": [618, 730], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00042003393173217773}}, {"prompt_attention_score": {"(0, 0)": 0.4193842113018036, "(0, 16)": 0.4193842113018036, "(2, 0)": 0.48352864384651184, "(2, 16)": 0.48352864384651184, "(4, 0)": 0.48352864384651184, "(4, 16)": 0.48352864384651184, "(6, 0)": 0.48352864384651184, "(6, 16)": 0.7934948205947876, "(8, 0)": 0.4193842113018036, "(8, 16)": 0.48352864384651184, "(10, 0)": 0.7934948205947876, "(10, 16)": 0.7934948205947876, "(12, 0)": 0.7934948205947876, "(12, 16)": 0.7934948205947876, "(14, 0)": 0.5165215730667114, "(14, 16)": 0.7934948205947876, "(16, 0)": 0.7934948205947876, "(16, 16)": 0.5165215730667114, "(18, 0)": 0.5165215730667114, "(18, 16)": 0.7934948205947876, "(20, 0)": 0.7934948205947876, "(20, 16)": 0.5165215730667114, "(22, 0)": 0.5165215730667114, "(22, 16)": 0.7934948205947876, "(24, 0)": 0.4193842113018036, "(24, 16)": 0.7934948205947876, "(26, 0)": 0.5165215730667114, "(26, 16)": 0.5165215730667114, "(28, 0)": 0.5165215730667114, "(28, 16)": 0.5165215730667114, "(30, 0)": 0.5165215730667114, "(30, 16)": 0.5165215730667114}, "r_span": [732, 752], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007668733596801758}}]}, {"id": "12015", "source_id": "14318", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main differences between tartrate and succinate are:\n\n1. Duration of action: Metoprolol succinate stays in the bloodstream for 24 hours, while metoprolol tartrate does not stay in the bloodstream as long and needs to be taken at regular intervals.\n2. Formation: Succinate is derived from succinic acid, while tartrate is derived from tartaric acid.\n\nTherefore, the answer to the question is:\n\nDifference between tartate and succinate: Succinate is derived from succinic acid, while tartrate is derived from tartaric acid; Succinate stays in the bloodstream for 24 hours, while tartrate does not.", "response_spans": [[0, 427], [429, 631]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9338012933731079, "(0, 16)": 0.9338012933731079, "(2, 0)": 0.9338012933731079, "(2, 16)": 0.9338012933731079, "(4, 0)": 0.9338012933731079, "(4, 16)": 0.9338012933731079, "(6, 0)": 0.9338012933731079, "(6, 16)": 0.9238847494125366, "(8, 0)": 0.9338012933731079, "(8, 16)": 0.9338012933731079, "(10, 0)": 0.41357216238975525, "(10, 16)": 0.41357216238975525, "(12, 0)": 0.9338012933731079, "(12, 16)": 0.9338012933731079, "(14, 0)": 0.9338012933731079, "(14, 16)": 0.41357216238975525, "(16, 0)": 0.7624014616012573, "(16, 16)": 0.9338012933731079, "(18, 0)": 0.41357216238975525, "(18, 16)": 0.9238847494125366, "(20, 0)": 0.9338012933731079, "(20, 16)": 0.9338012933731079, "(22, 0)": 0.833249568939209, "(22, 16)": 0.9238847494125366, "(24, 0)": 0.9338012933731079, "(24, 16)": 0.9238847494125366, "(26, 0)": 0.833249568939209, "(26, 16)": 0.833249568939209, "(28, 0)": 0.833249568939209, "(28, 16)": 0.9338012933731079, "(30, 0)": 0.833249568939209, "(30, 16)": 0.833249568939209}, "r_span": [589, 699], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018292069435119629}}, {"prompt_attention_score": {"(0, 0)": 0.8015888929367065, "(0, 16)": 0.8015888929367065, "(2, 0)": 0.8015888929367065, "(2, 16)": 0.5270925760269165, "(4, 0)": 0.5270925760269165, "(4, 16)": 0.8015888929367065, "(6, 0)": 0.8015888929367065, "(6, 16)": 0.9031504392623901, "(8, 0)": 0.8015888929367065, "(8, 16)": 0.8015888929367065, "(10, 0)": 0.8015888929367065, "(10, 16)": 0.8015888929367065, "(12, 0)": 0.8015888929367065, "(12, 16)": 0.9031504392623901, "(14, 0)": 0.8015888929367065, "(14, 16)": 0.4264794886112213, "(16, 0)": 0.8386383056640625, "(16, 16)": 0.7254762053489685, "(18, 0)": 0.7254762053489685, "(18, 16)": 0.9031504392623901, "(20, 0)": 0.9031504392623901, "(20, 16)": 0.8015888929367065, "(22, 0)": 0.7254762053489685, "(22, 16)": 0.9031504392623901, "(24, 0)": 0.8015888929367065, "(24, 16)": 0.9031504392623901, "(26, 0)": 0.7254762053489685, "(26, 16)": 0.7254762053489685, "(28, 0)": 0.7254762053489685, "(28, 16)": 0.8015888929367065, "(30, 0)": 0.7254762053489685, "(30, 16)": 0.7254762053489685}, "r_span": [701, 752], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00060272216796875}}]}, {"id": "12021", "source_id": "14319", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, DNA can be defined as follows:\n\n* A nucleic acid that contains the genetic instructions used in the development and functioning of all known living organisms and some viruses. (Passage 1)\n* Made up of molecules called nucleotides, each containing a phosphate group, a sugar group, and a nitrogen base. The order of these bases determines the genetic code. (Passage 2)\n* A double helix formed by base pairs attached to a sugar-phosphate backbone. (Passage 3)\n\nTherefore, the answer to the question \"What is DNA?\" is:\n\nDNA is a nucleic acid that contains the genetic instructions used in the development and functioning of all known living organisms and some viruses, composed of molecules called nucleotides, which are arranged in a specific order to determine the genetic code, and takes the form of a double helix.", "response_spans": [[0, 489], [491, 847]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8431816101074219, "(0, 16)": 0.8431816101074219, "(2, 0)": 0.8431816101074219, "(2, 16)": 0.8431816101074219, "(4, 0)": 0.8431816101074219, "(4, 16)": 0.8431816101074219, "(6, 0)": 0.8431816101074219, "(6, 16)": 0.8358469605445862, "(8, 0)": 0.8431816101074219, "(8, 16)": 0.8809893131256104, "(10, 0)": 0.8431816101074219, "(10, 16)": 0.8431816101074219, "(12, 0)": 0.8431816101074219, "(12, 16)": 0.8809893131256104, "(14, 0)": 0.8809893131256104, "(14, 16)": 0.8431816101074219, "(16, 0)": 0.8809893131256104, "(16, 16)": 0.8431816101074219, "(18, 0)": 0.46274834871292114, "(18, 16)": 0.8809893131256104, "(20, 0)": 0.8809893131256104, "(20, 16)": 0.8809893131256104, "(22, 0)": 0.8809893131256104, "(22, 16)": 0.8809893131256104, "(24, 0)": 0.8809893131256104, "(24, 16)": 0.8809893131256104, "(26, 0)": 0.8809893131256104, "(26, 16)": 0.8431816101074219, "(28, 0)": 0.8809893131256104, "(28, 16)": 0.8809893131256104, "(30, 0)": 0.8809893131256104, "(30, 16)": 0.8809893131256104}, "r_span": [585, 713], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002440154552459717}}, {"prompt_attention_score": {"(0, 0)": 0.7945089936256409, "(0, 16)": 0.7945089936256409, "(2, 0)": 0.7945089936256409, "(2, 16)": 0.7945089936256409, "(4, 0)": 0.7945089936256409, "(4, 16)": 0.7945089936256409, "(6, 0)": 0.7945089936256409, "(6, 16)": 0.8350521326065063, "(8, 0)": 0.7945089936256409, "(8, 16)": 0.7945089936256409, "(10, 0)": 0.4398736357688904, "(10, 16)": 0.7945089936256409, "(12, 0)": 0.8206034898757935, "(12, 16)": 0.8350521326065063, "(14, 0)": 0.8206034898757935, "(14, 16)": 0.4398736357688904, "(16, 0)": 0.7106677293777466, "(16, 16)": 0.8206034898757935, "(18, 0)": 0.8206034898757935, "(18, 16)": 0.7945089936256409, "(20, 0)": 0.8350521326065063, "(20, 16)": 0.8206034898757935, "(22, 0)": 0.8206034898757935, "(22, 16)": 0.7945089936256409, "(24, 0)": 0.8206034898757935, "(24, 16)": 0.7945089936256409, "(26, 0)": 0.8206034898757935, "(26, 16)": 0.8206034898757935, "(28, 0)": 0.8206034898757935, "(28, 16)": 0.8206034898757935, "(30, 0)": 0.8206034898757935, "(30, 16)": 0.8206034898757935}, "r_span": [715, 796], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007534623146057129}}]}, {"id": "12045", "source_id": "14323", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 335, "end": 394, "text": "5. Preheat the grill to high heat (unspecified in passages)", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of preheating the grill in high heat\nGenerative: \"Preheat the grill to high heat...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 467, "end": 698, "text": "7. Cook for 4-5 minutes per side, or until the internal temperature reaches your desired doneness (unspecified in passages)\n8. Remove from the grill and let rest for 5-10 minutes before slicing and serving (unspecified in passages)", "meta": "HIGH INTRO OF NEW INFO\nOriginal: These steps are not mentioned in the passages\nGenerative: Include steps such as cooking each side for 4-5 mins, and letting the steak rest for 10-15 mins.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to grill a Porterhouse steak:\n\n1. Dump a chimney of lit coals into the grill (Passage 1)\n2. Leave the section closest to you coal-free (Passage 2)\n3. Replace the grill grate (Passage 2)\n4. If using a gas grill, set it up for three-zone grilling (Passage 2)\n\nTo grill the Porterhouse steak:\n\n5. Preheat the grill to high heat (unspecified in passages)\n6. Place the Porterhouse steak on the grill, bone side down (Passage 3)\n7. Cook for 4-5 minutes per side, or until the internal temperature reaches your desired doneness (unspecified in passages)\n8. Remove from the grill and let rest for 5-10 minutes before slicing and serving (unspecified in passages)\n\nNote: The passages do not provide specific instructions for grilling the Porterhouse steak itself, so some trial and error may be required to achieve the desired level of doneness and flavor.", "response_spans": [[0, 333], [335, 698], [700, 891]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7296889424324036, "(0, 16)": 0.7296889424324036, "(2, 0)": 0.7296889424324036, "(2, 16)": 0.7296889424324036, "(4, 0)": 0.7296889424324036, "(4, 16)": 0.7296889424324036, "(6, 0)": 0.7296889424324036, "(6, 16)": 0.9118342399597168, "(8, 0)": 0.7296889424324036, "(8, 16)": 0.7296889424324036, "(10, 0)": 0.7296889424324036, "(10, 16)": 0.7296889424324036, "(12, 0)": 0.7296889424324036, "(12, 16)": 0.9118342399597168, "(14, 0)": 0.7296889424324036, "(14, 16)": 0.7296889424324036, "(16, 0)": 0.9118342399597168, "(16, 16)": 0.7296889424324036, "(18, 0)": 0.7296889424324036, "(18, 16)": 0.9118342399597168, "(20, 0)": 0.9118342399597168, "(20, 16)": 0.7296889424324036, "(22, 0)": 0.7296889424324036, "(22, 16)": 0.9118342399597168, "(24, 0)": 0.7296889424324036, "(24, 16)": 0.9118342399597168, "(26, 0)": 0.7296889424324036, "(26, 16)": 0.7296889424324036, "(28, 0)": 0.7296889424324036, "(28, 16)": 0.7296889424324036, "(30, 0)": 0.7296889424324036, "(30, 16)": 0.7296889424324036}, "r_span": [392, 507], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002121269702911377}}, {"prompt_attention_score": {"(0, 0)": 0.7026773691177368, "(0, 16)": 0.7026773691177368, "(2, 0)": 0.7026773691177368, "(2, 16)": 0.7026773691177368, "(4, 0)": 0.7026773691177368, "(4, 16)": 0.7026773691177368, "(6, 0)": 0.7026773691177368, "(6, 16)": 0.7685238122940063, "(8, 0)": 0.7026773691177368, "(8, 16)": 0.7026773691177368, "(10, 0)": 0.7026773691177368, "(10, 16)": 0.7026773691177368, "(12, 0)": 0.7026773691177368, "(12, 16)": 0.7026773691177368, "(14, 0)": 0.7026773691177368, "(14, 16)": 0.7026773691177368, "(16, 0)": 0.7026773691177368, "(16, 16)": 0.7026773691177368, "(18, 0)": 0.7026773691177368, "(18, 16)": 0.7026773691177368, "(20, 0)": 0.7026773691177368, "(20, 16)": 0.7026773691177368, "(22, 0)": 0.7026773691177368, "(22, 16)": 0.7026773691177368, "(24, 0)": 0.7026773691177368, "(24, 16)": 0.7026773691177368, "(26, 0)": 0.7026773691177368, "(26, 16)": 0.7026773691177368, "(28, 0)": 0.7026773691177368, "(28, 16)": 0.7026773691177368, "(30, 0)": 0.7026773691177368, "(30, 16)": 0.7026773691177368}, "r_span": [509, 616], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015935301780700684}}, {"prompt_attention_score": {"(0, 0)": 0.6816883087158203, "(0, 16)": 0.6816883087158203, "(2, 0)": 0.6816883087158203, "(2, 16)": 0.6816883087158203, "(4, 0)": 0.6816883087158203, "(4, 16)": 0.6816883087158203, "(6, 0)": 0.6816883087158203, "(6, 16)": 0.6816883087158203, "(8, 0)": 0.6816883087158203, "(8, 16)": 0.6816883087158203, "(10, 0)": 0.6816883087158203, "(10, 16)": 0.6816883087158203, "(12, 0)": 0.6816883087158203, "(12, 16)": 0.6816883087158203, "(14, 0)": 0.6816883087158203, "(14, 16)": 0.6816883087158203, "(16, 0)": 0.6816883087158203, "(16, 16)": 0.6816883087158203, "(18, 0)": 0.6816883087158203, "(18, 16)": 0.6816883087158203, "(20, 0)": 0.6816883087158203, "(20, 16)": 0.6816883087158203, "(22, 0)": 0.6816883087158203, "(22, 16)": 0.6816883087158203, "(24, 0)": 0.6816883087158203, "(24, 16)": 0.6816883087158203, "(26, 0)": 0.6816883087158203, "(26, 16)": 0.6816883087158203, "(28, 0)": 0.6816883087158203, "(28, 16)": 0.6816883087158203, "(30, 0)": 0.6816883087158203, "(30, 16)": 0.6816883087158203}, "r_span": [618, 659], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004906058311462402}}]}, {"id": "12069", "source_id": "14327", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is the answer to the question:\n\nMagellan of Virginia does offer continuing education clock hours/credits for their e-learning courses. According to passage 1, Magellan is approved to offer CE clock hours/credits by the American Psychological Association (APA) and the Association of Social Work Boards (ASWB).\n\nAdditionally, Magellan of Virginia has been selected by the Virginia Department of Medical Assistance Services (DMAS) to serve as the Behavioral Health Services Administrator (BHSA) for members enrolled in Virginia's Medicaid and FAMIS programs. This is mentioned in passage 2.\n\nFinally, Magellan of Virginia offers a Provider Q&A Session every Friday from 1 p.m. - 2:30 p.m. for providers to address their questions and issues. This is mentioned in passage 3.", "response_spans": [[0, 346], [348, 808]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7382959127426147, "(0, 16)": 0.7382959127426147, "(2, 0)": 0.7382959127426147, "(2, 16)": 0.7382959127426147, "(4, 0)": 0.7382959127426147, "(4, 16)": 0.7382959127426147, "(6, 0)": 0.7382959127426147, "(6, 16)": 0.9319485425949097, "(8, 0)": 0.6657179594039917, "(8, 16)": 0.7382959127426147, "(10, 0)": 0.7382959127426147, "(10, 16)": 0.7382959127426147, "(12, 0)": 0.7382959127426147, "(12, 16)": 0.9319485425949097, "(14, 0)": 0.6657179594039917, "(14, 16)": 0.7382959127426147, "(16, 0)": 0.7557761073112488, "(16, 16)": 0.7382959127426147, "(18, 0)": 0.7382959127426147, "(18, 16)": 0.9319485425949097, "(20, 0)": 0.9319485425949097, "(20, 16)": 0.6657179594039917, "(22, 0)": 0.6657179594039917, "(22, 16)": 0.9319485425949097, "(24, 0)": 0.6657179594039917, "(24, 16)": 0.9319485425949097, "(26, 0)": 0.6657179594039917, "(26, 16)": 0.6657179594039917, "(28, 0)": 0.6657179594039917, "(28, 16)": 0.6657179594039917, "(30, 0)": 0.6657179594039917, "(30, 16)": 0.6657179594039917}, "r_span": [408, 488], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003084540367126465}}, {"prompt_attention_score": {"(0, 0)": 0.7710578441619873, "(0, 16)": 0.7710578441619873, "(2, 0)": 0.7710578441619873, "(2, 16)": 0.7710578441619873, "(4, 0)": 0.7710578441619873, "(4, 16)": 0.7710578441619873, "(6, 0)": 0.7710578441619873, "(6, 16)": 0.8986049294471741, "(8, 0)": 0.7710578441619873, "(8, 16)": 0.8986049294471741, "(10, 0)": 0.7710578441619873, "(10, 16)": 0.7710578441619873, "(12, 0)": 0.8986049294471741, "(12, 16)": 0.8986049294471741, "(14, 0)": 0.8986049294471741, "(14, 16)": 0.7710578441619873, "(16, 0)": 0.7710578441619873, "(16, 16)": 0.7710578441619873, "(18, 0)": 0.7710578441619873, "(18, 16)": 0.8986049294471741, "(20, 0)": 0.7710578441619873, "(20, 16)": 0.8986049294471741, "(22, 0)": 0.8986049294471741, "(22, 16)": 0.7710578441619873, "(24, 0)": 0.8986049294471741, "(24, 16)": 0.8986049294471741, "(26, 0)": 0.8986049294471741, "(26, 16)": 0.8986049294471741, "(28, 0)": 0.8986049294471741, "(28, 16)": 0.8986049294471741, "(30, 0)": 0.8986049294471741, "(30, 16)": 0.8986049294471741}, "r_span": [490, 609], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0020033717155456543}}]}, {"id": "12105", "source_id": "14334", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to fix a door that won't lock:\n\nPassage 1 provides tips on how to repair stuck or frozen door locks, keys that don‚Äôt work, and latches that don‚Äôt latch. However, it does not specifically address the issue of a door that won't lock.\n\nPassage 2 provides instructions on how to fix a door that won't shut or lock properly by removing the door stop on the striker side of the jamb and aligning it back on. This method might work for doors that won't lock due to a misaligned door stop.\n\nPassage 3 provides additional troubleshooting steps for when a door latch won't catch due to misalignment with the strike plate. This passage suggests enlarging the latch hole in the jamb, tightening the hinges, and moving the strike plate to align with the latch.\n\nIn summary, there is no definitive solution in the provided passages to fix a door that won't lock directly. However, these passages provide general tips and troubleshooting steps that may help identify and resolve related issues such as misaligned door stops or latches. If the problem persists after trying these methods, it may be best to consult a professional locksmith or carpenter.", "response_spans": [[0, 275], [277, 525], [527, 791], [793, 1181]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7120374441146851, "(0, 16)": 0.7120374441146851, "(2, 0)": 0.7120374441146851, "(2, 16)": 0.7120374441146851, "(4, 0)": 0.7120374441146851, "(4, 16)": 0.7120374441146851, "(6, 0)": 0.7120374441146851, "(6, 16)": 0.8836954832077026, "(8, 0)": 0.6470515727996826, "(8, 16)": 0.7120374441146851, "(10, 0)": 0.5953127145767212, "(10, 16)": 0.5953127145767212, "(12, 0)": 0.5953127145767212, "(12, 16)": 0.8836954832077026, "(14, 0)": 0.7120374441146851, "(14, 16)": 0.5953127145767212, "(16, 0)": 0.8112828135490417, "(16, 16)": 0.8112828135490417, "(18, 0)": 0.5953127145767212, "(18, 16)": 0.8836954832077026, "(20, 0)": 0.8836954832077026, "(20, 16)": 0.7120374441146851, "(22, 0)": 0.8112828135490417, "(22, 16)": 0.8836954832077026, "(24, 0)": 0.7120374441146851, "(24, 16)": 0.8836954832077026, "(26, 0)": 0.8112828135490417, "(26, 16)": 0.8836954832077026, "(28, 0)": 0.8112828135490417, "(28, 16)": 0.7120374441146851, "(30, 0)": 0.7120374441146851, "(30, 16)": 0.8112828135490417}, "r_span": [612, 689], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0021033883094787598}}, {"prompt_attention_score": {"(0, 0)": 0.7699856758117676, "(0, 16)": 0.7699856758117676, "(2, 0)": 0.7699856758117676, "(2, 16)": 0.7699856758117676, "(4, 0)": 0.7699856758117676, "(4, 16)": 0.7699856758117676, "(6, 0)": 0.7699856758117676, "(6, 16)": 0.8198889493942261, "(8, 0)": 0.7699856758117676, "(8, 16)": 0.7699856758117676, "(10, 0)": 0.7699856758117676, "(10, 16)": 0.7699856758117676, "(12, 0)": 0.7699856758117676, "(12, 16)": 0.8198889493942261, "(14, 0)": 0.7699856758117676, "(14, 16)": 0.7699856758117676, "(16, 0)": 0.8198889493942261, "(16, 16)": 0.7732317447662354, "(18, 0)": 0.8198889493942261, "(18, 16)": 0.8198889493942261, "(20, 0)": 0.8198889493942261, "(20, 16)": 0.7699856758117676, "(22, 0)": 0.7732317447662354, "(22, 16)": 0.8198889493942261, "(24, 0)": 0.7699856758117676, "(24, 16)": 0.8198889493942261, "(26, 0)": 0.7732317447662354, "(26, 16)": 0.7699856758117676, "(28, 0)": 0.7732317447662354, "(28, 16)": 0.7699856758117676, "(30, 0)": 0.7699856758117676, "(30, 16)": 0.7732317447662354}, "r_span": [691, 751], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011532902717590332}}, {"prompt_attention_score": {"(0, 0)": 0.9358510971069336, "(0, 16)": 0.9358510971069336, "(2, 0)": 0.9358510971069336, "(2, 16)": 0.9358510971069336, "(4, 0)": 0.5324492454528809, "(4, 16)": 0.9358510971069336, "(6, 0)": 0.9358510971069336, "(6, 16)": 0.9358510971069336, "(8, 0)": 0.9358510971069336, "(8, 16)": 0.9358510971069336, "(10, 0)": 0.9358510971069336, "(10, 16)": 0.9358510971069336, "(12, 0)": 0.9358510971069336, "(12, 16)": 0.9358510971069336, "(14, 0)": 0.9358510971069336, "(14, 16)": 0.9358510971069336, "(16, 0)": 0.9358510971069336, "(16, 16)": 0.9358510971069336, "(18, 0)": 0.5324492454528809, "(18, 16)": 0.9358510971069336, "(20, 0)": 0.9358510971069336, "(20, 16)": 0.9358510971069336, "(22, 0)": 0.9358510971069336, "(22, 16)": 0.9358510971069336, "(24, 0)": 0.9358510971069336, "(24, 16)": 0.9358510971069336, "(26, 0)": 0.7186635732650757, "(26, 16)": 0.9358510971069336, "(28, 0)": 0.7186635732650757, "(28, 16)": 0.9358510971069336, "(30, 0)": 0.9358510971069336, "(30, 16)": 0.7186635732650757}, "r_span": [753, 817], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011500120162963867}}, {"prompt_attention_score": {"(0, 0)": 0.7503405809402466, "(0, 16)": 0.7503405809402466, "(2, 0)": 0.7503405809402466, "(2, 16)": 0.7503405809402466, "(4, 0)": 0.7503405809402466, "(4, 16)": 0.7503405809402466, "(6, 0)": 0.7503405809402466, "(6, 16)": 0.8121230006217957, "(8, 0)": 0.7503405809402466, "(8, 16)": 0.7503405809402466, "(10, 0)": 0.574105441570282, "(10, 16)": 0.574105441570282, "(12, 0)": 0.7503405809402466, "(12, 16)": 0.574105441570282, "(14, 0)": 0.7503405809402466, "(14, 16)": 0.574105441570282, "(16, 0)": 0.8078036308288574, "(16, 16)": 0.8078036308288574, "(18, 0)": 0.8078036308288574, "(18, 16)": 0.8121230006217957, "(20, 0)": 0.8121230006217957, "(20, 16)": 0.7503405809402466, "(22, 0)": 0.8078036308288574, "(22, 16)": 0.8121230006217957, "(24, 0)": 0.7503405809402466, "(24, 16)": 0.574105441570282, "(26, 0)": 0.8078036308288574, "(26, 16)": 0.8078036308288574, "(28, 0)": 0.8078036308288574, "(28, 16)": 0.7503405809402466, "(30, 0)": 0.7503405809402466, "(30, 16)": 0.8078036308288574}, "r_span": [819, 902], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.004268348217010498}}]}, {"id": "12135", "source_id": "14339", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to cook pollock:\n\nPassage 1:\n\n* Spray a baking sheet with butter-flavored cooking spray.\n* Season the pollock fillets with paprika and black pepper.\n* Place the fillets on the baking sheet and layer them with onion, green pepper, and tomato slices.\n* Bake in the preheated oven for about 15 minutes or until the fish has cooked and flakes easily.\n\nPassage 2:\n\n* Preheat the oven to 350 degrees F (175 degrees C).\n* Season the pollock fillets with paprika and black pepper.\n* Bake the fillets in the preheated oven for about 15 minutes or until the fish has cooked and flakes easily.\n\nPassage 3:\n\n* Bake the pollock fillets in the preheated oven for about 15 minutes or until the fish has cooked and flakes easily.\n* Turn off the oven and place two slices of cheese on top of each fillet.\n* Return the fish to the oven and allow the cheese to melt for about 3 minutes.\n\nTherefore, to cook pollock, you can follow these steps:\n\n1. Season the pollock fillets with paprika and black pepper.\n2. Place the fillets on a baking sheet or in the oven.\n3. Cook the pollock until it flakes easily, either by baking it in the oven or on the stovetop.\n4. Add cheese to the pollock if desired and return it to the oven to melt the cheese.", "response_spans": [[0, 402], [392, 638], [628, 968], [970, 1267]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9253347516059875, "(0, 16)": 0.9253347516059875, "(2, 0)": 0.9253347516059875, "(2, 16)": 0.9253347516059875, "(4, 0)": 0.9253347516059875, "(4, 16)": 0.9253347516059875, "(6, 0)": 0.9253347516059875, "(6, 16)": 0.9839226007461548, "(8, 0)": 0.9253347516059875, "(8, 16)": 0.9839226007461548, "(10, 0)": 0.9253347516059875, "(10, 16)": 0.9253347516059875, "(12, 0)": 0.9253347516059875, "(12, 16)": 0.9839226007461548, "(14, 0)": 0.9253347516059875, "(14, 16)": 0.9253347516059875, "(16, 0)": 0.9839226007461548, "(16, 16)": 0.9253347516059875, "(18, 0)": 0.387245774269104, "(18, 16)": 0.9839226007461548, "(20, 0)": 0.9839226007461548, "(20, 16)": 0.9253347516059875, "(22, 0)": 0.9253347516059875, "(22, 16)": 0.9839226007461548, "(24, 0)": 0.9253347516059875, "(24, 16)": 0.9839226007461548, "(26, 0)": 0.9253347516059875, "(26, 16)": 0.9839226007461548, "(28, 0)": 0.9253347516059875, "(28, 16)": 0.9253347516059875, "(30, 0)": 0.9253347516059875, "(30, 16)": 0.9253347516059875}, "r_span": [341, 466], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014609098434448242}}, {"prompt_attention_score": {"(0, 0)": 0.9870923161506653, "(0, 16)": 0.9870923161506653, "(2, 0)": 0.9870923161506653, "(2, 16)": 0.9870923161506653, "(4, 0)": 0.9870923161506653, "(4, 16)": 0.9870923161506653, "(6, 0)": 0.9068748950958252, "(6, 16)": 0.9870923161506653, "(8, 0)": 0.9870923161506653, "(8, 16)": 0.9068748950958252, "(10, 0)": 0.9870923161506653, "(10, 16)": 0.9870923161506653, "(12, 0)": 0.9870923161506653, "(12, 16)": 0.9870923161506653, "(14, 0)": 0.9870923161506653, "(14, 16)": 0.9870923161506653, "(16, 0)": 0.9870923161506653, "(16, 16)": 0.9068748950958252, "(18, 0)": 0.9068748950958252, "(18, 16)": 0.9870923161506653, "(20, 0)": 0.9870923161506653, "(20, 16)": 0.9870923161506653, "(22, 0)": 0.9870923161506653, "(22, 16)": 0.9870923161506653, "(24, 0)": 0.9870923161506653, "(24, 16)": 0.9870923161506653, "(26, 0)": 0.9870923161506653, "(26, 16)": 0.9870923161506653, "(28, 0)": 0.9870923161506653, "(28, 16)": 0.9870923161506653, "(30, 0)": 0.9870923161506653, "(30, 16)": 0.9870923161506653}, "r_span": [461, 545], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00019687414169311523}}, {"prompt_attention_score": {"(0, 0)": 0.9554039239883423, "(0, 16)": 0.9554039239883423, "(2, 0)": 0.9554039239883423, "(2, 16)": 0.9554039239883423, "(4, 0)": 0.9554039239883423, "(4, 16)": 0.9554039239883423, "(6, 0)": 0.9554039239883423, "(6, 16)": 0.9554039239883423, "(8, 0)": 0.9554039239883423, "(8, 16)": 0.9554039239883423, "(10, 0)": 0.9554039239883423, "(10, 16)": 0.9554039239883423, "(12, 0)": 0.9554039239883423, "(12, 16)": 0.9554039239883423, "(14, 0)": 0.9554039239883423, "(14, 16)": 0.9554039239883423, "(16, 0)": 0.9554039239883423, "(16, 16)": 0.9136677384376526, "(18, 0)": 0.9554039239883423, "(18, 16)": 0.9554039239883423, "(20, 0)": 0.9554039239883423, "(20, 16)": 0.9554039239883423, "(22, 0)": 0.9554039239883423, "(22, 16)": 0.9554039239883423, "(24, 0)": 0.9554039239883423, "(24, 16)": 0.9554039239883423, "(26, 0)": 0.9554039239883423, "(26, 16)": 0.9136677384376526, "(28, 0)": 0.9554039239883423, "(28, 16)": 0.9554039239883423, "(30, 0)": 0.9554039239883423, "(30, 16)": 0.9554039239883423}, "r_span": [540, 641], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010459423065185547}}, {"prompt_attention_score": {"(0, 0)": 0.886231005191803, "(0, 16)": 0.886231005191803, "(2, 0)": 0.886231005191803, "(2, 16)": 0.886231005191803, "(4, 0)": 0.9189118146896362, "(4, 16)": 0.9189118146896362, "(6, 0)": 0.886231005191803, "(6, 16)": 0.9189118146896362, "(8, 0)": 0.886231005191803, "(8, 16)": 0.886231005191803, "(10, 0)": 0.886231005191803, "(10, 16)": 0.9189118146896362, "(12, 0)": 0.886231005191803, "(12, 16)": 0.886231005191803, "(14, 0)": 0.886231005191803, "(14, 16)": 0.886231005191803, "(16, 0)": 0.9189118146896362, "(16, 16)": 0.886231005191803, "(18, 0)": 0.3380310535430908, "(18, 16)": 0.9189118146896362, "(20, 0)": 0.886231005191803, "(20, 16)": 0.886231005191803, "(22, 0)": 0.886231005191803, "(22, 16)": 0.886231005191803, "(24, 0)": 0.886231005191803, "(24, 16)": 0.886231005191803, "(26, 0)": 0.886231005191803, "(26, 16)": 0.886231005191803, "(28, 0)": 0.886231005191803, "(28, 16)": 0.886231005191803, "(30, 0)": 0.886231005191803, "(30, 16)": 0.886231005191803}, "r_span": [643, 734], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00015223026275634766}}]}, {"id": "12183", "source_id": "14347", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to remove plastic from a clothes dryer:\n\n1. Run the dryer on a regular setting for 20 minutes to soften the plastic, then scrape it off with a wooden or plastic spatula or paint scraper. (Passage 1)\n2. Heat the plastic with a hair dryer or heat gun to make it easier to peel off. Once heated, use a cloth to peel off the plastic. (Passage 2)\n3. Soak a cloth in an acetone-based nail polish remover and use it to scrub the remaining plastic off of the element after leaving it on the element for 5 minutes. Then, wipe the coils with a clean, damp cloth and remove any remaining residue with a cloth dipped in a solution of warm water and dish soap. (Passage 3)\n\nUnable to answer based on the given passages. The passages do not provide specific instructions on how to remove plastic from the drum of a clothes dryer.", "response_spans": [[0, 90], [92, 392], [393, 710], [712, 866]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6489683389663696, "(0, 16)": 0.6489683389663696, "(2, 0)": 0.6489683389663696, "(2, 16)": 0.6489683389663696, "(4, 0)": 0.6489683389663696, "(4, 16)": 0.44289645552635193, "(6, 0)": 0.44289645552635193, "(6, 16)": 0.8704202175140381, "(8, 0)": 0.6489683389663696, "(8, 16)": 0.44289645552635193, "(10, 0)": 0.44289645552635193, "(10, 16)": 0.44289645552635193, "(12, 0)": 0.44289645552635193, "(12, 16)": 0.8704202175140381, "(14, 0)": 0.777569591999054, "(14, 16)": 0.44289645552635193, "(16, 0)": 0.8704202175140381, "(16, 16)": 0.777569591999054, "(18, 0)": 0.44289645552635193, "(18, 16)": 0.8704202175140381, "(20, 0)": 0.8704202175140381, "(20, 16)": 0.777569591999054, "(22, 0)": 0.777569591999054, "(22, 16)": 0.6277850866317749, "(24, 0)": 0.777569591999054, "(24, 16)": 0.777569591999054, "(26, 0)": 0.777569591999054, "(26, 16)": 0.777569591999054, "(28, 0)": 0.44289645552635193, "(28, 16)": 0.777569591999054, "(30, 0)": 0.777569591999054, "(30, 16)": 0.777569591999054}, "r_span": [730, 752], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016978979110717773}}, {"prompt_attention_score": {"(0, 0)": 0.7215125560760498, "(0, 16)": 0.7215125560760498, "(2, 0)": 0.7215125560760498, "(2, 16)": 0.7215125560760498, "(4, 0)": 0.7215125560760498, "(4, 16)": 0.7215125560760498, "(6, 0)": 0.7215125560760498, "(6, 16)": 0.871570348739624, "(8, 0)": 0.7215125560760498, "(8, 16)": 0.7215125560760498, "(10, 0)": 0.8044919967651367, "(10, 16)": 0.7215125560760498, "(12, 0)": 0.871570348739624, "(12, 16)": 0.871570348739624, "(14, 0)": 0.871570348739624, "(14, 16)": 0.871570348739624, "(16, 0)": 0.8044919967651367, "(16, 16)": 0.871570348739624, "(18, 0)": 0.871570348739624, "(18, 16)": 0.871570348739624, "(20, 0)": 0.871570348739624, "(20, 16)": 0.871570348739624, "(22, 0)": 0.871570348739624, "(22, 16)": 0.871570348739624, "(24, 0)": 0.871570348739624, "(24, 16)": 0.871570348739624, "(26, 0)": 0.871570348739624, "(26, 16)": 0.871570348739624, "(28, 0)": 0.871570348739624, "(28, 16)": 0.871570348739624, "(30, 0)": 0.871570348739624, "(30, 16)": 0.871570348739624}, "r_span": [754, 847], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014556646347045898}}, {"prompt_attention_score": {"(0, 0)": 0.9237138628959656, "(0, 16)": 0.9237138628959656, "(2, 0)": 0.9237138628959656, "(2, 16)": 0.9237138628959656, "(4, 0)": 0.9237138628959656, "(4, 16)": 0.9237138628959656, "(6, 0)": 0.9237138628959656, "(6, 16)": 0.9237138628959656, "(8, 0)": 0.9237138628959656, "(8, 16)": 0.9237138628959656, "(10, 0)": 0.9237138628959656, "(10, 16)": 0.9237138628959656, "(12, 0)": 0.7864777445793152, "(12, 16)": 0.9237138628959656, "(14, 0)": 0.7864777445793152, "(14, 16)": 0.9237138628959656, "(16, 0)": 0.9237138628959656, "(16, 16)": 0.7864777445793152, "(18, 0)": 0.382986843585968, "(18, 16)": 0.9237138628959656, "(20, 0)": 0.9237138628959656, "(20, 16)": 0.7864777445793152, "(22, 0)": 0.7864777445793152, "(22, 16)": 0.9237138628959656, "(24, 0)": 0.7864777445793152, "(24, 16)": 0.9237138628959656, "(26, 0)": 0.7864777445793152, "(26, 16)": 0.9237138628959656, "(28, 0)": 0.7864777445793152, "(28, 16)": 0.7864777445793152, "(30, 0)": 0.7864777445793152, "(30, 16)": 0.7864777445793152}, "r_span": [848, 934], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007249116897583008}}, {"prompt_attention_score": {"(0, 0)": 0.6843560338020325, "(0, 16)": 0.6843560338020325, "(2, 0)": 0.6843560338020325, "(2, 16)": 0.6843560338020325, "(4, 0)": 0.6843560338020325, "(4, 16)": 0.5387604236602783, "(6, 0)": 0.6843560338020325, "(6, 16)": 0.8704087734222412, "(8, 0)": 0.6843560338020325, "(8, 16)": 0.6843560338020325, "(10, 0)": 0.5387604236602783, "(10, 16)": 0.5387604236602783, "(12, 0)": 0.7896838188171387, "(12, 16)": 0.5387604236602783, "(14, 0)": 0.7896838188171387, "(14, 16)": 0.5387604236602783, "(16, 0)": 0.5387604236602783, "(16, 16)": 0.7896838188171387, "(18, 0)": 0.7896838188171387, "(18, 16)": 0.5387604236602783, "(20, 0)": 0.657874584197998, "(20, 16)": 0.7896838188171387, "(22, 0)": 0.7896838188171387, "(22, 16)": 0.7896838188171387, "(24, 0)": 0.7896838188171387, "(24, 16)": 0.5387604236602783, "(26, 0)": 0.7896838188171387, "(26, 16)": 0.6843560338020325, "(28, 0)": 0.7896838188171387, "(28, 16)": 0.7896838188171387, "(30, 0)": 0.7896838188171387, "(30, 16)": 0.7896838188171387}, "r_span": [936, 970], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00020194053649902344}}]}, {"id": "12219", "source_id": "14353", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 975, "end": 1035, "text": "Passage 3 does not provide instructions for folding a quilt.", "meta": "EVIDENT CONFLICT:\nAIGC: Passage 3 does not provide instructions for folding a quilt.\nOriginal: Passage 3 stated steps in folding a quilt.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to fold a quilt:\n\nPassage 1 provides instructions for sewing binding to the edges of a quilt. However, it does not provide instructions for folding the quilt itself. Therefore, I am unable to answer the question based on this passage alone.\n\nPassage 2 describes how to fold a quilt into thirds along the bias of the fabric. The steps are as follows:\n\n1. Lay the quilt on a flat surface.\n2. Fold the lower right corner up towards the center of the quilt, making sure the fold is on the bias.\n3. Fold the lower left corner up towards the center of the quilt, making sure the fold is on the bias.\n4. Fold the top left corner down towards the center of the quilt, making sure the fold is on the bias.\n5. Fold the top right corner down towards the center of the quilt, making sure the fold is on the bias.\n\nTherefore, based on Passage 2, you should fold a quilt by laying it flat and folding it in thirds along the bias of the fabric.\n\nPassage 3 does not provide instructions for folding a quilt.\n\nIn conclusion, based on the provided passages, the steps for folding a quilt are:\n\n1. Lay the quilt flat.\n2. Fold the quilt in thirds along the bias of the fabric.", "response_spans": [[0, 393], [395, 844], [846, 1200]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8691942691802979, "(0, 16)": 0.8691942691802979, "(2, 0)": 0.8691942691802979, "(2, 16)": 0.8691942691802979, "(4, 0)": 0.8691942691802979, "(4, 16)": 0.8691942691802979, "(6, 0)": 0.8691942691802979, "(6, 16)": 0.8796542882919312, "(8, 0)": 0.8796542882919312, "(8, 16)": 0.8691942691802979, "(10, 0)": 0.8691942691802979, "(10, 16)": 0.8691942691802979, "(12, 0)": 0.8691942691802979, "(12, 16)": 0.8796542882919312, "(14, 0)": 0.8796542882919312, "(14, 16)": 0.8691942691802979, "(16, 0)": 0.8796542882919312, "(16, 16)": 0.8796542882919312, "(18, 0)": 0.8691942691802979, "(18, 16)": 0.8796542882919312, "(20, 0)": 0.8796542882919312, "(20, 16)": 0.8796542882919312, "(22, 0)": 0.8796542882919312, "(22, 16)": 0.8796542882919312, "(24, 0)": 0.8796542882919312, "(24, 16)": 0.8796542882919312, "(26, 0)": 0.8796542882919312, "(26, 16)": 0.8796542882919312, "(28, 0)": 0.8796542882919312, "(28, 16)": 0.8796542882919312, "(30, 0)": 0.8796542882919312, "(30, 16)": 0.8796542882919312}, "r_span": [372, 470], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0028844475746154785}}, {"prompt_attention_score": {"(0, 0)": 0.9272140264511108, "(0, 16)": 0.9272140264511108, "(2, 0)": 0.9272140264511108, "(2, 16)": 0.9272140264511108, "(4, 0)": 0.9272140264511108, "(4, 16)": 0.9272140264511108, "(6, 0)": 0.8399561643600464, "(6, 16)": 0.7995924353599548, "(8, 0)": 0.9272140264511108, "(8, 16)": 0.9272140264511108, "(10, 0)": 0.9272140264511108, "(10, 16)": 0.9272140264511108, "(12, 0)": 0.8399561643600464, "(12, 16)": 0.9272140264511108, "(14, 0)": 0.8399561643600464, "(14, 16)": 0.9272140264511108, "(16, 0)": 0.9272140264511108, "(16, 16)": 0.8399561643600464, "(18, 0)": 0.8399561643600464, "(18, 16)": 0.9272140264511108, "(20, 0)": 0.9272140264511108, "(20, 16)": 0.8399561643600464, "(22, 0)": 0.8399561643600464, "(22, 16)": 0.9272140264511108, "(24, 0)": 0.8399561643600464, "(24, 16)": 0.7995924353599548, "(26, 0)": 0.8399561643600464, "(26, 16)": 0.8399561643600464, "(28, 0)": 0.8399561643600464, "(28, 16)": 0.8399561643600464, "(30, 0)": 0.8399561643600464, "(30, 16)": 0.8399561643600464}, "r_span": [472, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00027549266815185547}}, {"prompt_attention_score": {"(0, 0)": 0.8835161924362183, "(0, 16)": 0.8835161924362183, "(2, 0)": 0.8835161924362183, "(2, 16)": 0.8835161924362183, "(4, 0)": 0.8835161924362183, "(4, 16)": 0.8835161924362183, "(6, 0)": 0.8550204038619995, "(6, 16)": 0.8550204038619995, "(8, 0)": 0.8835161924362183, "(8, 16)": 0.8835161924362183, "(10, 0)": 0.8835161924362183, "(10, 16)": 0.8835161924362183, "(12, 0)": 0.8835161924362183, "(12, 16)": 0.8835161924362183, "(14, 0)": 0.8550204038619995, "(14, 16)": 0.8835161924362183, "(16, 0)": 0.8550204038619995, "(16, 16)": 0.8550204038619995, "(18, 0)": 0.8550204038619995, "(18, 16)": 0.8550204038619995, "(20, 0)": 0.8835161924362183, "(20, 16)": 0.8550204038619995, "(22, 0)": 0.8550204038619995, "(22, 16)": 0.8835161924362183, "(24, 0)": 0.8550204038619995, "(24, 16)": 0.8550204038619995, "(26, 0)": 0.8550204038619995, "(26, 16)": 0.8550204038619995, "(28, 0)": 0.8550204038619995, "(28, 16)": 0.8550204038619995, "(30, 0)": 0.8550204038619995, "(30, 16)": 0.8550204038619995}, "r_span": [598, 702], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 4.887580871582031e-05}}]}, {"id": "12231", "source_id": "14355", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the benefits of using a water pick (also known as a Waterpik) include:\n\n1. Helping to keep teeth, gums, mouth, and overall body healthier by eliminating germs and plaque.\n2. Being a great oral care tool for removing food from areas that brushing cannot access.\n3. Massaging and stimulating soft tissue in the mouth to reduce the risk of gingivitis.\n4. Being an alternative to flossing and potentially offering similar benefits.\n\nUnable to answer based on given passages. The passages do not provide information on other potential benefits of using a water pick, such as its ability to reach areas between teeth or its effectiveness in reducing plaque buildup.", "response_spans": [[0, 459], [461, 691]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8142735958099365, "(0, 16)": 0.8142735958099365, "(2, 0)": 0.8142735958099365, "(2, 16)": 0.8142735958099365, "(4, 0)": 0.8142735958099365, "(4, 16)": 0.8142735958099365, "(6, 0)": 0.8142735958099365, "(6, 16)": 0.8044747114181519, "(8, 0)": 0.8142735958099365, "(8, 16)": 0.8142735958099365, "(10, 0)": 0.8142735958099365, "(10, 16)": 0.8142735958099365, "(12, 0)": 0.8142735958099365, "(12, 16)": 0.8142735958099365, "(14, 0)": 0.8044747114181519, "(14, 16)": 0.8142735958099365, "(16, 0)": 0.8044747114181519, "(16, 16)": 0.8142735958099365, "(18, 0)": 0.8142735958099365, "(18, 16)": 0.8044747114181519, "(20, 0)": 0.8044747114181519, "(20, 16)": 0.8044747114181519, "(22, 0)": 0.8044747114181519, "(22, 16)": 0.8044747114181519, "(24, 0)": 0.8044747114181519, "(24, 16)": 0.8044747114181519, "(26, 0)": 0.8044747114181519, "(26, 16)": 0.8044747114181519, "(28, 0)": 0.8044747114181519, "(28, 16)": 0.8044747114181519, "(30, 0)": 0.8044747114181519, "(30, 16)": 0.8044747114181519}, "r_span": [386, 501], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.004492282867431641}}, {"prompt_attention_score": {"(0, 0)": 0.7914416193962097, "(0, 16)": 0.7914416193962097, "(2, 0)": 0.7914416193962097, "(2, 16)": 0.7914416193962097, "(4, 0)": 0.7914416193962097, "(4, 16)": 0.7914416193962097, "(6, 0)": 0.7914416193962097, "(6, 16)": 0.7470242381095886, "(8, 0)": 0.7914416193962097, "(8, 16)": 0.7470242381095886, "(10, 0)": 0.7914416193962097, "(10, 16)": 0.7914416193962097, "(12, 0)": 0.7914416193962097, "(12, 16)": 0.7914416193962097, "(14, 0)": 0.7470242381095886, "(14, 16)": 0.7914416193962097, "(16, 0)": 0.7914416193962097, "(16, 16)": 0.7914416193962097, "(18, 0)": 0.7914416193962097, "(18, 16)": 0.7914416193962097, "(20, 0)": 0.7914416193962097, "(20, 16)": 0.7470242381095886, "(22, 0)": 0.7470242381095886, "(22, 16)": 0.7914416193962097, "(24, 0)": 0.7470242381095886, "(24, 16)": 0.7914416193962097, "(26, 0)": 0.7470242381095886, "(26, 16)": 0.7470242381095886, "(28, 0)": 0.7470242381095886, "(28, 16)": 0.7470242381095886, "(30, 0)": 0.7470242381095886, "(30, 16)": 0.7470242381095886}, "r_span": [503, 551], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -3.93986701965332e-05}}]}, {"id": "12243", "source_id": "14357", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to keep birds from building nests on your porch:\n\n1. Attach bird netting to the eaves around the perimeter of your porch using a staple gun. This will prevent birds from reaching those spaces they often choose to build their nests, which can block your ventilation systems, are made from flammable materials, and bird droppings can transmit disease. (Passage 1:4)\n2. Install bird netting over the top of your light fixture to block the birds' access to it. Choose a netting that is non-flammable and safe to use around light bulbs, and make sure it is installed so that it doesn't entangle birds. (Passage 2:1)\n3. Mount a plastic hawk on or near your porch. The sight of a predator can scare the birds away from the area and keep them from inhabiting your porch. Move the plastic hawk periodically to keep the birds from becoming accustomed to its presence. (Passage 3:1)\n\nTherefore, based on the provided passages, you can keep birds from building nests on your porch by using bird netting, installing bird netting over your light fixture, or mounting a plastic hawk near your porch.", "response_spans": [[0, 99], [101, 414], [415, 922], [924, 1135]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7640382051467896, "(0, 16)": 0.7640382051467896, "(2, 0)": 0.7640382051467896, "(2, 16)": 0.7640382051467896, "(4, 0)": 0.7640382051467896, "(4, 16)": 0.7640382051467896, "(6, 0)": 0.7640382051467896, "(6, 16)": 0.8778784275054932, "(8, 0)": 0.7640382051467896, "(8, 16)": 0.4559480845928192, "(10, 0)": 0.4559480845928192, "(10, 16)": 0.4559480845928192, "(12, 0)": 0.4559480845928192, "(12, 16)": 0.8778784275054932, "(14, 0)": 0.6703238487243652, "(14, 16)": 0.8778784275054932, "(16, 0)": 0.8778784275054932, "(16, 16)": 0.7640382051467896, "(18, 0)": 0.4559480845928192, "(18, 16)": 0.8778784275054932, "(20, 0)": 0.8778784275054932, "(20, 16)": 0.6703238487243652, "(22, 0)": 0.6703238487243652, "(22, 16)": 0.8778784275054932, "(24, 0)": 0.6703238487243652, "(24, 16)": 0.8778784275054932, "(26, 0)": 0.6703238487243652, "(26, 16)": 0.6703238487243652, "(28, 0)": 0.6703238487243652, "(28, 16)": 0.6703238487243652, "(30, 0)": 0.6703238487243652, "(30, 16)": 0.6703238487243652}, "r_span": [511, 535], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002827644348144531}}, {"prompt_attention_score": {"(0, 0)": 0.8064723610877991, "(0, 16)": 0.8064723610877991, "(2, 0)": 0.8064723610877991, "(2, 16)": 0.8064723610877991, "(4, 0)": 0.8064723610877991, "(4, 16)": 0.8064723610877991, "(6, 0)": 0.8064723610877991, "(6, 16)": 0.9254571199417114, "(8, 0)": 0.8064723610877991, "(8, 16)": 0.7487490773200989, "(10, 0)": 0.8064723610877991, "(10, 16)": 0.8064723610877991, "(12, 0)": 0.7487490773200989, "(12, 16)": 0.9254571199417114, "(14, 0)": 0.7487490773200989, "(14, 16)": 0.8064723610877991, "(16, 0)": 0.9254571199417114, "(16, 16)": 0.8064723610877991, "(18, 0)": 0.7487490773200989, "(18, 16)": 0.9254571199417114, "(20, 0)": 0.9254571199417114, "(20, 16)": 0.7487490773200989, "(22, 0)": 0.7487490773200989, "(22, 16)": 0.9254571199417114, "(24, 0)": 0.7487490773200989, "(24, 16)": 0.9254571199417114, "(26, 0)": 0.7487490773200989, "(26, 16)": 0.7487490773200989, "(28, 0)": 0.7487490773200989, "(28, 16)": 0.7487490773200989, "(30, 0)": 0.7487490773200989, "(30, 16)": 0.7487490773200989}, "r_span": [537, 612], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005474090576171875}}, {"prompt_attention_score": {"(0, 0)": 0.8630064129829407, "(0, 16)": 0.8630064129829407, "(2, 0)": 0.8630064129829407, "(2, 16)": 0.8630064129829407, "(4, 0)": 0.8630064129829407, "(4, 16)": 0.8630064129829407, "(6, 0)": 0.8630064129829407, "(6, 16)": 0.8822150230407715, "(8, 0)": 0.8630064129829407, "(8, 16)": 0.8822150230407715, "(10, 0)": 0.8630064129829407, "(10, 16)": 0.8630064129829407, "(12, 0)": 0.8822150230407715, "(12, 16)": 0.8822150230407715, "(14, 0)": 0.8822150230407715, "(14, 16)": 0.8630064129829407, "(16, 0)": 0.8630064129829407, "(16, 16)": 0.8822150230407715, "(18, 0)": 0.8822150230407715, "(18, 16)": 0.8822150230407715, "(20, 0)": 0.8822150230407715, "(20, 16)": 0.8822150230407715, "(22, 0)": 0.8822150230407715, "(22, 16)": 0.8630064129829407, "(24, 0)": 0.8822150230407715, "(24, 16)": 0.8822150230407715, "(26, 0)": 0.8822150230407715, "(26, 16)": 0.8822150230407715, "(28, 0)": 0.8822150230407715, "(28, 16)": 0.8822150230407715, "(30, 0)": 0.8822150230407715, "(30, 16)": 0.8822150230407715}, "r_span": [613, 753], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016202330589294434}}, {"prompt_attention_score": {"(0, 0)": 0.7932313680648804, "(0, 16)": 0.7932313680648804, "(2, 0)": 0.7932313680648804, "(2, 16)": 0.7932313680648804, "(4, 0)": 0.7932313680648804, "(4, 16)": 0.7932313680648804, "(6, 0)": 0.7932313680648804, "(6, 16)": 0.8222872018814087, "(8, 0)": 0.7932313680648804, "(8, 16)": 0.7932313680648804, "(10, 0)": 0.7932313680648804, "(10, 16)": 0.7932313680648804, "(12, 0)": 0.7655189633369446, "(12, 16)": 0.7932313680648804, "(14, 0)": 0.7655189633369446, "(14, 16)": 0.39985525608062744, "(16, 0)": 0.8043144941329956, "(16, 16)": 0.7655189633369446, "(18, 0)": 0.7655189633369446, "(18, 16)": 0.7655189633369446, "(20, 0)": 0.7932313680648804, "(20, 16)": 0.7655189633369446, "(22, 0)": 0.7655189633369446, "(22, 16)": 0.7932313680648804, "(24, 0)": 0.7655189633369446, "(24, 16)": 0.7932313680648804, "(26, 0)": 0.7655189633369446, "(26, 16)": 0.7655189633369446, "(28, 0)": 0.7655189633369446, "(28, 16)": 0.7655189633369446, "(30, 0)": 0.7655189633369446, "(30, 16)": 0.7655189633369446}, "r_span": [755, 807], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 8.112192153930664e-05}}]}, {"id": "12261", "source_id": "14360", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 1140, "end": 1256, "text": "4. Click on the General tab.\n5. Under Browsing history, select Use the current tab.\n6. Click OK to save the changes.", "meta": "HIGH INTRO OF NEW INFO\nAIGC: 4. Click on the General tab.\n5. Under Browsing history, select Use the current tab.\n6. Click OK to save the changes.\nOriginal: These steps are not mentioned in the passage 3.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 97, "end": 316, "text": "Passage 1 provides the general steps to set the default web browser in Windows 7:\n\n1. Open Control Panel.\n2. Click on Internet Options.\n3. Click on the Connections tab.\n4. Select the default web browser you want to use.", "meta": "HIGH INTRO OF NEW INFO\nAIGC:1. Open Control Panel.\n2. Click on Internet Options.\n3. Click on the Connections tab.\n4. Select the default web browser you want to use.\nOriginal: These steps are not mentioned in the passage 1.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the steps to set the default browser to Windows are as follows:\n\nPassage 1 provides the general steps to set the default web browser in Windows 7:\n\n1. Open Control Panel.\n2. Click on Internet Options.\n3. Click on the Connections tab.\n4. Select the default web browser you want to use.\n\nHowever, Passage 2 provides more detailed steps for setting the default browser in Windows 10 using the Settings app:\n\n1. Open the Settings app by clicking on the Start menu and selecting the Settings icon or pressing the Windows + I keyboard shortcut.\n2. Click on the System option in the left-hand menu.\n3. Scroll down to the Default apps section and click on the Web browser option.\n4. Select the browser you want to make the default browser (e.g., Edge or Mozilla Firefox).\n5. Click on the Choose an app option and select the desired browser.\n\nPassage 3 provides specific instructions for setting Mozilla Firefox as the default browser:\n\n1. Open Mozilla Firefox.\n2. Click on the Firefox menu button (three horizontal lines in the upper right-hand corner of the browser window).\n3. Select Options from the pop-up menu.\n4. Click on the General tab.\n5. Under Browsing history, select Use the current tab.\n6. Click OK to save the changes.\n\nTherefore, to set the default browser to Windows using the provided passages, follow the steps outlined in Passage 2.", "response_spans": [[0, 435], [437, 864], [866, 1375]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8216578364372253, "(0, 16)": 0.8216578364372253, "(2, 0)": 0.8216578364372253, "(2, 16)": 0.8216578364372253, "(4, 0)": 0.8216578364372253, "(4, 16)": 0.8216578364372253, "(6, 0)": 0.8216578364372253, "(6, 16)": 0.8603187203407288, "(8, 0)": 0.8069112300872803, "(8, 16)": 0.8216578364372253, "(10, 0)": 0.8216578364372253, "(10, 16)": 0.8216578364372253, "(12, 0)": 0.8216578364372253, "(12, 16)": 0.8603187203407288, "(14, 0)": 0.8069112300872803, "(14, 16)": 0.8216578364372253, "(16, 0)": 0.8603187203407288, "(16, 16)": 0.8069112300872803, "(18, 0)": 0.8216578364372253, "(18, 16)": 0.8069112300872803, "(20, 0)": 0.8603187203407288, "(20, 16)": 0.8069112300872803, "(22, 0)": 0.8069112300872803, "(22, 16)": 0.8603187203407288, "(24, 0)": 0.8069112300872803, "(24, 16)": 0.8603187203407288, "(26, 0)": 0.8069112300872803, "(26, 16)": 0.8069112300872803, "(28, 0)": 0.8603187203407288, "(28, 16)": 0.8069112300872803, "(30, 0)": 0.8069112300872803, "(30, 16)": 0.8069112300872803}, "r_span": [434, 544], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0016466975212097168}}, {"prompt_attention_score": {"(0, 0)": 0.8154756426811218, "(0, 16)": 0.8154756426811218, "(2, 0)": 0.8154756426811218, "(2, 16)": 0.8154756426811218, "(4, 0)": 0.8154756426811218, "(4, 16)": 0.8154756426811218, "(6, 0)": 0.8154756426811218, "(6, 16)": 0.8931435346603394, "(8, 0)": 0.8931435346603394, "(8, 16)": 0.8154756426811218, "(10, 0)": 0.8154756426811218, "(10, 16)": 0.8154756426811218, "(12, 0)": 0.8931435346603394, "(12, 16)": 0.8931435346603394, "(14, 0)": 0.8931435346603394, "(14, 16)": 0.8931435346603394, "(16, 0)": 0.8931435346603394, "(16, 16)": 0.8931435346603394, "(18, 0)": 0.8931435346603394, "(18, 16)": 0.8931435346603394, "(20, 0)": 0.8931435346603394, "(20, 16)": 0.8931435346603394, "(22, 0)": 0.8931435346603394, "(22, 16)": 0.8931435346603394, "(24, 0)": 0.8931435346603394, "(24, 16)": 0.8931435346603394, "(26, 0)": 0.8931435346603394, "(26, 16)": 0.8931435346603394, "(28, 0)": 0.8931435346603394, "(28, 16)": 0.8931435346603394, "(30, 0)": 0.8931435346603394, "(30, 16)": 0.8931435346603394}, "r_span": [546, 646], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.004265844821929932}}, {"prompt_attention_score": {"(0, 0)": 0.7581292986869812, "(0, 16)": 0.9509848356246948, "(2, 0)": 0.9509848356246948, "(2, 16)": 0.9509848356246948, "(4, 0)": 0.9509848356246948, "(4, 16)": 0.9509848356246948, "(6, 0)": 0.9509848356246948, "(6, 16)": 0.9509848356246948, "(8, 0)": 0.7581292986869812, "(8, 16)": 0.9509848356246948, "(10, 0)": 0.9509848356246948, "(10, 16)": 0.9509848356246948, "(12, 0)": 0.9509848356246948, "(12, 16)": 0.9509848356246948, "(14, 0)": 0.7581292986869812, "(14, 16)": 0.9509848356246948, "(16, 0)": 0.9509848356246948, "(16, 16)": 0.7581292986869812, "(18, 0)": 0.7581292986869812, "(18, 16)": 0.9509848356246948, "(20, 0)": 0.9509848356246948, "(20, 16)": 0.7581292986869812, "(22, 0)": 0.7581292986869812, "(22, 16)": 0.9509848356246948, "(24, 0)": 0.7581292986869812, "(24, 16)": 0.9509848356246948, "(26, 0)": 0.7581292986869812, "(26, 16)": 0.7581292986869812, "(28, 0)": 0.7581292986869812, "(28, 16)": 0.7581292986869812, "(30, 0)": 0.7581292986869812, "(30, 16)": 0.7581292986869812}, "r_span": [648, 773], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0024347901344299316}}]}, {"id": "12297", "source_id": "14366", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 263, "end": 483, "text": "2. Burn the flag in a proper ceremony. If you are able to personally discharge your worn flag from service, the ceremony that follows is the proper way. The flag must be folded in the customary triangle fold. (Passage 2)", "meta": "EVIDENT CONFLICT:\nAIGC: 2. Burn the flag in a proper ceremony.....folded in the customary triangle fold. (Passage 2)\nOriginal: This information is mentioned in passage 3.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the proper way to dispose of a worn USA flag is as follows:\n\n1. Remove the blue field from the flag and then place the flag out for collection. The blue field should be burned in a peaceful manner and the ashes buried. (Passage 1)\n2. Burn the flag in a proper ceremony. If you are able to personally discharge your worn flag from service, the ceremony that follows is the proper way. The flag must be folded in the customary triangle fold. (Passage 2)\n\nTherefore, the proper way to dispose of a worn USA flag is through burning it in a peaceful manner during a proper ceremony, or by placing it out for collection after removing the blue field and then properly disposing of the blue field through burning.", "response_spans": [[0, 483], [485, 738]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8431655764579773, "(0, 16)": 0.8431655764579773, "(2, 0)": 0.8431655764579773, "(2, 16)": 0.8431655764579773, "(4, 0)": 0.8431655764579773, "(4, 16)": 0.8431655764579773, "(6, 0)": 0.8431655764579773, "(6, 16)": 0.9576703310012817, "(8, 0)": 0.9576703310012817, "(8, 16)": 0.8431655764579773, "(10, 0)": 0.8431655764579773, "(10, 16)": 0.8431655764579773, "(12, 0)": 0.8431655764579773, "(12, 16)": 0.8431655764579773, "(14, 0)": 0.9576703310012817, "(14, 16)": 0.8431655764579773, "(16, 0)": 0.9576703310012817, "(16, 16)": 0.8431655764579773, "(18, 0)": 0.8431655764579773, "(18, 16)": 0.9576703310012817, "(20, 0)": 0.9576703310012817, "(20, 16)": 0.8431655764579773, "(22, 0)": 0.8431655764579773, "(22, 16)": 0.9576703310012817, "(24, 0)": 0.8431655764579773, "(24, 16)": 0.9576703310012817, "(26, 0)": 0.8431655764579773, "(26, 16)": 0.9576703310012817, "(28, 0)": 0.7275397777557373, "(28, 16)": 0.8431655764579773, "(30, 0)": 0.8431655764579773, "(30, 16)": 0.8431655764579773}, "r_span": [297, 417], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0027802586555480957}}, {"prompt_attention_score": {"(0, 0)": 0.7739126086235046, "(0, 16)": 0.7739126086235046, "(2, 0)": 0.7739126086235046, "(2, 16)": 0.7739126086235046, "(4, 0)": 0.7739126086235046, "(4, 16)": 0.7739126086235046, "(6, 0)": 0.7739126086235046, "(6, 16)": 0.8941895961761475, "(8, 0)": 0.8941895961761475, "(8, 16)": 0.8941895961761475, "(10, 0)": 0.7739126086235046, "(10, 16)": 0.7739126086235046, "(12, 0)": 0.8941895961761475, "(12, 16)": 0.8941895961761475, "(14, 0)": 0.8941895961761475, "(14, 16)": 0.7739126086235046, "(16, 0)": 0.8941895961761475, "(16, 16)": 0.8941895961761475, "(18, 0)": 0.7739126086235046, "(18, 16)": 0.8941895961761475, "(20, 0)": 0.8941895961761475, "(20, 16)": 0.8941895961761475, "(22, 0)": 0.8941895961761475, "(22, 16)": 0.8941895961761475, "(24, 0)": 0.8941895961761475, "(24, 16)": 0.8941895961761475, "(26, 0)": 0.8941895961761475, "(26, 16)": 0.7739126086235046, "(28, 0)": 0.7056841254234314, "(28, 16)": 0.8941895961761475, "(30, 0)": 0.8941895961761475, "(30, 16)": 0.7739126086235046}, "r_span": [419, 470], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0010673999786376953}}]}, {"id": "12333", "source_id": "14373", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some signs that may indicate if a male coworker is flirting with you:\n\n1. Physical contact that eludes to sexual activity or can be misconstrued as fondling (Passage 1).\n2. Staring at you excessively (Passage 2).\n3. Findings reasons to be near you (Passage 3).\n\nIt is important to note that these signs alone do not necessarily mean that the coworker is flirting with you, and it's always best to communicate directly with them to clarify their intentions. Additionally, it's important to respect boundaries and avoid making assumptions about someone's intentions without their consent.", "response_spans": [[0, 301], [303, 627]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6771804690361023, "(0, 16)": 0.6771804690361023, "(2, 0)": 0.6771804690361023, "(2, 16)": 0.6771804690361023, "(4, 0)": 0.6771804690361023, "(4, 16)": 0.6771804690361023, "(6, 0)": 0.6771804690361023, "(6, 16)": 0.746730625629425, "(8, 0)": 0.6771804690361023, "(8, 16)": 0.6771804690361023, "(10, 0)": 0.3697066903114319, "(10, 16)": 0.6771804690361023, "(12, 0)": 0.6771804690361023, "(12, 16)": 0.746730625629425, "(14, 0)": 0.6771804690361023, "(14, 16)": 0.746730625629425, "(16, 0)": 0.8241786360740662, "(16, 16)": 0.6771804690361023, "(18, 0)": 0.3697066903114319, "(18, 16)": 0.746730625629425, "(20, 0)": 0.746730625629425, "(20, 16)": 0.746730625629425, "(22, 0)": 0.746730625629425, "(22, 16)": 0.746730625629425, "(24, 0)": 0.746730625629425, "(24, 16)": 0.746730625629425, "(26, 0)": 0.746730625629425, "(26, 16)": 0.746730625629425, "(28, 0)": 0.746730625629425, "(28, 16)": 0.746730625629425, "(30, 0)": 0.746730625629425, "(30, 16)": 0.746730625629425}, "r_span": [629, 717], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00129622220993042}}, {"prompt_attention_score": {"(0, 0)": 0.6887428760528564, "(0, 16)": 0.6887428760528564, "(2, 0)": 0.6887428760528564, "(2, 16)": 0.6887428760528564, "(4, 0)": 0.6887428760528564, "(4, 16)": 0.6887428760528564, "(6, 0)": 0.6887428760528564, "(6, 16)": 0.7688119411468506, "(8, 0)": 0.6887428760528564, "(8, 16)": 0.6887428760528564, "(10, 0)": 0.7688119411468506, "(10, 16)": 0.6887428760528564, "(12, 0)": 0.4310610890388489, "(12, 16)": 0.751004695892334, "(14, 0)": 0.751004695892334, "(14, 16)": 0.4310610890388489, "(16, 0)": 0.6887428760528564, "(16, 16)": 0.751004695892334, "(18, 0)": 0.751004695892334, "(18, 16)": 0.751004695892334, "(20, 0)": 0.751004695892334, "(20, 16)": 0.6887428760528564, "(22, 0)": 0.751004695892334, "(22, 16)": 0.751004695892334, "(24, 0)": 0.751004695892334, "(24, 16)": 0.751004695892334, "(26, 0)": 0.751004695892334, "(26, 16)": 0.751004695892334, "(28, 0)": 0.751004695892334, "(28, 16)": 0.6887428760528564, "(30, 0)": 0.751004695892334, "(30, 16)": 0.751004695892334}, "r_span": [719, 784], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004583001136779785}}]}, {"id": "12345", "source_id": "14375", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 1047, "end": 1270, "text": "It is important to note that the cooking time may vary depending on the size and thickness of the bratwurst. Additionally, some recipes may recommend cooking the onions after cooking the bratwurst to avoid overcooking them.", "meta": "HIGH INTRO OF NEW INFO\nAIGC: It is important to note that the cooking time may vary depending on the size and thickness of the bratwurst. Additionally, some recipes may recommend cooking the onions after cooking the bratwurst to avoid overcooking them.\nOriginal: This not is not mentioned in the passages.\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here is how you can cook brats according to the provided passages:\n\nTo cook brats, follow these steps:\n\nPassage 1:\n\n* Preheat an outdoor grill for medium-high heat (step 1).\n* Lightly oil the grate (step 2).\n* Combine beer and onions in a large pot and bring to a boil (step 3).\n* Submerge the bratwurst in the beer mixture and add red pepper flakes, garlic powder, salt, and pepper (step 4).\n* Cook the bratwurst on the preheated grill for 5-10 minutes, turning once (step 5).\n\nPassage 2:\n\n* Preheat grill for medium-high heat (step 1).\n* Place pot over medium heat and simmer for 15-20 minutes (step 2).\n* Place the bratwurst in the pot with onions, butter, and beer (step 3).\n* Lightly oil the grate (step 4).\n* Cook the bratwurst on the preheated grill for 10-14 minutes, turning occasionally to brown evenly (step 5).\n\nPassage 3:\n\n* Add onions to the pot and brown them in the butter for 1-2 minutes, stirring frequently (step 1).\n* Cook the bratwurst on the preheated grill for 10-14 minutes, turning occasionally to brown evenly (step 2).\n\nIt is important to note that the cooking time may vary depending on the size and thickness of the bratwurst. Additionally, some recipes may recommend cooking the onions after cooking the bratwurst to avoid overcooking them.", "response_spans": [[0, 489], [479, 834], [824, 1270]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7328368425369263, "(0, 16)": 0.7328368425369263, "(2, 0)": 0.7328368425369263, "(2, 16)": 0.7328368425369263, "(4, 0)": 0.7328368425369263, "(4, 16)": 0.7328368425369263, "(6, 0)": 0.7328368425369263, "(6, 16)": 0.899749755859375, "(8, 0)": 0.7328368425369263, "(8, 16)": 0.7328368425369263, "(10, 0)": 0.7328368425369263, "(10, 16)": 0.7328368425369263, "(12, 0)": 0.8887194395065308, "(12, 16)": 0.899749755859375, "(14, 0)": 0.7328368425369263, "(14, 16)": 0.8887194395065308, "(16, 0)": 0.8887194395065308, "(16, 16)": 0.8887194395065308, "(18, 0)": 0.3830864429473877, "(18, 16)": 0.899749755859375, "(20, 0)": 0.899749755859375, "(20, 16)": 0.7328368425369263, "(22, 0)": 0.7328368425369263, "(22, 16)": 0.899749755859375, "(24, 0)": 0.7328368425369263, "(24, 16)": 0.899749755859375, "(26, 0)": 0.7328368425369263, "(26, 16)": 0.899749755859375, "(28, 0)": 0.7328368425369263, "(28, 16)": 0.7328368425369263, "(30, 0)": 0.7328368425369263, "(30, 16)": 0.7328368425369263}, "r_span": [619, 784], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0052568912506103516}}, {"prompt_attention_score": {"(0, 0)": 0.8073955178260803, "(0, 16)": 0.8073955178260803, "(2, 0)": 0.8073955178260803, "(2, 16)": 0.8073955178260803, "(4, 0)": 0.8073955178260803, "(4, 16)": 0.8073955178260803, "(6, 0)": 0.8073955178260803, "(6, 16)": 0.9677444696426392, "(8, 0)": 0.8073955178260803, "(8, 16)": 0.8073955178260803, "(10, 0)": 0.8073955178260803, "(10, 16)": 0.8073955178260803, "(12, 0)": 0.8073955178260803, "(12, 16)": 0.9677444696426392, "(14, 0)": 0.8073955178260803, "(14, 16)": 0.9677444696426392, "(16, 0)": 0.9677444696426392, "(16, 16)": 0.9677444696426392, "(18, 0)": 0.8073955178260803, "(18, 16)": 0.9677444696426392, "(20, 0)": 0.9677444696426392, "(20, 16)": 0.8073955178260803, "(22, 0)": 0.8073955178260803, "(22, 16)": 0.9677444696426392, "(24, 0)": 0.8073955178260803, "(24, 16)": 0.9677444696426392, "(26, 0)": 0.8073955178260803, "(26, 16)": 0.8073955178260803, "(28, 0)": 0.8073955178260803, "(28, 16)": 0.8073955178260803, "(30, 0)": 0.8073955178260803, "(30, 16)": 0.8073955178260803}, "r_span": [779, 906], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006363391876220703}}, {"prompt_attention_score": {"(0, 0)": 0.8999474048614502, "(0, 16)": 0.8638706207275391, "(2, 0)": 0.8638706207275391, "(2, 16)": 0.8638706207275391, "(4, 0)": 0.42438775300979614, "(4, 16)": 0.8638706207275391, "(6, 0)": 0.8638706207275391, "(6, 16)": 0.8638706207275391, "(8, 0)": 0.8638706207275391, "(8, 16)": 0.8638706207275391, "(10, 0)": 0.8638706207275391, "(10, 16)": 0.8638706207275391, "(12, 0)": 0.8999474048614502, "(12, 16)": 0.8638706207275391, "(14, 0)": 0.8638706207275391, "(14, 16)": 0.8638706207275391, "(16, 0)": 0.8638706207275391, "(16, 16)": 0.8999474048614502, "(18, 0)": 0.8638706207275391, "(18, 16)": 0.8638706207275391, "(20, 0)": 0.8638706207275391, "(20, 16)": 0.8638706207275391, "(22, 0)": 0.8638706207275391, "(22, 16)": 0.8638706207275391, "(24, 0)": 0.8638706207275391, "(24, 16)": 0.8638706207275391, "(26, 0)": 0.8638706207275391, "(26, 16)": 0.8638706207275391, "(28, 0)": 0.8638706207275391, "(28, 16)": 0.8638706207275391, "(30, 0)": 0.8638706207275391, "(30, 16)": 0.8638706207275391}, "r_span": [901, 1027], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015901923179626465}}]}, {"id": "12435", "source_id": "14390", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 115, "end": 146, "text": "2. Constipation (passage 2 & 3)", "meta": "EVIDENT CONFLICT\nOriginal: *this is from Passage 3 only*\nGenerative: \"2. Constipation (passage 2 & 3)\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the main symptoms of Irritable Bowel Syndrome (IBS) are:\n\n1. Diarrhea ( passage 1)\n2. Constipation (passage 2 & 3)\n3. Alternating constipation and diarrhea (passage 3)\n4. Belly pains or cramps (passage 3)\n5. Gas or bloating (passage 3)\n\nAs for the causes of IBS, the passages suggest that it may be due to a combination of factors, including:\n\n1. Abnormal gastrointestinal (GI) tract movements (passage 1)\n2. Alterations in GI tract motility (passage 2)\n3. Abnormal nervous system signals (passage 2)\n4. Increased sensitivity to pain (passage 2)\n5. Food intolerances (passage 2)\n\nIt is important to note that the exact cause of IBS is still unknown and may involve multiple factors. Additionally, the passages do not provide clear information on the specific causes of the symptoms mentioned above. Therefore, I am unable to answer the question regarding the specific causes of each symptom based on the provided passages.", "response_spans": [[0, 374], [376, 610], [612, 954]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8411367535591125, "(0, 16)": 0.8411367535591125, "(2, 0)": 0.8411367535591125, "(2, 16)": 0.8411367535591125, "(4, 0)": 0.8411367535591125, "(4, 16)": 0.8411367535591125, "(6, 0)": 0.8411367535591125, "(6, 16)": 0.8567376732826233, "(8, 0)": 0.8411367535591125, "(8, 16)": 0.8411367535591125, "(10, 0)": 0.8411367535591125, "(10, 16)": 0.8411367535591125, "(12, 0)": 0.8411367535591125, "(12, 16)": 0.8411367535591125, "(14, 0)": 0.8411367535591125, "(14, 16)": 0.8411367535591125, "(16, 0)": 0.8411367535591125, "(16, 16)": 0.8411367535591125, "(18, 0)": 0.8411367535591125, "(18, 16)": 0.8567376732826233, "(20, 0)": 0.8411367535591125, "(20, 16)": 0.8567376732826233, "(22, 0)": 0.8567376732826233, "(22, 16)": 0.8567376732826233, "(24, 0)": 0.8567376732826233, "(24, 16)": 0.8567376732826233, "(26, 0)": 0.8567376732826233, "(26, 16)": 0.8567376732826233, "(28, 0)": 0.8411367535591125, "(28, 16)": 0.8567376732826233, "(30, 0)": 0.8567376732826233, "(30, 16)": 0.8567376732826233}, "r_span": [439, 569], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0027130842208862305}}, {"prompt_attention_score": {"(0, 0)": 0.7813720703125, "(0, 16)": 0.7813720703125, "(2, 0)": 0.7813720703125, "(2, 16)": 0.7813720703125, "(4, 0)": 0.7813720703125, "(4, 16)": 0.7813720703125, "(6, 0)": 0.7813720703125, "(6, 16)": 0.772185742855072, "(8, 0)": 0.7813720703125, "(8, 16)": 0.7813720703125, "(10, 0)": 0.7813720703125, "(10, 16)": 0.7813720703125, "(12, 0)": 0.7813720703125, "(12, 16)": 0.772185742855072, "(14, 0)": 0.6871373057365417, "(14, 16)": 0.7813720703125, "(16, 0)": 0.772185742855072, "(16, 16)": 0.6871373057365417, "(18, 0)": 0.7813720703125, "(18, 16)": 0.772185742855072, "(20, 0)": 0.772185742855072, "(20, 16)": 0.6871373057365417, "(22, 0)": 0.6871373057365417, "(22, 16)": 0.772185742855072, "(24, 0)": 0.6871373057365417, "(24, 16)": 0.772185742855072, "(26, 0)": 0.6871373057365417, "(26, 16)": 0.6871373057365417, "(28, 0)": 0.7813720703125, "(28, 16)": 0.6871373057365417, "(30, 0)": 0.6871373057365417, "(30, 16)": 0.6871373057365417}, "r_span": [571, 654], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.003584444522857666}}, {"prompt_attention_score": {"(0, 0)": 0.7588536739349365, "(0, 16)": 0.7588536739349365, "(2, 0)": 0.7588536739349365, "(2, 16)": 0.7588536739349365, "(4, 0)": 0.7588536739349365, "(4, 16)": 0.7588536739349365, "(6, 0)": 0.7588536739349365, "(6, 16)": 0.80219966173172, "(8, 0)": 0.7588536739349365, "(8, 16)": 0.7588536739349365, "(10, 0)": 0.7588536739349365, "(10, 16)": 0.7588536739349365, "(12, 0)": 0.7588536739349365, "(12, 16)": 0.7588536739349365, "(14, 0)": 0.8358161449432373, "(14, 16)": 0.7588536739349365, "(16, 0)": 0.7588536739349365, "(16, 16)": 0.8358161449432373, "(18, 0)": 0.8358161449432373, "(18, 16)": 0.8358161449432373, "(20, 0)": 0.8358161449432373, "(20, 16)": 0.8358161449432373, "(22, 0)": 0.8358161449432373, "(22, 16)": 0.7588536739349365, "(24, 0)": 0.8358161449432373, "(24, 16)": 0.7588536739349365, "(26, 0)": 0.8358161449432373, "(26, 16)": 0.8358161449432373, "(28, 0)": 0.7588536739349365, "(28, 16)": 0.8358161449432373, "(30, 0)": 0.8358161449432373, "(30, 16)": 0.8358161449432373}, "r_span": [656, 722], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00018984079360961914}}]}, {"id": "12441", "source_id": "14391", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Sure, I'd be happy to help you with that! Here are the steps to prepare a blood slide based on the provided passages:\n\n1. First, sterilize a needle with a flame as described in Passage 1.\n2. Next, obtain a blood sample by pricking your finger or using a blood donation kit. This will require adult supervision, especially if you are doing it yourself.\n3. Place a drop of blood towards one end of a clean glass slide as instructed in Passage 2.\n4. Take another clean slide and, holding it at an angle of about 45 degrees, touch the blood with one end of the slide so that the blood runs along the edge of the slide through capillary action. Gently push the blood along the length of the first slide to produce a thin smear of blood. Repeat this step to make two smears.\n5. Allow the smears to air dry completely before labeling them clearly and placing them in the provided slide transport containers as suggested in Passage 3.\n\nI hope this helps! Let me know if you have any further questions.", "response_spans": [[0, 117], [119, 443], [444, 926], [928, 993]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.783707320690155, "(0, 16)": 0.783707320690155, "(2, 0)": 0.783707320690155, "(2, 16)": 0.783707320690155, "(4, 0)": 0.783707320690155, "(4, 16)": 0.783707320690155, "(6, 0)": 0.8363658785820007, "(6, 16)": 0.8363658785820007, "(8, 0)": 0.783707320690155, "(8, 16)": 0.5257447957992554, "(10, 0)": 0.5257447957992554, "(10, 16)": 0.5257447957992554, "(12, 0)": 0.8363658785820007, "(12, 16)": 0.8363658785820007, "(14, 0)": 0.8363658785820007, "(14, 16)": 0.5257447957992554, "(16, 0)": 0.8363658785820007, "(16, 16)": 0.8363658785820007, "(18, 0)": 0.8363658785820007, "(18, 16)": 0.8363658785820007, "(20, 0)": 0.8363658785820007, "(20, 16)": 0.8363658785820007, "(22, 0)": 0.8363658785820007, "(22, 16)": 0.8363658785820007, "(24, 0)": 0.8363658785820007, "(24, 16)": 0.8363658785820007, "(26, 0)": 0.8363658785820007, "(26, 16)": 0.8363658785820007, "(28, 0)": 0.8363658785820007, "(28, 16)": 0.8363658785820007, "(30, 0)": 0.8363658785820007, "(30, 16)": 0.8363658785820007}, "r_span": [399, 429], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001812577247619629}}, {"prompt_attention_score": {"(0, 0)": 0.8195499777793884, "(0, 16)": 0.8195499777793884, "(2, 0)": 0.8195499777793884, "(2, 16)": 0.8195499777793884, "(4, 0)": 0.8195499777793884, "(4, 16)": 0.8195499777793884, "(6, 0)": 0.8195499777793884, "(6, 16)": 0.8440276384353638, "(8, 0)": 0.8195499777793884, "(8, 16)": 0.8440276384353638, "(10, 0)": 0.8440276384353638, "(10, 16)": 0.8195499777793884, "(12, 0)": 0.8440276384353638, "(12, 16)": 0.8440276384353638, "(14, 0)": 0.8440276384353638, "(14, 16)": 0.8440276384353638, "(16, 0)": 0.8440276384353638, "(16, 16)": 0.8440276384353638, "(18, 0)": 0.8440276384353638, "(18, 16)": 0.8440276384353638, "(20, 0)": 0.8440276384353638, "(20, 16)": 0.8440276384353638, "(22, 0)": 0.8440276384353638, "(22, 16)": 0.8440276384353638, "(24, 0)": 0.8440276384353638, "(24, 16)": 0.8440276384353638, "(26, 0)": 0.8440276384353638, "(26, 16)": 0.8440276384353638, "(28, 0)": 0.8440276384353638, "(28, 16)": 0.8440276384353638, "(30, 0)": 0.8440276384353638, "(30, 16)": 0.8440276384353638}, "r_span": [431, 517], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00038057565689086914}}, {"prompt_attention_score": {"(0, 0)": 0.9339295625686646, "(0, 16)": 0.9339295625686646, "(2, 0)": 0.9339295625686646, "(2, 16)": 0.9339295625686646, "(4, 0)": 0.9339295625686646, "(4, 16)": 0.9339295625686646, "(6, 0)": 0.9339295625686646, "(6, 16)": 0.9339295625686646, "(8, 0)": 0.9339295625686646, "(8, 16)": 0.9339295625686646, "(10, 0)": 0.9339295625686646, "(10, 16)": 0.9339295625686646, "(12, 0)": 0.860029399394989, "(12, 16)": 0.9339295625686646, "(14, 0)": 0.860029399394989, "(14, 16)": 0.9339295625686646, "(16, 0)": 0.9339295625686646, "(16, 16)": 0.860029399394989, "(18, 0)": 0.860029399394989, "(18, 16)": 0.9339295625686646, "(20, 0)": 0.9339295625686646, "(20, 16)": 0.860029399394989, "(22, 0)": 0.860029399394989, "(22, 16)": 0.9339295625686646, "(24, 0)": 0.860029399394989, "(24, 16)": 0.9339295625686646, "(26, 0)": 0.860029399394989, "(26, 16)": 0.9339295625686646, "(28, 0)": 0.860029399394989, "(28, 16)": 0.860029399394989, "(30, 0)": 0.860029399394989, "(30, 16)": 0.860029399394989}, "r_span": [518, 628], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015963315963745117}}, {"prompt_attention_score": {"(0, 0)": 0.49218830466270447, "(0, 16)": 0.49218830466270447, "(2, 0)": 0.49218830466270447, "(2, 16)": 0.49218830466270447, "(4, 0)": 0.49218830466270447, "(4, 16)": 0.4745849668979645, "(6, 0)": 0.49218830466270447, "(6, 16)": 0.4745849668979645, "(8, 0)": 0.49218830466270447, "(8, 16)": 0.49218830466270447, "(10, 0)": 0.5375855565071106, "(10, 16)": 0.5375855565071106, "(12, 0)": 0.5375855565071106, "(12, 16)": 0.5375855565071106, "(14, 0)": 0.4745849668979645, "(14, 16)": 0.5375855565071106, "(16, 0)": 0.5375855565071106, "(16, 16)": 0.4745849668979645, "(18, 0)": 0.4745849668979645, "(18, 16)": 0.5375855565071106, "(20, 0)": 0.5375855565071106, "(20, 16)": 0.4745849668979645, "(22, 0)": 0.4745849668979645, "(22, 16)": 0.5375855565071106, "(24, 0)": 0.4745849668979645, "(24, 16)": 0.5375855565071106, "(26, 0)": 0.4745849668979645, "(26, 16)": 0.4745849668979645, "(28, 0)": 0.4745849668979645, "(28, 16)": 0.4745849668979645, "(30, 0)": 0.4745849668979645, "(30, 16)": 0.4745849668979645}, "r_span": [630, 645], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0011482834815979004}}]}, {"id": "12447", "source_id": "14392", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main differences between essential and non-essential amino acids are:\n\nEssential Amino Acids:\n\n* Must be obtained from the diet\n* Cannot be produced by the body\n* Nine out of 20 amino acids are considered essential (valine, isoleucine, leucine, lysine, methionine, phenylalanine, threonine, tryptophan, and histidine for infants)\n\nNon-Essential Amino Acids:\n\n* Can be produced by the body\n* Not necessarily required to obtain from the diet\n* Include alanine, asparagine, aspartic acid, glutamic acid, arginine, cysteine, glutamine, glycine, ornithine, proline, serine, and tyrosine\n\nIt is important to note that even though non-essential amino acids can be produced by the body, it is still important to consume a balanced diet that includes all of the essential amino acids to ensure proper bodily functions.", "response_spans": [[0, 393], [395, 845]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7989248037338257, "(0, 16)": 0.7989248037338257, "(2, 0)": 0.7989248037338257, "(2, 16)": 0.7989248037338257, "(4, 0)": 0.7989248037338257, "(4, 16)": 0.7989248037338257, "(6, 0)": 0.7989248037338257, "(6, 16)": 0.8392168283462524, "(8, 0)": 0.7989248037338257, "(8, 16)": 0.7989248037338257, "(10, 0)": 0.4319537580013275, "(10, 16)": 0.7989248037338257, "(12, 0)": 0.7989248037338257, "(12, 16)": 0.8392168283462524, "(14, 0)": 0.7989248037338257, "(14, 16)": 0.7989248037338257, "(16, 0)": 0.7865639925003052, "(16, 16)": 0.7989248037338257, "(18, 0)": 0.4319537580013275, "(18, 16)": 0.8392168283462524, "(20, 0)": 0.8392168283462524, "(20, 16)": 0.7989248037338257, "(22, 0)": 0.7865639925003052, "(22, 16)": 0.8392168283462524, "(24, 0)": 0.7865639925003052, "(24, 16)": 0.8392168283462524, "(26, 0)": 0.7897403240203857, "(26, 16)": 0.8392168283462524, "(28, 0)": 0.7865639925003052, "(28, 16)": 0.7989248037338257, "(30, 0)": 0.7865639925003052, "(30, 16)": 0.7897403240203857}, "r_span": [615, 742], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004030466079711914}}, {"prompt_attention_score": {"(0, 0)": 0.7773901224136353, "(0, 16)": 0.7773901224136353, "(2, 0)": 0.7773901224136353, "(2, 16)": 0.7773901224136353, "(4, 0)": 0.7773901224136353, "(4, 16)": 0.7773901224136353, "(6, 0)": 0.7773901224136353, "(6, 16)": 0.8304877877235413, "(8, 0)": 0.7773901224136353, "(8, 16)": 0.7773901224136353, "(10, 0)": 0.7773901224136353, "(10, 16)": 0.7773901224136353, "(12, 0)": 0.7773901224136353, "(12, 16)": 0.8304877877235413, "(14, 0)": 0.7773901224136353, "(14, 16)": 0.7773901224136353, "(16, 0)": 0.8304877877235413, "(16, 16)": 0.8304877877235413, "(18, 0)": 0.8304877877235413, "(18, 16)": 0.8304877877235413, "(20, 0)": 0.8304877877235413, "(20, 16)": 0.7773901224136353, "(22, 0)": 0.8304877877235413, "(22, 16)": 0.8304877877235413, "(24, 0)": 0.8304877877235413, "(24, 16)": 0.8304877877235413, "(26, 0)": 0.663928747177124, "(26, 16)": 0.8304877877235413, "(28, 0)": 0.7773901224136353, "(28, 16)": 0.7773901224136353, "(30, 0)": 0.8304877877235413, "(30, 16)": 0.663928747177124}, "r_span": [744, 871], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009469389915466309}}]}, {"id": "12459", "source_id": "14394", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 238, "end": 276, "text": "average annual snowfall of 15.3 inches", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"average annual snowfall of 15.3 inches\" was not mentioned in the passages and original answer", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 361, "end": 387, "text": "with four distinct seasons", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\n\"with four distinct seasons\" was not mentioned in the passages and original answer", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is the typical weather in Indiana:\n\n* Indianapolis, IN: The city experiences hot, humid summers and chilly, windy winters. The average temperature ranges from 22¬∞F to 85¬∞F throughout the year, with an average annual snowfall of 15.3 inches. (Passage 1)\n* Average weather in Indianapolis, IN: The city has a moderate climate with four distinct seasons. Summers are long, warm, and humid, while winters are cold and windy. (Passage 2)\n* Wettest year in Indianapolis: 1876 saw the highest amount of rainfall, with 57.65 inches of measured rain. (Passage 3)\n* Driest year in Indianapolis: 1934 had the lowest amount of rainfall, with only 24.97 inches of measured rain. (Passage 3)\n* Most snowfall in Rockford, IN: 74.5 inches of snow fell in one season in 1979. (Passage 3)\n\nUnable to answer based on given passages. The passages do not provide information on the average temperature range in Indiana during different times of the year or the frequency of heatwaves.", "response_spans": [[0, 71], [73, 469], [470, 807], [809, 1000]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6739554405212402, "(0, 16)": 0.6739554405212402, "(2, 0)": 0.6739554405212402, "(2, 16)": 0.6739554405212402, "(4, 0)": 0.6739554405212402, "(4, 16)": 0.6739554405212402, "(6, 0)": 0.6739554405212402, "(6, 16)": 0.792506754398346, "(8, 0)": 0.6739554405212402, "(8, 16)": 0.6739554405212402, "(10, 0)": 0.6739554405212402, "(10, 16)": 0.6739554405212402, "(12, 0)": 0.6739554405212402, "(12, 16)": 0.792506754398346, "(14, 0)": 0.6739554405212402, "(14, 16)": 0.6739554405212402, "(16, 0)": 0.792506754398346, "(16, 16)": 0.6739554405212402, "(18, 0)": 0.6739554405212402, "(18, 16)": 0.792506754398346, "(20, 0)": 0.792506754398346, "(20, 16)": 0.6739554405212402, "(22, 0)": 0.6739554405212402, "(22, 16)": 0.792506754398346, "(24, 0)": 0.6739554405212402, "(24, 16)": 0.792506754398346, "(26, 0)": 0.792506754398346, "(26, 16)": 0.792506754398346, "(28, 0)": 0.6739554405212402, "(28, 16)": 0.6739554405212402, "(30, 0)": 0.8173068165779114, "(30, 16)": 0.792506754398346}, "r_span": [397, 413], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008259415626525879}}, {"prompt_attention_score": {"(0, 0)": 0.6684162020683289, "(0, 16)": 0.6684162020683289, "(2, 0)": 0.6684162020683289, "(2, 16)": 0.6684162020683289, "(4, 0)": 0.6684162020683289, "(4, 16)": 0.6684162020683289, "(6, 0)": 0.6684162020683289, "(6, 16)": 0.9488322138786316, "(8, 0)": 0.6684162020683289, "(8, 16)": 0.6684162020683289, "(10, 0)": 0.6684162020683289, "(10, 16)": 0.6684162020683289, "(12, 0)": 0.6684162020683289, "(12, 16)": 0.9488322138786316, "(14, 0)": 0.6684162020683289, "(14, 16)": 0.6684162020683289, "(16, 0)": 0.8369013667106628, "(16, 16)": 0.6684162020683289, "(18, 0)": 0.6684162020683289, "(18, 16)": 0.9488322138786316, "(20, 0)": 0.9488322138786316, "(20, 16)": 0.6684162020683289, "(22, 0)": 0.6684162020683289, "(22, 16)": 0.8369013667106628, "(24, 0)": 0.6684162020683289, "(24, 16)": 0.9488322138786316, "(26, 0)": 0.8369013667106628, "(26, 16)": 0.6684162020683289, "(28, 0)": 0.6684162020683289, "(28, 16)": 0.6684162020683289, "(30, 0)": 0.8369013667106628, "(30, 16)": 0.8369013667106628}, "r_span": [415, 528], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0003867149353027344}}, {"prompt_attention_score": {"(0, 0)": 0.8502357602119446, "(0, 16)": 0.8502357602119446, "(2, 0)": 0.8502357602119446, "(2, 16)": 0.8502357602119446, "(4, 0)": 0.8502357602119446, "(4, 16)": 0.8502357602119446, "(6, 0)": 0.8502357602119446, "(6, 16)": 0.8502357602119446, "(8, 0)": 0.8502357602119446, "(8, 16)": 0.8502357602119446, "(10, 0)": 0.8502357602119446, "(10, 16)": 0.8502357602119446, "(12, 0)": 0.8502357602119446, "(12, 16)": 0.8502357602119446, "(14, 0)": 0.8502357602119446, "(14, 16)": 0.8502357602119446, "(16, 0)": 0.8502357602119446, "(16, 16)": 0.6812587976455688, "(18, 0)": 0.8502357602119446, "(18, 16)": 0.8502357602119446, "(20, 0)": 0.8502357602119446, "(20, 16)": 0.8502357602119446, "(22, 0)": 0.8502357602119446, "(22, 16)": 0.8502357602119446, "(24, 0)": 0.8502357602119446, "(24, 16)": 0.8502357602119446, "(26, 0)": 0.8502357602119446, "(26, 16)": 0.8502357602119446, "(28, 0)": 0.8502357602119446, "(28, 16)": 0.8502357602119446, "(30, 0)": 0.6881871223449707, "(30, 16)": 0.6812587976455688}, "r_span": [529, 649], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0012258291244506836}}, {"prompt_attention_score": {"(0, 0)": 0.7115756869316101, "(0, 16)": 0.7115756869316101, "(2, 0)": 0.7115756869316101, "(2, 16)": 0.7115756869316101, "(4, 0)": 0.7115756869316101, "(4, 16)": 0.7115756869316101, "(6, 0)": 0.7115756869316101, "(6, 16)": 0.7578348517417908, "(8, 0)": 0.7115756869316101, "(8, 16)": 0.7115756869316101, "(10, 0)": 0.7115756869316101, "(10, 16)": 0.7115756869316101, "(12, 0)": 0.7115756869316101, "(12, 16)": 0.7115756869316101, "(14, 0)": 0.7115756869316101, "(14, 16)": 0.7115756869316101, "(16, 0)": 0.7115756869316101, "(16, 16)": 0.7115756869316101, "(18, 0)": 0.7115756869316101, "(18, 16)": 0.7578348517417908, "(20, 0)": 0.7578348517417908, "(20, 16)": 0.7115756869316101, "(22, 0)": 0.7115756869316101, "(22, 16)": 0.7115756869316101, "(24, 0)": 0.7115756869316101, "(24, 16)": 0.7115756869316101, "(26, 0)": 0.7578348517417908, "(26, 16)": 0.767143726348877, "(28, 0)": 0.7115756869316101, "(28, 16)": 0.7115756869316101, "(30, 0)": 0.767143726348877, "(30, 16)": 0.7578348517417908}, "r_span": [651, 689], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00022810697555541992}}]}, {"id": "12471", "source_id": "14396", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 113, "end": 168, "text": "Connect your iPhone to your computer using a USB cable.", "meta": "EVIDENT CONFLICT\nReason: This is mentioned in Passage 2 and not Passage 1\nGenerated: Connect your iPhone to your computer using a USB cable.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 346, "end": 410, "text": "Connect your iPhone to the computer and wait for iTunes to sync.", "meta": "EVIDENT CONFLICT\nReason: This is mentioned in Passage 2 and not Passage 1\nGenerated: Connect your iPhone to the computer and wait for iTunes to sync.", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the steps to sync an audiobook from an iPhone to iTunes:\n\nPassage 1:\n\n* Connect your iPhone to your computer using a USB cable.\n* Open OverDrive for Windows on your computer.\n* In iTunes, turn on the \"Manually manage music\" setting.\n* Transfer the audiobook from OverDrive for Windows to your computer.\n* Connect your iPhone to the computer and wait for iTunes to sync.\n\nPassage 2:\n\n* Download the audiobook from iTunes.\n* Click on \"Audiobooks\" in the left task pane of the iTunes window.\n* Find the audiobook you want to transfer and click the box next to it to select it.\n* Connect your iPhone to the computer using a USB cable.\n* Wait for iTunes to sync the audiobook to your iPhone.\n\nPassage 3:\n\n* Launch iTunes on your computer and connect your iPhone/iPod/iPad to the computer using a USB cable.\n* Click the name of your device under \"Devices\" in the left column.\n* Click \"Books\" above the main iTunes window and select the audiobook you want to transfer.\n* Click \"Sync Audiobooks\" and choose the audiobook you want to transfer or select \"All Audiobooks\" to transfer all of them.\n* Click \"Apply\" or \"Import\" to complete the transfer process.\n\nBased on the provided passages, the steps to sync an audiobook from an iPhone to iTunes are as follows:\n\n1. Connect your iPhone to your computer using a USB cable.\n2. Open iTunes and turn on the \"Manually manage music\" setting.\n3. Transfer the audiobook from OverDrive for Windows to your computer.\n4. Connect your iPhone to the computer and wait for iTunes to sync the audiobook.\n5. Download the audiobook from iTunes and select it in iTunes.\n6. Connect your iPhone to the computer using a USB cable.\n7. Click \"Sync Audiobooks\" and choose the audiobook you want to transfer or select \"All Audiobooks\" to transfer all of them.\n8. Click \"Apply\" or \"Import\" to complete the transfer process.", "response_spans": [[0, 422], [412, 739], [729, 1188], [1190, 1293], [1295, 1691], [1692, 1879]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8542985916137695, "(0, 16)": 0.8542985916137695, "(2, 0)": 0.8542985916137695, "(2, 16)": 0.8542985916137695, "(4, 0)": 0.8542985916137695, "(4, 16)": 0.8542985916137695, "(6, 0)": 0.8542985916137695, "(6, 16)": 0.9134321808815002, "(8, 0)": 0.8542985916137695, "(8, 16)": 0.8542985916137695, "(10, 0)": 0.4174584746360779, "(10, 16)": 0.8542985916137695, "(12, 0)": 0.4174584746360779, "(12, 16)": 0.9134321808815002, "(14, 0)": 0.9134321808815002, "(14, 16)": 0.4174584746360779, "(16, 0)": 0.9134321808815002, "(16, 16)": 0.9134321808815002, "(18, 0)": 0.4174584746360779, "(18, 16)": 0.9134321808815002, "(20, 0)": 0.9134321808815002, "(20, 16)": 0.9134321808815002, "(22, 0)": 0.9134321808815002, "(22, 16)": 0.9134321808815002, "(24, 0)": 0.9134321808815002, "(24, 16)": 0.9134321808815002, "(26, 0)": 0.9134321808815002, "(26, 16)": 0.9134321808815002, "(28, 0)": 0.9134321808815002, "(28, 16)": 0.9134321808815002, "(30, 0)": 0.9134321808815002, "(30, 16)": 0.9134321808815002}, "r_span": [596, 712], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0025911331176757812}}, {"prompt_attention_score": {"(0, 0)": 0.9339199066162109, "(0, 16)": 0.9339199066162109, "(2, 0)": 0.9339199066162109, "(2, 16)": 0.9339199066162109, "(4, 0)": 0.9339199066162109, "(4, 16)": 0.9339199066162109, "(6, 0)": 0.9339199066162109, "(6, 16)": 0.9463830590248108, "(8, 0)": 0.9339199066162109, "(8, 16)": 0.9339199066162109, "(10, 0)": 0.9339199066162109, "(10, 16)": 0.8689194917678833, "(12, 0)": 0.8689194917678833, "(12, 16)": 0.9463830590248108, "(14, 0)": 0.8689194917678833, "(14, 16)": 0.9339199066162109, "(16, 0)": 0.9339199066162109, "(16, 16)": 0.8689194917678833, "(18, 0)": 0.5019025802612305, "(18, 16)": 0.9463830590248108, "(20, 0)": 0.9463830590248108, "(20, 16)": 0.8689194917678833, "(22, 0)": 0.8689194917678833, "(22, 16)": 0.9463830590248108, "(24, 0)": 0.8689194917678833, "(24, 16)": 0.9339199066162109, "(26, 0)": 0.8689194917678833, "(26, 16)": 0.8689194917678833, "(28, 0)": 0.8689194917678833, "(28, 16)": 0.8689194917678833, "(30, 0)": 0.8689194917678833, "(30, 16)": 0.8689194917678833}, "r_span": [707, 802], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005221962928771973}}, {"prompt_attention_score": {"(0, 0)": 0.9831335544586182, "(0, 16)": 0.9831335544586182, "(2, 0)": 0.9831335544586182, "(2, 16)": 0.9831335544586182, "(4, 0)": 0.9831335544586182, "(4, 16)": 0.9831335544586182, "(6, 0)": 0.9831335544586182, "(6, 16)": 0.9831335544586182, "(8, 0)": 0.9831335544586182, "(8, 16)": 0.8815935254096985, "(10, 0)": 0.9831335544586182, "(10, 16)": 0.9831335544586182, "(12, 0)": 0.8815935254096985, "(12, 16)": 0.9831335544586182, "(14, 0)": 0.8815935254096985, "(14, 16)": 0.9831335544586182, "(16, 0)": 0.9831335544586182, "(16, 16)": 0.8815935254096985, "(18, 0)": 0.8815935254096985, "(18, 16)": 0.9831335544586182, "(20, 0)": 0.9831335544586182, "(20, 16)": 0.8815935254096985, "(22, 0)": 0.8815935254096985, "(22, 16)": 0.9831335544586182, "(24, 0)": 0.8815935254096985, "(24, 16)": 0.9831335544586182, "(26, 0)": 0.8815935254096985, "(26, 16)": 0.8815935254096985, "(28, 0)": 0.8815935254096985, "(28, 16)": 0.8815935254096985, "(30, 0)": 0.8815935254096985, "(30, 16)": 0.8815935254096985}, "r_span": [797, 920], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005548596382141113}}, {"prompt_attention_score": {"(0, 0)": 0.8137441873550415, "(0, 16)": 0.8137441873550415, "(2, 0)": 0.4984265863895416, "(2, 16)": 0.4984265863895416, "(4, 0)": 0.4984265863895416, "(4, 16)": 0.8137441873550415, "(6, 0)": 0.783767819404602, "(6, 16)": 0.8800231218338013, "(8, 0)": 0.783767819404602, "(8, 16)": 0.783767819404602, "(10, 0)": 0.4984265863895416, "(10, 16)": 0.4984265863895416, "(12, 0)": 0.4984265863895416, "(12, 16)": 0.4984265863895416, "(14, 0)": 0.783767819404602, "(14, 16)": 0.4984265863895416, "(16, 0)": 0.4984265863895416, "(16, 16)": 0.783767819404602, "(18, 0)": 0.783767819404602, "(18, 16)": 0.8800231218338013, "(20, 0)": 0.4984265863895416, "(20, 16)": 0.783767819404602, "(22, 0)": 0.783767819404602, "(22, 16)": 0.4984265863895416, "(24, 0)": 0.783767819404602, "(24, 16)": 0.783767819404602, "(26, 0)": 0.783767819404602, "(26, 16)": 0.783767819404602, "(28, 0)": 0.783767819404602, "(28, 16)": 0.783767819404602, "(30, 0)": 0.783767819404602, "(30, 16)": 0.783767819404602}, "r_span": [922, 948], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004330873489379883}}, {"prompt_attention_score": {"(0, 0)": 0.80938321352005, "(0, 16)": 0.80938321352005, "(2, 0)": 0.8200887441635132, "(2, 16)": 0.3994910717010498, "(4, 0)": 0.80938321352005, "(4, 16)": 0.80938321352005, "(6, 0)": 0.8900113105773926, "(6, 16)": 0.8200887441635132, "(8, 0)": 0.8900113105773926, "(8, 16)": 0.8900113105773926, "(10, 0)": 0.8900113105773926, "(10, 16)": 0.8900113105773926, "(12, 0)": 0.8900113105773926, "(12, 16)": 0.8200887441635132, "(14, 0)": 0.8900113105773926, "(14, 16)": 0.3994910717010498, "(16, 0)": 0.8900113105773926, "(16, 16)": 0.8900113105773926, "(18, 0)": 0.8900113105773926, "(18, 16)": 0.8900113105773926, "(20, 0)": 0.8900113105773926, "(20, 16)": 0.8900113105773926, "(22, 0)": 0.8900113105773926, "(22, 16)": 0.8900113105773926, "(24, 0)": 0.8900113105773926, "(24, 16)": 0.8900113105773926, "(26, 0)": 0.8900113105773926, "(26, 16)": 0.8900113105773926, "(28, 0)": 0.8900113105773926, "(28, 16)": 0.8900113105773926, "(30, 0)": 0.8900113105773926, "(30, 16)": 0.8900113105773926}, "r_span": [950, 1053], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00083160400390625}}, {"prompt_attention_score": {"(0, 0)": 0.8310357928276062, "(0, 16)": 0.8310357928276062, "(2, 0)": 0.7588902711868286, "(2, 16)": 0.7986565232276917, "(4, 0)": 0.7986565232276917, "(4, 16)": 0.8310357928276062, "(6, 0)": 0.7588902711868286, "(6, 16)": 0.8310357928276062, "(8, 0)": 0.7997643947601318, "(8, 16)": 0.7997643947601318, "(10, 0)": 0.8310357928276062, "(10, 16)": 0.8310357928276062, "(12, 0)": 0.7997643947601318, "(12, 16)": 0.8310357928276062, "(14, 0)": 0.7997643947601318, "(14, 16)": 0.8310357928276062, "(16, 0)": 0.7997643947601318, "(16, 16)": 0.7997643947601318, "(18, 0)": 0.7997643947601318, "(18, 16)": 0.8310357928276062, "(20, 0)": 0.8310357928276062, "(20, 16)": 0.7997643947601318, "(22, 0)": 0.7997643947601318, "(22, 16)": 0.8310357928276062, "(24, 0)": 0.7997643947601318, "(24, 16)": 0.8310357928276062, "(26, 0)": 0.7997643947601318, "(26, 16)": 0.7997643947601318, "(28, 0)": 0.7997643947601318, "(28, 16)": 0.7997643947601318, "(30, 0)": 0.7997643947601318, "(30, 16)": 0.7997643947601318}, "r_span": [1054, 1102], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018504858016967773}}]}, {"id": "12519", "source_id": "14404", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how the body systems work together:\n\n1. The skeletal, muscular, digestive, respiratory, circulatory, urinary, endocrine, lymphatic, immune, and nervous systems all work together to help keep the body functioning normally. (Passage 1)\n2. The urinary system works closely with all other systems of the body to clean blood from the body and remove waste products from the skeletal, muscular, digestive, respiratory, circulatory, and nervous systems. (Passage 2)\n3. The respiratory system provides oxygen for all body parts and removes carbon dioxide from the muscular, digestive, skeletal, circulatory, urinary, and nervous systems. (Passage 3)\n\nTherefore, the body systems work together in the following ways:\n\n* The skeletal system provides support and structure for the body, while the muscular system helps move the body and its parts.\n* The digestive system breaks down food into nutrients that can be absorbed and used by the body, while the respiratory system provides oxygen for energy production.\n* The circulatory system delivers oxygenated blood to the body's cells and removes carbon dioxide, while the urinary system removes waste products from the blood.\n* The endocrine system produces hormones that regulate various bodily functions, including growth and development, metabolism, and reproductive processes.\n* The lymphatic system helps defend the body against infection and disease, while the immune system fights off foreign invaders.\n* The nervous system controls and coordinates the body's functions, including movement, sensation, and thought processes.\n\nOverall, the body's systems work together in a complex interplay to maintain homeostasis and ensure the proper functioning of the body.", "response_spans": [[0, 74], [76, 497], [498, 680], [682, 746], [748, 1204], [1205, 1610], [1612, 1747]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7309598922729492, "(0, 16)": 0.7309598922729492, "(2, 0)": 0.7309598922729492, "(2, 16)": 0.7309598922729492, "(4, 0)": 0.7309598922729492, "(4, 16)": 0.7309598922729492, "(6, 0)": 0.7309598922729492, "(6, 16)": 0.8173062801361084, "(8, 0)": 0.7309598922729492, "(8, 16)": 0.7309598922729492, "(10, 0)": 0.7309598922729492, "(10, 16)": 0.7309598922729492, "(12, 0)": 0.7309598922729492, "(12, 16)": 0.8173062801361084, "(14, 0)": 0.7309598922729492, "(14, 16)": 0.7309598922729492, "(16, 0)": 0.8173062801361084, "(16, 16)": 0.7309598922729492, "(18, 0)": 0.7309598922729492, "(18, 16)": 0.8173062801361084, "(20, 0)": 0.8173062801361084, "(20, 16)": 0.715662956237793, "(22, 0)": 0.715662956237793, "(22, 16)": 0.8173062801361084, "(24, 0)": 0.715662956237793, "(24, 16)": 0.8173062801361084, "(26, 0)": 0.715662956237793, "(26, 16)": 0.715662956237793, "(28, 0)": 0.7309598922729492, "(28, 16)": 0.715662956237793, "(30, 0)": 0.715662956237793, "(30, 16)": 0.715662956237793}, "r_span": [327, 345], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010752081871032715}}, {"prompt_attention_score": {"(0, 0)": 0.8289649486541748, "(0, 16)": 0.8289649486541748, "(2, 0)": 0.8289649486541748, "(2, 16)": 0.8289649486541748, "(4, 0)": 0.8289649486541748, "(4, 16)": 0.8289649486541748, "(6, 0)": 0.8289649486541748, "(6, 16)": 0.8953661918640137, "(8, 0)": 0.8289649486541748, "(8, 16)": 0.8289649486541748, "(10, 0)": 0.8289649486541748, "(10, 16)": 0.8289649486541748, "(12, 0)": 0.8289649486541748, "(12, 16)": 0.9020153880119324, "(14, 0)": 0.9020153880119324, "(14, 16)": 0.8289649486541748, "(16, 0)": 0.9020153880119324, "(16, 16)": 0.8289649486541748, "(18, 0)": 0.8289649486541748, "(18, 16)": 0.8953661918640137, "(20, 0)": 0.9020153880119324, "(20, 16)": 0.9020153880119324, "(22, 0)": 0.9020153880119324, "(22, 16)": 0.9020153880119324, "(24, 0)": 0.9020153880119324, "(24, 16)": 0.8953661918640137, "(26, 0)": 0.9020153880119324, "(26, 16)": 0.9020153880119324, "(28, 0)": 0.9020153880119324, "(28, 16)": 0.9020153880119324, "(30, 0)": 0.9020153880119324, "(30, 16)": 0.9020153880119324}, "r_span": [347, 462], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010488033294677734}}, {"prompt_attention_score": {"(0, 0)": 0.937052845954895, "(0, 16)": 0.937052845954895, "(2, 0)": 0.937052845954895, "(2, 16)": 0.937052845954895, "(4, 0)": 0.937052845954895, "(4, 16)": 0.937052845954895, "(6, 0)": 0.937052845954895, "(6, 16)": 0.937052845954895, "(8, 0)": 0.937052845954895, "(8, 16)": 0.937052845954895, "(10, 0)": 0.937052845954895, "(10, 16)": 0.937052845954895, "(12, 0)": 0.937052845954895, "(12, 16)": 0.937052845954895, "(14, 0)": 0.7992917895317078, "(14, 16)": 0.937052845954895, "(16, 0)": 0.937052845954895, "(16, 16)": 0.937052845954895, "(18, 0)": 0.937052845954895, "(18, 16)": 0.937052845954895, "(20, 0)": 0.937052845954895, "(20, 16)": 0.7992917895317078, "(22, 0)": 0.7992917895317078, "(22, 16)": 0.937052845954895, "(24, 0)": 0.7992917895317078, "(24, 16)": 0.937052845954895, "(26, 0)": 0.7992917895317078, "(26, 16)": 0.7992917895317078, "(28, 0)": 0.7992917895317078, "(28, 16)": 0.7992917895317078, "(30, 0)": 0.7992917895317078, "(30, 16)": 0.7992917895317078}, "r_span": [463, 513], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005033016204833984}}, {"prompt_attention_score": {"(0, 0)": 0.714383602142334, "(0, 16)": 0.714383602142334, "(2, 0)": 0.714383602142334, "(2, 16)": 0.714383602142334, "(4, 0)": 0.714383602142334, "(4, 16)": 0.714383602142334, "(6, 0)": 0.714383602142334, "(6, 16)": 0.8502987623214722, "(8, 0)": 0.714383602142334, "(8, 16)": 0.714383602142334, "(10, 0)": 0.714383602142334, "(10, 16)": 0.714383602142334, "(12, 0)": 0.714383602142334, "(12, 16)": 0.8502987623214722, "(14, 0)": 0.7293187379837036, "(14, 16)": 0.714383602142334, "(16, 0)": 0.8502987623214722, "(16, 16)": 0.714383602142334, "(18, 0)": 0.7293187379837036, "(18, 16)": 0.8502987623214722, "(20, 0)": 0.8502987623214722, "(20, 16)": 0.7293187379837036, "(22, 0)": 0.7293187379837036, "(22, 16)": 0.8502987623214722, "(24, 0)": 0.7293187379837036, "(24, 16)": 0.8502987623214722, "(26, 0)": 0.7293187379837036, "(26, 16)": 0.7293187379837036, "(28, 0)": 0.7293187379837036, "(28, 16)": 0.7293187379837036, "(30, 0)": 0.7293187379837036, "(30, 16)": 0.7293187379837036}, "r_span": [515, 528], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003917217254638672}}, {"prompt_attention_score": {"(0, 0)": 0.8217992186546326, "(0, 16)": 0.8217992186546326, "(2, 0)": 0.8217992186546326, "(2, 16)": 0.8217992186546326, "(4, 0)": 0.8217992186546326, "(4, 16)": 0.8217992186546326, "(6, 0)": 0.8217992186546326, "(6, 16)": 0.8217992186546326, "(8, 0)": 0.8217992186546326, "(8, 16)": 0.8217992186546326, "(10, 0)": 0.8217992186546326, "(10, 16)": 0.8217992186546326, "(12, 0)": 0.8081277012825012, "(12, 16)": 0.8217992186546326, "(14, 0)": 0.8081277012825012, "(14, 16)": 0.8081277012825012, "(16, 0)": 0.7882989645004272, "(16, 16)": 0.7882989645004272, "(18, 0)": 0.8081277012825012, "(18, 16)": 0.7882989645004272, "(20, 0)": 0.8081277012825012, "(20, 16)": 0.8081277012825012, "(22, 0)": 0.8081277012825012, "(22, 16)": 0.8081277012825012, "(24, 0)": 0.8081277012825012, "(24, 16)": 0.7882989645004272, "(26, 0)": 0.8081277012825012, "(26, 16)": 0.8081277012825012, "(28, 0)": 0.8081277012825012, "(28, 16)": 0.8081277012825012, "(30, 0)": 0.8081277012825012, "(30, 16)": 0.8081277012825012}, "r_span": [530, 632], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002219080924987793}}, {"prompt_attention_score": {"(0, 0)": 0.7074686884880066, "(0, 16)": 0.7074686884880066, "(2, 0)": 0.7074686884880066, "(2, 16)": 0.7074686884880066, "(4, 0)": 0.7074686884880066, "(4, 16)": 0.7074686884880066, "(6, 0)": 0.7074686884880066, "(6, 16)": 0.7475529313087463, "(8, 0)": 0.7074686884880066, "(8, 16)": 0.7074686884880066, "(10, 0)": 0.7074686884880066, "(10, 16)": 0.7475529313087463, "(12, 0)": 0.7284632921218872, "(12, 16)": 0.7475529313087463, "(14, 0)": 0.7284632921218872, "(14, 16)": 0.7475529313087463, "(16, 0)": 0.7074686884880066, "(16, 16)": 0.7284632921218872, "(18, 0)": 0.7074686884880066, "(18, 16)": 0.7475529313087463, "(20, 0)": 0.7475529313087463, "(20, 16)": 0.7284632921218872, "(22, 0)": 0.7284632921218872, "(22, 16)": 0.7475529313087463, "(24, 0)": 0.7284632921218872, "(24, 16)": 0.7475529313087463, "(26, 0)": 0.7284632921218872, "(26, 16)": 0.7475529313087463, "(28, 0)": 0.7284632921218872, "(28, 16)": 0.7284632921218872, "(30, 0)": 0.7284632921218872, "(30, 16)": 0.7284632921218872}, "r_span": [633, 721], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003141164779663086}}, {"prompt_attention_score": {"(0, 0)": 0.6544804573059082, "(0, 16)": 0.6544804573059082, "(2, 0)": 0.6544804573059082, "(2, 16)": 0.6544804573059082, "(4, 0)": 0.6544804573059082, "(4, 16)": 0.7693946361541748, "(6, 0)": 0.6544804573059082, "(6, 16)": 0.7693946361541748, "(8, 0)": 0.6544804573059082, "(8, 16)": 0.682872474193573, "(10, 0)": 0.6544804573059082, "(10, 16)": 0.6544804573059082, "(12, 0)": 0.682872474193573, "(12, 16)": 0.7693946361541748, "(14, 0)": 0.682872474193573, "(14, 16)": 0.7693946361541748, "(16, 0)": 0.6544804573059082, "(16, 16)": 0.682872474193573, "(18, 0)": 0.6544804573059082, "(18, 16)": 0.7693946361541748, "(20, 0)": 0.7693946361541748, "(20, 16)": 0.682872474193573, "(22, 0)": 0.682872474193573, "(22, 16)": 0.6544804573059082, "(24, 0)": 0.682872474193573, "(24, 16)": 0.7693946361541748, "(26, 0)": 0.682872474193573, "(26, 16)": 0.682872474193573, "(28, 0)": 0.682872474193573, "(28, 16)": 0.682872474193573, "(30, 0)": 0.682872474193573, "(30, 16)": 0.682872474193573}, "r_span": [723, 753], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -8.559226989746094e-05}}]}, {"id": "12525", "source_id": "14405", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main difference between the Windward Islands and the Leeward Islands is that the Windward Islands receive more rain and are wetter due to their proximity to the ocean, while the Leeward Islands are drier but still receive some rainfall. The Windward Islands are located closer to the ocean and are exposed to the northeast trade winds, which bring more moisture and precipitation to the area. In contrast, the Leeward Islands are farther away from the ocean and receive less rainfall due to their location on the leeward side of the mountains.", "response_spans": [[0, 510], [494, 579]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7808901071548462, "(0, 16)": 0.7808901071548462, "(2, 0)": 0.7808901071548462, "(2, 16)": 0.7808901071548462, "(4, 0)": 0.7808901071548462, "(4, 16)": 0.7808901071548462, "(6, 0)": 0.7808901071548462, "(6, 16)": 0.7956744432449341, "(8, 0)": 0.7808901071548462, "(8, 16)": 0.7808901071548462, "(10, 0)": 0.7808901071548462, "(10, 16)": 0.7808901071548462, "(12, 0)": 0.7808901071548462, "(12, 16)": 0.8170440196990967, "(14, 0)": 0.7808901071548462, "(14, 16)": 0.7808901071548462, "(16, 0)": 0.7985678911209106, "(16, 16)": 0.7808901071548462, "(18, 0)": 0.7808901071548462, "(18, 16)": 0.8170440196990967, "(20, 0)": 0.8170440196990967, "(20, 16)": 0.7956744432449341, "(22, 0)": 0.7956744432449341, "(22, 16)": 0.8170440196990967, "(24, 0)": 0.7956744432449341, "(24, 16)": 0.8170440196990967, "(26, 0)": 0.7956744432449341, "(26, 16)": 0.7956744432449341, "(28, 0)": 0.7956744432449341, "(28, 16)": 0.7956744432449341, "(30, 0)": 0.7956744432449341, "(30, 16)": 0.7956744432449341}, "r_span": [358, 470], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014162063598632812}}, {"prompt_attention_score": {"(0, 0)": 0.513124942779541, "(0, 16)": 0.513124942779541, "(2, 0)": 0.513124942779541, "(2, 16)": 0.513124942779541, "(4, 0)": 0.513124942779541, "(4, 16)": 0.513124942779541, "(6, 0)": 0.513124942779541, "(6, 16)": 0.661662757396698, "(8, 0)": 0.513124942779541, "(8, 16)": 0.5357405543327332, "(10, 0)": 0.513124942779541, "(10, 16)": 0.5357405543327332, "(12, 0)": 0.513124942779541, "(12, 16)": 0.5357405543327332, "(14, 0)": 0.5357405543327332, "(14, 16)": 0.513124942779541, "(16, 0)": 0.513124942779541, "(16, 16)": 0.513124942779541, "(18, 0)": 0.5357405543327332, "(18, 16)": 0.661662757396698, "(20, 0)": 0.661662757396698, "(20, 16)": 0.5357405543327332, "(22, 0)": 0.5357405543327332, "(22, 16)": 0.661662757396698, "(24, 0)": 0.5357405543327332, "(24, 16)": 0.661662757396698, "(26, 0)": 0.5357405543327332, "(26, 16)": 0.513124942779541, "(28, 0)": 0.5357405543327332, "(28, 16)": 0.5357405543327332, "(30, 0)": 0.5357405543327332, "(30, 16)": 0.5357405543327332}, "r_span": [468, 487], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00012123584747314453}}]}, {"id": "12555", "source_id": "14410", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how water shares are transferred:\n\n1. Passage 1 states that a fee of $75.00 must be paid to process a Water Stock Certificate transfer. The passage also mentions that a new Water Stock Certificate will be issued to the new owner of record.\n2. Passage 2 outlines the steps required to transfer a Water Stock Certificate: (a) The seller must return the Water Stock Certificate and sign the back of the certificate, (b) the new owner of the property must provide proof of ownership, (c) a fee of $75.00 must be paid to process the transfer, and (d) a new Water Stock Certificate will be issued to the new owner.\n3. Passage 3 provides general information about buying a home with water shares or rights, including the need to understand the steps involved in transferring water rights into the buyer's name. However, this passage does not provide specific instructions for transferring water shares.\n\nTherefore, based on the provided passages, the answer to the question is:\n\nTransferring water shares involves paying a fee of $75.00 to process the transfer, returning the Water Stock Certificate to the company, providing proof of ownership, and obtaining a new Water Stock Certificate in the new owner's name.", "response_spans": [[0, 72], [74, 278], [279, 647], [648, 934], [936, 1246]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6784462928771973, "(0, 16)": 0.6784462928771973, "(2, 0)": 0.6784462928771973, "(2, 16)": 0.6784462928771973, "(4, 0)": 0.6784462928771973, "(4, 16)": 0.6784462928771973, "(6, 0)": 0.6784462928771973, "(6, 16)": 0.7293349504470825, "(8, 0)": 0.6784462928771973, "(8, 16)": 0.5068446397781372, "(10, 0)": 0.5068446397781372, "(10, 16)": 0.5068446397781372, "(12, 0)": 0.7293349504470825, "(12, 16)": 0.7293349504470825, "(14, 0)": 0.7293349504470825, "(14, 16)": 0.5068446397781372, "(16, 0)": 0.7293349504470825, "(16, 16)": 0.7293349504470825, "(18, 0)": 0.5068446397781372, "(18, 16)": 0.7293349504470825, "(20, 0)": 0.7293349504470825, "(20, 16)": 0.7293349504470825, "(22, 0)": 0.7293349504470825, "(22, 16)": 0.7293349504470825, "(24, 0)": 0.7293349504470825, "(24, 16)": 0.7293349504470825, "(26, 0)": 0.7293349504470825, "(26, 16)": 0.7293349504470825, "(28, 0)": 0.5068446397781372, "(28, 16)": 0.7293349504470825, "(30, 0)": 0.7293349504470825, "(30, 16)": 0.7293349504470825}, "r_span": [390, 407], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -5.513429641723633e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6659033298492432, "(0, 16)": 0.6659033298492432, "(2, 0)": 0.6659033298492432, "(2, 16)": 0.6659033298492432, "(4, 0)": 0.6659033298492432, "(4, 16)": 0.6659033298492432, "(6, 0)": 0.6659033298492432, "(6, 16)": 0.9498967528343201, "(8, 0)": 0.9498967528343201, "(8, 16)": 0.6659033298492432, "(10, 0)": 0.6659033298492432, "(10, 16)": 0.6659033298492432, "(12, 0)": 0.9498967528343201, "(12, 16)": 0.9498967528343201, "(14, 0)": 0.9498967528343201, "(14, 16)": 0.9498967528343201, "(16, 0)": 0.9498967528343201, "(16, 16)": 0.9498967528343201, "(18, 0)": 0.9498967528343201, "(18, 16)": 0.9498967528343201, "(20, 0)": 0.9498967528343201, "(20, 16)": 0.9498967528343201, "(22, 0)": 0.9498967528343201, "(22, 16)": 0.9498967528343201, "(24, 0)": 0.9498967528343201, "(24, 16)": 0.9498967528343201, "(26, 0)": 0.9498967528343201, "(26, 16)": 0.9498967528343201, "(28, 0)": 0.9498967528343201, "(28, 16)": 0.9498967528343201, "(30, 0)": 0.9498967528343201, "(30, 16)": 0.9498967528343201}, "r_span": [409, 459], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00015854835510253906}}, {"prompt_attention_score": {"(0, 0)": 0.7091448307037354, "(0, 16)": 0.7091448307037354, "(2, 0)": 0.7091448307037354, "(2, 16)": 0.7091448307037354, "(4, 0)": 0.7091448307037354, "(4, 16)": 0.7091448307037354, "(6, 0)": 0.7091448307037354, "(6, 16)": 0.9245697855949402, "(8, 0)": 0.7091448307037354, "(8, 16)": 0.7091448307037354, "(10, 0)": 0.7091448307037354, "(10, 16)": 0.7091448307037354, "(12, 0)": 0.9245697855949402, "(12, 16)": 0.98836350440979, "(14, 0)": 0.9245697855949402, "(14, 16)": 0.98836350440979, "(16, 0)": 0.98836350440979, "(16, 16)": 0.9245697855949402, "(18, 0)": 0.9245697855949402, "(18, 16)": 0.98836350440979, "(20, 0)": 0.98836350440979, "(20, 16)": 0.9245697855949402, "(22, 0)": 0.9245697855949402, "(22, 16)": 0.98836350440979, "(24, 0)": 0.9245697855949402, "(24, 16)": 0.98836350440979, "(26, 0)": 0.9245697855949402, "(26, 16)": 0.9245697855949402, "(28, 0)": 0.9245697855949402, "(28, 16)": 0.9245697855949402, "(30, 0)": 0.9245697855949402, "(30, 16)": 0.9245697855949402}, "r_span": [460, 553], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001246929168701172}}, {"prompt_attention_score": {"(0, 0)": 0.7460026144981384, "(0, 16)": 0.8800241947174072, "(2, 0)": 0.8800241947174072, "(2, 16)": 0.7757723331451416, "(4, 0)": 0.8800241947174072, "(4, 16)": 0.8800241947174072, "(6, 0)": 0.8800241947174072, "(6, 16)": 0.8800241947174072, "(8, 0)": 0.8800241947174072, "(8, 16)": 0.7757723331451416, "(10, 0)": 0.8800241947174072, "(10, 16)": 0.8800241947174072, "(12, 0)": 0.7460026144981384, "(12, 16)": 0.8800241947174072, "(14, 0)": 0.7460026144981384, "(14, 16)": 0.5227507948875427, "(16, 0)": 0.8800241947174072, "(16, 16)": 0.7460026144981384, "(18, 0)": 0.7460026144981384, "(18, 16)": 0.8800241947174072, "(20, 0)": 0.8800241947174072, "(20, 16)": 0.7460026144981384, "(22, 0)": 0.7460026144981384, "(22, 16)": 0.8800241947174072, "(24, 0)": 0.7460026144981384, "(24, 16)": 0.8800241947174072, "(26, 0)": 0.7460026144981384, "(26, 16)": 0.7460026144981384, "(28, 0)": 0.7460026144981384, "(28, 16)": 0.7460026144981384, "(30, 0)": 0.7460026144981384, "(30, 16)": 0.7460026144981384}, "r_span": [554, 610], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006961822509765625}}, {"prompt_attention_score": {"(0, 0)": 0.9455356001853943, "(0, 16)": 0.9455356001853943, "(2, 0)": 0.6848506927490234, "(2, 16)": 0.6848506927490234, "(4, 0)": 0.6848506927490234, "(4, 16)": 0.9455356001853943, "(6, 0)": 0.6848506927490234, "(6, 16)": 0.9455356001853943, "(8, 0)": 0.6848506927490234, "(8, 16)": 0.6848506927490234, "(10, 0)": 0.4095214605331421, "(10, 16)": 0.6848506927490234, "(12, 0)": 0.9455356001853943, "(12, 16)": 0.9118310213088989, "(14, 0)": 0.9455356001853943, "(14, 16)": 0.4095214605331421, "(16, 0)": 0.9455356001853943, "(16, 16)": 0.9455356001853943, "(18, 0)": 0.9455356001853943, "(18, 16)": 0.9455356001853943, "(20, 0)": 0.9455356001853943, "(20, 16)": 0.9455356001853943, "(22, 0)": 0.9455356001853943, "(22, 16)": 0.9455356001853943, "(24, 0)": 0.9455356001853943, "(24, 16)": 0.9455356001853943, "(26, 0)": 0.9455356001853943, "(26, 16)": 0.9455356001853943, "(28, 0)": 0.9455356001853943, "(28, 16)": 0.9455356001853943, "(30, 0)": 0.9455356001853943, "(30, 16)": 0.9455356001853943}, "r_span": [612, 685], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009555220603942871}}]}, {"id": "12603", "source_id": "14418", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the meaning of the name Teresa is:\n\n* In Greek, the meaning of Teresa is \"Reap; from Therasia.\"\n* In American, the meaning of Teresa is \"Reaper; from Therasia.\"\n* In Italian, the meaning of Teresa is \"Harvester.\"\n* In Spanish, the meaning of Teresa is \"Name of two popular saints 'Teresa of Avila' and 'Therese of Lisieux.'\"\n\nTherefore, I can confidently answer the question.", "response_spans": [[0, 407]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8204032182693481, "(0, 16)": 0.8204032182693481, "(2, 0)": 0.8204032182693481, "(2, 16)": 0.8204032182693481, "(4, 0)": 0.8204032182693481, "(4, 16)": 0.8204032182693481, "(6, 0)": 0.8204032182693481, "(6, 16)": 0.8956358432769775, "(8, 0)": 0.8204032182693481, "(8, 16)": 0.8204032182693481, "(10, 0)": 0.8204032182693481, "(10, 16)": 0.8204032182693481, "(12, 0)": 0.8204032182693481, "(12, 16)": 0.914935827255249, "(14, 0)": 0.8204032182693481, "(14, 16)": 0.39661505818367004, "(16, 0)": 0.8204032182693481, "(16, 16)": 0.8204032182693481, "(18, 0)": 0.8204032182693481, "(18, 16)": 0.8956358432769775, "(20, 0)": 0.8956358432769775, "(20, 16)": 0.8204032182693481, "(22, 0)": 0.8204032182693481, "(22, 16)": 0.39661505818367004, "(24, 0)": 0.8204032182693481, "(24, 16)": 0.8956358432769775, "(26, 0)": 0.8204032182693481, "(26, 16)": 0.8204032182693481, "(28, 0)": 0.8204032182693481, "(28, 16)": 0.8204032182693481, "(30, 0)": 0.8204032182693481, "(30, 16)": 0.8204032182693481}, "r_span": [602, 725], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015943050384521484}}]}, {"id": "12621", "source_id": "14421", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's my attempt to answer your question based on the provided passages:\n\nHow do you prepare the site for building a lean-to shed?\n\nAccording to passage 1, step 1, you should prepare the site by laying down a 4\" layer of compacted gravel. This will provide a stable base for the shed's foundation. Additionally, passage 2 mentions cutting two pressure-treated 4x4s to a length of 6 feet for the skids, which will serve as the foundation for the shed. Finally, passage 3 provides instructions for building the shed's floor, including cutting rim joists to a length of 6 feet. Based on these passages, it appears that preparing the site involves laying down a layer of gravel and setting the skids in place before constructing the floor.", "response_spans": [[0, 137], [139, 650], [633, 742]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7400833368301392, "(0, 16)": 0.7400833368301392, "(2, 0)": 0.7400833368301392, "(2, 16)": 0.7400833368301392, "(4, 0)": 0.7400833368301392, "(4, 16)": 0.7400833368301392, "(6, 0)": 0.7400833368301392, "(6, 16)": 0.852174699306488, "(8, 0)": 0.7400833368301392, "(8, 16)": 0.7400833368301392, "(10, 0)": 0.7400833368301392, "(10, 16)": 0.7400833368301392, "(12, 0)": 0.7400833368301392, "(12, 16)": 0.7400833368301392, "(14, 0)": 0.7400833368301392, "(14, 16)": 0.7400833368301392, "(16, 0)": 0.852174699306488, "(16, 16)": 0.7400833368301392, "(18, 0)": 0.7400833368301392, "(18, 16)": 0.8338422179222107, "(20, 0)": 0.8338422179222107, "(20, 16)": 0.7400833368301392, "(22, 0)": 0.7400833368301392, "(22, 16)": 0.852174699306488, "(24, 0)": 0.7400833368301392, "(24, 16)": 0.7400833368301392, "(26, 0)": 0.7400833368301392, "(26, 16)": 0.8338422179222107, "(28, 0)": 0.7400833368301392, "(28, 16)": 0.7400833368301392, "(30, 0)": 0.7400833368301392, "(30, 16)": 0.8338422179222107}, "r_span": [439, 474], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014162063598632812}}, {"prompt_attention_score": {"(0, 0)": 0.8711042404174805, "(0, 16)": 0.8711042404174805, "(2, 0)": 0.8711042404174805, "(2, 16)": 0.8711042404174805, "(4, 0)": 0.8711042404174805, "(4, 16)": 0.8711042404174805, "(6, 0)": 0.8711042404174805, "(6, 16)": 0.8671357035636902, "(8, 0)": 0.8835111260414124, "(8, 16)": 0.8711042404174805, "(10, 0)": 0.8711042404174805, "(10, 16)": 0.8711042404174805, "(12, 0)": 0.8711042404174805, "(12, 16)": 0.8711042404174805, "(14, 0)": 0.8711042404174805, "(14, 16)": 0.8711042404174805, "(16, 0)": 0.8711042404174805, "(16, 16)": 0.8711042404174805, "(18, 0)": 0.8711042404174805, "(18, 16)": 0.8835111260414124, "(20, 0)": 0.8835111260414124, "(20, 16)": 0.8711042404174805, "(22, 0)": 0.8711042404174805, "(22, 16)": 0.8835111260414124, "(24, 0)": 0.8711042404174805, "(24, 16)": 0.8835111260414124, "(26, 0)": 0.8835111260414124, "(26, 16)": 0.8711042404174805, "(28, 0)": 0.8835111260414124, "(28, 16)": 0.8711042404174805, "(30, 0)": 0.8835111260414124, "(30, 16)": 0.8835111260414124}, "r_span": [476, 601], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018650293350219727}}, {"prompt_attention_score": {"(0, 0)": 0.581378161907196, "(0, 16)": 0.581378161907196, "(2, 0)": 0.581378161907196, "(2, 16)": 0.581378161907196, "(4, 0)": 0.581378161907196, "(4, 16)": 0.581378161907196, "(6, 0)": 0.581378161907196, "(6, 16)": 0.6966168880462646, "(8, 0)": 0.6966168880462646, "(8, 16)": 0.581378161907196, "(10, 0)": 0.581378161907196, "(10, 16)": 0.581378161907196, "(12, 0)": 0.581378161907196, "(12, 16)": 0.6966168880462646, "(14, 0)": 0.581378161907196, "(14, 16)": 0.581378161907196, "(16, 0)": 0.581378161907196, "(16, 16)": 0.581378161907196, "(18, 0)": 0.581378161907196, "(18, 16)": 0.6966168880462646, "(20, 0)": 0.6966168880462646, "(20, 16)": 0.581378161907196, "(22, 0)": 0.581378161907196, "(22, 16)": 0.6966168880462646, "(24, 0)": 0.581378161907196, "(24, 16)": 0.6966168880462646, "(26, 0)": 0.6966168880462646, "(26, 16)": 0.6966168880462646, "(28, 0)": 0.6966168880462646, "(28, 16)": 0.581378161907196, "(30, 0)": 0.6966168880462646, "(30, 16)": 0.6966168880462646}, "r_span": [599, 622], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008015632629394531}}]}, {"id": "12693", "source_id": "14433", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 605, "end": 657, "text": "France opposed Indian involvement in the Vietnam War", "meta": "HIGH INTRO OF NEW INFO\nIt includes a point about France opposing Indian involvement in the Vietnam War, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some differences between Vietnam and India:\n\n1. Education system: While India's education system is more focused on getting children into school, Vietnam's education system is more equitable, meaning that poorer children receive the same quality of education as their wealthier counterparts.\n2. Colonial history: India was a colony of the United Kingdom, while Vietnam was a colony of France. Both countries gained independence from their colonizers in the mid-20th century.\n3. Relationship with France: India supported Vietnam's independence from France, whereas France opposed Indian involvement in the Vietnam War.\n4. Economic links: Both India and Vietnam have cultural and economic ties dating back to the 2nd century, with the Indic ChƒÉm Pa kingdom having some influence on Vietnamese music.\n5. Post-colonial division: Unlike India, where the country became divided between Hindus, Muslims, and Sikhs after independence, Vietnam did not experience such divisions after gaining independence from France.\n\nUnable to answer based on given passages.", "response_spans": [[0, 84], [86, 515], [516, 838], [839, 1049], [1051, 1092]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6528815627098083, "(0, 16)": 0.6528815627098083, "(2, 0)": 0.6528815627098083, "(2, 16)": 0.6528815627098083, "(4, 0)": 0.6528815627098083, "(4, 16)": 0.6528815627098083, "(6, 0)": 0.49312639236450195, "(6, 16)": 0.8926315307617188, "(8, 0)": 0.6528815627098083, "(8, 16)": 0.49312639236450195, "(10, 0)": 0.49312639236450195, "(10, 16)": 0.49312639236450195, "(12, 0)": 0.49312639236450195, "(12, 16)": 0.8926315307617188, "(14, 0)": 0.6528815627098083, "(14, 16)": 0.49312639236450195, "(16, 0)": 0.8926315307617188, "(16, 16)": 0.49312639236450195, "(18, 0)": 0.49312639236450195, "(18, 16)": 0.8926315307617188, "(20, 0)": 0.8926315307617188, "(20, 16)": 0.6528815627098083, "(22, 0)": 0.4970652461051941, "(22, 16)": 0.8926315307617188, "(24, 0)": 0.6528815627098083, "(24, 16)": 0.8926315307617188, "(26, 0)": 0.4970652461051941, "(26, 16)": 0.4970652461051941, "(28, 0)": 0.49312639236450195, "(28, 16)": 0.6528815627098083, "(30, 0)": 0.4970652461051941, "(30, 16)": 0.4970652461051941}, "r_span": [486, 503], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005998611450195312}}, {"prompt_attention_score": {"(0, 0)": 0.6503720283508301, "(0, 16)": 0.6503720283508301, "(2, 0)": 0.6503720283508301, "(2, 16)": 0.6503720283508301, "(4, 0)": 0.6503720283508301, "(4, 16)": 0.6503720283508301, "(6, 0)": 0.6503720283508301, "(6, 16)": 0.7342166900634766, "(8, 0)": 0.6503720283508301, "(8, 16)": 0.6503720283508301, "(10, 0)": 0.7342166900634766, "(10, 16)": 0.6875594258308411, "(12, 0)": 0.6503720283508301, "(12, 16)": 0.6503720283508301, "(14, 0)": 0.6503720283508301, "(14, 16)": 0.6503720283508301, "(16, 0)": 0.7342166900634766, "(16, 16)": 0.6503720283508301, "(18, 0)": 0.6503720283508301, "(18, 16)": 0.7342166900634766, "(20, 0)": 0.7342166900634766, "(20, 16)": 0.6503720283508301, "(22, 0)": 0.5778766870498657, "(22, 16)": 0.6503720283508301, "(24, 0)": 0.6503720283508301, "(24, 16)": 0.7342166900634766, "(26, 0)": 0.5778766870498657, "(26, 16)": 0.6503720283508301, "(28, 0)": 0.5778766870498657, "(28, 16)": 0.6503720283508301, "(30, 0)": 0.5778766870498657, "(30, 16)": 0.5778766870498657}, "r_span": [505, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005585551261901855}}, {"prompt_attention_score": {"(0, 0)": 0.6582632064819336, "(0, 16)": 0.6582632064819336, "(2, 0)": 0.6582632064819336, "(2, 16)": 0.8645572662353516, "(4, 0)": 0.6582632064819336, "(4, 16)": 0.6582632064819336, "(6, 0)": 0.8645572662353516, "(6, 16)": 0.8645572662353516, "(8, 0)": 0.6582632064819336, "(8, 16)": 0.6582632064819336, "(10, 0)": 0.6582632064819336, "(10, 16)": 0.6582632064819336, "(12, 0)": 0.8645572662353516, "(12, 16)": 0.8645572662353516, "(14, 0)": 0.6582632064819336, "(14, 16)": 0.8645572662353516, "(16, 0)": 0.6582632064819336, "(16, 16)": 0.6582632064819336, "(18, 0)": 0.4063275456428528, "(18, 16)": 0.8645572662353516, "(20, 0)": 0.8645572662353516, "(20, 16)": 0.6582632064819336, "(22, 0)": 0.4031645655632019, "(22, 16)": 0.8645572662353516, "(24, 0)": 0.6582632064819336, "(24, 16)": 0.8645572662353516, "(26, 0)": 0.4031645655632019, "(26, 16)": 0.6582632064819336, "(28, 0)": 0.4031645655632019, "(28, 16)": 0.6582632064819336, "(30, 0)": 0.4031645655632019, "(30, 16)": 0.4031645655632019}, "r_span": [597, 669], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0016704201698303223}}, {"prompt_attention_score": {"(0, 0)": 0.6964513659477234, "(0, 16)": 0.6964513659477234, "(2, 0)": 0.6964513659477234, "(2, 16)": 0.6964513659477234, "(4, 0)": 0.6964513659477234, "(4, 16)": 0.6964513659477234, "(6, 0)": 0.6964513659477234, "(6, 16)": 0.7897527813911438, "(8, 0)": 0.6964513659477234, "(8, 16)": 0.6964513659477234, "(10, 0)": 0.6964513659477234, "(10, 16)": 0.6964513659477234, "(12, 0)": 0.6964513659477234, "(12, 16)": 0.7897527813911438, "(14, 0)": 0.6964513659477234, "(14, 16)": 0.7897527813911438, "(16, 0)": 0.6964513659477234, "(16, 16)": 0.6964513659477234, "(18, 0)": 0.6964513659477234, "(18, 16)": 0.7897527813911438, "(20, 0)": 0.6964513659477234, "(20, 16)": 0.6964513659477234, "(22, 0)": 0.6964513659477234, "(22, 16)": 0.6964513659477234, "(24, 0)": 0.6964513659477234, "(24, 16)": 0.7897527813911438, "(26, 0)": 0.4645836353302002, "(26, 16)": 0.6964513659477234, "(28, 0)": 0.4645836353302002, "(28, 16)": 0.6964513659477234, "(30, 0)": 0.4645836353302002, "(30, 16)": 0.4645836353302002}, "r_span": [670, 715], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0014448165893554688}}, {"prompt_attention_score": {"(0, 0)": 0.6294246912002563, "(0, 16)": 0.6294246912002563, "(2, 0)": 0.6294246912002563, "(2, 16)": 0.6294246912002563, "(4, 0)": 0.6294246912002563, "(4, 16)": 0.6294246912002563, "(6, 0)": 0.9034074544906616, "(6, 16)": 0.9034074544906616, "(8, 0)": 0.6294246912002563, "(8, 16)": 0.6294246912002563, "(10, 0)": 0.9034074544906616, "(10, 16)": 0.9034074544906616, "(12, 0)": 0.9034074544906616, "(12, 16)": 0.9034074544906616, "(14, 0)": 0.5487350225448608, "(14, 16)": 0.9034074544906616, "(16, 0)": 0.9034074544906616, "(16, 16)": 0.6294246912002563, "(18, 0)": 0.6294246912002563, "(18, 16)": 0.9034074544906616, "(20, 0)": 0.9034074544906616, "(20, 16)": 0.6294246912002563, "(22, 0)": 0.5487350225448608, "(22, 16)": 0.9034074544906616, "(24, 0)": 0.6294246912002563, "(24, 16)": 0.9034074544906616, "(26, 0)": 0.5487350225448608, "(26, 16)": 0.5487350225448608, "(28, 0)": 0.5487350225448608, "(28, 16)": 0.5487350225448608, "(30, 0)": 0.5487350225448608, "(30, 16)": 0.5487350225448608}, "r_span": [717, 727], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001658797264099121}}]}, {"id": "12705", "source_id": "14435", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Here are brief answers to the question on how to roast individual garlic cloves based on the provided passages:\n\nPassage 1: The passage does not provide information on how to roast individual garlic cloves specifically. However, it does mention that larger garlic cloves may take up to an hour to soften when roasted, so it is possible to assume that smaller cloves will take less time.\n\nPassage 2: This passage provides some options for seasoning the garlic before roasting, but it does not provide instructions on how to roast individual garlic cloves.\n\nPassage 3: This passage provides a method for roasting entire garlic heads, but it does not address how to roast individual garlic cloves. The passage does mention that cutting the top of the garlic bulb and exposing the individual cloves can help them roast more evenly, but it does not provide specific instructions on how to do this.\n\nUnable to answer based on given passages.", "response_spans": [[0, 386], [388, 892], [894, 935]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.740910530090332, "(0, 16)": 0.740910530090332, "(2, 0)": 0.740910530090332, "(2, 16)": 0.740910530090332, "(4, 0)": 0.740910530090332, "(4, 16)": 0.740910530090332, "(6, 0)": 0.740910530090332, "(6, 16)": 0.9342650175094604, "(8, 0)": 0.740910530090332, "(8, 16)": 0.441298246383667, "(10, 0)": 0.441298246383667, "(10, 16)": 0.441298246383667, "(12, 0)": 0.9342650175094604, "(12, 16)": 0.9342650175094604, "(14, 0)": 0.9342650175094604, "(14, 16)": 0.9342650175094604, "(16, 0)": 0.9342650175094604, "(16, 16)": 0.9342650175094604, "(18, 0)": 0.441298246383667, "(18, 16)": 0.9342650175094604, "(20, 0)": 0.9342650175094604, "(20, 16)": 0.740910530090332, "(22, 0)": 0.9342650175094604, "(22, 16)": 0.9342650175094604, "(24, 0)": 0.7332959175109863, "(24, 16)": 0.9342650175094604, "(26, 0)": 0.9342650175094604, "(26, 16)": 0.9342650175094604, "(28, 0)": 0.9342650175094604, "(28, 16)": 0.740910530090332, "(30, 0)": 0.9342650175094604, "(30, 16)": 0.9342650175094604}, "r_span": [474, 562], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001159965991973877}}, {"prompt_attention_score": {"(0, 0)": 0.8484222292900085, "(0, 16)": 0.8484222292900085, "(2, 0)": 0.8484222292900085, "(2, 16)": 0.8484222292900085, "(4, 0)": 0.8484222292900085, "(4, 16)": 0.8484222292900085, "(6, 0)": 0.8484222292900085, "(6, 16)": 0.789872407913208, "(8, 0)": 0.8484222292900085, "(8, 16)": 0.8484222292900085, "(10, 0)": 0.8484222292900085, "(10, 16)": 0.8484222292900085, "(12, 0)": 0.789872407913208, "(12, 16)": 0.8484222292900085, "(14, 0)": 0.789872407913208, "(14, 16)": 0.8484222292900085, "(16, 0)": 0.789872407913208, "(16, 16)": 0.789872407913208, "(18, 0)": 0.789872407913208, "(18, 16)": 0.8484222292900085, "(20, 0)": 0.8484222292900085, "(20, 16)": 0.8484222292900085, "(22, 0)": 0.789872407913208, "(22, 16)": 0.8484222292900085, "(24, 0)": 0.8484222292900085, "(24, 16)": 0.8484222292900085, "(26, 0)": 0.789872407913208, "(26, 16)": 0.8484222292900085, "(28, 0)": 0.789872407913208, "(28, 16)": 0.8484222292900085, "(30, 0)": 0.7764793634414673, "(30, 16)": 0.789872407913208}, "r_span": [564, 681], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0024932026863098145}}, {"prompt_attention_score": {"(0, 0)": 0.4915989637374878, "(0, 16)": 0.4915989637374878, "(2, 0)": 0.4915989637374878, "(2, 16)": 0.4915989637374878, "(4, 0)": 0.4915989637374878, "(4, 16)": 0.4915989637374878, "(6, 0)": 0.4915989637374878, "(6, 16)": 0.9034074544906616, "(8, 0)": 0.4915989637374878, "(8, 16)": 0.4915989637374878, "(10, 0)": 0.9034074544906616, "(10, 16)": 0.9034074544906616, "(12, 0)": 0.44580554962158203, "(12, 16)": 0.9034074544906616, "(14, 0)": 0.44580554962158203, "(14, 16)": 0.9034074544906616, "(16, 0)": 0.9034074544906616, "(16, 16)": 0.44580554962158203, "(18, 0)": 0.44580554962158203, "(18, 16)": 0.9034074544906616, "(20, 0)": 0.9034074544906616, "(20, 16)": 0.4915989637374878, "(22, 0)": 0.44580554962158203, "(22, 16)": 0.9034074544906616, "(24, 0)": 0.4915989637374878, "(24, 16)": 0.9034074544906616, "(26, 0)": 0.44580554962158203, "(26, 16)": 0.44580554962158203, "(28, 0)": 0.44580554962158203, "(28, 16)": 0.4915989637374878, "(30, 0)": 0.44580554962158203, "(30, 16)": 0.44580554962158203}, "r_span": [683, 693], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0001767277717590332}}]}, {"id": "12765", "source_id": "14445", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 826, "end": 861, "text": "Section 50(1) of the Income Tax Act", "meta": "EVIDENT CONFLICT\nOriginal: section 43(6)\nGenerated: Section 50(1) of the Income Tax Act", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the treatment for an asset discarded as per the Income Tax Act is as follows:\n\n1. If an asset is discarded by a business without selling it, the scrap value of the asset can be reduced from the block of assets in the previous year in which the asset was discarded, as per Section 43(6) of the Income Tax Act.\n2. The block concept applies to all assets falling within the same class and subject to the same rate of depreciation, and any alterations to the value of the block must be made in accordance with the provisions of Chapter IV D of the Income Tax Act, 1961.\n3. If the assessee is entitled to claim depreciation on the residual value of a discarded asset, they can do so even if the asset is not used for business or professional purposes in the current year or subsequent years, as per Section 50(1) of the Income Tax Act.\n\nTherefore, the treatment for an asset discarded as per the Income Tax Act is to reduce the scrap value from the block of assets in the previous year, follow the block concept for calculating depreciation, and claim depreciation on the residual value of the discarded asset even if it is not used for business or professional purposes.", "response_spans": [[0, 109], [111, 597], [598, 862], [864, 1198]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7144207954406738, "(0, 16)": 0.7144207954406738, "(2, 0)": 0.7144207954406738, "(2, 16)": 0.7144207954406738, "(4, 0)": 0.7144207954406738, "(4, 16)": 0.7144207954406738, "(6, 0)": 0.7144207954406738, "(6, 16)": 0.860533595085144, "(8, 0)": 0.6567387580871582, "(8, 16)": 0.7144207954406738, "(10, 0)": 0.538995623588562, "(10, 16)": 0.538995623588562, "(12, 0)": 0.538995623588562, "(12, 16)": 0.860533595085144, "(14, 0)": 0.630164623260498, "(14, 16)": 0.538995623588562, "(16, 0)": 0.860533595085144, "(16, 16)": 0.7144207954406738, "(18, 0)": 0.538995623588562, "(18, 16)": 0.860533595085144, "(20, 0)": 0.860533595085144, "(20, 16)": 0.630164623260498, "(22, 0)": 0.630164623260498, "(22, 16)": 0.860533595085144, "(24, 0)": 0.630164623260498, "(24, 16)": 0.860533595085144, "(26, 0)": 0.630164623260498, "(26, 16)": 0.7767593860626221, "(28, 0)": 0.538995623588562, "(28, 16)": 0.630164623260498, "(30, 0)": 0.630164623260498, "(30, 16)": 0.630164623260498}, "r_span": [584, 610], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006638169288635254}}, {"prompt_attention_score": {"(0, 0)": 0.807203471660614, "(0, 16)": 0.807203471660614, "(2, 0)": 0.807203471660614, "(2, 16)": 0.807203471660614, "(4, 0)": 0.807203471660614, "(4, 16)": 0.807203471660614, "(6, 0)": 0.807203471660614, "(6, 16)": 0.871504545211792, "(8, 0)": 0.807203471660614, "(8, 16)": 0.807203471660614, "(10, 0)": 0.807203471660614, "(10, 16)": 0.807203471660614, "(12, 0)": 0.807203471660614, "(12, 16)": 0.871504545211792, "(14, 0)": 0.5483947992324829, "(14, 16)": 0.871504545211792, "(16, 0)": 0.871504545211792, "(16, 16)": 0.807203471660614, "(18, 0)": 0.807203471660614, "(18, 16)": 0.871504545211792, "(20, 0)": 0.871504545211792, "(20, 16)": 0.5483947992324829, "(22, 0)": 0.5483947992324829, "(22, 16)": 0.871504545211792, "(24, 0)": 0.5483947992324829, "(24, 16)": 0.871504545211792, "(26, 0)": 0.5483947992324829, "(26, 16)": 0.5483947992324829, "(28, 0)": 0.5483947992324829, "(28, 16)": 0.5483947992324829, "(30, 0)": 0.5483947992324829, "(30, 16)": 0.5483947992324829}, "r_span": [612, 734], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006601810455322266}}, {"prompt_attention_score": {"(0, 0)": 0.7564231157302856, "(0, 16)": 0.7564231157302856, "(2, 0)": 0.7564231157302856, "(2, 16)": 0.45519331097602844, "(4, 0)": 0.7564231157302856, "(4, 16)": 0.7564231157302856, "(6, 0)": 0.7564231157302856, "(6, 16)": 0.7410052418708801, "(8, 0)": 0.7564231157302856, "(8, 16)": 0.7564231157302856, "(10, 0)": 0.7564231157302856, "(10, 16)": 0.7564231157302856, "(12, 0)": 0.7564231157302856, "(12, 16)": 0.7564231157302856, "(14, 0)": 0.4777040183544159, "(14, 16)": 0.7564231157302856, "(16, 0)": 0.7564231157302856, "(16, 16)": 0.4777040183544159, "(18, 0)": 0.45519331097602844, "(18, 16)": 0.7564231157302856, "(20, 0)": 0.7564231157302856, "(20, 16)": 0.4777040183544159, "(22, 0)": 0.4777040183544159, "(22, 16)": 0.7564231157302856, "(24, 0)": 0.4777040183544159, "(24, 16)": 0.7564231157302856, "(26, 0)": 0.4777040183544159, "(26, 16)": 0.7564231157302856, "(28, 0)": 0.4777040183544159, "(28, 16)": 0.4777040183544159, "(30, 0)": 0.4777040183544159, "(30, 16)": 0.4777040183544159}, "r_span": [735, 800], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005612969398498535}}, {"prompt_attention_score": {"(0, 0)": 0.6602680087089539, "(0, 16)": 0.7770529985427856, "(2, 0)": 0.7770529985427856, "(2, 16)": 0.7770529985427856, "(4, 0)": 0.7770529985427856, "(4, 16)": 0.7770529985427856, "(6, 0)": 0.7770529985427856, "(6, 16)": 0.7770529985427856, "(8, 0)": 0.7770529985427856, "(8, 16)": 0.7770529985427856, "(10, 0)": 0.7770529985427856, "(10, 16)": 0.7770529985427856, "(12, 0)": 0.7770529985427856, "(12, 16)": 0.7770529985427856, "(14, 0)": 0.5275285243988037, "(14, 16)": 0.4308187663555145, "(16, 0)": 0.4308187663555145, "(16, 16)": 0.5275285243988037, "(18, 0)": 0.7770529985427856, "(18, 16)": 0.7770529985427856, "(20, 0)": 0.7770529985427856, "(20, 16)": 0.5275285243988037, "(22, 0)": 0.5275285243988037, "(22, 16)": 0.7770529985427856, "(24, 0)": 0.5275285243988037, "(24, 16)": 0.7770529985427856, "(26, 0)": 0.5275285243988037, "(26, 16)": 0.5275285243988037, "(28, 0)": 0.5275285243988037, "(28, 16)": 0.5275285243988037, "(30, 0)": 0.5275285243988037, "(30, 16)": 0.5275285243988037}, "r_span": [802, 873], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006060600280761719}}]}, {"id": "12843", "source_id": "14458", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's how to sew a zipper gusset based on the provided passages:\n\nTo sew a zipper gusset, follow these steps:\n\n1. Make a zipper sandwich by placing a piece of lining fabric face up, then the zipper, and finally the outer fabric right side facing down. Line up the three edges and sew across the top using a zipper foot. Repeat this process for the other side of the zipper. (Passage 2)\n2. Trace the pattern onto the remaining fabric and cut it. Make a few stitches near the top stop of the zipper. Pin the zipper gusset to the zipper with right sides facing each other, and sew a line near the seam line to secure its position. (Passage 3)\n3. Place the zipper gusset lining on top of the main zipper gusset with right sides facing down, and stitch along the seam line. Flip the lining to the bottom of the main zipper gusset, and topstitch near the seam line. Repeat the process for the other side of the zipper gusset. The width of the zipper between the gusset should measure 1/2\". (Passage 3)\n\nThat's it! Based on the provided passages, there is no additional information needed to answer the question.", "response_spans": [[0, 116], [118, 392], [393, 646], [647, 1002], [1004, 1112]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7609672546386719, "(0, 16)": 0.7609672546386719, "(2, 0)": 0.7609672546386719, "(2, 16)": 0.7609672546386719, "(4, 0)": 0.7609672546386719, "(4, 16)": 0.4865187108516693, "(6, 0)": 0.7609672546386719, "(6, 16)": 0.8850521445274353, "(8, 0)": 0.6736463308334351, "(8, 16)": 0.4865187108516693, "(10, 0)": 0.4865187108516693, "(10, 16)": 0.4865187108516693, "(12, 0)": 0.4865187108516693, "(12, 16)": 0.8850521445274353, "(14, 0)": 0.7609672546386719, "(14, 16)": 0.4865187108516693, "(16, 0)": 0.8850521445274353, "(16, 16)": 0.7609672546386719, "(18, 0)": 0.4865187108516693, "(18, 16)": 0.8850521445274353, "(20, 0)": 0.8850521445274353, "(20, 16)": 0.6736463308334351, "(22, 0)": 0.6736463308334351, "(22, 16)": 0.6736463308334351, "(24, 0)": 0.6736463308334351, "(24, 16)": 0.6736463308334351, "(26, 0)": 0.6736463308334351, "(26, 16)": 0.6736463308334351, "(28, 0)": 0.4865187108516693, "(28, 16)": 0.6736463308334351, "(30, 0)": 0.6736463308334351, "(30, 16)": 0.6736463308334351}, "r_span": [770, 811], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011273622512817383}}, {"prompt_attention_score": {"(0, 0)": 0.7731683254241943, "(0, 16)": 0.7731683254241943, "(2, 0)": 0.7731683254241943, "(2, 16)": 0.7731683254241943, "(4, 0)": 0.7731683254241943, "(4, 16)": 0.7731683254241943, "(6, 0)": 0.7731683254241943, "(6, 16)": 0.934956967830658, "(8, 0)": 0.6779688596725464, "(8, 16)": 0.7731683254241943, "(10, 0)": 0.8208304047584534, "(10, 16)": 0.8208304047584534, "(12, 0)": 0.7731683254241943, "(12, 16)": 0.934956967830658, "(14, 0)": 0.7731683254241943, "(14, 16)": 0.934956967830658, "(16, 0)": 0.6779688596725464, "(16, 16)": 0.7731683254241943, "(18, 0)": 0.4106760025024414, "(18, 16)": 0.934956967830658, "(20, 0)": 0.934956967830658, "(20, 16)": 0.6779688596725464, "(22, 0)": 0.6779688596725464, "(22, 16)": 0.934956967830658, "(24, 0)": 0.6779688596725464, "(24, 16)": 0.934956967830658, "(26, 0)": 0.6779688596725464, "(26, 16)": 0.6779688596725464, "(28, 0)": 0.6779688596725464, "(28, 16)": 0.6779688596725464, "(30, 0)": 0.6779688596725464, "(30, 16)": 0.6779688596725464}, "r_span": [813, 887], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001469254493713379}}, {"prompt_attention_score": {"(0, 0)": 0.7946087121963501, "(0, 16)": 0.7946087121963501, "(2, 0)": 0.7946087121963501, "(2, 16)": 0.9050589799880981, "(4, 0)": 0.7946087121963501, "(4, 16)": 0.7946087121963501, "(6, 0)": 0.9050589799880981, "(6, 16)": 0.9050589799880981, "(8, 0)": 0.7946087121963501, "(8, 16)": 0.71695876121521, "(10, 0)": 0.7946087121963501, "(10, 16)": 0.9050589799880981, "(12, 0)": 0.71695876121521, "(12, 16)": 0.9050589799880981, "(14, 0)": 0.7946087121963501, "(14, 16)": 0.7946087121963501, "(16, 0)": 0.9050589799880981, "(16, 16)": 0.7946087121963501, "(18, 0)": 0.71695876121521, "(18, 16)": 0.9050589799880981, "(20, 0)": 0.9050589799880981, "(20, 16)": 0.71695876121521, "(22, 0)": 0.71695876121521, "(22, 16)": 0.9050589799880981, "(24, 0)": 0.71695876121521, "(24, 16)": 0.9050589799880981, "(26, 0)": 0.71695876121521, "(26, 16)": 0.71695876121521, "(28, 0)": 0.71695876121521, "(28, 16)": 0.71695876121521, "(30, 0)": 0.71695876121521, "(30, 16)": 0.71695876121521}, "r_span": [888, 958], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014303922653198242}}, {"prompt_attention_score": {"(0, 0)": 0.8869180083274841, "(0, 16)": 0.8869180083274841, "(2, 0)": 0.8869180083274841, "(2, 16)": 0.8869180083274841, "(4, 0)": 0.8869180083274841, "(4, 16)": 0.8869180083274841, "(6, 0)": 0.8869180083274841, "(6, 16)": 0.8505259156227112, "(8, 0)": 0.8869180083274841, "(8, 16)": 0.8869180083274841, "(10, 0)": 0.8869180083274841, "(10, 16)": 0.8869180083274841, "(12, 0)": 0.8869180083274841, "(12, 16)": 0.8505259156227112, "(14, 0)": 0.8869180083274841, "(14, 16)": 0.8869180083274841, "(16, 0)": 0.8869180083274841, "(16, 16)": 0.8869180083274841, "(18, 0)": 0.7465119957923889, "(18, 16)": 0.8869180083274841, "(20, 0)": 0.8505259156227112, "(20, 16)": 0.7465119957923889, "(22, 0)": 0.7465119957923889, "(22, 16)": 0.8505259156227112, "(24, 0)": 0.7465119957923889, "(24, 16)": 0.8505259156227112, "(26, 0)": 0.7465119957923889, "(26, 16)": 0.7465119957923889, "(28, 0)": 0.7465119957923889, "(28, 16)": 0.7465119957923889, "(30, 0)": 0.7465119957923889, "(30, 16)": 0.7465119957923889}, "r_span": [959, 1067], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.003829061985015869}}, {"prompt_attention_score": {"(0, 0)": 0.3520469069480896, "(0, 16)": 0.3520469069480896, "(2, 0)": 0.3520469069480896, "(2, 16)": 0.3520469069480896, "(4, 0)": 0.3520469069480896, "(4, 16)": 0.6542907953262329, "(6, 0)": 0.3520469069480896, "(6, 16)": 0.6542907953262329, "(8, 0)": 0.47127389907836914, "(8, 16)": 0.3520469069480896, "(10, 0)": 0.6542907953262329, "(10, 16)": 0.6542907953262329, "(12, 0)": 0.6542907953262329, "(12, 16)": 0.6542907953262329, "(14, 0)": 0.3520469069480896, "(14, 16)": 0.6542907953262329, "(16, 0)": 0.6542907953262329, "(16, 16)": 0.47127389907836914, "(18, 0)": 0.47127389907836914, "(18, 16)": 0.6542907953262329, "(20, 0)": 0.6542907953262329, "(20, 16)": 0.47127389907836914, "(22, 0)": 0.47127389907836914, "(22, 16)": 0.6542907953262329, "(24, 0)": 0.47127389907836914, "(24, 16)": 0.6542907953262329, "(26, 0)": 0.47127389907836914, "(26, 16)": 0.47127389907836914, "(28, 0)": 0.47127389907836914, "(28, 16)": 0.47127389907836914, "(30, 0)": 0.47127389907836914, "(30, 16)": 0.47127389907836914}, "r_span": [1069, 1092], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003204941749572754}}]}, {"id": "12903", "source_id": "14468", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 1226, "end": 1565, "text": "Based on these passages, to bake hard-boiled eggs, follow these steps:\n\n1. Place the hard-boiled eggs in a single layer in a baking dish.\n2. Bake the eggs in a preheated oven at 300¬∞F (150¬∞C) for 15-20 minutes, or until the whites are set and the yolks are cooked through.\n3. Remove the eggs from the oven and let them cool before serving.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of these steps. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to bake hard-boiled eggs:\n\nPassage 1 provides the steps for cooking hard-boiled eggs:\n\n1. Place eggs into a saucepan and pour in cold water to cover.\n2. Place the pan over high heat and bring the water to a boil.\n3. Once the water is simmering, turn off the heat, cover the pan with a lid, and let the eggs stand for 17 minutes.\n4. After 17 minutes, pour out the hot water and pour cold water over the eggs.\n\nPassage 2 provides tips for testing whether an egg is hard-boiled without breaking it:\n\n1. Whirl the egg on a table to test its hardness. If it spins fast and easily, it is hard-boiled.\n2. If the egg wobbles, it needs more time in the water.\n\nPassage 3 provides additional tips for making hard-boiled eggs easier to peel and avoiding common problems such as green-gray yolks:\n\n1. Place the cold eggs in a single layer in a pan with enough cold water to cover them by about 1 inch.\n2. Place the pan over high heat and bring the water to a boil.\n3. Turn off the heat, cover the pan, and remove it from the heat after 9 minutes for medium-sized eggs, 12 minutes for large eggs, or 15 minutes for extra-large eggs.\n4. Allow the eggs to sit in the water until they are cooked.\n\nBased on these passages, to bake hard-boiled eggs, follow these steps:\n\n1. Place the hard-boiled eggs in a single layer in a baking dish.\n2. Bake the eggs in a preheated oven at 300¬∞F (150¬∞C) for 15-20 minutes, or until the whites are set and the yolks are cooked through.\n3. Remove the eggs from the oven and let them cool before serving.\n\nUnable to answer based on given passages. The passages do not provide instructions on how to bake hard-boiled eggs once they have been cooked.", "response_spans": [[0, 451], [453, 828], [830, 1296], [1298, 1709]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8193373084068298, "(0, 16)": 0.8193373084068298, "(2, 0)": 0.8193373084068298, "(2, 16)": 0.8193373084068298, "(4, 0)": 0.8193373084068298, "(4, 16)": 0.8193373084068298, "(6, 0)": 0.8193373084068298, "(6, 16)": 0.9642662405967712, "(8, 0)": 0.9642662405967712, "(8, 16)": 0.8193373084068298, "(10, 0)": 0.8193373084068298, "(10, 16)": 0.8193373084068298, "(12, 0)": 0.9642662405967712, "(12, 16)": 0.9642662405967712, "(14, 0)": 0.9642662405967712, "(14, 16)": 0.9642662405967712, "(16, 0)": 0.9642662405967712, "(16, 16)": 0.9642662405967712, "(18, 0)": 0.9642662405967712, "(18, 16)": 0.9642662405967712, "(20, 0)": 0.9642662405967712, "(20, 16)": 0.9642662405967712, "(22, 0)": 0.9642662405967712, "(22, 16)": 0.9642662405967712, "(24, 0)": 0.9642662405967712, "(24, 16)": 0.9642662405967712, "(26, 0)": 0.9642662405967712, "(26, 16)": 0.9642662405967712, "(28, 0)": 0.9642662405967712, "(28, 16)": 0.9642662405967712, "(30, 0)": 0.9642662405967712, "(30, 16)": 0.9642662405967712}, "r_span": [464, 595], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016606450080871582}}, {"prompt_attention_score": {"(0, 0)": 0.7969467639923096, "(0, 16)": 0.7969467639923096, "(2, 0)": 0.7969467639923096, "(2, 16)": 0.7969467639923096, "(4, 0)": 0.7969467639923096, "(4, 16)": 0.7969467639923096, "(6, 0)": 0.7969467639923096, "(6, 16)": 0.8906753659248352, "(8, 0)": 0.7969467639923096, "(8, 16)": 0.7969467639923096, "(10, 0)": 0.7969467639923096, "(10, 16)": 0.7969467639923096, "(12, 0)": 0.7544057369232178, "(12, 16)": 0.8906753659248352, "(14, 0)": 0.7544057369232178, "(14, 16)": 0.7969467639923096, "(16, 0)": 0.8906753659248352, "(16, 16)": 0.7544057369232178, "(18, 0)": 0.7544057369232178, "(18, 16)": 0.8906753659248352, "(20, 0)": 0.8906753659248352, "(20, 16)": 0.7544057369232178, "(22, 0)": 0.7544057369232178, "(22, 16)": 0.7969467639923096, "(24, 0)": 0.7544057369232178, "(24, 16)": 0.8906753659248352, "(26, 0)": 0.7544057369232178, "(26, 16)": 0.7544057369232178, "(28, 0)": 0.7544057369232178, "(28, 16)": 0.7544057369232178, "(30, 0)": 0.7544057369232178, "(30, 16)": 0.7544057369232178}, "r_span": [597, 700], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0028378963470458984}}, {"prompt_attention_score": {"(0, 0)": 0.8410566449165344, "(0, 16)": 0.8410566449165344, "(2, 0)": 0.8410566449165344, "(2, 16)": 0.8410566449165344, "(4, 0)": 0.8410566449165344, "(4, 16)": 0.8410566449165344, "(6, 0)": 0.8410566449165344, "(6, 16)": 0.8410566449165344, "(8, 0)": 0.8410566449165344, "(8, 16)": 0.9116042852401733, "(10, 0)": 0.8410566449165344, "(10, 16)": 0.9116042852401733, "(12, 0)": 0.9116042852401733, "(12, 16)": 0.8410566449165344, "(14, 0)": 0.9116042852401733, "(14, 16)": 0.8410566449165344, "(16, 0)": 0.9116042852401733, "(16, 16)": 0.9116042852401733, "(18, 0)": 0.9116042852401733, "(18, 16)": 0.8410566449165344, "(20, 0)": 0.8410566449165344, "(20, 16)": 0.9116042852401733, "(22, 0)": 0.9116042852401733, "(22, 16)": 0.8410566449165344, "(24, 0)": 0.9116042852401733, "(24, 16)": 0.8410566449165344, "(26, 0)": 0.9116042852401733, "(26, 16)": 0.8410566449165344, "(28, 0)": 0.9116042852401733, "(28, 16)": 0.9116042852401733, "(30, 0)": 0.9116042852401733, "(30, 16)": 0.9116042852401733}, "r_span": [702, 834], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0025360584259033203}}, {"prompt_attention_score": {"(0, 0)": 0.8030283451080322, "(0, 16)": 0.8030283451080322, "(2, 0)": 0.8030283451080322, "(2, 16)": 0.8030283451080322, "(4, 0)": 0.8030283451080322, "(4, 16)": 0.8030283451080322, "(6, 0)": 0.9039701223373413, "(6, 16)": 0.8030283451080322, "(8, 0)": 0.9039701223373413, "(8, 16)": 0.9039701223373413, "(10, 0)": 0.8030283451080322, "(10, 16)": 0.9039701223373413, "(12, 0)": 0.9039701223373413, "(12, 16)": 0.393405020236969, "(14, 0)": 0.9039701223373413, "(14, 16)": 0.393405020236969, "(16, 0)": 0.9039701223373413, "(16, 16)": 0.9039701223373413, "(18, 0)": 0.9039701223373413, "(18, 16)": 0.9039701223373413, "(20, 0)": 0.8030283451080322, "(20, 16)": 0.9039701223373413, "(22, 0)": 0.9039701223373413, "(22, 16)": 0.9039701223373413, "(24, 0)": 0.9039701223373413, "(24, 16)": 0.9039701223373413, "(26, 0)": 0.9039701223373413, "(26, 16)": 0.9039701223373413, "(28, 0)": 0.9039701223373413, "(28, 16)": 0.9039701223373413, "(30, 0)": 0.9039701223373413, "(30, 16)": 0.9039701223373413}, "r_span": [836, 962], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015110969543457031}}]}, {"id": "12915", "source_id": "14470", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the answer to the question \"What is the drawer for on the bottom of an oven stove?\" is:\n\nUnable to answer based on given passages.\n\nNone of the passages explicitly state what the drawer at the bottom of an oven stove is for. Some suggest that it may be a warming drawer, while others indicate that it may be used for storage. Without additional information, it cannot be determined what the specific purpose of this drawer is on a particular oven model.", "response_spans": [[0, 485]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8556939363479614, "(0, 16)": 0.8556939363479614, "(2, 0)": 0.8556939363479614, "(2, 16)": 0.8556939363479614, "(4, 0)": 0.8556939363479614, "(4, 16)": 0.8556939363479614, "(6, 0)": 0.8556939363479614, "(6, 16)": 0.8993303775787354, "(8, 0)": 0.8638134598731995, "(8, 16)": 0.8556939363479614, "(10, 0)": 0.8556939363479614, "(10, 16)": 0.8556939363479614, "(12, 0)": 0.8556939363479614, "(12, 16)": 0.8556939363479614, "(14, 0)": 0.8638134598731995, "(14, 16)": 0.8556939363479614, "(16, 0)": 0.8993303775787354, "(16, 16)": 0.8638134598731995, "(18, 0)": 0.8556939363479614, "(18, 16)": 0.8993303775787354, "(20, 0)": 0.8993303775787354, "(20, 16)": 0.8638134598731995, "(22, 0)": 0.8638134598731995, "(22, 16)": 0.8993303775787354, "(24, 0)": 0.8638134598731995, "(24, 16)": 0.8993303775787354, "(26, 0)": 0.8638134598731995, "(26, 16)": 0.8638134598731995, "(28, 0)": 0.8638134598731995, "(28, 16)": 0.8638134598731995, "(30, 0)": 0.8638134598731995, "(30, 16)": 0.8638134598731995}, "r_span": [404, 520], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015044212341308594}}]}, {"id": "13041", "source_id": "15092", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to factory reset an HTC One VX:\n\nPassage 1:\n\n* To switch off the device, hold down the Power button for a while.\n* Press and hold the Volume Down + Power key for a couple of seconds to enter Bootloader Mode.\n* From the Bootloader Mode menu, choose option RECOVERY MODE by using Volume buttons to scroll and Power key to select.\n* Press and hold the Volume Down + Power key for a couple of seconds to initiate the factory reset process.\n\nPassage 2:\n\n* Switch off the phone by using the Power rocker.\n* Press and hold the Volume Down and Power buttons together for a couple of seconds to enter Bootloader Mode.\n* Choose the Factory Reset by pressing the Volum Down button to scroll and Power key to select.\n* Press and hold the Volume Down + Power key for a couple of seconds to initiate the factory reset process.\n\nPassage 3: (unavailable)\n\nIt seems that passage 3 does not provide enough information to perform a factory reset on an HTC One VX. Therefore, I am unable to answer the question based on the provided passages.", "response_spans": [[0, 491], [481, 882], [884, 1066]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8856407403945923, "(0, 16)": 0.8856407403945923, "(2, 0)": 0.8856407403945923, "(2, 16)": 0.8856407403945923, "(4, 0)": 0.8856407403945923, "(4, 16)": 0.8856407403945923, "(6, 0)": 0.8856407403945923, "(6, 16)": 0.7271702289581299, "(8, 0)": 0.8856407403945923, "(8, 16)": 0.8856407403945923, "(10, 0)": 0.3825357258319855, "(10, 16)": 0.3825357258319855, "(12, 0)": 0.8856407403945923, "(12, 16)": 0.7271702289581299, "(14, 0)": 0.7271702289581299, "(14, 16)": 0.7271702289581299, "(16, 0)": 0.7271702289581299, "(16, 16)": 0.7271702289581299, "(18, 0)": 0.3825357258319855, "(18, 16)": 0.7271702289581299, "(20, 0)": 0.7271702289581299, "(20, 16)": 0.7271702289581299, "(22, 0)": 0.8856407403945923, "(22, 16)": 0.7271702289581299, "(24, 0)": 0.7271702289581299, "(24, 16)": 0.7271702289581299, "(26, 0)": 0.7271702289581299, "(26, 16)": 0.7271702289581299, "(28, 0)": 0.8856407403945923, "(28, 16)": 0.8856407403945923, "(30, 0)": 0.7271702289581299, "(30, 16)": 0.7271702289581299}, "r_span": [557, 685], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014820694923400879}}, {"prompt_attention_score": {"(0, 0)": 0.7695891261100769, "(0, 16)": 0.7695891261100769, "(2, 0)": 0.7695891261100769, "(2, 16)": 0.7695891261100769, "(4, 0)": 0.7695891261100769, "(4, 16)": 0.7695891261100769, "(6, 0)": 0.7695891261100769, "(6, 16)": 0.9454419016838074, "(8, 0)": 0.7695891261100769, "(8, 16)": 0.4941214919090271, "(10, 0)": 0.7695891261100769, "(10, 16)": 0.7695891261100769, "(12, 0)": 0.8751223683357239, "(12, 16)": 0.9454419016838074, "(14, 0)": 0.8751223683357239, "(14, 16)": 0.7695891261100769, "(16, 0)": 0.9454419016838074, "(16, 16)": 0.8751223683357239, "(18, 0)": 0.4941214919090271, "(18, 16)": 0.9454419016838074, "(20, 0)": 0.9454419016838074, "(20, 16)": 0.8751223683357239, "(22, 0)": 0.8751223683357239, "(22, 16)": 0.9454419016838074, "(24, 0)": 0.8751223683357239, "(24, 16)": 0.9454419016838074, "(26, 0)": 0.8751223683357239, "(26, 16)": 0.7695891261100769, "(28, 0)": 0.7695891261100769, "(28, 16)": 0.7695891261100769, "(30, 0)": 0.7695891261100769, "(30, 16)": 0.8751223683357239}, "r_span": [680, 780], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001410067081451416}}, {"prompt_attention_score": {"(0, 0)": 0.8203239440917969, "(0, 16)": 0.8203239440917969, "(2, 0)": 0.8203239440917969, "(2, 16)": 0.8203239440917969, "(4, 0)": 0.8203239440917969, "(4, 16)": 0.8203239440917969, "(6, 0)": 0.8203239440917969, "(6, 16)": 0.8203239440917969, "(8, 0)": 0.8203239440917969, "(8, 16)": 0.8203239440917969, "(10, 0)": 0.5953546762466431, "(10, 16)": 0.5953546762466431, "(12, 0)": 0.8203239440917969, "(12, 16)": 0.5953546762466431, "(14, 0)": 0.615881085395813, "(14, 16)": 0.5953546762466431, "(16, 0)": 0.5953546762466431, "(16, 16)": 0.615881085395813, "(18, 0)": 0.8203239440917969, "(18, 16)": 0.5953546762466431, "(20, 0)": 0.5953546762466431, "(20, 16)": 0.615881085395813, "(22, 0)": 0.615881085395813, "(22, 16)": 0.5953546762466431, "(24, 0)": 0.8203239440917969, "(24, 16)": 0.5953546762466431, "(26, 0)": 0.615881085395813, "(26, 16)": 0.8203239440917969, "(28, 0)": 0.8203239440917969, "(28, 16)": 0.8203239440917969, "(30, 0)": 0.8203239440917969, "(30, 16)": 0.5547095537185669}, "r_span": [782, 822], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001671135425567627}}]}, {"id": "13071", "source_id": "15097", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, PSA (Prostate-Specific Antigen) levels refer to the measure of the amount of PSA proteins present in a man's blood. The PSA test is used to detect and monitor prostate cancer, as well as non-cancerous conditions such as prostatitis and benign prostatic hyperplasia (BPH). The test involves taking a blood sample to be analyzed in a laboratory, and the results are typically reported as ng/mL (nanograms per milliliter) of blood.\n\nFrom the passages, we can infer the following meanings of PSA levels:\n\n* Elevated PSA levels may indicate prostate cancer, prostatitis, or an enlarged prostate. (Passage 2)\n* Total PSA levels between 4.0 ng/ml and 10.0 ng/ml may indicate prostate cancer, BPH, or inflammation of the prostate, with a higher likelihood in the elderly. (Passage 3)\n* Free PSA test can help to distinguish between prostate cancer and other non-cancer causes of elevated PSA levels. (Passage 3)\n\nTherefore, based on the provided passages, the answer to the question \"What does PSA levels mean?\" is:\n\nPSA levels refer to the amount of PSA proteins present in a man's blood, and elevated levels may indicate prostate cancer, prostatitis, or an enlarged prostate.", "response_spans": [[0, 460], [462, 935], [937, 1201]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8294351100921631, "(0, 16)": 0.8294351100921631, "(2, 0)": 0.8294351100921631, "(2, 16)": 0.8294351100921631, "(4, 0)": 0.8294351100921631, "(4, 16)": 0.8294351100921631, "(6, 0)": 0.8294351100921631, "(6, 16)": 0.8828808665275574, "(8, 0)": 0.8294351100921631, "(8, 16)": 0.8294351100921631, "(10, 0)": 0.8294351100921631, "(10, 16)": 0.8294351100921631, "(12, 0)": 0.8294351100921631, "(12, 16)": 0.8828808665275574, "(14, 0)": 0.8828808665275574, "(14, 16)": 0.8828808665275574, "(16, 0)": 0.8828808665275574, "(16, 16)": 0.8294351100921631, "(18, 0)": 0.4329347610473633, "(18, 16)": 0.8828808665275574, "(20, 0)": 0.8828808665275574, "(20, 16)": 0.8828808665275574, "(22, 0)": 0.8828808665275574, "(22, 16)": 0.8828808665275574, "(24, 0)": 0.8828808665275574, "(24, 16)": 0.8828808665275574, "(26, 0)": 0.8828808665275574, "(26, 16)": 0.8828808665275574, "(28, 0)": 0.8828808665275574, "(28, 16)": 0.8828808665275574, "(30, 0)": 0.8828808665275574, "(30, 16)": 0.8828808665275574}, "r_span": [576, 695], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002424001693725586}}, {"prompt_attention_score": {"(0, 0)": 0.9270435571670532, "(0, 16)": 0.9270435571670532, "(2, 0)": 0.9270435571670532, "(2, 16)": 0.9270435571670532, "(4, 0)": 0.9270435571670532, "(4, 16)": 0.9270435571670532, "(6, 0)": 0.9270435571670532, "(6, 16)": 0.9270435571670532, "(8, 0)": 0.9270435571670532, "(8, 16)": 0.9270435571670532, "(10, 0)": 0.9270435571670532, "(10, 16)": 0.9270435571670532, "(12, 0)": 0.9270435571670532, "(12, 16)": 0.9270435571670532, "(14, 0)": 0.8143610954284668, "(14, 16)": 0.9270435571670532, "(16, 0)": 0.9270435571670532, "(16, 16)": 0.8143610954284668, "(18, 0)": 0.8143610954284668, "(18, 16)": 0.9270435571670532, "(20, 0)": 0.9270435571670532, "(20, 16)": 0.8143610954284668, "(22, 0)": 0.8143610954284668, "(22, 16)": 0.9270435571670532, "(24, 0)": 0.8143610954284668, "(24, 16)": 0.9270435571670532, "(26, 0)": 0.8143610954284668, "(26, 16)": 0.9270435571670532, "(28, 0)": 0.9270435571670532, "(28, 16)": 0.8143610954284668, "(30, 0)": 0.8143610954284668, "(30, 16)": 0.8143610954284668}, "r_span": [697, 838], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002733886241912842}}, {"prompt_attention_score": {"(0, 0)": 0.8176479339599609, "(0, 16)": 0.8176479339599609, "(2, 0)": 0.8176479339599609, "(2, 16)": 0.8176479339599609, "(4, 0)": 0.8176479339599609, "(4, 16)": 0.8176479339599609, "(6, 0)": 0.8176479339599609, "(6, 16)": 0.8783379197120667, "(8, 0)": 0.8176479339599609, "(8, 16)": 0.8176479339599609, "(10, 0)": 0.5029425024986267, "(10, 16)": 0.5029425024986267, "(12, 0)": 0.8238153457641602, "(12, 16)": 0.5029425024986267, "(14, 0)": 0.8238153457641602, "(14, 16)": 0.5029425024986267, "(16, 0)": 0.8244562149047852, "(16, 16)": 0.8176479339599609, "(18, 0)": 0.8238153457641602, "(18, 16)": 0.8244562149047852, "(20, 0)": 0.8244562149047852, "(20, 16)": 0.8238153457641602, "(22, 0)": 0.8238153457641602, "(22, 16)": 0.8238153457641602, "(24, 0)": 0.8238153457641602, "(24, 16)": 0.8238153457641602, "(26, 0)": 0.8238153457641602, "(26, 16)": 0.8238153457641602, "(28, 0)": 0.8238153457641602, "(28, 16)": 0.8238153457641602, "(30, 0)": 0.8238153457641602, "(30, 16)": 0.8238153457641602}, "r_span": [840, 909], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010831952095031738}}]}, {"id": "13107", "source_id": "15103", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 1232, "end": 1272, "text": "x-axis (categories) and y-axis (values).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *no mention of use of pattern*\nGenerative: x-axis (categories) and y-axis (values).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! To make a graph for your research, you can follow these general steps based on the provided passages:\n\n1. Collect your data: As stated in Passage 1, the first step is to collect all the data you want to represent in your graph. For example, if your goal is to compare the amount of rainfall in different months, you would need to measure and record the rainfall data for each month.\n2. Determine the type of graph: Based on the information provided in Passage 2, you can choose to make either a bar graph or a line graph. A bar graph is suitable for comparing groups or types, while a line graph is better suited for showing trends over time.\n3. Title your graph: According to Passage 2, it's important to title your graph to provide context and explain what the graph represents. Make sure to include a clear and concise title that describes the data being displayed.\n4. Find out how high your graph needs to go: As mentioned in Passage 2, you'll need to determine the height of your graph based on the data you're presenting. This will ensure that the bars or lines are proportional to the size of the categories they represent.\n5. Use appropriate scales: When making a bar graph, make sure to use appropriate scales on the x-axis (categories) and y-axis (values). This will allow the reader to easily interpret the data and understand the relationships between the categories.\n6. Proportionately size the bars: As noted in Passage 3, it's important to proportionally size the bars based on the size of the category they represent. This will create a clearer visual representation of the data and prevent any one category from dominating the graph.\n7. Add colors or labels: Depending on the type of graph you choose, you may want to add colors or labels to make it more visually appealing and easy to read.\n\nUnable to answer based on given passages. Please provide additional information or clarify the question.", "response_spans": [[0, 107], [109, 388], [389, 874], [875, 1385], [1386, 1814], [1816, 1920]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6576522588729858, "(0, 16)": 0.6576522588729858, "(2, 0)": 0.6576522588729858, "(2, 16)": 0.6576522588729858, "(4, 0)": 0.6576522588729858, "(4, 16)": 0.6576522588729858, "(6, 0)": 0.6576522588729858, "(6, 16)": 0.7066338062286377, "(8, 0)": 0.6576522588729858, "(8, 16)": 0.5463691353797913, "(10, 0)": 0.5463691353797913, "(10, 16)": 0.5463691353797913, "(12, 0)": 0.5463691353797913, "(12, 16)": 0.7066338062286377, "(14, 0)": 0.6668063402175903, "(14, 16)": 0.5463691353797913, "(16, 0)": 0.7066338062286377, "(16, 16)": 0.6668063402175903, "(18, 0)": 0.5463691353797913, "(18, 16)": 0.7066338062286377, "(20, 0)": 0.7066338062286377, "(20, 16)": 0.6668063402175903, "(22, 0)": 0.6668063402175903, "(22, 16)": 0.7066338062286377, "(24, 0)": 0.6668063402175903, "(24, 16)": 0.7066338062286377, "(26, 0)": 0.6668063402175903, "(26, 16)": 0.6668063402175903, "(28, 0)": 0.6668063402175903, "(28, 16)": 0.6668063402175903, "(30, 0)": 0.6668063402175903, "(30, 16)": 0.6668063402175903}, "r_span": [581, 605], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 9.435415267944336e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6806442737579346, "(0, 16)": 0.6806442737579346, "(2, 0)": 0.6806442737579346, "(2, 16)": 0.6806442737579346, "(4, 0)": 0.6806442737579346, "(4, 16)": 0.6806442737579346, "(6, 0)": 0.6806442737579346, "(6, 16)": 0.7627549171447754, "(8, 0)": 0.6806442737579346, "(8, 16)": 0.6806442737579346, "(10, 0)": 0.6806442737579346, "(10, 16)": 0.6806442737579346, "(12, 0)": 0.6806442737579346, "(12, 16)": 0.7627549171447754, "(14, 0)": 0.7627549171447754, "(14, 16)": 0.7627549171447754, "(16, 0)": 0.7627549171447754, "(16, 16)": 0.7627549171447754, "(18, 0)": 0.7627549171447754, "(18, 16)": 0.7627549171447754, "(20, 0)": 0.7627549171447754, "(20, 16)": 0.7627549171447754, "(22, 0)": 0.7627549171447754, "(22, 16)": 0.7627549171447754, "(24, 0)": 0.7627549171447754, "(24, 16)": 0.7627549171447754, "(26, 0)": 0.7627549171447754, "(26, 16)": 0.7627549171447754, "(28, 0)": 0.7627549171447754, "(28, 16)": 0.7627549171447754, "(30, 0)": 0.7627549171447754, "(30, 16)": 0.7627549171447754}, "r_span": [607, 673], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001718282699584961}}, {"prompt_attention_score": {"(0, 0)": 0.7416383624076843, "(0, 16)": 0.7416383624076843, "(2, 0)": 0.7416383624076843, "(2, 16)": 0.7416383624076843, "(4, 0)": 0.7416383624076843, "(4, 16)": 0.7416383624076843, "(6, 0)": 0.7416383624076843, "(6, 16)": 0.844372034072876, "(8, 0)": 0.7416383624076843, "(8, 16)": 0.7416383624076843, "(10, 0)": 0.7416383624076843, "(10, 16)": 0.7416383624076843, "(12, 0)": 0.7416383624076843, "(12, 16)": 0.844372034072876, "(14, 0)": 0.8108431696891785, "(14, 16)": 0.7416383624076843, "(16, 0)": 0.844372034072876, "(16, 16)": 0.8108431696891785, "(18, 0)": 0.8108431696891785, "(18, 16)": 0.844372034072876, "(20, 0)": 0.844372034072876, "(20, 16)": 0.8108431696891785, "(22, 0)": 0.8108431696891785, "(22, 16)": 0.844372034072876, "(24, 0)": 0.8108431696891785, "(24, 16)": 0.8108431696891785, "(26, 0)": 0.8108431696891785, "(26, 16)": 0.8108431696891785, "(28, 0)": 0.8108431696891785, "(28, 16)": 0.8108431696891785, "(30, 0)": 0.8108431696891785, "(30, 16)": 0.8108431696891785}, "r_span": [674, 784], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0019268989562988281}}, {"prompt_attention_score": {"(0, 0)": 0.7781515121459961, "(0, 16)": 0.7781515121459961, "(2, 0)": 0.7781515121459961, "(2, 16)": 0.7781515121459961, "(4, 0)": 0.7781515121459961, "(4, 16)": 0.7781515121459961, "(6, 0)": 0.7781515121459961, "(6, 16)": 0.7751615643501282, "(8, 0)": 0.7781515121459961, "(8, 16)": 0.7781515121459961, "(10, 0)": 0.7781515121459961, "(10, 16)": 0.7781515121459961, "(12, 0)": 0.7781515121459961, "(12, 16)": 0.7751615643501282, "(14, 0)": 0.7665428519248962, "(14, 16)": 0.7781515121459961, "(16, 0)": 0.7781515121459961, "(16, 16)": 0.7665428519248962, "(18, 0)": 0.7665428519248962, "(18, 16)": 0.7781515121459961, "(20, 0)": 0.7781515121459961, "(20, 16)": 0.7665428519248962, "(22, 0)": 0.7665428519248962, "(22, 16)": 0.7781515121459961, "(24, 0)": 0.7665428519248962, "(24, 16)": 0.7781515121459961, "(26, 0)": 0.7665428519248962, "(26, 16)": 0.7665428519248962, "(28, 0)": 0.7665428519248962, "(28, 16)": 0.7665428519248962, "(30, 0)": 0.7665428519248962, "(30, 16)": 0.7665428519248962}, "r_span": [785, 897], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001330733299255371}}, {"prompt_attention_score": {"(0, 0)": 0.7543880939483643, "(0, 16)": 0.7543880939483643, "(2, 0)": 0.7543880939483643, "(2, 16)": 0.7543880939483643, "(4, 0)": 0.7543880939483643, "(4, 16)": 0.7543880939483643, "(6, 0)": 0.7324184775352478, "(6, 16)": 0.7543880939483643, "(8, 0)": 0.7543880939483643, "(8, 16)": 0.7324184775352478, "(10, 0)": 0.7543880939483643, "(10, 16)": 0.7543880939483643, "(12, 0)": 0.7324184775352478, "(12, 16)": 0.7543880939483643, "(14, 0)": 0.7324184775352478, "(14, 16)": 0.7543880939483643, "(16, 0)": 0.7543880939483643, "(16, 16)": 0.7324184775352478, "(18, 0)": 0.470541387796402, "(18, 16)": 0.7543880939483643, "(20, 0)": 0.7543880939483643, "(20, 16)": 0.7324184775352478, "(22, 0)": 0.7324184775352478, "(22, 16)": 0.7543880939483643, "(24, 0)": 0.7324184775352478, "(24, 16)": 0.7543880939483643, "(26, 0)": 0.7324184775352478, "(26, 16)": 0.7324184775352478, "(28, 0)": 0.7324184775352478, "(28, 16)": 0.7324184775352478, "(30, 0)": 0.7324184775352478, "(30, 16)": 0.7324184775352478}, "r_span": [898, 995], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000475466251373291}}, {"prompt_attention_score": {"(0, 0)": 0.6676070690155029, "(0, 16)": 0.6676070690155029, "(2, 0)": 0.6676070690155029, "(2, 16)": 0.8147053122520447, "(4, 0)": 0.6676070690155029, "(4, 16)": 0.6676070690155029, "(6, 0)": 0.5604560375213623, "(6, 16)": 0.8147053122520447, "(8, 0)": 0.4897201359272003, "(8, 16)": 0.5604560375213623, "(10, 0)": 0.8147053122520447, "(10, 16)": 0.8147053122520447, "(12, 0)": 0.8147053122520447, "(12, 16)": 0.8147053122520447, "(14, 0)": 0.5664740800857544, "(14, 16)": 0.8147053122520447, "(16, 0)": 0.8147053122520447, "(16, 16)": 0.5664740800857544, "(18, 0)": 0.8147053122520447, "(18, 16)": 0.8147053122520447, "(20, 0)": 0.8147053122520447, "(20, 16)": 0.5664740800857544, "(22, 0)": 0.5664740800857544, "(22, 16)": 0.8147053122520447, "(24, 0)": 0.5664740800857544, "(24, 16)": 0.8147053122520447, "(26, 0)": 0.5664740800857544, "(26, 16)": 0.5664740800857544, "(28, 0)": 0.5664740800857544, "(28, 16)": 0.5664740800857544, "(30, 0)": 0.5664740800857544, "(30, 16)": 0.5664740800857544}, "r_span": [997, 1016], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008903145790100098}}]}, {"id": "13131", "source_id": "15107", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to soften sugar:\n\n1. To soften brown sugar, place it in a plastic container with a small piece of plastic wrap or foil over the sugar, and cover tightly. Remove the damp paper towel after a couple of days. (Passage 1)\n2. To soften hardened granulated sugar, preheat the oven to a low temperature (150-200¬∞F), remove the sugar from its package, and place it in an ovenproof container. Warm the sugar in the oven for about 15 minutes, then tap it with a spoon. If it starts to fall apart, leave it in the oven for a longer period of time to completely dry out. Always store granulated sugar in an airtight container. (Passage 2)\n3. To keep brown sugar soft, pack it into the smallest container possible to minimize air exposure. (Passage 3)\n\nUnable to answer based on given passages. The passages do not provide information on how to soften other types of sugar, such as confectioner's sugar.", "response_spans": [[0, 67], [69, 268], [269, 677], [678, 789], [791, 941]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7452547550201416, "(0, 16)": 0.7452547550201416, "(2, 0)": 0.7452547550201416, "(2, 16)": 0.7452547550201416, "(4, 0)": 0.7452547550201416, "(4, 16)": 0.7452547550201416, "(6, 0)": 0.7452547550201416, "(6, 16)": 0.7901265025138855, "(8, 0)": 0.7452547550201416, "(8, 16)": 0.7452547550201416, "(10, 0)": 0.7452547550201416, "(10, 16)": 0.7452547550201416, "(12, 0)": 0.7452547550201416, "(12, 16)": 0.7901265025138855, "(14, 0)": 0.7452547550201416, "(14, 16)": 0.7452547550201416, "(16, 0)": 0.7901265025138855, "(16, 16)": 0.7452547550201416, "(18, 0)": 0.7452547550201416, "(18, 16)": 0.7901265025138855, "(20, 0)": 0.7901265025138855, "(20, 16)": 0.6174986362457275, "(22, 0)": 0.6174986362457275, "(22, 16)": 0.7901265025138855, "(24, 0)": 0.6174986362457275, "(24, 16)": 0.7901265025138855, "(26, 0)": 0.6174986362457275, "(26, 16)": 0.7452547550201416, "(28, 0)": 0.7452547550201416, "(28, 16)": 0.6174986362457275, "(30, 0)": 0.6174986362457275, "(30, 16)": 0.6174986362457275}, "r_span": [408, 425], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005373358726501465}}, {"prompt_attention_score": {"(0, 0)": 0.8669924736022949, "(0, 16)": 0.8669924736022949, "(2, 0)": 0.8669924736022949, "(2, 16)": 0.8669924736022949, "(4, 0)": 0.8669924736022949, "(4, 16)": 0.8669924736022949, "(6, 0)": 0.8669924736022949, "(6, 16)": 0.9594671130180359, "(8, 0)": 0.8669924736022949, "(8, 16)": 0.8669924736022949, "(10, 0)": 0.8669924736022949, "(10, 16)": 0.8669924736022949, "(12, 0)": 0.9594671130180359, "(12, 16)": 0.9594671130180359, "(14, 0)": 0.6853705048561096, "(14, 16)": 0.9594671130180359, "(16, 0)": 0.9594671130180359, "(16, 16)": 0.9594671130180359, "(18, 0)": 0.8669924736022949, "(18, 16)": 0.9594671130180359, "(20, 0)": 0.9594671130180359, "(20, 16)": 0.6853705048561096, "(22, 0)": 0.6853705048561096, "(22, 16)": 0.9594671130180359, "(24, 0)": 0.6853705048561096, "(24, 16)": 0.9594671130180359, "(26, 0)": 0.6853705048561096, "(26, 16)": 0.8669924736022949, "(28, 0)": 0.6853705048561096, "(28, 16)": 0.6853705048561096, "(30, 0)": 0.6853705048561096, "(30, 16)": 0.6853705048561096}, "r_span": [427, 481], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 1.0073184967041016e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7773016691207886, "(0, 16)": 0.7773016691207886, "(2, 0)": 0.7773016691207886, "(2, 16)": 0.7773016691207886, "(4, 0)": 0.7773016691207886, "(4, 16)": 0.7773016691207886, "(6, 0)": 0.7773016691207886, "(6, 16)": 0.9613991975784302, "(8, 0)": 0.7773016691207886, "(8, 16)": 0.7773016691207886, "(10, 0)": 0.7773016691207886, "(10, 16)": 0.7773016691207886, "(12, 0)": 0.7773016691207886, "(12, 16)": 0.9613991975784302, "(14, 0)": 0.9613991975784302, "(14, 16)": 0.9613991975784302, "(16, 0)": 0.9613991975784302, "(16, 16)": 0.7773016691207886, "(18, 0)": 0.7773016691207886, "(18, 16)": 0.9613991975784302, "(20, 0)": 0.9613991975784302, "(20, 16)": 0.7484040856361389, "(22, 0)": 0.7484040856361389, "(22, 16)": 0.9613991975784302, "(24, 0)": 0.7484040856361389, "(24, 16)": 0.9613991975784302, "(26, 0)": 0.7484040856361389, "(26, 16)": 0.7484040856361389, "(28, 0)": 0.7484040856361389, "(28, 16)": 0.7484040856361389, "(30, 0)": 0.7484040856361389, "(30, 16)": 0.7484040856361389}, "r_span": [482, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00010532140731811523}}, {"prompt_attention_score": {"(0, 0)": 0.909853458404541, "(0, 16)": 0.909853458404541, "(2, 0)": 0.909853458404541, "(2, 16)": 0.909853458404541, "(4, 0)": 0.909853458404541, "(4, 16)": 0.909853458404541, "(6, 0)": 0.909853458404541, "(6, 16)": 0.909853458404541, "(8, 0)": 0.909853458404541, "(8, 16)": 0.909853458404541, "(10, 0)": 0.909853458404541, "(10, 16)": 0.909853458404541, "(12, 0)": 0.909853458404541, "(12, 16)": 0.909853458404541, "(14, 0)": 0.708253026008606, "(14, 16)": 0.909853458404541, "(16, 0)": 0.909853458404541, "(16, 16)": 0.909853458404541, "(18, 0)": 0.7629902958869934, "(18, 16)": 0.909853458404541, "(20, 0)": 0.909853458404541, "(20, 16)": 0.708253026008606, "(22, 0)": 0.708253026008606, "(22, 16)": 0.909853458404541, "(24, 0)": 0.708253026008606, "(24, 16)": 0.909853458404541, "(26, 0)": 0.708253026008606, "(26, 16)": 0.909853458404541, "(28, 0)": 0.708253026008606, "(28, 16)": 0.708253026008606, "(30, 0)": 0.708253026008606, "(30, 16)": 0.708253026008606}, "r_span": [597, 625], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004177689552307129}}, {"prompt_attention_score": {"(0, 0)": 0.752278208732605, "(0, 16)": 0.752278208732605, "(2, 0)": 0.752278208732605, "(2, 16)": 0.752278208732605, "(4, 0)": 0.752278208732605, "(4, 16)": 0.752278208732605, "(6, 0)": 0.752278208732605, "(6, 16)": 0.7656611800193787, "(8, 0)": 0.752278208732605, "(8, 16)": 0.6643900871276855, "(10, 0)": 0.752278208732605, "(10, 16)": 0.752278208732605, "(12, 0)": 0.752278208732605, "(12, 16)": 0.752278208732605, "(14, 0)": 0.7327556014060974, "(14, 16)": 0.752278208732605, "(16, 0)": 0.752278208732605, "(16, 16)": 0.7327556014060974, "(18, 0)": 0.7327556014060974, "(18, 16)": 0.752278208732605, "(20, 0)": 0.7656611800193787, "(20, 16)": 0.6643900871276855, "(22, 0)": 0.6643900871276855, "(22, 16)": 0.752278208732605, "(24, 0)": 0.6643900871276855, "(24, 16)": 0.752278208732605, "(26, 0)": 0.6643900871276855, "(26, 16)": 0.752278208732605, "(28, 0)": 0.6643900871276855, "(28, 16)": 0.6643900871276855, "(30, 0)": 0.6643900871276855, "(30, 16)": 0.6643900871276855}, "r_span": [627, 663], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00046837329864501953}}]}, {"id": "13137", "source_id": "15108", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 749, "end": 1063, "text": "navigate to the \"Choose what the power buttons do\" section.\n* Click on the \"Change setting\" link next to \"Turn on fast startup (recommended).\"\n* Uncheck the box next to \"Turn on fast startup (recommended)\" to disable it.\n* Set the desired amount of time for the computer to remain awake before entering sleep mode.", "meta": "HIGH INTRO OF NEW INFO\nIt includes extra steps such as navigating 'Choose what the power buttons do,' 'Clicking on the \"Change setting\" link,' 'Unchecking the box next to \"Turn on fast startup (recommended)\",' and 'Setting the desired amount of time' which is not mentioned in the original sources. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 1183, "end": 1385, "text": "* In the Shut down options, toggle the switch next to \"Put the computer to sleep\" to enable or disable it.\n* Enter the desired amount of time for the computer to remain awake before entering sleep mode.", "meta": "HIGH INTRO OF NEW INFO\nIn the Windows 8.1/Windows RT 8.1 section, the steps about 'Shut down options,' toggling the switch next to 'Put the computer to sleep' and 'entering the desired amount of time' are not mentioned in the original sources.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 1675, "end": 1695, "text": "4. Save the changes.", "meta": "HIGH INTRO OF NEW INFO\nIt is not mentioned in the original sources about saving the changes.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to change the sleep time on a computer:\n\nPassage 1 (Windows 7):\n\n* Step 1: Click Start Menu to load the Help Center.\n* Step 2: Enter Power Management Settings in the search field.\n* Step 3: Click Change Power Management settings. The Power Options window will then appear.\n* Step 4: On the left side of the window, click Change when the computer sleeps.\n* Step 5: Change the Put the computer to sleep entry with the desired amount of time you will allow the computer to sit idle before it sleeps, or automatically turn off its option to enter into Sleep mode.\n\nPassage 2 (Windows 10):\n\n* Open power options by typing \"power options\" in the search box on the taskbar.\n* Select the Power Options window and navigate to the \"Choose what the power buttons do\" section.\n* Click on the \"Change setting\" link next to \"Turn on fast startup (recommended).\"\n* Uncheck the box next to \"Turn on fast startup (recommended)\" to disable it.\n* Set the desired amount of time for the computer to remain awake before entering sleep mode.\n\nPassage 3 (Windows 8.1/Windows RT 8.1):\n\n* Click the Start button and select Power.\n* Select Shut down from the menu.\n* In the Shut down options, toggle the switch next to \"Put the computer to sleep\" to enable or disable it.\n* Enter the desired amount of time for the computer to remain awake before entering sleep mode.\n\nBased on these passages, to change the sleep time on a computer, you can follow these general steps:\n\n1. Open the Power Options or Control Panel.\n2. Navigate to the section related to sleep settings.\n3. Adjust the desired time for the computer to remain awake before entering sleep mode.\n4. Save the changes.\n\nUnable to answer based on given passages.", "response_spans": [[0, 107], [109, 603], [605, 1104], [1106, 1487], [1489, 1738]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6357855796813965, "(0, 16)": 0.6357855796813965, "(2, 0)": 0.6357855796813965, "(2, 16)": 0.6357855796813965, "(4, 0)": 0.6357855796813965, "(4, 16)": 0.6357855796813965, "(6, 0)": 0.6357855796813965, "(6, 16)": 0.8456953763961792, "(8, 0)": 0.6357855796813965, "(8, 16)": 0.6357855796813965, "(10, 0)": 0.6357855796813965, "(10, 16)": 0.6357855796813965, "(12, 0)": 0.6357855796813965, "(12, 16)": 0.6357855796813965, "(14, 0)": 0.6357855796813965, "(14, 16)": 0.6357855796813965, "(16, 0)": 0.8456953763961792, "(16, 16)": 0.8456953763961792, "(18, 0)": 0.6357855796813965, "(18, 16)": 0.8456953763961792, "(20, 0)": 0.8456953763961792, "(20, 16)": 0.6357855796813965, "(22, 0)": 0.6357855796813965, "(22, 16)": 0.8456953763961792, "(24, 0)": 0.6357855796813965, "(24, 16)": 0.8345116972923279, "(26, 0)": 0.6357855796813965, "(26, 16)": 0.8345116972923279, "(28, 0)": 0.6357855796813965, "(28, 16)": 0.6357855796813965, "(30, 0)": 0.6357855796813965, "(30, 16)": 0.6357855796813965}, "r_span": [387, 418], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00042241811752319336}}, {"prompt_attention_score": {"(0, 0)": 0.666124165058136, "(0, 16)": 0.666124165058136, "(2, 0)": 0.666124165058136, "(2, 16)": 0.666124165058136, "(4, 0)": 0.666124165058136, "(4, 16)": 0.666124165058136, "(6, 0)": 0.666124165058136, "(6, 16)": 0.9587967395782471, "(8, 0)": 0.666124165058136, "(8, 16)": 0.666124165058136, "(10, 0)": 0.666124165058136, "(10, 16)": 0.666124165058136, "(12, 0)": 0.9587967395782471, "(12, 16)": 0.9587967395782471, "(14, 0)": 0.9587967395782471, "(14, 16)": 0.9587967395782471, "(16, 0)": 0.9587967395782471, "(16, 16)": 0.666124165058136, "(18, 0)": 0.666124165058136, "(18, 16)": 0.9587967395782471, "(20, 0)": 0.9587967395782471, "(20, 16)": 0.9587967395782471, "(22, 0)": 0.666124165058136, "(22, 16)": 0.9587967395782471, "(24, 0)": 0.9587967395782471, "(24, 16)": 0.9587967395782471, "(26, 0)": 0.666124165058136, "(26, 16)": 0.9587967395782471, "(28, 0)": 0.666124165058136, "(28, 16)": 0.9587967395782471, "(30, 0)": 0.9587967395782471, "(30, 16)": 0.666124165058136}, "r_span": [420, 537], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018649697303771973}}, {"prompt_attention_score": {"(0, 0)": 0.7959716320037842, "(0, 16)": 0.7959716320037842, "(2, 0)": 0.7959716320037842, "(2, 16)": 0.7959716320037842, "(4, 0)": 0.7959716320037842, "(4, 16)": 0.7959716320037842, "(6, 0)": 0.7959716320037842, "(6, 16)": 0.8307405710220337, "(8, 0)": 0.7959716320037842, "(8, 16)": 0.7959716320037842, "(10, 0)": 0.7959716320037842, "(10, 16)": 0.7959716320037842, "(12, 0)": 0.7959716320037842, "(12, 16)": 0.7539464831352234, "(14, 0)": 0.6920161247253418, "(14, 16)": 0.7959716320037842, "(16, 0)": 0.7539464831352234, "(16, 16)": 0.7959716320037842, "(18, 0)": 0.7959716320037842, "(18, 16)": 0.7539464831352234, "(20, 0)": 0.7539464831352234, "(20, 16)": 0.7959716320037842, "(22, 0)": 0.6920161247253418, "(22, 16)": 0.7959716320037842, "(24, 0)": 0.8307405710220337, "(24, 16)": 0.7539464831352234, "(26, 0)": 0.7959716320037842, "(26, 16)": 0.8307405710220337, "(28, 0)": 0.7959716320037842, "(28, 16)": 0.7959716320037842, "(30, 0)": 0.7959716320037842, "(30, 16)": 0.6920161247253418}, "r_span": [539, 678], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010794997215270996}}, {"prompt_attention_score": {"(0, 0)": 0.7021649479866028, "(0, 16)": 0.7021649479866028, "(2, 0)": 0.7021649479866028, "(2, 16)": 0.7021649479866028, "(4, 0)": 0.7021649479866028, "(4, 16)": 0.7021649479866028, "(6, 0)": 0.7021649479866028, "(6, 16)": 0.8715543746948242, "(8, 0)": 0.7021649479866028, "(8, 16)": 0.7021649479866028, "(10, 0)": 0.7021649479866028, "(10, 16)": 0.7021649479866028, "(12, 0)": 0.7021649479866028, "(12, 16)": 0.7021649479866028, "(14, 0)": 0.7782481908798218, "(14, 16)": 0.7021649479866028, "(16, 0)": 0.7021649479866028, "(16, 16)": 0.7021649479866028, "(18, 0)": 0.7021649479866028, "(18, 16)": 0.7021649479866028, "(20, 0)": 0.7021649479866028, "(20, 16)": 0.7021649479866028, "(22, 0)": 0.7782481908798218, "(22, 16)": 0.7021649479866028, "(24, 0)": 0.7021649479866028, "(24, 16)": 0.7021649479866028, "(26, 0)": 0.7021649479866028, "(26, 16)": 0.8715543746948242, "(28, 0)": 0.7021649479866028, "(28, 16)": 0.7021649479866028, "(30, 0)": 0.7021649479866028, "(30, 16)": 0.8715543746948242}, "r_span": [680, 771], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0024852752685546875}}, {"prompt_attention_score": {"(0, 0)": 0.6089528203010559, "(0, 16)": 0.6089528203010559, "(2, 0)": 0.6089528203010559, "(2, 16)": 0.6089528203010559, "(4, 0)": 0.7151206731796265, "(4, 16)": 0.6089528203010559, "(6, 0)": 0.6089528203010559, "(6, 16)": 0.8460588455200195, "(8, 0)": 0.6089528203010559, "(8, 16)": 0.7932035326957703, "(10, 0)": 0.6089528203010559, "(10, 16)": 0.6089528203010559, "(12, 0)": 0.7932035326957703, "(12, 16)": 0.6089528203010559, "(14, 0)": 0.7932035326957703, "(14, 16)": 0.6089528203010559, "(16, 0)": 0.6089528203010559, "(16, 16)": 0.6089528203010559, "(18, 0)": 0.6089528203010559, "(18, 16)": 0.8460588455200195, "(20, 0)": 0.8460588455200195, "(20, 16)": 0.6089528203010559, "(22, 0)": 0.7932035326957703, "(22, 16)": 0.8460588455200195, "(24, 0)": 0.6089528203010559, "(24, 16)": 0.8460588455200195, "(26, 0)": 0.7932035326957703, "(26, 16)": 0.6089528203010559, "(28, 0)": 0.6089528203010559, "(28, 16)": 0.6089528203010559, "(30, 0)": 0.6089528203010559, "(30, 16)": 0.7932035326957703}, "r_span": [773, 837], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0010152459144592285}}]}, {"id": "13155", "source_id": "15111", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 625, "end": 657, "text": "can significantly reduce anxiety", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *no mention of use of anxiety*\nGenerative: can significantly reduce anxiety", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 687, "end": 847, "text": "4. Increases feelings of social connection: Hugging can create a sense of belonging and social connection, which is essential for mental well-being (Passage 1).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned in passage 1*\nGenerative: 4. Increases feelings of social connection: Hugging can create a sense of belonging and social connection, which is essential for mental well-being (Passage 1).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 848, "end": 1013, "text": "5. Supports emotional healing: The physical contact involved in hugging can help release oxytocin, a hormone that promotes emotional healing and bonding (Passage 1).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned in passage 1*\nGenerative: 5. Supports emotional healing: The physical contact involved in hugging can help release oxytocin, a hormone that promotes emotional healing and bonding (Passage 1).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 81, "end": 260, "text": "1. Improves mood and reduces stress: According to passage 1, hugging has a positive impact on the body's physiology, resulting in feelings of relaxation and reduced stress levels.", "meta": "LOW INTRODUCTION OF NEW INFORMATION\nOriginal: *not specifically stated*\nGenerative: 1. Improves mood and reduces stress: According to passage 1, hugging has a positive impact on the body's physiology, resulting in feelings of relaxation and reduced stress levels.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some psychological effects of hugging:\n\n1. Improves mood and reduces stress: According to passage 1, hugging has a positive impact on the body's physiology, resulting in feelings of relaxation and reduced stress levels.\n2. Enhances empathy and communication: Passage 2 highlights the importance of empathy and listening skills in building strong relationships. Hugging can be seen as a form of nonverbal communication that conveys empathy and understanding.\n3. Reduces anxiety and worry: Study published in Psychological Science (referenced in passage 3) shows that hugging and touch can significantly reduce anxiety and worries about mortality.\n4. Increases feelings of social connection: Hugging can create a sense of belonging and social connection, which is essential for mental well-being (Passage 1).\n5. Supports emotional healing: The physical contact involved in hugging can help release oxytocin, a hormone that promotes emotional healing and bonding (Passage 1).\n\nUnable to answer based on given passages.", "response_spans": [[0, 79], [81, 498], [499, 847], [848, 1013], [1015, 1056]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7767189741134644, "(0, 16)": 0.7767189741134644, "(2, 0)": 0.7767189741134644, "(2, 16)": 0.7767189741134644, "(4, 0)": 0.7767189741134644, "(4, 16)": 0.7767189741134644, "(6, 0)": 0.7767189741134644, "(6, 16)": 0.8250735998153687, "(8, 0)": 0.7767189741134644, "(8, 16)": 0.7767189741134644, "(10, 0)": 0.7767189741134644, "(10, 16)": 0.7767189741134644, "(12, 0)": 0.7767189741134644, "(12, 16)": 0.8250735998153687, "(14, 0)": 0.8250735998153687, "(14, 16)": 0.7767189741134644, "(16, 0)": 0.8250735998153687, "(16, 16)": 0.7767189741134644, "(18, 0)": 0.7767189741134644, "(18, 16)": 0.8250735998153687, "(20, 0)": 0.8250735998153687, "(20, 16)": 0.8250735998153687, "(22, 0)": 0.8250735998153687, "(22, 16)": 0.8250735998153687, "(24, 0)": 0.8250735998153687, "(24, 16)": 0.8250735998153687, "(26, 0)": 0.8250735998153687, "(26, 16)": 0.8250735998153687, "(28, 0)": 0.8250735998153687, "(28, 16)": 0.8250735998153687, "(30, 0)": 0.8250735998153687, "(30, 16)": 0.8250735998153687}, "r_span": [340, 359], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002448558807373047}}, {"prompt_attention_score": {"(0, 0)": 0.8013112545013428, "(0, 16)": 0.8013112545013428, "(2, 0)": 0.8013112545013428, "(2, 16)": 0.8013112545013428, "(4, 0)": 0.8013112545013428, "(4, 16)": 0.8013112545013428, "(6, 0)": 0.8013112545013428, "(6, 16)": 0.8717032670974731, "(8, 0)": 0.8013112545013428, "(8, 16)": 0.8013112545013428, "(10, 0)": 0.8013112545013428, "(10, 16)": 0.8013112545013428, "(12, 0)": 0.8717032670974731, "(12, 16)": 0.8164386749267578, "(14, 0)": 0.8717032670974731, "(14, 16)": 0.8717032670974731, "(16, 0)": 0.8717032670974731, "(16, 16)": 0.8717032670974731, "(18, 0)": 0.8717032670974731, "(18, 16)": 0.8717032670974731, "(20, 0)": 0.8164386749267578, "(20, 16)": 0.8717032670974731, "(22, 0)": 0.8717032670974731, "(22, 16)": 0.8717032670974731, "(24, 0)": 0.8717032670974731, "(24, 16)": 0.8164386749267578, "(26, 0)": 0.8717032670974731, "(26, 16)": 0.8717032670974731, "(28, 0)": 0.8717032670974731, "(28, 16)": 0.8717032670974731, "(30, 0)": 0.8717032670974731, "(30, 16)": 0.8717032670974731}, "r_span": [361, 461], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008028745651245117}}, {"prompt_attention_score": {"(0, 0)": 0.8559209108352661, "(0, 16)": 0.8559209108352661, "(2, 0)": 0.8559209108352661, "(2, 16)": 0.8559209108352661, "(4, 0)": 0.8559209108352661, "(4, 16)": 0.8559209108352661, "(6, 0)": 0.8559209108352661, "(6, 16)": 0.8559209108352661, "(8, 0)": 0.8559209108352661, "(8, 16)": 0.826738715171814, "(10, 0)": 0.8559209108352661, "(10, 16)": 0.8559209108352661, "(12, 0)": 0.8559209108352661, "(12, 16)": 0.8559209108352661, "(14, 0)": 0.826738715171814, "(14, 16)": 0.8559209108352661, "(16, 0)": 0.8559209108352661, "(16, 16)": 0.826738715171814, "(18, 0)": 0.826738715171814, "(18, 16)": 0.8559209108352661, "(20, 0)": 0.8559209108352661, "(20, 16)": 0.826738715171814, "(22, 0)": 0.826738715171814, "(22, 16)": 0.8559209108352661, "(24, 0)": 0.826738715171814, "(24, 16)": 0.8559209108352661, "(26, 0)": 0.826738715171814, "(26, 16)": 0.826738715171814, "(28, 0)": 0.826738715171814, "(28, 16)": 0.826738715171814, "(30, 0)": 0.826738715171814, "(30, 16)": 0.826738715171814}, "r_span": [462, 544], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0009804368019104004}}, {"prompt_attention_score": {"(0, 0)": 0.7387995719909668, "(0, 16)": 0.7387995719909668, "(2, 0)": 0.7387995719909668, "(2, 16)": 0.7387995719909668, "(4, 0)": 0.7387995719909668, "(4, 16)": 0.7387995719909668, "(6, 0)": 0.7387995719909668, "(6, 16)": 0.738656759262085, "(8, 0)": 0.7387995719909668, "(8, 16)": 0.7970480918884277, "(10, 0)": 0.7387995719909668, "(10, 16)": 0.7387995719909668, "(12, 0)": 0.7970480918884277, "(12, 16)": 0.7970480918884277, "(14, 0)": 0.7970480918884277, "(14, 16)": 0.7970480918884277, "(16, 0)": 0.7970480918884277, "(16, 16)": 0.7970480918884277, "(18, 0)": 0.7970480918884277, "(18, 16)": 0.7970480918884277, "(20, 0)": 0.7387995719909668, "(20, 16)": 0.7970480918884277, "(22, 0)": 0.7970480918884277, "(22, 16)": 0.7387995719909668, "(24, 0)": 0.7970480918884277, "(24, 16)": 0.7387995719909668, "(26, 0)": 0.7970480918884277, "(26, 16)": 0.7970480918884277, "(28, 0)": 0.7970480918884277, "(28, 16)": 0.7970480918884277, "(30, 0)": 0.7970480918884277, "(30, 16)": 0.7970480918884277}, "r_span": [545, 590], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0017222166061401367}}, {"prompt_attention_score": {"(0, 0)": 0.5885828733444214, "(0, 16)": 0.5885828733444214, "(2, 0)": 0.5885828733444214, "(2, 16)": 0.5885828733444214, "(4, 0)": 0.5885828733444214, "(4, 16)": 0.5885828733444214, "(6, 0)": 0.5885828733444214, "(6, 16)": 0.5885828733444214, "(8, 0)": 0.5106139183044434, "(8, 16)": 0.5885828733444214, "(10, 0)": 0.5885828733444214, "(10, 16)": 0.5885828733444214, "(12, 0)": 0.5885828733444214, "(12, 16)": 0.5885828733444214, "(14, 0)": 0.465305894613266, "(14, 16)": 0.5885828733444214, "(16, 0)": 0.5885828733444214, "(16, 16)": 0.465305894613266, "(18, 0)": 0.465305894613266, "(18, 16)": 0.5885828733444214, "(20, 0)": 0.5885828733444214, "(20, 16)": 0.465305894613266, "(22, 0)": 0.465305894613266, "(22, 16)": 0.5885828733444214, "(24, 0)": 0.465305894613266, "(24, 16)": 0.5885828733444214, "(26, 0)": 0.465305894613266, "(26, 16)": 0.465305894613266, "(28, 0)": 0.465305894613266, "(28, 16)": 0.465305894613266, "(30, 0)": 0.465305894613266, "(30, 16)": 0.465305894613266}, "r_span": [592, 602], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005279779434204102}}]}, {"id": "13161", "source_id": "15112", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 718, "end": 841, "text": "Return the prime rib to the oven and baste it with the au jus every 20-30 minutes during the last 20-30 minutes of cooking.", "meta": "HIGH INTRO OF NEW INFO\nThis step and its details were not mentioned in the passages. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 1091, "end": 1237, "text": "Once the prime rib reaches the desired internal temperature, remove it from the oven and let it rest for 10-15 minutes before slicing and serving.", "meta": "HIGH INTRO OF NEW INFO\nThis step and its details were not mentioned in the passages. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 1331, "end": 1349, "text": "or smaller roasts.", "meta": "EVIDENT CONFLICT\nOriginal: The question is about small roasts, therefore, the passages provided answers that is SUITABLE for smaller roasts. \nGenerative: \"...and may not be suitable for...smaller roasts.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 966, "end": 1087, "text": "an internal temperature of 130¬∞F to 135¬∞F for medium-rare, 140¬∞F to 145¬∞F for medium, and 150¬∞F to 155¬∞F for medium-well.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of internal temperatures. \nGenerative: an internal temperature of 130¬∞F to 135¬∞F for medium-rare, 140¬∞F to 145¬∞F for medium, and 150¬∞F to 155¬∞F for medium-well.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the steps to cook a small prime rib roast in the oven:\n\n1. Allow the roast to stand at room temperature for at least 1 hour before preheating the oven to 375¬∞F.\n2. Rub the roast with House Seasoning and place it on a rack in a roasting pan with the rib side down and the fatty side up.\n3. Roast the prime rib for 1 hour, then turn off the oven.\n4. While the roast is resting, prepare the au jus by placing the roasting pan on top of the stove over high heat. Cook the au jus for 8-10 minutes, stirring and scraping any brown bits.\n5. Add the wine to the au jus and cook for 20 minutes or until the juice has reduced by half. Season the au jus with salt and pepper to taste.\n6. Return the prime rib to the oven and baste it with the au jus every 20-30 minutes during the last 20-30 minutes of cooking.\n7. After 20-30 minutes of basting, check the internal temperature of the prime rib with a meat thermometer. It should reach an internal temperature of 130¬∞F to 135¬∞F for medium-rare, 140¬∞F to 145¬∞F for medium, and 150¬∞F to 155¬∞F for medium-well.\n8. Once the prime rib reaches the desired internal temperature, remove it from the oven and let it rest for 10-15 minutes before slicing and serving.\n\nNote: These instructions are based on the given passages and may not be suitable for larger or smaller roasts. Additionally, adjust the cooking time and temperature as needed based on the size and thickness of the prime rib.", "response_spans": [[0, 95], [97, 571], [572, 841], [842, 1237], [1239, 1463]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7406114339828491, "(0, 16)": 0.7406114339828491, "(2, 0)": 0.7406114339828491, "(2, 16)": 0.7406114339828491, "(4, 0)": 0.7406114339828491, "(4, 16)": 0.7406114339828491, "(6, 0)": 0.47727760672569275, "(6, 16)": 0.8931447863578796, "(8, 0)": 0.8072183728218079, "(8, 16)": 0.47727760672569275, "(10, 0)": 0.47727760672569275, "(10, 16)": 0.47727760672569275, "(12, 0)": 0.47727760672569275, "(12, 16)": 0.8931447863578796, "(14, 0)": 0.7406114339828491, "(14, 16)": 0.47727760672569275, "(16, 0)": 0.8931447863578796, "(16, 16)": 0.47727760672569275, "(18, 0)": 0.47727760672569275, "(18, 16)": 0.8931447863578796, "(20, 0)": 0.8931447863578796, "(20, 16)": 0.8072183728218079, "(22, 0)": 0.8072183728218079, "(22, 16)": 0.8931447863578796, "(24, 0)": 0.8072183728218079, "(24, 16)": 0.8931447863578796, "(26, 0)": 0.8072183728218079, "(26, 16)": 0.8072183728218079, "(28, 0)": 0.47727760672569275, "(28, 16)": 0.8072183728218079, "(30, 0)": 0.8072183728218079, "(30, 16)": 0.8072183728218079}, "r_span": [619, 644], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010022521018981934}}, {"prompt_attention_score": {"(0, 0)": 0.8490309715270996, "(0, 16)": 0.8490309715270996, "(2, 0)": 0.8490309715270996, "(2, 16)": 0.8490309715270996, "(4, 0)": 0.8490309715270996, "(4, 16)": 0.8490309715270996, "(6, 0)": 0.8490309715270996, "(6, 16)": 0.8588908910751343, "(8, 0)": 0.8490309715270996, "(8, 16)": 0.8490309715270996, "(10, 0)": 0.8490309715270996, "(10, 16)": 0.8490309715270996, "(12, 0)": 0.8490309715270996, "(12, 16)": 0.8588908910751343, "(14, 0)": 0.8490309715270996, "(14, 16)": 0.8490309715270996, "(16, 0)": 0.8588908910751343, "(16, 16)": 0.8490309715270996, "(18, 0)": 0.3931751251220703, "(18, 16)": 0.8588908910751343, "(20, 0)": 0.8588908910751343, "(20, 16)": 0.8490309715270996, "(22, 0)": 0.8333714008331299, "(22, 16)": 0.8588908910751343, "(24, 0)": 0.8333714008331299, "(24, 16)": 0.8490309715270996, "(26, 0)": 0.8333714008331299, "(26, 16)": 0.8333714008331299, "(28, 0)": 0.8333714008331299, "(28, 16)": 0.8333714008331299, "(30, 0)": 0.8333714008331299, "(30, 16)": 0.8333714008331299}, "r_span": [646, 790], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004781484603881836}}, {"prompt_attention_score": {"(0, 0)": 0.8291056752204895, "(0, 16)": 0.8291056752204895, "(2, 0)": 0.8291056752204895, "(2, 16)": 0.8291056752204895, "(4, 0)": 0.8291056752204895, "(4, 16)": 0.8291056752204895, "(6, 0)": 0.8291056752204895, "(6, 16)": 0.8291056752204895, "(8, 0)": 0.8291056752204895, "(8, 16)": 0.8291056752204895, "(10, 0)": 0.8291056752204895, "(10, 16)": 0.8291056752204895, "(12, 0)": 0.8291056752204895, "(12, 16)": 0.8291056752204895, "(14, 0)": 0.8291056752204895, "(14, 16)": 0.8291056752204895, "(16, 0)": 0.8291056752204895, "(16, 16)": 0.7829878330230713, "(18, 0)": 0.3956123888492584, "(18, 16)": 0.8291056752204895, "(20, 0)": 0.8291056752204895, "(20, 16)": 0.7829878330230713, "(22, 0)": 0.7829878330230713, "(22, 16)": 0.8291056752204895, "(24, 0)": 0.7829878330230713, "(24, 16)": 0.8291056752204895, "(26, 0)": 0.7829878330230713, "(26, 16)": 0.7829878330230713, "(28, 0)": 0.7829878330230713, "(28, 16)": 0.7829878330230713, "(30, 0)": 0.7829878330230713, "(30, 16)": 0.7829878330230713}, "r_span": [791, 873], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 9.03010368347168e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7117869257926941, "(0, 16)": 0.7117869257926941, "(2, 0)": 0.7117869257926941, "(2, 16)": 0.7117869257926941, "(4, 0)": 0.40575656294822693, "(4, 16)": 0.7117869257926941, "(6, 0)": 0.7117869257926941, "(6, 16)": 0.7873733043670654, "(8, 0)": 0.7117869257926941, "(8, 16)": 0.7873733043670654, "(10, 0)": 0.7117869257926941, "(10, 16)": 0.7117869257926941, "(12, 0)": 0.7528160810470581, "(12, 16)": 0.7117869257926941, "(14, 0)": 0.7117869257926941, "(14, 16)": 0.7117869257926941, "(16, 0)": 0.7117869257926941, "(16, 16)": 0.7117869257926941, "(18, 0)": 0.40575656294822693, "(18, 16)": 0.7873733043670654, "(20, 0)": 0.7528160810470581, "(20, 16)": 0.7873733043670654, "(22, 0)": 0.7873733043670654, "(22, 16)": 0.7873733043670654, "(24, 0)": 0.7873733043670654, "(24, 16)": 0.7117869257926941, "(26, 0)": 0.7873733043670654, "(26, 16)": 0.7117869257926941, "(28, 0)": 0.7873733043670654, "(28, 16)": 0.7873733043670654, "(30, 0)": 0.7873733043670654, "(30, 16)": 0.7873733043670654}, "r_span": [874, 1000], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0025166869163513184}}, {"prompt_attention_score": {"(0, 0)": 0.7117860317230225, "(0, 16)": 0.7117860317230225, "(2, 0)": 0.7117860317230225, "(2, 16)": 0.5292211174964905, "(4, 0)": 0.7117860317230225, "(4, 16)": 0.7117860317230225, "(6, 0)": 0.7117860317230225, "(6, 16)": 0.804323673248291, "(8, 0)": 0.7777027487754822, "(8, 16)": 0.7777027487754822, "(10, 0)": 0.5292211174964905, "(10, 16)": 0.5292211174964905, "(12, 0)": 0.5292211174964905, "(12, 16)": 0.5292211174964905, "(14, 0)": 0.7777027487754822, "(14, 16)": 0.5292211174964905, "(16, 0)": 0.5292211174964905, "(16, 16)": 0.7777027487754822, "(18, 0)": 0.5292211174964905, "(18, 16)": 0.5292211174964905, "(20, 0)": 0.804323673248291, "(20, 16)": 0.7777027487754822, "(22, 0)": 0.7777027487754822, "(22, 16)": 0.5292211174964905, "(24, 0)": 0.7777027487754822, "(24, 16)": 0.7777027487754822, "(26, 0)": 0.7777027487754822, "(26, 16)": 0.7777027487754822, "(28, 0)": 0.7777027487754822, "(28, 16)": 0.7777027487754822, "(30, 0)": 0.7777027487754822, "(30, 16)": 0.7777027487754822}, "r_span": [1002, 1048], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0006441473960876465}}]}, {"id": "13209", "source_id": "15120", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the time it takes to make chicken tenders in a crock pot is:\n\nPassage 1: 6-8 hours on low heat\nPassage 2: 6-8 hours on low heat\nPassage 3: 8 hours on low heat for chicken breasts, but the same method can be used for chicken tenders.\n\nTherefore, the estimated time to make chicken tenders in a crock pot is around 6-8 hours on low heat, depending on the size and number of tenders being cooked.", "response_spans": [[0, 425]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8051937818527222, "(0, 16)": 0.8051937818527222, "(2, 0)": 0.8051937818527222, "(2, 16)": 0.8051937818527222, "(4, 0)": 0.8051937818527222, "(4, 16)": 0.8051937818527222, "(6, 0)": 0.8051937818527222, "(6, 16)": 0.8758724331855774, "(8, 0)": 0.8051937818527222, "(8, 16)": 0.8051937818527222, "(10, 0)": 0.8051937818527222, "(10, 16)": 0.37839046120643616, "(12, 0)": 0.37839046120643616, "(12, 16)": 0.8051937818527222, "(14, 0)": 0.6572749018669128, "(14, 16)": 0.37839046120643616, "(16, 0)": 0.8051937818527222, "(16, 16)": 0.8051937818527222, "(18, 0)": 0.37839046120643616, "(18, 16)": 0.8051937818527222, "(20, 0)": 0.8051937818527222, "(20, 16)": 0.6572749018669128, "(22, 0)": 0.8758724331855774, "(22, 16)": 0.8051937818527222, "(24, 0)": 0.7928183078765869, "(24, 16)": 0.8051937818527222, "(26, 0)": 0.6572749018669128, "(26, 16)": 0.7928183078765869, "(28, 0)": 0.37839046120643616, "(28, 16)": 0.8051937818527222, "(30, 0)": 0.8051937818527222, "(30, 16)": 0.6572749018669128}, "r_span": [569, 697], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0023888349533081055}}]}, {"id": "13233", "source_id": "15124", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some steps for attaching multiple picture frames together:\n\nPassage 1: Table-Stand Grouping\nTo join two or three frames together, you can use identical frames or one larger frame as the middle piece. Place the frames beside each other to see if you like the effect, and then mark the hinge placement on the connecting sides. Attach two small hinges to the marked areas to join the frames together.\n\nPassage 2: Hanging Multiple Pictures Together\nBefore attaching the frames together, test different arrangements of the group of multiple pictures on the floor. Once you have decided on the layout, screw the frames to the backer board, repeating the process for each frame. Attach a hanging wire to the back of the frames and hang them on the wall to enjoy the finished result.\n\nPassage 3: Attaching Frames Together\nTo attach two frames together, place them back to back and mark the hinge placement on the connecting sides. The placement should be the same distance from the bottom edge of each frame to ensure stability when the grouped pictures are placed on a table. Attach two small hinges to the marked areas to join the frames together.\n\nIn conclusion, the recommended method for attaching multiple picture frames together involves using identical or matching frames, marking the hinge placement on the connecting sides, and attaching small hinges to join the frames together. It's also important to test different arrangements of the group of pictures on the floor before attaching the frames together, and to ensure that the frames are securely attached to the backer board before hanging them on the wall.", "response_spans": [[0, 438], [440, 816], [818, 1182], [1184, 1654]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8455883264541626, "(0, 16)": 0.8455883264541626, "(2, 0)": 0.8455883264541626, "(2, 16)": 0.8455883264541626, "(4, 0)": 0.8455883264541626, "(4, 16)": 0.8455883264541626, "(6, 0)": 0.8455883264541626, "(6, 16)": 0.8898754119873047, "(8, 0)": 0.7154367566108704, "(8, 16)": 0.8455883264541626, "(10, 0)": 0.3988962173461914, "(10, 16)": 0.8455883264541626, "(12, 0)": 0.8455883264541626, "(12, 16)": 0.8898754119873047, "(14, 0)": 0.7154367566108704, "(14, 16)": 0.3988962173461914, "(16, 0)": 0.868327260017395, "(16, 16)": 0.7154367566108704, "(18, 0)": 0.3988962173461914, "(18, 16)": 0.8898754119873047, "(20, 0)": 0.8898754119873047, "(20, 16)": 0.7154367566108704, "(22, 0)": 0.7154367566108704, "(22, 16)": 0.8898754119873047, "(24, 0)": 0.7154367566108704, "(24, 16)": 0.8898754119873047, "(26, 0)": 0.7154367566108704, "(26, 16)": 0.7154367566108704, "(28, 0)": 0.7154367566108704, "(28, 16)": 0.7154367566108704, "(30, 0)": 0.7154367566108704, "(30, 16)": 0.7154367566108704}, "r_span": [554, 653], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0010074377059936523}}, {"prompt_attention_score": {"(0, 0)": 0.867638349533081, "(0, 16)": 0.867638349533081, "(2, 0)": 0.867638349533081, "(2, 16)": 0.844424843788147, "(4, 0)": 0.867638349533081, "(4, 16)": 0.867638349533081, "(6, 0)": 0.867638349533081, "(6, 16)": 0.7811983227729797, "(8, 0)": 0.867638349533081, "(8, 16)": 0.844424843788147, "(10, 0)": 0.867638349533081, "(10, 16)": 0.867638349533081, "(12, 0)": 0.844424843788147, "(12, 16)": 0.867638349533081, "(14, 0)": 0.844424843788147, "(14, 16)": 0.844424843788147, "(16, 0)": 0.867638349533081, "(16, 16)": 0.844424843788147, "(18, 0)": 0.844424843788147, "(18, 16)": 0.844424843788147, "(20, 0)": 0.867638349533081, "(20, 16)": 0.844424843788147, "(22, 0)": 0.844424843788147, "(22, 16)": 0.844424843788147, "(24, 0)": 0.844424843788147, "(24, 16)": 0.867638349533081, "(26, 0)": 0.844424843788147, "(26, 16)": 0.844424843788147, "(28, 0)": 0.844424843788147, "(28, 16)": 0.844424843788147, "(30, 0)": 0.844424843788147, "(30, 16)": 0.844424843788147}, "r_span": [655, 737], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 4.6372413635253906e-05}}, {"prompt_attention_score": {"(0, 0)": 0.9081152081489563, "(0, 16)": 0.9081152081489563, "(2, 0)": 0.9081152081489563, "(2, 16)": 0.9081152081489563, "(4, 0)": 0.9081152081489563, "(4, 16)": 0.9081152081489563, "(6, 0)": 0.9081152081489563, "(6, 16)": 0.9231479167938232, "(8, 0)": 0.9081152081489563, "(8, 16)": 0.9081152081489563, "(10, 0)": 0.9081152081489563, "(10, 16)": 0.9081152081489563, "(12, 0)": 0.9081152081489563, "(12, 16)": 0.9081152081489563, "(14, 0)": 0.7005934715270996, "(14, 16)": 0.9081152081489563, "(16, 0)": 0.9081152081489563, "(16, 16)": 0.7005934715270996, "(18, 0)": 0.7005934715270996, "(18, 16)": 0.9231479167938232, "(20, 0)": 0.9081152081489563, "(20, 16)": 0.7005934715270996, "(22, 0)": 0.7005934715270996, "(22, 16)": 0.9231479167938232, "(24, 0)": 0.7005934715270996, "(24, 16)": 0.9081152081489563, "(26, 0)": 0.7005934715270996, "(26, 16)": 0.7005934715270996, "(28, 0)": 0.7005934715270996, "(28, 16)": 0.7005934715270996, "(30, 0)": 0.7005934715270996, "(30, 16)": 0.7005934715270996}, "r_span": [739, 819], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0010862350463867188}}, {"prompt_attention_score": {"(0, 0)": 0.8484821319580078, "(0, 16)": 0.8484821319580078, "(2, 0)": 0.8484821319580078, "(2, 16)": 0.8484821319580078, "(4, 0)": 0.7336326837539673, "(4, 16)": 0.8484821319580078, "(6, 0)": 0.8484821319580078, "(6, 16)": 0.8251805305480957, "(8, 0)": 0.801035463809967, "(8, 16)": 0.7336326837539673, "(10, 0)": 0.7336326837539673, "(10, 16)": 0.7336326837539673, "(12, 0)": 0.7336326837539673, "(12, 16)": 0.8484821319580078, "(14, 0)": 0.7336326837539673, "(14, 16)": 0.3957432508468628, "(16, 0)": 0.3957432508468628, "(16, 16)": 0.7336326837539673, "(18, 0)": 0.7336326837539673, "(18, 16)": 0.7336326837539673, "(20, 0)": 0.8484821319580078, "(20, 16)": 0.7336326837539673, "(22, 0)": 0.7336326837539673, "(22, 16)": 0.8484821319580078, "(24, 0)": 0.7336326837539673, "(24, 16)": 0.8484821319580078, "(26, 0)": 0.7336326837539673, "(26, 16)": 0.7336326837539673, "(28, 0)": 0.7336326837539673, "(28, 16)": 0.7336326837539673, "(30, 0)": 0.7336326837539673, "(30, 16)": 0.7336326837539673}, "r_span": [821, 914], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012729763984680176}}]}, {"id": "13263", "source_id": "15130", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 452, "end": 540, "text": "the duration of the lease, the payment amount, and any other conditions or restrictions.", "meta": "HIGH INTRO OF NEW INFO\nThe 'duration of the lease, the payment amount, and any other conditions or restrictions' are not mentioned in the original sources. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the definition of leasing can be summarized as follows:\n\n* Leasing is a process where a firm obtains the use of a fixed asset for a period of time in exchange for regular, contractual payments.\n* The lessee is the individual or organization using the asset, while the lessor is the owner of the asset.\n* The lease agreement is a contract between the lessor and the lessee that outlines the terms of the lease, including the duration of the lease, the payment amount, and any other conditions or restrictions.\n* The consideration for the lease is called rent.\n\nTherefore, the answer to the question \"What is leasing?\" is:\n\nLeasing is a process where a firm obtains the use of a fixed asset for a period of time in exchange for regular, contractual payments.", "response_spans": [[0, 87], [89, 590], [592, 788]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7447274327278137, "(0, 16)": 0.7447274327278137, "(2, 0)": 0.7447274327278137, "(2, 16)": 0.7447274327278137, "(4, 0)": 0.7447274327278137, "(4, 16)": 0.7447274327278137, "(6, 0)": 0.5361980199813843, "(6, 16)": 0.7970770001411438, "(8, 0)": 0.7447274327278137, "(8, 16)": 0.5361980199813843, "(10, 0)": 0.5361980199813843, "(10, 16)": 0.5361980199813843, "(12, 0)": 0.5361980199813843, "(12, 16)": 0.7970770001411438, "(14, 0)": 0.7447274327278137, "(14, 16)": 0.5361980199813843, "(16, 0)": 0.7970770001411438, "(16, 16)": 0.7447274327278137, "(18, 0)": 0.5361980199813843, "(18, 16)": 0.7970770001411438, "(20, 0)": 0.7970770001411438, "(20, 16)": 0.7447274327278137, "(22, 0)": 0.7447274327278137, "(22, 16)": 0.7970770001411438, "(24, 0)": 0.7447274327278137, "(24, 16)": 0.7970770001411438, "(26, 0)": 0.7447274327278137, "(26, 16)": 0.7447274327278137, "(28, 0)": 0.5361980199813843, "(28, 16)": 0.7447274327278137, "(30, 0)": 0.7447274327278137, "(30, 16)": 0.7447274327278137}, "r_span": [445, 465], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00039333105087280273}}, {"prompt_attention_score": {"(0, 0)": 0.9027997851371765, "(0, 16)": 0.9027997851371765, "(2, 0)": 0.9027997851371765, "(2, 16)": 0.9027997851371765, "(4, 0)": 0.9027997851371765, "(4, 16)": 0.9027997851371765, "(6, 0)": 0.9027997851371765, "(6, 16)": 0.9064050316810608, "(8, 0)": 0.9027997851371765, "(8, 16)": 0.9027997851371765, "(10, 0)": 0.9027997851371765, "(10, 16)": 0.9027997851371765, "(12, 0)": 0.9027997851371765, "(12, 16)": 0.9027997851371765, "(14, 0)": 0.9027997851371765, "(14, 16)": 0.9027997851371765, "(16, 0)": 0.9027997851371765, "(16, 16)": 0.9027997851371765, "(18, 0)": 0.9027997851371765, "(18, 16)": 0.9064050316810608, "(20, 0)": 0.9064050316810608, "(20, 16)": 0.9027997851371765, "(22, 0)": 0.9027997851371765, "(22, 16)": 0.9064050316810608, "(24, 0)": 0.9027997851371765, "(24, 16)": 0.9027997851371765, "(26, 0)": 0.9027997851371765, "(26, 16)": 0.9027997851371765, "(28, 0)": 0.9027997851371765, "(28, 16)": 0.9027997851371765, "(30, 0)": 0.9027997851371765, "(30, 16)": 0.9027997851371765}, "r_span": [467, 582], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002618074417114258}}, {"prompt_attention_score": {"(0, 0)": 0.8032748699188232, "(0, 16)": 0.8032748699188232, "(2, 0)": 0.8032748699188232, "(2, 16)": 0.43830159306526184, "(4, 0)": 0.8032748699188232, "(4, 16)": 0.8032748699188232, "(6, 0)": 0.8032748699188232, "(6, 16)": 0.8736770153045654, "(8, 0)": 0.8032748699188232, "(8, 16)": 0.8032748699188232, "(10, 0)": 0.43830159306526184, "(10, 16)": 0.43830159306526184, "(12, 0)": 0.8032748699188232, "(12, 16)": 0.43830159306526184, "(14, 0)": 0.8032748699188232, "(14, 16)": 0.43830159306526184, "(16, 0)": 0.777184009552002, "(16, 16)": 0.8032748699188232, "(18, 0)": 0.43830159306526184, "(18, 16)": 0.8736770153045654, "(20, 0)": 0.8736770153045654, "(20, 16)": 0.8032748699188232, "(22, 0)": 0.8032748699188232, "(22, 16)": 0.8736770153045654, "(24, 0)": 0.8032748699188232, "(24, 16)": 0.8736770153045654, "(26, 0)": 0.8032748699188232, "(26, 16)": 0.8032748699188232, "(28, 0)": 0.8032748699188232, "(28, 16)": 0.8032748699188232, "(30, 0)": 0.8032748699188232, "(30, 16)": 0.8032748699188232}, "r_span": [584, 633], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000820159912109375}}]}, {"id": "13293", "source_id": "15135", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 217, "end": 252, "text": "accounting for around 70% of cases.", "meta": "LOW INTRODUCTION OF NEW INFORMATION \n Original: *not mentioned*\n Generative: accounting for around 70% of cases.", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the main causes of necrotizing fasciitis are:\n\n1. Group A beta-hemolytic streptococci (Streptococcus pyogenes): This type of bacteria is the most common cause of necrotizing fasciitis, accounting for around 70% of cases.\n2. Other types of bacteria: Passage 3 mentions that several other types of bacteria can also cause necrotizing fasciitis, including staphylococcus.\n3. Trauma: Passage 1 states that prior trauma, such as cuts, scrapes, insect bites, burns, or needle puncture wounds, can increase the risk of developing necrotizing fasciitis.\n\nTherefore, the answer to the question is: Group A beta-hemolytic streptococci, other types of bacteria, and trauma.", "response_spans": [[0, 77], [79, 577], [579, 694]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.807293176651001, "(0, 16)": 0.807293176651001, "(2, 0)": 0.807293176651001, "(2, 16)": 0.807293176651001, "(4, 0)": 0.807293176651001, "(4, 16)": 0.5245604515075684, "(6, 0)": 0.5245604515075684, "(6, 16)": 0.8357954025268555, "(8, 0)": 0.8093600869178772, "(8, 16)": 0.5245604515075684, "(10, 0)": 0.5245604515075684, "(10, 16)": 0.5245604515075684, "(12, 0)": 0.8093600869178772, "(12, 16)": 0.8357954025268555, "(14, 0)": 0.8093600869178772, "(14, 16)": 0.5245604515075684, "(16, 0)": 0.8357954025268555, "(16, 16)": 0.807293176651001, "(18, 0)": 0.5245604515075684, "(18, 16)": 0.8357954025268555, "(20, 0)": 0.8051839470863342, "(20, 16)": 0.8093600869178772, "(22, 0)": 0.8093600869178772, "(22, 16)": 0.8357954025268555, "(24, 0)": 0.8093600869178772, "(24, 16)": 0.8357954025268555, "(26, 0)": 0.8093600869178772, "(26, 16)": 0.8093600869178772, "(28, 0)": 0.5245604515075684, "(28, 16)": 0.8093600869178772, "(30, 0)": 0.8093600869178772, "(30, 16)": 0.8093600869178772}, "r_span": [656, 677], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00012665987014770508}}, {"prompt_attention_score": {"(0, 0)": 0.819593608379364, "(0, 16)": 0.819593608379364, "(2, 0)": 0.819593608379364, "(2, 16)": 0.819593608379364, "(4, 0)": 0.819593608379364, "(4, 16)": 0.819593608379364, "(6, 0)": 0.819593608379364, "(6, 16)": 0.8102468252182007, "(8, 0)": 0.819593608379364, "(8, 16)": 0.8555766344070435, "(10, 0)": 0.819593608379364, "(10, 16)": 0.819593608379364, "(12, 0)": 0.8555766344070435, "(12, 16)": 0.8102468252182007, "(14, 0)": 0.8555766344070435, "(14, 16)": 0.8555766344070435, "(16, 0)": 0.8555766344070435, "(16, 16)": 0.8555766344070435, "(18, 0)": 0.8555766344070435, "(18, 16)": 0.7473351955413818, "(20, 0)": 0.8102468252182007, "(20, 16)": 0.8555766344070435, "(22, 0)": 0.8555766344070435, "(22, 16)": 0.8102468252182007, "(24, 0)": 0.8555766344070435, "(24, 16)": 0.7473351955413818, "(26, 0)": 0.8555766344070435, "(26, 16)": 0.8555766344070435, "(28, 0)": 0.8555766344070435, "(28, 16)": 0.8555766344070435, "(30, 0)": 0.8555766344070435, "(30, 16)": 0.8555766344070435}, "r_span": [679, 833], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0034903287887573242}}, {"prompt_attention_score": {"(0, 0)": 0.7128536701202393, "(0, 16)": 0.7128536701202393, "(2, 0)": 0.7128536701202393, "(2, 16)": 0.7128536701202393, "(4, 0)": 0.7128536701202393, "(4, 16)": 0.4792819619178772, "(6, 0)": 0.7128536701202393, "(6, 16)": 0.737250566482544, "(8, 0)": 0.7128536701202393, "(8, 16)": 0.7438536286354065, "(10, 0)": 0.4792819619178772, "(10, 16)": 0.4792819619178772, "(12, 0)": 0.4792819619178772, "(12, 16)": 0.737250566482544, "(14, 0)": 0.7438536286354065, "(14, 16)": 0.4792819619178772, "(16, 0)": 0.6430298089981079, "(16, 16)": 0.7438536286354065, "(18, 0)": 0.7438536286354065, "(18, 16)": 0.737250566482544, "(20, 0)": 0.737250566482544, "(20, 16)": 0.7438536286354065, "(22, 0)": 0.7438536286354065, "(22, 16)": 0.737250566482544, "(24, 0)": 0.7438536286354065, "(24, 16)": 0.737250566482544, "(26, 0)": 0.7438536286354065, "(26, 16)": 0.7438536286354065, "(28, 0)": 0.7438536286354065, "(28, 16)": 0.7438536286354065, "(30, 0)": 0.7438536286354065, "(30, 16)": 0.7438536286354065}, "r_span": [835, 870], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005208253860473633}}]}, {"id": "13311", "source_id": "15138", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is what can be inferred about the vegetable \"chard\":\n\n* Chard is a type of beet (Beta vulgaris subsp. maritima) that has been chosen for leaf production over storage root formation.\n* Chard has large, fleshy but tender deep green leaves and thick, crisp stalks.\n* The flavor of chard is similar to spinach but with a stronger, more assertive taste (some consider it bitter).\n* Fresh young chard can be used raw in salads, while mature chard leaves and stalks are typically cooked to reduce bitterness and bring out a refined flavor.\n* Chard is an attractive ornamental plant that adds color to the vegetable garden.\n* Chard is perishable and should be stored in the refrigerator to minimize spoilage.\n\nTherefore, the answer to the question \"What is chard vegetable?\" is: A beet variety (Beta vulgaris subsp. maritima) grown for leaf production, characterized by large, fleshy leaves and stalks with a strong, bitter flavor that becomes more refined with cooking.", "response_spans": [[0, 89], [91, 569], [570, 737], [739, 999]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7560677528381348, "(0, 16)": 0.7560677528381348, "(2, 0)": 0.7560677528381348, "(2, 16)": 0.7560677528381348, "(4, 0)": 0.7560677528381348, "(4, 16)": 0.7560677528381348, "(6, 0)": 0.6059132814407349, "(6, 16)": 0.8013485670089722, "(8, 0)": 0.6917482018470764, "(8, 16)": 0.6059132814407349, "(10, 0)": 0.6059132814407349, "(10, 16)": 0.6059132814407349, "(12, 0)": 0.6059132814407349, "(12, 16)": 0.8013485670089722, "(14, 0)": 0.7560677528381348, "(14, 16)": 0.6059132814407349, "(16, 0)": 0.8013485670089722, "(16, 16)": 0.7560677528381348, "(18, 0)": 0.6059132814407349, "(18, 16)": 0.8013485670089722, "(20, 0)": 0.8013485670089722, "(20, 16)": 0.6917482018470764, "(22, 0)": 0.6917482018470764, "(22, 16)": 0.8013485670089722, "(24, 0)": 0.6917482018470764, "(24, 16)": 0.8013485670089722, "(26, 0)": 0.6917482018470764, "(26, 16)": 0.6917482018470764, "(28, 0)": 0.6917482018470764, "(28, 16)": 0.7560677528381348, "(30, 0)": 0.6917482018470764, "(30, 16)": 0.6917482018470764}, "r_span": [516, 539], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006782412528991699}}, {"prompt_attention_score": {"(0, 0)": 0.8108615875244141, "(0, 16)": 0.8108615875244141, "(2, 0)": 0.8108615875244141, "(2, 16)": 0.8108615875244141, "(4, 0)": 0.8108615875244141, "(4, 16)": 0.8108615875244141, "(6, 0)": 0.8108615875244141, "(6, 16)": 0.7220010757446289, "(8, 0)": 0.8108615875244141, "(8, 16)": 0.8108615875244141, "(10, 0)": 0.8108615875244141, "(10, 16)": 0.8108615875244141, "(12, 0)": 0.8108615875244141, "(12, 16)": 0.8516349196434021, "(14, 0)": 0.8108615875244141, "(14, 16)": 0.8108615875244141, "(16, 0)": 0.7220010757446289, "(16, 16)": 0.8108615875244141, "(18, 0)": 0.7220010757446289, "(18, 16)": 0.8516349196434021, "(20, 0)": 0.8516349196434021, "(20, 16)": 0.8108615875244141, "(22, 0)": 0.7220010757446289, "(22, 16)": 0.7220010757446289, "(24, 0)": 0.8108615875244141, "(24, 16)": 0.8516349196434021, "(26, 0)": 0.7220010757446289, "(26, 16)": 0.7220010757446289, "(28, 0)": 0.7220010757446289, "(28, 16)": 0.8108615875244141, "(30, 0)": 0.7220010757446289, "(30, 16)": 0.7220010757446289}, "r_span": [541, 668], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 4.2498111724853516e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7956729531288147, "(0, 16)": 0.7956729531288147, "(2, 0)": 0.7956729531288147, "(2, 16)": 0.3891057074069977, "(4, 0)": 0.7956729531288147, "(4, 16)": 0.7956729531288147, "(6, 0)": 0.7956729531288147, "(6, 16)": 0.7956729531288147, "(8, 0)": 0.7956729531288147, "(8, 16)": 0.7956729531288147, "(10, 0)": 0.7956729531288147, "(10, 16)": 0.7956729531288147, "(12, 0)": 0.7956729531288147, "(12, 16)": 0.7956729531288147, "(14, 0)": 0.7956729531288147, "(14, 16)": 0.7956729531288147, "(16, 0)": 0.7956729531288147, "(16, 16)": 0.6335595846176147, "(18, 0)": 0.3891057074069977, "(18, 16)": 0.7956729531288147, "(20, 0)": 0.7956729531288147, "(20, 16)": 0.7956729531288147, "(22, 0)": 0.6335595846176147, "(22, 16)": 0.7956729531288147, "(24, 0)": 0.7956729531288147, "(24, 16)": 0.7956729531288147, "(26, 0)": 0.6335595846176147, "(26, 16)": 0.7956729531288147, "(28, 0)": 0.6335595846176147, "(28, 16)": 0.7956729531288147, "(30, 0)": 0.6335595846176147, "(30, 16)": 0.6335595846176147}, "r_span": [669, 713], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005617737770080566}}, {"prompt_attention_score": {"(0, 0)": 0.7958998680114746, "(0, 16)": 0.7958998680114746, "(2, 0)": 0.7958998680114746, "(2, 16)": 0.7958998680114746, "(4, 0)": 0.7958998680114746, "(4, 16)": 0.7958998680114746, "(6, 0)": 0.7958998680114746, "(6, 16)": 0.7806636095046997, "(8, 0)": 0.7958998680114746, "(8, 16)": 0.7958998680114746, "(10, 0)": 0.4376050531864166, "(10, 16)": 0.4376050531864166, "(12, 0)": 0.7958998680114746, "(12, 16)": 0.7806636095046997, "(14, 0)": 0.7958998680114746, "(14, 16)": 0.4376050531864166, "(16, 0)": 0.7337334156036377, "(16, 16)": 0.7958998680114746, "(18, 0)": 0.6611714363098145, "(18, 16)": 0.7806636095046997, "(20, 0)": 0.7806636095046997, "(20, 16)": 0.7958998680114746, "(22, 0)": 0.6611714363098145, "(22, 16)": 0.7806636095046997, "(24, 0)": 0.7958998680114746, "(24, 16)": 0.7806636095046997, "(26, 0)": 0.6611714363098145, "(26, 16)": 0.7806636095046997, "(28, 0)": 0.6611714363098145, "(28, 16)": 0.7958998680114746, "(30, 0)": 0.6611714363098145, "(30, 16)": 0.6611714363098145}, "r_span": [715, 783], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004361271858215332}}]}, {"id": "13341", "source_id": "15143", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Here are my answers to the question based on the provided passages:\n\nQ: What are the differences between elements, compounds, and mixtures?\nA: Based on the passages provided, here are the differences between elements, compounds, and mixtures:\n\nElements:\n\n* Are the purest form of a chemical substance (Passage 3)\n* Consist of only one type of atom with the same number of protons (Passage 3)\n\nCompounds:\n\n* Are substances composed of two or more different elements (Passage 3)\n* Are also pure substances (Passage 3)\n\nMixtures:\n\n* Contain two or more substances that are relatively easy to separate (Passage 1)\n* Have a variable composition (Passage 2)\n* Show the properties of their constituent substances (Passage 2)\n* Can be separated by physical means (Passage 2)", "response_spans": [[0, 403], [393, 766]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8909049034118652, "(0, 16)": 0.8909049034118652, "(2, 0)": 0.8909049034118652, "(2, 16)": 0.8909049034118652, "(4, 0)": 0.8909049034118652, "(4, 16)": 0.8909049034118652, "(6, 0)": 0.8909049034118652, "(6, 16)": 0.8829343318939209, "(8, 0)": 0.8909049034118652, "(8, 16)": 0.8909049034118652, "(10, 0)": 0.5243391990661621, "(10, 16)": 0.5243391990661621, "(12, 0)": 0.8909049034118652, "(12, 16)": 0.8909049034118652, "(14, 0)": 0.8909049034118652, "(14, 16)": 0.8909049034118652, "(16, 0)": 0.8829343318939209, "(16, 16)": 0.8909049034118652, "(18, 0)": 0.8909049034118652, "(18, 16)": 0.8909049034118652, "(20, 0)": 0.8909049034118652, "(20, 16)": 0.8909049034118652, "(22, 0)": 0.8909049034118652, "(22, 16)": 0.8829343318939209, "(24, 0)": 0.8909049034118652, "(24, 16)": 0.8829343318939209, "(26, 0)": 0.8829343318939209, "(26, 16)": 0.8909049034118652, "(28, 0)": 0.8909049034118652, "(28, 16)": 0.8909049034118652, "(30, 0)": 0.8909049034118652, "(30, 16)": 0.8829343318939209}, "r_span": [494, 603], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005413293838500977}}, {"prompt_attention_score": {"(0, 0)": 0.9274662733078003, "(0, 16)": 0.9274662733078003, "(2, 0)": 0.9274662733078003, "(2, 16)": 0.5173424482345581, "(4, 0)": 0.9274662733078003, "(4, 16)": 0.9274662733078003, "(6, 0)": 0.9274662733078003, "(6, 16)": 0.8845629096031189, "(8, 0)": 0.8867274522781372, "(8, 16)": 0.9274662733078003, "(10, 0)": 0.9274662733078003, "(10, 16)": 0.9274662733078003, "(12, 0)": 0.9274662733078003, "(12, 16)": 0.9274662733078003, "(14, 0)": 0.9274662733078003, "(14, 16)": 0.9274662733078003, "(16, 0)": 0.8867274522781372, "(16, 16)": 0.9274662733078003, "(18, 0)": 0.5173424482345581, "(18, 16)": 0.8867274522781372, "(20, 0)": 0.8867274522781372, "(20, 16)": 0.9274662733078003, "(22, 0)": 0.9274662733078003, "(22, 16)": 0.9274662733078003, "(24, 0)": 0.9274662733078003, "(24, 16)": 0.8867274522781372, "(26, 0)": 0.8223695158958435, "(26, 16)": 0.9274662733078003, "(28, 0)": 0.9274662733078003, "(28, 16)": 0.9274662733078003, "(30, 0)": 0.9274662733078003, "(30, 16)": 0.8223695158958435}, "r_span": [600, 707], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00014221668243408203}}]}, {"id": "13365", "source_id": "15147", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the steps to properly wash wine glasses:\n\n1. If hot water and mild detergent cannot remove wine residue, use baking soda to dissolve and loosen the adhesive residue (Passage 1).\n2. To clean the inside of a glass, use a stemware brush with soft-foam bristles and rinse thoroughly with hot water (Passage 2).\n3. For hand cleaning, lay a towel in the sink before filling with hot water and wash one wine glass at a time to avoid damage (Passage 3). Use a small amount of detergent and only in the bottom of the glass and around the rim to avoid flavoring future wine. Cradle the bowl of the glass in one hand while washing to protect the stem.\n\nUnable to answer based on given passages.", "response_spans": [[0, 81], [83, 347], [348, 681], [683, 724]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8036620616912842, "(0, 16)": 0.8036620616912842, "(2, 0)": 0.8036620616912842, "(2, 16)": 0.8036620616912842, "(4, 0)": 0.8036620616912842, "(4, 16)": 0.8036620616912842, "(6, 0)": 0.8036620616912842, "(6, 16)": 0.7935460805892944, "(8, 0)": 0.8036620616912842, "(8, 16)": 0.44981876015663147, "(10, 0)": 0.44981876015663147, "(10, 16)": 0.44981876015663147, "(12, 0)": 0.7935460805892944, "(12, 16)": 0.7935460805892944, "(14, 0)": 0.7935460805892944, "(14, 16)": 0.7935460805892944, "(16, 0)": 0.7935460805892944, "(16, 16)": 0.7935460805892944, "(18, 0)": 0.44981876015663147, "(18, 16)": 0.7935460805892944, "(20, 0)": 0.7935460805892944, "(20, 16)": 0.7935460805892944, "(22, 0)": 0.7935460805892944, "(22, 16)": 0.7935460805892944, "(24, 0)": 0.7935460805892944, "(24, 16)": 0.7935460805892944, "(26, 0)": 0.7935460805892944, "(26, 16)": 0.8036620616912842, "(28, 0)": 0.44981876015663147, "(28, 16)": 0.7935460805892944, "(30, 0)": 0.7935460805892944, "(30, 16)": 0.7935460805892944}, "r_span": [417, 437], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00036275386810302734}}, {"prompt_attention_score": {"(0, 0)": 0.7964234352111816, "(0, 16)": 0.7964234352111816, "(2, 0)": 0.7964234352111816, "(2, 16)": 0.7964234352111816, "(4, 0)": 0.7964234352111816, "(4, 16)": 0.7964234352111816, "(6, 0)": 0.7964234352111816, "(6, 16)": 0.882021963596344, "(8, 0)": 0.7964234352111816, "(8, 16)": 0.7964234352111816, "(10, 0)": 0.7964234352111816, "(10, 16)": 0.7964234352111816, "(12, 0)": 0.882021963596344, "(12, 16)": 0.882021963596344, "(14, 0)": 0.882021963596344, "(14, 16)": 0.7964234352111816, "(16, 0)": 0.882021963596344, "(16, 16)": 0.882021963596344, "(18, 0)": 0.882021963596344, "(18, 16)": 0.882021963596344, "(20, 0)": 0.882021963596344, "(20, 16)": 0.7964234352111816, "(22, 0)": 0.882021963596344, "(22, 16)": 0.882021963596344, "(24, 0)": 0.882021963596344, "(24, 16)": 0.882021963596344, "(26, 0)": 0.882021963596344, "(26, 16)": 0.8274028301239014, "(28, 0)": 0.882021963596344, "(28, 16)": 0.882021963596344, "(30, 0)": 0.882021963596344, "(30, 16)": 0.882021963596344}, "r_span": [439, 517], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007001757621765137}}, {"prompt_attention_score": {"(0, 0)": 0.9286214709281921, "(0, 16)": 0.9286214709281921, "(2, 0)": 0.9286214709281921, "(2, 16)": 0.9286214709281921, "(4, 0)": 0.9286214709281921, "(4, 16)": 0.9286214709281921, "(6, 0)": 0.9286214709281921, "(6, 16)": 0.9286214709281921, "(8, 0)": 0.9286214709281921, "(8, 16)": 0.9286214709281921, "(10, 0)": 0.9286214709281921, "(10, 16)": 0.9286214709281921, "(12, 0)": 0.8311610221862793, "(12, 16)": 0.9286214709281921, "(14, 0)": 0.8388076424598694, "(14, 16)": 0.9286214709281921, "(16, 0)": 0.9286214709281921, "(16, 16)": 0.8311610221862793, "(18, 0)": 0.8311610221862793, "(18, 16)": 0.9286214709281921, "(20, 0)": 0.9286214709281921, "(20, 16)": 0.8388076424598694, "(22, 0)": 0.8311610221862793, "(22, 16)": 0.9286214709281921, "(24, 0)": 0.8388076424598694, "(24, 16)": 0.9286214709281921, "(26, 0)": 0.8311610221862793, "(26, 16)": 0.9286214709281921, "(28, 0)": 0.8311610221862793, "(28, 16)": 0.9286214709281921, "(30, 0)": 0.8311610221862793, "(30, 16)": 0.8311610221862793}, "r_span": [518, 602], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0020452141761779785}}, {"prompt_attention_score": {"(0, 0)": 0.43459007143974304, "(0, 16)": 0.43459007143974304, "(2, 0)": 0.43459007143974304, "(2, 16)": 0.43459007143974304, "(4, 0)": 0.43459007143974304, "(4, 16)": 0.43459007143974304, "(6, 0)": 0.9034074544906616, "(6, 16)": 0.9034074544906616, "(8, 0)": 0.43459007143974304, "(8, 16)": 0.43459007143974304, "(10, 0)": 0.9034074544906616, "(10, 16)": 0.9034074544906616, "(12, 0)": 0.9034074544906616, "(12, 16)": 0.9034074544906616, "(14, 0)": 0.41144803166389465, "(14, 16)": 0.9034074544906616, "(16, 0)": 0.9034074544906616, "(16, 16)": 0.41144803166389465, "(18, 0)": 0.9034074544906616, "(18, 16)": 0.9034074544906616, "(20, 0)": 0.9034074544906616, "(20, 16)": 0.3928842842578888, "(22, 0)": 0.41144803166389465, "(22, 16)": 0.9034074544906616, "(24, 0)": 0.3928842842578888, "(24, 16)": 0.9034074544906616, "(26, 0)": 0.41144803166389465, "(26, 16)": 0.41144803166389465, "(28, 0)": 0.41144803166389465, "(28, 16)": 0.43459007143974304, "(30, 0)": 0.41144803166389465, "(30, 16)": 0.41144803166389465}, "r_span": [604, 614], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00013643503189086914}}]}, {"id": "13377", "source_id": "15149", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how to peel potatoes quickly:\n\n1. Use the shock method described in passage 1 by placing washed, unpeeled potatoes in a pot of cold water after boiling them. This will help loosen the skin and make it easier to peel.\n2. Score the potato all the way around the center before boiling it as described in passage 2. This will help the skin come off more easily when you put the potato in ice water.\n3. Cut the potato skin lengthwise before boiling it as described in passage 3. This will also make the skin come off more easily when cooled and rubbed.\n\nIn summary, the best way to peel potatoes quickly is to use the shock method, score the potato before boiling, or cut the potato skin lengthwise before boiling.", "response_spans": [[0, 68], [70, 433], [434, 586], [588, 748]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7440212965011597, "(0, 16)": 0.7440212965011597, "(2, 0)": 0.7440212965011597, "(2, 16)": 0.7440212965011597, "(4, 0)": 0.7440212965011597, "(4, 16)": 0.7440212965011597, "(6, 0)": 0.458242803812027, "(6, 16)": 0.8050574064254761, "(8, 0)": 0.7440212965011597, "(8, 16)": 0.458242803812027, "(10, 0)": 0.458242803812027, "(10, 16)": 0.458242803812027, "(12, 0)": 0.458242803812027, "(12, 16)": 0.8050574064254761, "(14, 0)": 0.8136105537414551, "(14, 16)": 0.458242803812027, "(16, 0)": 0.8050574064254761, "(16, 16)": 0.7440212965011597, "(18, 0)": 0.458242803812027, "(18, 16)": 0.8050574064254761, "(20, 0)": 0.8050574064254761, "(20, 16)": 0.8136105537414551, "(22, 0)": 0.8136105537414551, "(22, 16)": 0.8050574064254761, "(24, 0)": 0.8136105537414551, "(24, 16)": 0.8050574064254761, "(26, 0)": 0.8136105537414551, "(26, 16)": 0.8136105537414551, "(28, 0)": 0.458242803812027, "(28, 16)": 0.8136105537414551, "(30, 0)": 0.8136105537414551, "(30, 16)": 0.8136105537414551}, "r_span": [469, 488], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004360675811767578}}, {"prompt_attention_score": {"(0, 0)": 0.8488063812255859, "(0, 16)": 0.8290151357650757, "(2, 0)": 0.8488063812255859, "(2, 16)": 0.8488063812255859, "(4, 0)": 0.8488063812255859, "(4, 16)": 0.8488063812255859, "(6, 0)": 0.8290151357650757, "(6, 16)": 0.8690770864486694, "(8, 0)": 0.8488063812255859, "(8, 16)": 0.8290151357650757, "(10, 0)": 0.8488063812255859, "(10, 16)": 0.8290151357650757, "(12, 0)": 0.8290151357650757, "(12, 16)": 0.8690770864486694, "(14, 0)": 0.8290151357650757, "(14, 16)": 0.8690770864486694, "(16, 0)": 0.8290151357650757, "(16, 16)": 0.8290151357650757, "(18, 0)": 0.8290151357650757, "(18, 16)": 0.8290151357650757, "(20, 0)": 0.8290151357650757, "(20, 16)": 0.8290151357650757, "(22, 0)": 0.8290151357650757, "(22, 16)": 0.8690770864486694, "(24, 0)": 0.8290151357650757, "(24, 16)": 0.8290151357650757, "(26, 0)": 0.8290151357650757, "(26, 16)": 0.8290151357650757, "(28, 0)": 0.8290151357650757, "(28, 16)": 0.8290151357650757, "(30, 0)": 0.8290151357650757, "(30, 16)": 0.8290151357650757}, "r_span": [490, 582], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00041687488555908203}}, {"prompt_attention_score": {"(0, 0)": 0.8768621683120728, "(0, 16)": 0.7979174256324768, "(2, 0)": 0.8768621683120728, "(2, 16)": 0.8768621683120728, "(4, 0)": 0.8768621683120728, "(4, 16)": 0.8768621683120728, "(6, 0)": 0.7979174256324768, "(6, 16)": 0.7979174256324768, "(8, 0)": 0.8768621683120728, "(8, 16)": 0.7979174256324768, "(10, 0)": 0.8768621683120728, "(10, 16)": 0.8768621683120728, "(12, 0)": 0.7979174256324768, "(12, 16)": 0.8768621683120728, "(14, 0)": 0.7979174256324768, "(14, 16)": 0.3603190779685974, "(16, 0)": 0.8768621683120728, "(16, 16)": 0.7979174256324768, "(18, 0)": 0.7979174256324768, "(18, 16)": 0.8768621683120728, "(20, 0)": 0.8768621683120728, "(20, 16)": 0.7979174256324768, "(22, 0)": 0.7979174256324768, "(22, 16)": 0.8768621683120728, "(24, 0)": 0.7979174256324768, "(24, 16)": 0.8768621683120728, "(26, 0)": 0.7979174256324768, "(26, 16)": 0.8768621683120728, "(28, 0)": 0.7979174256324768, "(28, 16)": 0.7979174256324768, "(30, 0)": 0.7979174256324768, "(30, 16)": 0.7979174256324768}, "r_span": [583, 622], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004989504814147949}}, {"prompt_attention_score": {"(0, 0)": 0.7594397068023682, "(0, 16)": 0.7822842597961426, "(2, 0)": 0.7594397068023682, "(2, 16)": 0.3514936566352844, "(4, 0)": 0.3514936566352844, "(4, 16)": 0.7594397068023682, "(6, 0)": 0.7822842597961426, "(6, 16)": 0.7822842597961426, "(8, 0)": 0.7594397068023682, "(8, 16)": 0.7822842597961426, "(10, 0)": 0.7822842597961426, "(10, 16)": 0.3514936566352844, "(12, 0)": 0.7822842597961426, "(12, 16)": 0.7594397068023682, "(14, 0)": 0.7822842597961426, "(14, 16)": 0.3514936566352844, "(16, 0)": 0.8475399017333984, "(16, 16)": 0.7822842597961426, "(18, 0)": 0.7822842597961426, "(18, 16)": 0.7822842597961426, "(20, 0)": 0.8475399017333984, "(20, 16)": 0.7822842597961426, "(22, 0)": 0.7822842597961426, "(22, 16)": 0.8475399017333984, "(24, 0)": 0.7822842597961426, "(24, 16)": 0.7822842597961426, "(26, 0)": 0.7822842597961426, "(26, 16)": 0.7822842597961426, "(28, 0)": 0.7822842597961426, "(28, 16)": 0.7822842597961426, "(30, 0)": 0.7822842597961426, "(30, 16)": 0.7822842597961426}, "r_span": [624, 663], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001454174518585205}}]}, {"id": "13431", "source_id": "15158", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how to fix a lift valve in a toilet:\n\n1. Shut off the water supply valve to the toilet before starting the repair (Passage 1).\n2. Remove the old flapper valve by slipping it off the mounting arms, and remove any remaining broken lift chain from the lift arm (Passage 1).\n3. Open the water valve to fill the tank and flush the toilet to check for correct operation. If necessary, readjust the lift chain by moving the metal clip up or down a couple of links (Passage 2).\n4. Connect the chain to the third hole on the lift arm, which is the hole closest to the edge of the lift arm (Passage 3). Secure it using pliers to ensure it is tightly fastened.\n5. Turn the water valve back on and test the toilet's flush function. If the toilet flushes slowly, adjust the chain to make it a little tighter on the lift arm (Passage 3).\n\nUnable to answer based on the given passages. The passages do not provide instructions on how to fix a specific issue with the lift valve, such as a stuck or leaking valve.", "response_spans": [[0, 75], [77, 508], [509, 862], [864, 1036]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7784522175788879, "(0, 16)": 0.7784522175788879, "(2, 0)": 0.7784522175788879, "(2, 16)": 0.7784522175788879, "(4, 0)": 0.7784522175788879, "(4, 16)": 0.7784522175788879, "(6, 0)": 0.7784522175788879, "(6, 16)": 0.794002890586853, "(8, 0)": 0.7784522175788879, "(8, 16)": 0.5253422260284424, "(10, 0)": 0.5253422260284424, "(10, 16)": 0.5253422260284424, "(12, 0)": 0.794002890586853, "(12, 16)": 0.794002890586853, "(14, 0)": 0.7793019413948059, "(14, 16)": 0.794002890586853, "(16, 0)": 0.794002890586853, "(16, 16)": 0.794002890586853, "(18, 0)": 0.5253422260284424, "(18, 16)": 0.794002890586853, "(20, 0)": 0.794002890586853, "(20, 16)": 0.7793019413948059, "(22, 0)": 0.7793019413948059, "(22, 16)": 0.794002890586853, "(24, 0)": 0.7793019413948059, "(24, 16)": 0.794002890586853, "(26, 0)": 0.7793019413948059, "(26, 16)": 0.7793019413948059, "(28, 0)": 0.5253422260284424, "(28, 16)": 0.7793019413948059, "(30, 0)": 0.7793019413948059, "(30, 16)": 0.7793019413948059}, "r_span": [404, 428], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008385777473449707}}, {"prompt_attention_score": {"(0, 0)": 0.8363051414489746, "(0, 16)": 0.8363051414489746, "(2, 0)": 0.8363051414489746, "(2, 16)": 0.8363051414489746, "(4, 0)": 0.8363051414489746, "(4, 16)": 0.8363051414489746, "(6, 0)": 0.8363051414489746, "(6, 16)": 0.877845048904419, "(8, 0)": 0.8363051414489746, "(8, 16)": 0.8363051414489746, "(10, 0)": 0.8363051414489746, "(10, 16)": 0.8363051414489746, "(12, 0)": 0.8716104030609131, "(12, 16)": 0.877845048904419, "(14, 0)": 0.8716104030609131, "(14, 16)": 0.877845048904419, "(16, 0)": 0.877845048904419, "(16, 16)": 0.8363051414489746, "(18, 0)": 0.8716104030609131, "(18, 16)": 0.8716104030609131, "(20, 0)": 0.877845048904419, "(20, 16)": 0.8716104030609131, "(22, 0)": 0.8716104030609131, "(22, 16)": 0.877845048904419, "(24, 0)": 0.8716104030609131, "(24, 16)": 0.877845048904419, "(26, 0)": 0.8716104030609131, "(26, 16)": 0.8716104030609131, "(28, 0)": 0.8716104030609131, "(28, 16)": 0.8716104030609131, "(30, 0)": 0.8716104030609131, "(30, 16)": 0.8716104030609131}, "r_span": [430, 542], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000655829906463623}}, {"prompt_attention_score": {"(0, 0)": 0.9423635601997375, "(0, 16)": 0.9423635601997375, "(2, 0)": 0.9423635601997375, "(2, 16)": 0.9423635601997375, "(4, 0)": 0.9423635601997375, "(4, 16)": 0.9423635601997375, "(6, 0)": 0.9423635601997375, "(6, 16)": 0.9423635601997375, "(8, 0)": 0.9423635601997375, "(8, 16)": 0.8709088563919067, "(10, 0)": 0.9423635601997375, "(10, 16)": 0.9423635601997375, "(12, 0)": 0.8709088563919067, "(12, 16)": 0.9423635601997375, "(14, 0)": 0.8709088563919067, "(14, 16)": 0.9423635601997375, "(16, 0)": 0.9423635601997375, "(16, 16)": 0.8709088563919067, "(18, 0)": 0.8709088563919067, "(18, 16)": 0.9423635601997375, "(20, 0)": 0.9423635601997375, "(20, 16)": 0.8709088563919067, "(22, 0)": 0.8709088563919067, "(22, 16)": 0.9423635601997375, "(24, 0)": 0.8709088563919067, "(24, 16)": 0.9423635601997375, "(26, 0)": 0.8709088563919067, "(26, 16)": 0.8709088563919067, "(28, 0)": 0.8709088563919067, "(28, 16)": 0.8709088563919067, "(30, 0)": 0.8709088563919067, "(30, 16)": 0.8709088563919067}, "r_span": [543, 640], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0019598007202148438}}, {"prompt_attention_score": {"(0, 0)": 0.6856578588485718, "(0, 16)": 0.6856578588485718, "(2, 0)": 0.6856578588485718, "(2, 16)": 0.6856578588485718, "(4, 0)": 0.6856578588485718, "(4, 16)": 0.6856578588485718, "(6, 0)": 0.6856578588485718, "(6, 16)": 0.6890636682510376, "(8, 0)": 0.6856578588485718, "(8, 16)": 0.6856578588485718, "(10, 0)": 0.6655986309051514, "(10, 16)": 0.6655986309051514, "(12, 0)": 0.6655986309051514, "(12, 16)": 0.6655986309051514, "(14, 0)": 0.6741896271705627, "(14, 16)": 0.6655986309051514, "(16, 0)": 0.6890636682510376, "(16, 16)": 0.6741896271705627, "(18, 0)": 0.6741896271705627, "(18, 16)": 0.6890636682510376, "(20, 0)": 0.6890636682510376, "(20, 16)": 0.6741896271705627, "(22, 0)": 0.6741896271705627, "(22, 16)": 0.6890636682510376, "(24, 0)": 0.6741896271705627, "(24, 16)": 0.6890636682510376, "(26, 0)": 0.6741896271705627, "(26, 16)": 0.6741896271705627, "(28, 0)": 0.6741896271705627, "(28, 16)": 0.6741896271705627, "(30, 0)": 0.6741896271705627, "(30, 16)": 0.6741896271705627}, "r_span": [642, 683], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0012496709823608398}}]}, {"id": "13443", "source_id": "15160", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to remove oil stains from a concrete driveway:\n\n1. For fresh oil stains, try using a poultice method by applying a commercial-grade cleaner to the affected area and scrubbing with a brush or broom.\n2. For larger or older oil stains, use a pressure washer with detergent to clean the area. Apply the cleaner at a consistent distance from the surface of the concrete and move the nozzle in an even pattern to prevent streaking.\n3. Before cleaning, remove any dirt or debris from the area around the oil stain using a hose or bucket of water. Avoid using a high-pressure hose as it can push the oil deeper into the pavement.\n4. The choice of cleaner depends on the type of stain, with oven cleaner, goop hand cleaner, and carburetor cleaner being mentioned as options in passage 1.\n5. If the stain is still difficult to remove after using these methods, consider using a professional cleaning service. (Unable to answer based on given passages)", "response_spans": [[0, 90], [92, 469], [470, 822], [823, 985]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8663234710693359, "(0, 16)": 0.8663234710693359, "(2, 0)": 0.8663234710693359, "(2, 16)": 0.8663234710693359, "(4, 0)": 0.8663234710693359, "(4, 16)": 0.8663234710693359, "(6, 0)": 0.8663234710693359, "(6, 16)": 0.8734689950942993, "(8, 0)": 0.8663234710693359, "(8, 16)": 0.4321299195289612, "(10, 0)": 0.4321299195289612, "(10, 16)": 0.4321299195289612, "(12, 0)": 0.4321299195289612, "(12, 16)": 0.8734689950942993, "(14, 0)": 0.8734689950942993, "(14, 16)": 0.4321299195289612, "(16, 0)": 0.8734689950942993, "(16, 16)": 0.8734689950942993, "(18, 0)": 0.4321299195289612, "(18, 16)": 0.8734689950942993, "(20, 0)": 0.8734689950942993, "(20, 16)": 0.8734689950942993, "(22, 0)": 0.8734689950942993, "(22, 16)": 0.8636491894721985, "(24, 0)": 0.8734689950942993, "(24, 16)": 0.8734689950942993, "(26, 0)": 0.8734689950942993, "(26, 16)": 0.8734689950942993, "(28, 0)": 0.8734689950942993, "(28, 16)": 0.8734689950942993, "(30, 0)": 0.8734689950942993, "(30, 16)": 0.8734689950942993}, "r_span": [511, 533], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002735257148742676}}, {"prompt_attention_score": {"(0, 0)": 0.8395385146141052, "(0, 16)": 0.8395385146141052, "(2, 0)": 0.8395385146141052, "(2, 16)": 0.8395385146141052, "(4, 0)": 0.8395385146141052, "(4, 16)": 0.8395385146141052, "(6, 0)": 0.8395385146141052, "(6, 16)": 0.7649824619293213, "(8, 0)": 0.8395385146141052, "(8, 16)": 0.8395385146141052, "(10, 0)": 0.8395385146141052, "(10, 16)": 0.8395385146141052, "(12, 0)": 0.8395385146141052, "(12, 16)": 0.8395385146141052, "(14, 0)": 0.7703430652618408, "(14, 16)": 0.8395385146141052, "(16, 0)": 0.8395385146141052, "(16, 16)": 0.7703430652618408, "(18, 0)": 0.7703430652618408, "(18, 16)": 0.8395385146141052, "(20, 0)": 0.8395385146141052, "(20, 16)": 0.7703430652618408, "(22, 0)": 0.7703430652618408, "(22, 16)": 0.8395385146141052, "(24, 0)": 0.7703430652618408, "(24, 16)": 0.8395385146141052, "(26, 0)": 0.7703430652618408, "(26, 16)": 0.7703430652618408, "(28, 0)": 0.7703430652618408, "(28, 16)": 0.7703430652618408, "(30, 0)": 0.7703430652618408, "(30, 16)": 0.7703430652618408}, "r_span": [535, 627], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005729198455810547}}, {"prompt_attention_score": {"(0, 0)": 0.7939765453338623, "(0, 16)": 0.7939765453338623, "(2, 0)": 0.7939765453338623, "(2, 16)": 0.7939765453338623, "(4, 0)": 0.7939765453338623, "(4, 16)": 0.7939765453338623, "(6, 0)": 0.7939765453338623, "(6, 16)": 0.8727891445159912, "(8, 0)": 0.7939765453338623, "(8, 16)": 0.7939765453338623, "(10, 0)": 0.7939765453338623, "(10, 16)": 0.7939765453338623, "(12, 0)": 0.787442684173584, "(12, 16)": 0.8727891445159912, "(14, 0)": 0.787442684173584, "(14, 16)": 0.7939765453338623, "(16, 0)": 0.8727891445159912, "(16, 16)": 0.787442684173584, "(18, 0)": 0.787442684173584, "(18, 16)": 0.8727891445159912, "(20, 0)": 0.8727891445159912, "(20, 16)": 0.787442684173584, "(22, 0)": 0.787442684173584, "(22, 16)": 0.8727891445159912, "(24, 0)": 0.787442684173584, "(24, 16)": 0.787442684173584, "(26, 0)": 0.787442684173584, "(26, 16)": 0.787442684173584, "(28, 0)": 0.787442684173584, "(28, 16)": 0.787442684173584, "(30, 0)": 0.787442684173584, "(30, 16)": 0.787442684173584}, "r_span": [628, 721], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002938508987426758}}, {"prompt_attention_score": {"(0, 0)": 0.714545726776123, "(0, 16)": 0.714545726776123, "(2, 0)": 0.714545726776123, "(2, 16)": 0.714545726776123, "(4, 0)": 0.714545726776123, "(4, 16)": 0.714545726776123, "(6, 0)": 0.714545726776123, "(6, 16)": 0.6691567897796631, "(8, 0)": 0.714545726776123, "(8, 16)": 0.714545726776123, "(10, 0)": 0.714545726776123, "(10, 16)": 0.5038273334503174, "(12, 0)": 0.6372878551483154, "(12, 16)": 0.5038273334503174, "(14, 0)": 0.6372878551483154, "(14, 16)": 0.5038273334503174, "(16, 0)": 0.5038273334503174, "(16, 16)": 0.6372878551483154, "(18, 0)": 0.6372878551483154, "(18, 16)": 0.714545726776123, "(20, 0)": 0.714545726776123, "(20, 16)": 0.6372878551483154, "(22, 0)": 0.6372878551483154, "(22, 16)": 0.714545726776123, "(24, 0)": 0.6372878551483154, "(24, 16)": 0.5038273334503174, "(26, 0)": 0.6372878551483154, "(26, 16)": 0.6691567897796631, "(28, 0)": 0.6372878551483154, "(28, 16)": 0.6372878551483154, "(30, 0)": 0.6372878551483154, "(30, 16)": 0.6372878551483154}, "r_span": [722, 757], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003508925437927246}}]}, {"id": "13467", "source_id": "15164", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the average weather in Sausalito can be summarized as follows:\n\n* Temperature: The average temperature in Sausalito ranges from 50¬∞F (December) to 58¬∞F (September).\n* Precipitation: Sausalito receives an average of 34 inches of rain per year, with the most precipitation occurring in January (0 inches).\n* Air Quality Index: The air quality index in Sausalito is 13% better than the national average, but the pollution index is 61% worse than the national average.\n* Sunshine: Sausalito experiences 256 sunny days per year, with an average of 56 days with measurable precipitation.\n* Comfort Index: According to Sperling's comfort index, Sausalito has a score of 84 out of 100, indicating a comfortable year-round climate.\n\nUnable to answer based on given passages regarding the average weather in Sausalito during a specific month or time period.", "response_spans": [[0, 94], [96, 496], [497, 754], [756, 879]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8332324028015137, "(0, 16)": 0.6333156824111938, "(2, 0)": 0.6333156824111938, "(2, 16)": 0.6333156824111938, "(4, 0)": 0.6333156824111938, "(4, 16)": 0.6333156824111938, "(6, 0)": 0.47820523381233215, "(6, 16)": 0.8595622777938843, "(8, 0)": 0.8332324028015137, "(8, 16)": 0.47820523381233215, "(10, 0)": 0.47820523381233215, "(10, 16)": 0.47820523381233215, "(12, 0)": 0.47820523381233215, "(12, 16)": 0.8595622777938843, "(14, 0)": 0.8332324028015137, "(14, 16)": 0.47820523381233215, "(16, 0)": 0.47820523381233215, "(16, 16)": 0.8332324028015137, "(18, 0)": 0.47820523381233215, "(18, 16)": 0.8595622777938843, "(20, 0)": 0.8595622777938843, "(20, 16)": 0.8332324028015137, "(22, 0)": 0.8332324028015137, "(22, 16)": 0.8595622777938843, "(24, 0)": 0.8332324028015137, "(24, 16)": 0.8595622777938843, "(26, 0)": 0.8332324028015137, "(26, 16)": 0.8332324028015137, "(28, 0)": 0.8332324028015137, "(28, 16)": 0.8332324028015137, "(30, 0)": 0.8332324028015137, "(30, 16)": 0.8332324028015137}, "r_span": [524, 547], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004407167434692383}}, {"prompt_attention_score": {"(0, 0)": 0.8303365111351013, "(0, 16)": 0.8303365111351013, "(2, 0)": 0.49253788590431213, "(2, 16)": 0.49253788590431213, "(4, 0)": 0.49253788590431213, "(4, 16)": 0.49253788590431213, "(6, 0)": 0.8303365111351013, "(6, 16)": 0.9040061235427856, "(8, 0)": 0.8303365111351013, "(8, 16)": 0.8303365111351013, "(10, 0)": 0.8303365111351013, "(10, 16)": 0.8303365111351013, "(12, 0)": 0.8303365111351013, "(12, 16)": 0.9040061235427856, "(14, 0)": 0.8303365111351013, "(14, 16)": 0.8303365111351013, "(16, 0)": 0.8303365111351013, "(16, 16)": 0.8303365111351013, "(18, 0)": 0.8303365111351013, "(18, 16)": 0.9040061235427856, "(20, 0)": 0.9040061235427856, "(20, 16)": 0.8303365111351013, "(22, 0)": 0.8303365111351013, "(22, 16)": 0.8303365111351013, "(24, 0)": 0.8303365111351013, "(24, 16)": 0.8303365111351013, "(26, 0)": 0.8303365111351013, "(26, 16)": 0.8303365111351013, "(28, 0)": 0.8303365111351013, "(28, 16)": 0.8303365111351013, "(30, 0)": 0.8303365111351013, "(30, 16)": 0.8303365111351013}, "r_span": [549, 663], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011012554168701172}}, {"prompt_attention_score": {"(0, 0)": 0.8517855405807495, "(0, 16)": 0.8517855405807495, "(2, 0)": 0.4899199306964874, "(2, 16)": 0.3464120924472809, "(4, 0)": 0.4899199306964874, "(4, 16)": 0.4899199306964874, "(6, 0)": 0.4899199306964874, "(6, 16)": 0.8517855405807495, "(8, 0)": 0.8517855405807495, "(8, 16)": 0.8517855405807495, "(10, 0)": 0.4899199306964874, "(10, 16)": 0.3464120924472809, "(12, 0)": 0.8517855405807495, "(12, 16)": 0.8517855405807495, "(14, 0)": 0.8517855405807495, "(14, 16)": 0.8517855405807495, "(16, 0)": 0.8517855405807495, "(16, 16)": 0.8517855405807495, "(18, 0)": 0.8517855405807495, "(18, 16)": 0.8517855405807495, "(20, 0)": 0.8517855405807495, "(20, 16)": 0.8517855405807495, "(22, 0)": 0.8517855405807495, "(22, 16)": 0.8517855405807495, "(24, 0)": 0.8517855405807495, "(24, 16)": 0.8517855405807495, "(26, 0)": 0.8517855405807495, "(26, 16)": 0.8517855405807495, "(28, 0)": 0.8517855405807495, "(28, 16)": 0.8517855405807495, "(30, 0)": 0.8517855405807495, "(30, 16)": 0.8517855405807495}, "r_span": [664, 740], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007090568542480469}}, {"prompt_attention_score": {"(0, 0)": 0.7783989906311035, "(0, 16)": 0.7783989906311035, "(2, 0)": 0.6498481035232544, "(2, 16)": 0.6498481035232544, "(4, 0)": 0.6498481035232544, "(4, 16)": 0.6498481035232544, "(6, 0)": 0.6498481035232544, "(6, 16)": 0.784279465675354, "(8, 0)": 0.6498481035232544, "(8, 16)": 0.7783989906311035, "(10, 0)": 0.6636285781860352, "(10, 16)": 0.6636285781860352, "(12, 0)": 0.7783989906311035, "(12, 16)": 0.6636285781860352, "(14, 0)": 0.7783989906311035, "(14, 16)": 0.6636285781860352, "(16, 0)": 0.6636285781860352, "(16, 16)": 0.6498481035232544, "(18, 0)": 0.7783989906311035, "(18, 16)": 0.8675612807273865, "(20, 0)": 0.8675612807273865, "(20, 16)": 0.7783989906311035, "(22, 0)": 0.7783989906311035, "(22, 16)": 0.8675612807273865, "(24, 0)": 0.7783989906311035, "(24, 16)": 0.6636285781860352, "(26, 0)": 0.7783989906311035, "(26, 16)": 0.7783989906311035, "(28, 0)": 0.7783989906311035, "(28, 16)": 0.7783989906311035, "(30, 0)": 0.7783989906311035, "(30, 16)": 0.7783989906311035}, "r_span": [742, 768], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 8.90493392944336e-05}}]}, {"id": "13491", "source_id": "15168", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how crab traps work:\n\n1. Pot Design: Crab traps are designed with a system of nets inside a large metal cage made of wire or flat metal mesh, which is reinforced with steel bars. The traps are designed to allow crabs in but not let them out. (Passage 1)\n2. Getting the Catch: A crab pot is a large square about 2 feet high and 8 feet wide. The trap has two ends with lead-ins that angle into the trap from the sides and bottom to a narrow slit about 2 feet into the pot. This slit is the only entrance into the trap, and the crabs must crawl up the leads to get to their free meal. (Passage 1)\n3. Tweet: The author recommends using topless crab traps, which seem to work best. (Passage 2)\n4. The Trap Is Set: King crab pots can range in size from about 6 by 6 feet to about 8 by 8 feet, with heights between about 2 and 3 feet. Over time, mechanisms such as biodegradable mesh or dissolvable cord can disable crab pots, making them unable to trap any more crabs that wander inside and preventing them from ghost fishing. (Passage 3)\n\nTherefore, based on the given passages, crab traps are designed with a system of nets inside a metal cage, have a narrow slit as the only entrance, and can be made topless for better performance.", "response_spans": [[0, 60], [62, 293], [294, 728], [729, 1072], [1074, 1269]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6919689178466797, "(0, 16)": 0.6919689178466797, "(2, 0)": 0.6919689178466797, "(2, 16)": 0.6919689178466797, "(4, 0)": 0.6919689178466797, "(4, 16)": 0.6919689178466797, "(6, 0)": 0.501842737197876, "(6, 16)": 0.8799455165863037, "(8, 0)": 0.6919689178466797, "(8, 16)": 0.501842737197876, "(10, 0)": 0.501842737197876, "(10, 16)": 0.501842737197876, "(12, 0)": 0.501842737197876, "(12, 16)": 0.8799455165863037, "(14, 0)": 0.729823112487793, "(14, 16)": 0.501842737197876, "(16, 0)": 0.8799455165863037, "(16, 16)": 0.6919689178466797, "(18, 0)": 0.501842737197876, "(18, 16)": 0.8799455165863037, "(20, 0)": 0.8799455165863037, "(20, 16)": 0.5752644538879395, "(22, 0)": 0.5752644538879395, "(22, 16)": 0.8799455165863037, "(24, 0)": 0.5752644538879395, "(24, 16)": 0.8799455165863037, "(26, 0)": 0.5752644538879395, "(26, 16)": 0.5752644538879395, "(28, 0)": 0.501842737197876, "(28, 16)": 0.5752644538879395, "(30, 0)": 0.5752644538879395, "(30, 16)": 0.5752644538879395}, "r_span": [556, 573], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 7.921457290649414e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7416480779647827, "(0, 16)": 0.7416480779647827, "(2, 0)": 0.7416480779647827, "(2, 16)": 0.7416480779647827, "(4, 0)": 0.7416480779647827, "(4, 16)": 0.7416480779647827, "(6, 0)": 0.7416480779647827, "(6, 16)": 0.8621528148651123, "(8, 0)": 0.7416480779647827, "(8, 16)": 0.7416480779647827, "(10, 0)": 0.7416480779647827, "(10, 16)": 0.7416480779647827, "(12, 0)": 0.7416480779647827, "(12, 16)": 0.8621528148651123, "(14, 0)": 0.46221646666526794, "(14, 16)": 0.8621528148651123, "(16, 0)": 0.8621528148651123, "(16, 16)": 0.7416480779647827, "(18, 0)": 0.4223766326904297, "(18, 16)": 0.8621528148651123, "(20, 0)": 0.8621528148651123, "(20, 16)": 0.46221646666526794, "(22, 0)": 0.46221646666526794, "(22, 16)": 0.8621528148651123, "(24, 0)": 0.46221646666526794, "(24, 16)": 0.8621528148651123, "(26, 0)": 0.46221646666526794, "(26, 16)": 0.8621528148651123, "(28, 0)": 0.46221646666526794, "(28, 16)": 0.46221646666526794, "(30, 0)": 0.46221646666526794, "(30, 16)": 0.46221646666526794}, "r_span": [575, 638], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010777711868286133}}, {"prompt_attention_score": {"(0, 0)": 0.8043082356452942, "(0, 16)": 0.8043082356452942, "(2, 0)": 0.8043082356452942, "(2, 16)": 0.8043082356452942, "(4, 0)": 0.8043082356452942, "(4, 16)": 0.8043082356452942, "(6, 0)": 0.8043082356452942, "(6, 16)": 0.8437004685401917, "(8, 0)": 0.8043082356452942, "(8, 16)": 0.8043082356452942, "(10, 0)": 0.8043082356452942, "(10, 16)": 0.8043082356452942, "(12, 0)": 0.7364398241043091, "(12, 16)": 0.8437004685401917, "(14, 0)": 0.4728679060935974, "(14, 16)": 0.8437004685401917, "(16, 0)": 0.7364398241043091, "(16, 16)": 0.7364398241043091, "(18, 0)": 0.4053812623023987, "(18, 16)": 0.8437004685401917, "(20, 0)": 0.8437004685401917, "(20, 16)": 0.4728679060935974, "(22, 0)": 0.4728679060935974, "(22, 16)": 0.8437004685401917, "(24, 0)": 0.4728679060935974, "(24, 16)": 0.8437004685401917, "(26, 0)": 0.4728679060935974, "(26, 16)": 0.4728679060935974, "(28, 0)": 0.4728679060935974, "(28, 16)": 0.4728679060935974, "(30, 0)": 0.4728679060935974, "(30, 16)": 0.4728679060935974}, "r_span": [639, 764], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00100785493850708}}, {"prompt_attention_score": {"(0, 0)": 0.8625112771987915, "(0, 16)": 0.8625112771987915, "(2, 0)": 0.8625112771987915, "(2, 16)": 0.8625112771987915, "(4, 0)": 0.8625112771987915, "(4, 16)": 0.8625112771987915, "(6, 0)": 0.8625112771987915, "(6, 16)": 0.8625112771987915, "(8, 0)": 0.8625112771987915, "(8, 16)": 0.8625112771987915, "(10, 0)": 0.8625112771987915, "(10, 16)": 0.8625112771987915, "(12, 0)": 0.8625112771987915, "(12, 16)": 0.8625112771987915, "(14, 0)": 0.5116395354270935, "(14, 16)": 0.8625112771987915, "(16, 0)": 0.8625112771987915, "(16, 16)": 0.8625112771987915, "(18, 0)": 0.5116395354270935, "(18, 16)": 0.8625112771987915, "(20, 0)": 0.8625112771987915, "(20, 16)": 0.5116395354270935, "(22, 0)": 0.5116395354270935, "(22, 16)": 0.8625112771987915, "(24, 0)": 0.5116395354270935, "(24, 16)": 0.8625112771987915, "(26, 0)": 0.5116395354270935, "(26, 16)": 0.5116395354270935, "(28, 0)": 0.5116395354270935, "(28, 16)": 0.5116395354270935, "(30, 0)": 0.5116395354270935, "(30, 16)": 0.5116395354270935}, "r_span": [765, 865], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006762146949768066}}, {"prompt_attention_score": {"(0, 0)": 0.6047284007072449, "(0, 16)": 0.6047284007072449, "(2, 0)": 0.6579093933105469, "(2, 16)": 0.6047284007072449, "(4, 0)": 0.39335063099861145, "(4, 16)": 0.6047284007072449, "(6, 0)": 0.6047284007072449, "(6, 16)": 0.6834841370582581, "(8, 0)": 0.6047284007072449, "(8, 16)": 0.4969645142555237, "(10, 0)": 0.6047284007072449, "(10, 16)": 0.39335063099861145, "(12, 0)": 0.6579093933105469, "(12, 16)": 0.6834841370582581, "(14, 0)": 0.4969645142555237, "(14, 16)": 0.39335063099861145, "(16, 0)": 0.6781327128410339, "(16, 16)": 0.6579093933105469, "(18, 0)": 0.4969645142555237, "(18, 16)": 0.6834841370582581, "(20, 0)": 0.6834841370582581, "(20, 16)": 0.4969645142555237, "(22, 0)": 0.4969645142555237, "(22, 16)": 0.6834841370582581, "(24, 0)": 0.4969645142555237, "(24, 16)": 0.6834841370582581, "(26, 0)": 0.4969645142555237, "(26, 16)": 0.4969645142555237, "(28, 0)": 0.4969645142555237, "(28, 16)": 0.4969645142555237, "(30, 0)": 0.4969645142555237, "(30, 16)": 0.4969645142555237}, "r_span": [867, 916], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007675290107727051}}]}, {"id": "13533", "source_id": "15175", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main differences between the Fair Employment and Housing Act (FEHA) and the Americans with Disabilities Act (ADA) are:\n\n1. Scope of application: The ADA applies to all employers in the private sector with four to fifteen employees, while the FEHA affects more employees and does not distinguish between private and public employers like the ADA does.\n2. Definition of disability: The FEHA requires that a disability must limit a major life activity, while the ADA requires that a physical or mental impairment substantially limits a major life activity.\n3. Number of employees: The ADA applies to employers with four to fifteen employees, while the FEHA has no such requirement.\n\nTherefore, the main difference between FEHA and ADA is the scope of application and the definition of disability.", "response_spans": [[0, 154], [156, 589], [590, 714], [716, 829]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8473463654518127, "(0, 16)": 0.8473463654518127, "(2, 0)": 0.8473463654518127, "(2, 16)": 0.8473463654518127, "(4, 0)": 0.8473463654518127, "(4, 16)": 0.8986687660217285, "(6, 0)": 0.8473463654518127, "(6, 16)": 0.8986687660217285, "(8, 0)": 0.8986687660217285, "(8, 16)": 0.8986687660217285, "(10, 0)": 0.4586150050163269, "(10, 16)": 0.4586150050163269, "(12, 0)": 0.8986687660217285, "(12, 16)": 0.8986687660217285, "(14, 0)": 0.8986687660217285, "(14, 16)": 0.8986687660217285, "(16, 0)": 0.8986687660217285, "(16, 16)": 0.8986687660217285, "(18, 0)": 0.4586150050163269, "(18, 16)": 0.8986687660217285, "(20, 0)": 0.8986687660217285, "(20, 16)": 0.8986687660217285, "(22, 0)": 0.8986687660217285, "(22, 16)": 0.8986687660217285, "(24, 0)": 0.8986687660217285, "(24, 16)": 0.8986687660217285, "(26, 0)": 0.8986687660217285, "(26, 16)": 0.8986687660217285, "(28, 0)": 0.8986687660217285, "(28, 16)": 0.8986687660217285, "(30, 0)": 0.8986687660217285, "(30, 16)": 0.8986687660217285}, "r_span": [346, 384], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007748007774353027}}, {"prompt_attention_score": {"(0, 0)": 0.8599259853363037, "(0, 16)": 0.8693208694458008, "(2, 0)": 0.8599259853363037, "(2, 16)": 0.8599259853363037, "(4, 0)": 0.8599259853363037, "(4, 16)": 0.8599259853363037, "(6, 0)": 0.8599259853363037, "(6, 16)": 0.8693208694458008, "(8, 0)": 0.8693208694458008, "(8, 16)": 0.8693208694458008, "(10, 0)": 0.8599259853363037, "(10, 16)": 0.8599259853363037, "(12, 0)": 0.8693208694458008, "(12, 16)": 0.8599259853363037, "(14, 0)": 0.8693208694458008, "(14, 16)": 0.8693208694458008, "(16, 0)": 0.8693208694458008, "(16, 16)": 0.8693208694458008, "(18, 0)": 0.8693208694458008, "(18, 16)": 0.8693208694458008, "(20, 0)": 0.8693208694458008, "(20, 16)": 0.8693208694458008, "(22, 0)": 0.8693208694458008, "(22, 16)": 0.8599259853363037, "(24, 0)": 0.8693208694458008, "(24, 16)": 0.8693208694458008, "(26, 0)": 0.8693208694458008, "(26, 16)": 0.8693208694458008, "(28, 0)": 0.8693208694458008, "(28, 16)": 0.8693208694458008, "(30, 0)": 0.8693208694458008, "(30, 16)": 0.8693208694458008}, "r_span": [386, 481], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0022435784339904785}}, {"prompt_attention_score": {"(0, 0)": 0.8181991577148438, "(0, 16)": 0.8181991577148438, "(2, 0)": 0.744385838508606, "(2, 16)": 0.8181991577148438, "(4, 0)": 0.744385838508606, "(4, 16)": 0.8181991577148438, "(6, 0)": 0.8181991577148438, "(6, 16)": 0.8181991577148438, "(8, 0)": 0.8181991577148438, "(8, 16)": 0.8181991577148438, "(10, 0)": 0.8181991577148438, "(10, 16)": 0.8181991577148438, "(12, 0)": 0.8181991577148438, "(12, 16)": 0.8181991577148438, "(14, 0)": 0.8181991577148438, "(14, 16)": 0.8181991577148438, "(16, 0)": 0.8181991577148438, "(16, 16)": 0.8181991577148438, "(18, 0)": 0.8181991577148438, "(18, 16)": 0.8181991577148438, "(20, 0)": 0.8181991577148438, "(20, 16)": 0.8181991577148438, "(22, 0)": 0.8181991577148438, "(22, 16)": 0.744385838508606, "(24, 0)": 0.8181991577148438, "(24, 16)": 0.8181991577148438, "(26, 0)": 0.8181991577148438, "(26, 16)": 0.8181991577148438, "(28, 0)": 0.8181991577148438, "(28, 16)": 0.8181991577148438, "(30, 0)": 0.8181991577148438, "(30, 16)": 0.8181991577148438}, "r_span": [482, 511], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005492568016052246}}, {"prompt_attention_score": {"(0, 0)": 0.8104471564292908, "(0, 16)": 0.8104471564292908, "(2, 0)": 0.8482791185379028, "(2, 16)": 0.37564221024513245, "(4, 0)": 0.37564221024513245, "(4, 16)": 0.37564221024513245, "(6, 0)": 0.8104471564292908, "(6, 16)": 0.8104471564292908, "(8, 0)": 0.8104471564292908, "(8, 16)": 0.8104471564292908, "(10, 0)": 0.37564221024513245, "(10, 16)": 0.37564221024513245, "(12, 0)": 0.37564221024513245, "(12, 16)": 0.8104471564292908, "(14, 0)": 0.8104471564292908, "(14, 16)": 0.37564221024513245, "(16, 0)": 0.8104471564292908, "(16, 16)": 0.8104471564292908, "(18, 0)": 0.8104471564292908, "(18, 16)": 0.8104471564292908, "(20, 0)": 0.8104471564292908, "(20, 16)": 0.8104471564292908, "(22, 0)": 0.8104471564292908, "(22, 16)": 0.8104471564292908, "(24, 0)": 0.8104471564292908, "(24, 16)": 0.8104471564292908, "(26, 0)": 0.8104471564292908, "(26, 16)": 0.8104471564292908, "(28, 0)": 0.8104471564292908, "(28, 16)": 0.8104471564292908, "(30, 0)": 0.8104471564292908, "(30, 16)": 0.8104471564292908}, "r_span": [513, 538], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003845095634460449}}]}, {"id": "13563", "source_id": "15180", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to grill pork chops according to Allrecipes.com:\n\n1. Preheat an outdoor grill for medium heat, and lightly oil the grate. (Passage 1)\n2. In a bowl, mix together seasoned salt, black pepper, garlic powder, onion powder, paprika, Worcestershire sauce, and smoke flavoring until thoroughly combined. Rinse pork chops, and sprinkle the wet chops on both sides with the spice mixture. (Passage 1)\n3. For Oven-Fried Pork Chops, use stuffing mix for the breading. The pork chops come out tender and juicy. This recipe takes 30 minutes to prepare and 10 minutes to prep. (Passage 2)\n4. To grill pork chops over indirect heat, rinse the chops and sprinkle the wet chops on both sides with the spice mixture. Massage the spice rub into the meat for 10 minutes before grilling. Grill the chops until no longer pink inside, about 12 minutes per side. (Passage 3)\n\nTherefore, to grill pork chops according to Allrecipes.com, you should preheat the grill, season the pork chops with a spice mixture, and grill them over indirect heat until they are cooked through.", "response_spans": [[0, 92], [94, 435], [436, 894], [896, 1094]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7457866668701172, "(0, 16)": 0.7457866668701172, "(2, 0)": 0.7457866668701172, "(2, 16)": 0.7457866668701172, "(4, 0)": 0.7457866668701172, "(4, 16)": 0.7457866668701172, "(6, 0)": 0.7457866668701172, "(6, 16)": 0.8119341731071472, "(8, 0)": 0.7457866668701172, "(8, 16)": 0.7457866668701172, "(10, 0)": 0.7457866668701172, "(10, 16)": 0.7457866668701172, "(12, 0)": 0.7457866668701172, "(12, 16)": 0.8119341731071472, "(14, 0)": 0.6552433967590332, "(14, 16)": 0.7457866668701172, "(16, 0)": 0.8119341731071472, "(16, 16)": 0.7457866668701172, "(18, 0)": 0.7457866668701172, "(18, 16)": 0.8119341731071472, "(20, 0)": 0.8119341731071472, "(20, 16)": 0.6552433967590332, "(22, 0)": 0.6552433967590332, "(22, 16)": 0.8119341731071472, "(24, 0)": 0.6552433967590332, "(24, 16)": 0.8119341731071472, "(26, 0)": 0.6552433967590332, "(26, 16)": 0.6552433967590332, "(28, 0)": 0.7457866668701172, "(28, 16)": 0.6552433967590332, "(30, 0)": 0.6552433967590332, "(30, 16)": 0.6552433967590332}, "r_span": [370, 396], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006899833679199219}}, {"prompt_attention_score": {"(0, 0)": 0.8411102294921875, "(0, 16)": 0.8411102294921875, "(2, 0)": 0.8411102294921875, "(2, 16)": 0.8411102294921875, "(4, 0)": 0.8411102294921875, "(4, 16)": 0.8411102294921875, "(6, 0)": 0.8411102294921875, "(6, 16)": 0.9304244518280029, "(8, 0)": 0.9304244518280029, "(8, 16)": 0.8411102294921875, "(10, 0)": 0.8411102294921875, "(10, 16)": 0.8411102294921875, "(12, 0)": 0.8411102294921875, "(12, 16)": 0.9304244518280029, "(14, 0)": 0.7315680980682373, "(14, 16)": 0.8411102294921875, "(16, 0)": 0.9304244518280029, "(16, 16)": 0.8411102294921875, "(18, 0)": 0.8411102294921875, "(18, 16)": 0.9304244518280029, "(20, 0)": 0.9304244518280029, "(20, 16)": 0.7315680980682373, "(22, 0)": 0.7315680980682373, "(22, 16)": 0.9304244518280029, "(24, 0)": 0.7315680980682373, "(24, 16)": 0.9304244518280029, "(26, 0)": 0.7315680980682373, "(26, 16)": 0.7315680980682373, "(28, 0)": 0.7315680980682373, "(28, 16)": 0.7315680980682373, "(30, 0)": 0.7315680980682373, "(30, 16)": 0.7315680980682373}, "r_span": [398, 504], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018969178199768066}}, {"prompt_attention_score": {"(0, 0)": 0.912152886390686, "(0, 16)": 0.912152886390686, "(2, 0)": 0.912152886390686, "(2, 16)": 0.912152886390686, "(4, 0)": 0.912152886390686, "(4, 16)": 0.912152886390686, "(6, 0)": 0.912152886390686, "(6, 16)": 0.912152886390686, "(8, 0)": 0.912152886390686, "(8, 16)": 0.912152886390686, "(10, 0)": 0.912152886390686, "(10, 16)": 0.912152886390686, "(12, 0)": 0.912152886390686, "(12, 16)": 0.912152886390686, "(14, 0)": 0.88746178150177, "(14, 16)": 0.88746178150177, "(16, 0)": 0.912152886390686, "(16, 16)": 0.88746178150177, "(18, 0)": 0.912152886390686, "(18, 16)": 0.88746178150177, "(20, 0)": 0.912152886390686, "(20, 16)": 0.88746178150177, "(22, 0)": 0.88746178150177, "(22, 16)": 0.912152886390686, "(24, 0)": 0.88746178150177, "(24, 16)": 0.912152886390686, "(26, 0)": 0.88746178150177, "(26, 16)": 0.8498215675354004, "(28, 0)": 0.88746178150177, "(28, 16)": 0.88746178150177, "(30, 0)": 0.88746178150177, "(30, 16)": 0.88746178150177}, "r_span": [505, 643], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -7.528066635131836e-05}}, {"prompt_attention_score": {"(0, 0)": 0.8008593916893005, "(0, 16)": 0.8008593916893005, "(2, 0)": 0.8008593916893005, "(2, 16)": 0.8008593916893005, "(4, 0)": 0.8008593916893005, "(4, 16)": 0.8008593916893005, "(6, 0)": 0.8008593916893005, "(6, 16)": 0.8898035287857056, "(8, 0)": 0.8008593916893005, "(8, 16)": 0.8008593916893005, "(10, 0)": 0.8008593916893005, "(10, 16)": 0.8008593916893005, "(12, 0)": 0.8008593916893005, "(12, 16)": 0.8898035287857056, "(14, 0)": 0.7186582684516907, "(14, 16)": 0.8008593916893005, "(16, 0)": 0.8898035287857056, "(16, 16)": 0.7186582684516907, "(18, 0)": 0.8008593916893005, "(18, 16)": 0.8898035287857056, "(20, 0)": 0.8898035287857056, "(20, 16)": 0.7186582684516907, "(22, 0)": 0.7186582684516907, "(22, 16)": 0.8898035287857056, "(24, 0)": 0.7186582684516907, "(24, 16)": 0.8898035287857056, "(26, 0)": 0.7186582684516907, "(26, 16)": 0.7186582684516907, "(28, 0)": 0.7186582684516907, "(28, 16)": 0.7186582684516907, "(30, 0)": 0.7186582684516907, "(30, 16)": 0.7186582684516907}, "r_span": [645, 698], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011292099952697754}}]}, {"id": "13719", "source_id": "15206", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Sure, I can help you with that! Here are the steps to clean a dryer vent based on the provided passages:\n\n1. Locate the dryer vent cover on the outside of your house (passage 1) and remove it by sliding it out if it isn't fastened or sealed to the exterior (step 2).\n2. Use a dryer vent brush to remove lint from the hole where the vent connects to the dryer (step 3).\n3. Remove the vent from the back of the dryer by unscrewing the vent clamp and sliding the vent out of the elbow-shaped joint (step 4).\n4. Clean the lint from the vent and the hole in the back of the dryer using the dryer vent brush (step 4).\n5. Reconnect the vent and move the dryer back against the wall (step 5).\n6. If desired, remove the bottom front panel of the dryer and clean the area around the lint filter (passage 2).\n7. Use a vacuum nozzle to clean the lint deposits in the area around the lint filter frame (passage 2).\n\nNote: Passage 3 provides additional information but does not provide specific instructions for cleaning the dryer vent. Therefore, these steps are based on the information provided in passages 1-2.", "response_spans": [[0, 104], [106, 611], [612, 901], [903, 1100]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8093994855880737, "(0, 16)": 0.8093994855880737, "(2, 0)": 0.8093994855880737, "(2, 16)": 0.8093994855880737, "(4, 0)": 0.8093994855880737, "(4, 16)": 0.8093994855880737, "(6, 0)": 0.8093994855880737, "(6, 16)": 0.8767440319061279, "(8, 0)": 0.8093994855880737, "(8, 16)": 0.4636096954345703, "(10, 0)": 0.4636096954345703, "(10, 16)": 0.4636096954345703, "(12, 0)": 0.4636096954345703, "(12, 16)": 0.8767440319061279, "(14, 0)": 0.7962038516998291, "(14, 16)": 0.4636096954345703, "(16, 0)": 0.8767440319061279, "(16, 16)": 0.8093994855880737, "(18, 0)": 0.4636096954345703, "(18, 16)": 0.8767440319061279, "(20, 0)": 0.8767440319061279, "(20, 16)": 0.7962038516998291, "(22, 0)": 0.7962038516998291, "(22, 16)": 0.8767440319061279, "(24, 0)": 0.7962038516998291, "(24, 16)": 0.8767440319061279, "(26, 0)": 0.7962038516998291, "(26, 16)": 0.7962038516998291, "(28, 0)": 0.4636096954345703, "(28, 16)": 0.7962038516998291, "(30, 0)": 0.7962038516998291, "(30, 16)": 0.7962038516998291}, "r_span": [587, 614], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00025391578674316406}}, {"prompt_attention_score": {"(0, 0)": 0.8304209113121033, "(0, 16)": 0.8304209113121033, "(2, 0)": 0.8304209113121033, "(2, 16)": 0.8304209113121033, "(4, 0)": 0.8304209113121033, "(4, 16)": 0.8304209113121033, "(6, 0)": 0.8304209113121033, "(6, 16)": 0.9284899234771729, "(8, 0)": 0.8304209113121033, "(8, 16)": 0.8304209113121033, "(10, 0)": 0.8304209113121033, "(10, 16)": 0.8304209113121033, "(12, 0)": 0.9284899234771729, "(12, 16)": 0.9284899234771729, "(14, 0)": 0.9284899234771729, "(14, 16)": 0.9284899234771729, "(16, 0)": 0.9284899234771729, "(16, 16)": 0.9284899234771729, "(18, 0)": 0.9284899234771729, "(18, 16)": 0.9284899234771729, "(20, 0)": 0.9284899234771729, "(20, 16)": 0.9284899234771729, "(22, 0)": 0.9284899234771729, "(22, 16)": 0.9284899234771729, "(24, 0)": 0.9284899234771729, "(24, 16)": 0.9284899234771729, "(26, 0)": 0.9284899234771729, "(26, 16)": 0.9284899234771729, "(28, 0)": 0.9284899234771729, "(28, 16)": 0.9284899234771729, "(30, 0)": 0.9284899234771729, "(30, 16)": 0.9284899234771729}, "r_span": [616, 767], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0037626028060913086}}, {"prompt_attention_score": {"(0, 0)": 0.796574592590332, "(0, 16)": 0.796574592590332, "(2, 0)": 0.796574592590332, "(2, 16)": 0.796574592590332, "(4, 0)": 0.796574592590332, "(4, 16)": 0.796574592590332, "(6, 0)": 0.8410862684249878, "(6, 16)": 0.8934135437011719, "(8, 0)": 0.796574592590332, "(8, 16)": 0.796574592590332, "(10, 0)": 0.796574592590332, "(10, 16)": 0.796574592590332, "(12, 0)": 0.796574592590332, "(12, 16)": 0.8934135437011719, "(14, 0)": 0.8410862684249878, "(14, 16)": 0.796574592590332, "(16, 0)": 0.796574592590332, "(16, 16)": 0.796574592590332, "(18, 0)": 0.8410862684249878, "(18, 16)": 0.8934135437011719, "(20, 0)": 0.8934135437011719, "(20, 16)": 0.8410862684249878, "(22, 0)": 0.8410862684249878, "(22, 16)": 0.8934135437011719, "(24, 0)": 0.8410862684249878, "(24, 16)": 0.8934135437011719, "(26, 0)": 0.8410862684249878, "(26, 16)": 0.8410862684249878, "(28, 0)": 0.8410862684249878, "(28, 16)": 0.8410862684249878, "(30, 0)": 0.8410862684249878, "(30, 16)": 0.8410862684249878}, "r_span": [768, 851], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009148120880126953}}, {"prompt_attention_score": {"(0, 0)": 0.7892780303955078, "(0, 16)": 0.7892780303955078, "(2, 0)": 0.7892780303955078, "(2, 16)": 0.7892780303955078, "(4, 0)": 0.7892780303955078, "(4, 16)": 0.7713320851325989, "(6, 0)": 0.7892780303955078, "(6, 16)": 0.7713320851325989, "(8, 0)": 0.7892780303955078, "(8, 16)": 0.7762295007705688, "(10, 0)": 0.5962996482849121, "(10, 16)": 0.5962996482849121, "(12, 0)": 0.5962996482849121, "(12, 16)": 0.5962996482849121, "(14, 0)": 0.7762295007705688, "(14, 16)": 0.5962996482849121, "(16, 0)": 0.5962996482849121, "(16, 16)": 0.7762295007705688, "(18, 0)": 0.7762295007705688, "(18, 16)": 0.5962996482849121, "(20, 0)": 0.5962996482849121, "(20, 16)": 0.7762295007705688, "(22, 0)": 0.7762295007705688, "(22, 16)": 0.5962996482849121, "(24, 0)": 0.7762295007705688, "(24, 16)": 0.5962996482849121, "(26, 0)": 0.7762295007705688, "(26, 16)": 0.7762295007705688, "(28, 0)": 0.7762295007705688, "(28, 16)": 0.7762295007705688, "(30, 0)": 0.7762295007705688, "(30, 16)": 0.7762295007705688}, "r_span": [853, 894], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004736185073852539}}]}, {"id": "13743", "source_id": "15210", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the benefits of MSM powder are:\n\n1. Increased efficiency of oxygen delivery to the blood with the same amount of effort. (Passage 1)\n2. Improved nutrient absorption through increased permeability of cell walls. (Passage 2)\n3. Relief from muscular aches and pains through reduction of inflammation. (Passage 3)\n\nTherefore, the three main benefits of MSM powder are:\n\na. Increased oxygen delivery\nb. Better nutrient absorption\nc. Reduced inflammation and pain relief", "response_spans": [[0, 496]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8379764556884766, "(0, 16)": 0.8379764556884766, "(2, 0)": 0.8379764556884766, "(2, 16)": 0.8379764556884766, "(4, 0)": 0.8379764556884766, "(4, 16)": 0.8379764556884766, "(6, 0)": 0.8379764556884766, "(6, 16)": 0.9059707522392273, "(8, 0)": 0.8379764556884766, "(8, 16)": 0.8379764556884766, "(10, 0)": 0.8379764556884766, "(10, 16)": 0.8379764556884766, "(12, 0)": 0.8379764556884766, "(12, 16)": 0.9059707522392273, "(14, 0)": 0.8379764556884766, "(14, 16)": 0.8379764556884766, "(16, 0)": 0.9059707522392273, "(16, 16)": 0.8379764556884766, "(18, 0)": 0.8379764556884766, "(18, 16)": 0.9059707522392273, "(20, 0)": 0.9059707522392273, "(20, 16)": 0.7945123314857483, "(22, 0)": 0.7945123314857483, "(22, 16)": 0.9059707522392273, "(24, 0)": 0.7945123314857483, "(24, 16)": 0.8379764556884766, "(26, 0)": 0.7945123314857483, "(26, 16)": 0.7945123314857483, "(28, 0)": 0.7945123314857483, "(28, 16)": 0.7945123314857483, "(30, 0)": 0.7945123314857483, "(30, 16)": 0.7945123314857483}, "r_span": [323, 467], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012397170066833496}}]}, {"id": "13911", "source_id": "15238", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is my answer:\n\nThe passage highlights the key role of visual merchandisers in creating an immersive and engaging retail experience for customers. They are responsible for bringing the retail strategy and company goals to life in the store through effective display and presentation of products. The passage also emphasizes the importance of visual merchandising in influencing consumer behavior, particularly in the context of shop windows.\n\nThe second passage discusses the role of merchandisers in making the product interesting and appealing to consumers, drawing a comparison between the role of marketers (who bring customers to the store) and merchandisers (who make them buy).\n\nThe third passage focuses specifically on the impact of visual merchandising on consumer buying behavior, particularly in terms of the effect of shop window displays on consumer behavior. The passage also considers the influence of other factors such as sex and store attributes on consumer behavior.\n\nOverall, these passages suggest that visual merchandising plays a crucial role in retail by creating an inviting and persuasive shopping environment that encourages consumers to make purchases.", "response_spans": [[0, 477], [479, 720], [722, 1217]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.804841935634613, "(0, 16)": 0.804841935634613, "(2, 0)": 0.804841935634613, "(2, 16)": 0.804841935634613, "(4, 0)": 0.804841935634613, "(4, 16)": 0.804841935634613, "(6, 0)": 0.804841935634613, "(6, 16)": 0.8469011783599854, "(8, 0)": 0.804841935634613, "(8, 16)": 0.804841935634613, "(10, 0)": 0.804841935634613, "(10, 16)": 0.804841935634613, "(12, 0)": 0.804841935634613, "(12, 16)": 0.804841935634613, "(14, 0)": 0.785152792930603, "(14, 16)": 0.8469011783599854, "(16, 0)": 0.8469011783599854, "(16, 16)": 0.785152792930603, "(18, 0)": 0.804841935634613, "(18, 16)": 0.8469011783599854, "(20, 0)": 0.8469011783599854, "(20, 16)": 0.785152792930603, "(22, 0)": 0.785152792930603, "(22, 16)": 0.8469011783599854, "(24, 0)": 0.785152792930603, "(24, 16)": 0.8469011783599854, "(26, 0)": 0.785152792930603, "(26, 16)": 0.785152792930603, "(28, 0)": 0.785152792930603, "(28, 16)": 0.785152792930603, "(30, 0)": 0.785152792930603, "(30, 16)": 0.785152792930603}, "r_span": [316, 411], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001004040241241455}}, {"prompt_attention_score": {"(0, 0)": 0.6941092014312744, "(0, 16)": 0.6941092014312744, "(2, 0)": 0.6941092014312744, "(2, 16)": 0.6941092014312744, "(4, 0)": 0.6941092014312744, "(4, 16)": 0.6941092014312744, "(6, 0)": 0.6941092014312744, "(6, 16)": 0.7011439800262451, "(8, 0)": 0.6941092014312744, "(8, 16)": 0.6941092014312744, "(10, 0)": 0.6941092014312744, "(10, 16)": 0.6941092014312744, "(12, 0)": 0.7219724655151367, "(12, 16)": 0.7219724655151367, "(14, 0)": 0.7219724655151367, "(14, 16)": 0.7011439800262451, "(16, 0)": 0.7219724655151367, "(16, 16)": 0.7219724655151367, "(18, 0)": 0.7219724655151367, "(18, 16)": 0.7219724655151367, "(20, 0)": 0.7219724655151367, "(20, 16)": 0.7219724655151367, "(22, 0)": 0.7219724655151367, "(22, 16)": 0.7219724655151367, "(24, 0)": 0.7219724655151367, "(24, 16)": 0.7219724655151367, "(26, 0)": 0.7219724655151367, "(26, 16)": 0.7219724655151367, "(28, 0)": 0.7219724655151367, "(28, 16)": 0.7219724655151367, "(30, 0)": 0.7219724655151367, "(30, 16)": 0.7219724655151367}, "r_span": [413, 465], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0022551417350769043}}, {"prompt_attention_score": {"(0, 0)": 0.8678176403045654, "(0, 16)": 0.8678176403045654, "(2, 0)": 0.8678176403045654, "(2, 16)": 0.8678176403045654, "(4, 0)": 0.8678176403045654, "(4, 16)": 0.8678176403045654, "(6, 0)": 0.8678176403045654, "(6, 16)": 0.7644788026809692, "(8, 0)": 0.8678176403045654, "(8, 16)": 0.8678176403045654, "(10, 0)": 0.8678176403045654, "(10, 16)": 0.8678176403045654, "(12, 0)": 0.7438746094703674, "(12, 16)": 0.8678176403045654, "(14, 0)": 0.7438746094703674, "(14, 16)": 0.8678176403045654, "(16, 0)": 0.8678176403045654, "(16, 16)": 0.7438746094703674, "(18, 0)": 0.7438746094703674, "(18, 16)": 0.8678176403045654, "(20, 0)": 0.8678176403045654, "(20, 16)": 0.7438746094703674, "(22, 0)": 0.7438746094703674, "(22, 16)": 0.8678176403045654, "(24, 0)": 0.7438746094703674, "(24, 16)": 0.8678176403045654, "(26, 0)": 0.7438746094703674, "(26, 16)": 0.7438746094703674, "(28, 0)": 0.7438746094703674, "(28, 16)": 0.7438746094703674, "(30, 0)": 0.7438746094703674, "(30, 16)": 0.7438746094703674}, "r_span": [467, 567], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001885533332824707}}]}, {"id": "13917", "source_id": "15239", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 126, "end": 162, "text": "* Dizziness (mentioned in passage 5)", "meta": "EVIDENT CONFLICT\nOriginal: \"Dizziness (mentioned in Passage 1)\"\nGenerative: \"Dizziness (mentioned in passage 5)\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 416, "end": 556, "text": "Additionally, some women may experience nausea and vomiting during early pregnancy, although this is not mentioned in the passages provided.", "meta": "EVIDENT CONFLICT\nOriginal: \"...pregnant women experience nausea and vomiting...\" (mentioned in Passage 3)\nGenerative: \"some women may experience nausea and vomiting during early pregnancy, although this is not mentioned in the passages provided\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the earliest signs and symptoms of pregnancy include:\n\n* Mood swings (mentioned in passage 1)\n* Dizziness (mentioned in passage 5)\n* Bloating (mentioned in passage 2)\n* Spotting (mentioned in passage 2)\n* Cramping (mentioned in passage 2)\n\nIt is worth noting that these symptoms can sometimes be easy to overlook, as they are not always obvious or severe (as mentioned in passage 2). Additionally, some women may experience nausea and vomiting during early pregnancy, although this is not mentioned in the passages provided.", "response_spans": [[0, 270], [272, 556]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7664375305175781, "(0, 16)": 0.7664375305175781, "(2, 0)": 0.7664375305175781, "(2, 16)": 0.7664375305175781, "(4, 0)": 0.7664375305175781, "(4, 16)": 0.7664375305175781, "(6, 0)": 0.7664375305175781, "(6, 16)": 0.8693951368331909, "(8, 0)": 0.7664375305175781, "(8, 16)": 0.7664375305175781, "(10, 0)": 0.7664375305175781, "(10, 16)": 0.7664375305175781, "(12, 0)": 0.7664375305175781, "(12, 16)": 0.8717631697654724, "(14, 0)": 0.8717631697654724, "(14, 16)": 0.7664375305175781, "(16, 0)": 0.8693951368331909, "(16, 16)": 0.7664375305175781, "(18, 0)": 0.7664375305175781, "(18, 16)": 0.8693951368331909, "(20, 0)": 0.8693951368331909, "(20, 16)": 0.8717631697654724, "(22, 0)": 0.7664375305175781, "(22, 16)": 0.8693951368331909, "(24, 0)": 0.7664375305175781, "(24, 16)": 0.8693951368331909, "(26, 0)": 0.7664375305175781, "(26, 16)": 0.8693951368331909, "(28, 0)": 0.8693951368331909, "(28, 16)": 0.7664375305175781, "(30, 0)": 0.7664375305175781, "(30, 16)": 0.8717631697654724}, "r_span": [348, 434], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.000919640064239502}}, {"prompt_attention_score": {"(0, 0)": 0.8193988800048828, "(0, 16)": 0.8193988800048828, "(2, 0)": 0.8193988800048828, "(2, 16)": 0.8193988800048828, "(4, 0)": 0.8193988800048828, "(4, 16)": 0.8193988800048828, "(6, 0)": 0.8193988800048828, "(6, 16)": 0.7959389090538025, "(8, 0)": 0.8193988800048828, "(8, 16)": 0.8193988800048828, "(10, 0)": 0.8193988800048828, "(10, 16)": 0.8193988800048828, "(12, 0)": 0.8193988800048828, "(12, 16)": 0.8193988800048828, "(14, 0)": 0.8026328086853027, "(14, 16)": 0.8193988800048828, "(16, 0)": 0.8193988800048828, "(16, 16)": 0.8193988800048828, "(18, 0)": 0.8193988800048828, "(18, 16)": 0.8193988800048828, "(20, 0)": 0.8193988800048828, "(20, 16)": 0.8026328086853027, "(22, 0)": 0.7959389090538025, "(22, 16)": 0.8026328086853027, "(24, 0)": 0.8193988800048828, "(24, 16)": 0.8193988800048828, "(26, 0)": 0.8193988800048828, "(26, 16)": 0.8193988800048828, "(28, 0)": 0.7959389090538025, "(28, 16)": 0.8193988800048828, "(30, 0)": 0.8193988800048828, "(30, 16)": 0.8026328086853027}, "r_span": [436, 498], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00018084049224853516}}]}, {"id": "13941", "source_id": "15243", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, severe osteoporosis refers to a condition where the bones have been significantly weakened to the point of causing symptoms such as back pain, loss of height, and fractures. According to passage 3, osteoporosis typically has no symptoms until significant bone damage has occurred, making it a \"silent disease\" until it reaches this advanced stage. Passage 2 also highlights that compression fractures of the spine are a common cause of osteoporosis pain, which can be severe and debilitating. Therefore, severe osteoporosis is characterized by a high risk of fractures, particularly in the spine and hips, as well as persistent back pain and loss of height.", "response_spans": [[0, 510], [493, 689]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.852658212184906, "(0, 16)": 0.852658212184906, "(2, 0)": 0.852658212184906, "(2, 16)": 0.852658212184906, "(4, 0)": 0.852658212184906, "(4, 16)": 0.852658212184906, "(6, 0)": 0.852658212184906, "(6, 16)": 0.8730306029319763, "(8, 0)": 0.852658212184906, "(8, 16)": 0.852658212184906, "(10, 0)": 0.499752938747406, "(10, 16)": 0.852658212184906, "(12, 0)": 0.852658212184906, "(12, 16)": 0.852658212184906, "(14, 0)": 0.852658212184906, "(14, 16)": 0.852658212184906, "(16, 0)": 0.852658212184906, "(16, 16)": 0.852658212184906, "(18, 0)": 0.499752938747406, "(18, 16)": 0.852658212184906, "(20, 0)": 0.852658212184906, "(20, 16)": 0.852658212184906, "(22, 0)": 0.852658212184906, "(22, 16)": 0.852658212184906, "(24, 0)": 0.8347004652023315, "(24, 16)": 0.852658212184906, "(26, 0)": 0.8347004652023315, "(26, 16)": 0.852658212184906, "(28, 0)": 0.8347004652023315, "(28, 16)": 0.852658212184906, "(30, 0)": 0.8347004652023315, "(30, 16)": 0.8347004652023315}, "r_span": [623, 743], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -5.3882598876953125e-05}}, {"prompt_attention_score": {"(0, 0)": 0.783536434173584, "(0, 16)": 0.783536434173584, "(2, 0)": 0.783536434173584, "(2, 16)": 0.783536434173584, "(4, 0)": 0.783536434173584, "(4, 16)": 0.783536434173584, "(6, 0)": 0.783536434173584, "(6, 16)": 0.783536434173584, "(8, 0)": 0.783536434173584, "(8, 16)": 0.783536434173584, "(10, 0)": 0.46206724643707275, "(10, 16)": 0.783536434173584, "(12, 0)": 0.46206724643707275, "(12, 16)": 0.783536434173584, "(14, 0)": 0.783536434173584, "(14, 16)": 0.783536434173584, "(16, 0)": 0.46206724643707275, "(16, 16)": 0.783536434173584, "(18, 0)": 0.46206724643707275, "(18, 16)": 0.783536434173584, "(20, 0)": 0.783536434173584, "(20, 16)": 0.783536434173584, "(22, 0)": 0.783536434173584, "(22, 16)": 0.783536434173584, "(24, 0)": 0.7549553513526917, "(24, 16)": 0.783536434173584, "(26, 0)": 0.7549553513526917, "(26, 16)": 0.783536434173584, "(28, 0)": 0.7549553513526917, "(28, 16)": 0.783536434173584, "(30, 0)": 0.7549553513526917, "(30, 16)": 0.7549553513526917}, "r_span": [740, 788], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018281340599060059}}]}, {"id": "14007", "source_id": "15254", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 544, "end": 556, "text": "him, her, it", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nPassages did not provide pronouns such as him, her, and it, as relative pronouns.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the main difference between an adverb clause and an adjective clause is as follows:\n\n* An adverb clause is a dependent clause that modifies a verb, adjective, or another adverb. It is introduced by subordinate conjunctions such as after, although, as, as if, before, because, if, since, so that, than, though, unless, until, when, where, and while. (Passage 1)\n* An adjective clause, on the other hand, is a dependent clause that modifies a noun or a pronoun. It is introduced by a relative pronoun (who, whose, him, her, it, that) or a subordinate conjunction (when and where). (Passage 2)\n\nIn summary, while both adverb clauses and adjective clauses are dependent clauses, they differ in their function and the words that introduce them. Adverb clauses modify verbs, adjectives, or another adverbs, while adjective clauses modify nouns or pronouns.", "response_spans": [[0, 115], [117, 622], [624, 882]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8080896735191345, "(0, 16)": 0.8080896735191345, "(2, 0)": 0.8080896735191345, "(2, 16)": 0.8080896735191345, "(4, 0)": 0.8080896735191345, "(4, 16)": 0.8080896735191345, "(6, 0)": 0.8080896735191345, "(6, 16)": 0.9013175964355469, "(8, 0)": 0.8080896735191345, "(8, 16)": 0.8080896735191345, "(10, 0)": 0.8080896735191345, "(10, 16)": 0.8080896735191345, "(12, 0)": 0.9013175964355469, "(12, 16)": 0.9013175964355469, "(14, 0)": 0.8080896735191345, "(14, 16)": 0.8080896735191345, "(16, 0)": 0.9013175964355469, "(16, 16)": 0.8080896735191345, "(18, 0)": 0.8080896735191345, "(18, 16)": 0.9013175964355469, "(20, 0)": 0.9013175964355469, "(20, 16)": 0.9013175964355469, "(22, 0)": 0.9013175964355469, "(22, 16)": 0.9013175964355469, "(24, 0)": 0.8080896735191345, "(24, 16)": 0.9013175964355469, "(26, 0)": 0.9013175964355469, "(26, 16)": 0.9013175964355469, "(28, 0)": 0.8080896735191345, "(28, 16)": 0.9013175964355469, "(30, 0)": 0.9013175964355469, "(30, 16)": 0.8080896735191345}, "r_span": [337, 362], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006086826324462891}}, {"prompt_attention_score": {"(0, 0)": 0.871366024017334, "(0, 16)": 0.871366024017334, "(2, 0)": 0.871366024017334, "(2, 16)": 0.871366024017334, "(4, 0)": 0.871366024017334, "(4, 16)": 0.871366024017334, "(6, 0)": 0.871366024017334, "(6, 16)": 0.9441366195678711, "(8, 0)": 0.9441366195678711, "(8, 16)": 0.871366024017334, "(10, 0)": 0.871366024017334, "(10, 16)": 0.871366024017334, "(12, 0)": 0.9441366195678711, "(12, 16)": 0.9441366195678711, "(14, 0)": 0.9441366195678711, "(14, 16)": 0.9441366195678711, "(16, 0)": 0.9441366195678711, "(16, 16)": 0.9441366195678711, "(18, 0)": 0.871366024017334, "(18, 16)": 0.9441366195678711, "(20, 0)": 0.9441366195678711, "(20, 16)": 0.9441366195678711, "(22, 0)": 0.9441366195678711, "(22, 16)": 0.9441366195678711, "(24, 0)": 0.9441366195678711, "(24, 16)": 0.9441366195678711, "(26, 0)": 0.9441366195678711, "(26, 16)": 0.9441366195678711, "(28, 0)": 0.9441366195678711, "(28, 16)": 0.9441366195678711, "(30, 0)": 0.9441366195678711, "(30, 16)": 0.9441366195678711}, "r_span": [364, 504], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00017207860946655273}}, {"prompt_attention_score": {"(0, 0)": 0.8684274554252625, "(0, 16)": 0.8684274554252625, "(2, 0)": 0.8684274554252625, "(2, 16)": 0.8684274554252625, "(4, 0)": 0.8684274554252625, "(4, 16)": 0.8684274554252625, "(6, 0)": 0.9378880262374878, "(6, 16)": 0.9378880262374878, "(8, 0)": 0.9378880262374878, "(8, 16)": 0.8684274554252625, "(10, 0)": 0.8684274554252625, "(10, 16)": 0.8684274554252625, "(12, 0)": 0.9378880262374878, "(12, 16)": 0.8684274554252625, "(14, 0)": 0.9378880262374878, "(14, 16)": 0.8684274554252625, "(16, 0)": 0.9378880262374878, "(16, 16)": 0.9378880262374878, "(18, 0)": 0.9378880262374878, "(18, 16)": 0.9378880262374878, "(20, 0)": 0.9378880262374878, "(20, 16)": 0.9378880262374878, "(22, 0)": 0.9378880262374878, "(22, 16)": 0.9378880262374878, "(24, 0)": 0.9378880262374878, "(24, 16)": 0.9378880262374878, "(26, 0)": 0.9378880262374878, "(26, 16)": 0.9378880262374878, "(28, 0)": 0.8684274554252625, "(28, 16)": 0.9378880262374878, "(30, 0)": 0.9378880262374878, "(30, 16)": 0.9378880262374878}, "r_span": [506, 569], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011812448501586914}}]}, {"id": "14055", "source_id": "15262", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to cook a frozen pork loin roast in the oven:\n\nPassage 1 states to defrost the roast first and then place it in the oven at 250¬∞F for about an hour. After taking it out, season the roast and turn the oven temperature to 350¬∞F. Cook for 1.5 to 3 hours, depending on the size of the roast, making sure it's cooked all the way through.\n\nPassage 2 provides specific instructions for preparing the roast before cooking. Rub the surface of the frozen pork loin with olive oil and season with salt, pepper, and any desired herbs. Place the roast in a preheated oven at 325¬∞F and determine the cooking time based on the weight of the roast.\n\nPassage 3 suggests starting by preheating the oven to 350¬∞F and then placing the frozen pork loin in a shallow baking pan on a roasting rack. Cook for 20-30 minutes per pound, inserting a meat thermometer to check the internal temperature once cooked. Once the temperature reaches 150¬∞F, remove the roast from the oven and let it rest for 30 minutes before slicing and serving.\n\nBased on these passages, the general steps to cook a frozen pork loin roast in the oven are:\n\n1. Defrost the roast if not already thawed.\n2. Season the roast with salt, pepper, and herbs.\n3. Place the roast in a preheated oven at the appropriate temperature (250¬∞F or 325¬∞F) for the specified time.\n4. Check the internal temperature of the roast using a meat thermometer to ensure it reaches the desired doneness.\n5. Remove the roast from the oven and let it rest for 30 minutes before slicing and serving.", "response_spans": [[0, 376], [378, 676], [678, 1149], [1151, 1563]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8915594816207886, "(0, 16)": 0.8915594816207886, "(2, 0)": 0.8539035320281982, "(2, 16)": 0.8539035320281982, "(4, 0)": 0.8539035320281982, "(4, 16)": 0.8539035320281982, "(6, 0)": 0.8915594816207886, "(6, 16)": 0.8941380977630615, "(8, 0)": 0.8539035320281982, "(8, 16)": 0.8539035320281982, "(10, 0)": 0.3969980478286743, "(10, 16)": 0.3969980478286743, "(12, 0)": 0.8539035320281982, "(12, 16)": 0.8941380977630615, "(14, 0)": 0.8539035320281982, "(14, 16)": 0.8539035320281982, "(16, 0)": 0.8941380977630615, "(16, 16)": 0.8539035320281982, "(18, 0)": 0.3969980478286743, "(18, 16)": 0.8941380977630615, "(20, 0)": 0.8941380977630615, "(20, 16)": 0.8539035320281982, "(22, 0)": 0.8539035320281982, "(22, 16)": 0.8941380977630615, "(24, 0)": 0.8539035320281982, "(24, 16)": 0.8941380977630615, "(26, 0)": 0.8539035320281982, "(26, 16)": 0.8695989847183228, "(28, 0)": 0.3969980478286743, "(28, 16)": 0.8539035320281982, "(30, 0)": 0.8539035320281982, "(30, 16)": 0.8695989847183228}, "r_span": [771, 887], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000616610050201416}}, {"prompt_attention_score": {"(0, 0)": 0.8964434266090393, "(0, 16)": 0.8964434266090393, "(2, 0)": 0.8162481784820557, "(2, 16)": 0.8964434266090393, "(4, 0)": 0.8162481784820557, "(4, 16)": 0.8162481784820557, "(6, 0)": 0.8964434266090393, "(6, 16)": 0.9159054160118103, "(8, 0)": 0.8162481784820557, "(8, 16)": 0.8162481784820557, "(10, 0)": 0.8964434266090393, "(10, 16)": 0.8964434266090393, "(12, 0)": 0.8621655702590942, "(12, 16)": 0.9159054160118103, "(14, 0)": 0.8162481784820557, "(14, 16)": 0.8162481784820557, "(16, 0)": 0.9159054160118103, "(16, 16)": 0.8162481784820557, "(18, 0)": 0.4180411398410797, "(18, 16)": 0.9159054160118103, "(20, 0)": 0.9159054160118103, "(20, 16)": 0.8162481784820557, "(22, 0)": 0.8162481784820557, "(22, 16)": 0.9159054160118103, "(24, 0)": 0.8162481784820557, "(24, 16)": 0.9159054160118103, "(26, 0)": 0.8162481784820557, "(26, 16)": 0.8162481784820557, "(28, 0)": 0.8162481784820557, "(28, 16)": 0.8162481784820557, "(30, 0)": 0.8162481784820557, "(30, 16)": 0.9159054160118103}, "r_span": [889, 968], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00026351213455200195}}, {"prompt_attention_score": {"(0, 0)": 0.9262017011642456, "(0, 16)": 0.9262017011642456, "(2, 0)": 0.8360508680343628, "(2, 16)": 0.8360508680343628, "(4, 0)": 0.8360508680343628, "(4, 16)": 0.8360508680343628, "(6, 0)": 0.9262017011642456, "(6, 16)": 0.9262017011642456, "(8, 0)": 0.8360508680343628, "(8, 16)": 0.8360508680343628, "(10, 0)": 0.8360508680343628, "(10, 16)": 0.8360508680343628, "(12, 0)": 0.8360508680343628, "(12, 16)": 0.9262017011642456, "(14, 0)": 0.8360508680343628, "(14, 16)": 0.4103958308696747, "(16, 0)": 0.8360508680343628, "(16, 16)": 0.8360508680343628, "(18, 0)": 0.8360508680343628, "(18, 16)": 0.9262017011642456, "(20, 0)": 0.9262017011642456, "(20, 16)": 0.8360508680343628, "(22, 0)": 0.8360508680343628, "(22, 16)": 0.9262017011642456, "(24, 0)": 0.8360508680343628, "(24, 16)": 0.9262017011642456, "(26, 0)": 0.8360508680343628, "(26, 16)": 0.8360508680343628, "(28, 0)": 0.8360508680343628, "(28, 16)": 0.8360508680343628, "(30, 0)": 0.8360508680343628, "(30, 16)": 0.8684568405151367}, "r_span": [970, 1106], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001398921012878418}}, {"prompt_attention_score": {"(0, 0)": 0.8010884523391724, "(0, 16)": 0.8010884523391724, "(2, 0)": 0.8010884523391724, "(2, 16)": 0.417880117893219, "(4, 0)": 0.417880117893219, "(4, 16)": 0.8010884523391724, "(6, 0)": 0.8010884523391724, "(6, 16)": 0.8359119892120361, "(8, 0)": 0.8538528680801392, "(8, 16)": 0.8538528680801392, "(10, 0)": 0.8010884523391724, "(10, 16)": 0.8010884523391724, "(12, 0)": 0.8359119892120361, "(12, 16)": 0.8538528680801392, "(14, 0)": 0.8538528680801392, "(14, 16)": 0.417880117893219, "(16, 0)": 0.8538528680801392, "(16, 16)": 0.8538528680801392, "(18, 0)": 0.417880117893219, "(18, 16)": 0.8538528680801392, "(20, 0)": 0.8538528680801392, "(20, 16)": 0.8538528680801392, "(22, 0)": 0.8538528680801392, "(22, 16)": 0.8404426574707031, "(24, 0)": 0.8538528680801392, "(24, 16)": 0.8538528680801392, "(26, 0)": 0.8359119892120361, "(26, 16)": 0.8538528680801392, "(28, 0)": 0.8538528680801392, "(28, 16)": 0.8538528680801392, "(30, 0)": 0.8538528680801392, "(30, 16)": 0.8359119892120361}, "r_span": [1108, 1228], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014775395393371582}}]}, {"id": "14097", "source_id": "15269", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 288, "end": 347, "text": "while cool season grasses should be fertilized in the fall.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *this is not mentioned*\nGenerative: \"while cool season grasses should be fertilized in the fall. .\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the proper way to fertilize your grass is as follows:\n\n1. Time your fertilization at the beginning of the growing season, which varies for different types of grasses. Warm season grasses should be fertilized when the grass turns green in the early spring, while cool season grasses should be fertilized in the fall. (Passage 1)\n2. Choose a fertilizer that is appropriate for your specific type of grass and perform a pH soil test to determine the correct pH level for your fertilizer. (Passage 2)\n3. Apply the remaining fertilizer in a perpendicular pattern, and check if the leaf blade bounces back up after stepping on the turf to ensure that your lawn is in good shape. If the leaf blade lies flat, you may have over-fertilized. (Passage 3)\n\nUnable to answer based on given passages. The passages do not provide information on the amount of fertilizer to use, how often to fertilize, or any specific guidelines for organic or slow-release fertilizers.", "response_spans": [[0, 85], [87, 528], [529, 775], [777, 986]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7627660036087036, "(0, 16)": 0.7627660036087036, "(2, 0)": 0.7627660036087036, "(2, 16)": 0.7627660036087036, "(4, 0)": 0.7627660036087036, "(4, 16)": 0.7627660036087036, "(6, 0)": 0.7627660036087036, "(6, 16)": 0.838839054107666, "(8, 0)": 0.7627660036087036, "(8, 16)": 0.7627660036087036, "(10, 0)": 0.7627660036087036, "(10, 16)": 0.7627660036087036, "(12, 0)": 0.7627660036087036, "(12, 16)": 0.838839054107666, "(14, 0)": 0.7627660036087036, "(14, 16)": 0.7627660036087036, "(16, 0)": 0.838839054107666, "(16, 16)": 0.7627660036087036, "(18, 0)": 0.7627660036087036, "(18, 16)": 0.838839054107666, "(20, 0)": 0.838839054107666, "(20, 16)": 0.838839054107666, "(22, 0)": 0.838839054107666, "(22, 16)": 0.838839054107666, "(24, 0)": 0.7627660036087036, "(24, 16)": 0.838839054107666, "(26, 0)": 0.838839054107666, "(26, 16)": 0.838839054107666, "(28, 0)": 0.7627660036087036, "(28, 16)": 0.838839054107666, "(30, 0)": 0.838839054107666, "(30, 16)": 0.838839054107666}, "r_span": [360, 381], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -1.7523765563964844e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7485525608062744, "(0, 16)": 0.7485525608062744, "(2, 0)": 0.7485525608062744, "(2, 16)": 0.7485525608062744, "(4, 0)": 0.7485525608062744, "(4, 16)": 0.7485525608062744, "(6, 0)": 0.7485525608062744, "(6, 16)": 0.8953346610069275, "(8, 0)": 0.7485525608062744, "(8, 16)": 0.7485525608062744, "(10, 0)": 0.7485525608062744, "(10, 16)": 0.7485525608062744, "(12, 0)": 0.8953346610069275, "(12, 16)": 0.8953346610069275, "(14, 0)": 0.8953346610069275, "(14, 16)": 0.8953346610069275, "(16, 0)": 0.8953346610069275, "(16, 16)": 0.8953346610069275, "(18, 0)": 0.7485525608062744, "(18, 16)": 0.8953346610069275, "(20, 0)": 0.8953346610069275, "(20, 16)": 0.8953346610069275, "(22, 0)": 0.8953346610069275, "(22, 16)": 0.8953346610069275, "(24, 0)": 0.8953346610069275, "(24, 16)": 0.8953346610069275, "(26, 0)": 0.8953346610069275, "(26, 16)": 0.8953346610069275, "(28, 0)": 0.8953346610069275, "(28, 16)": 0.8953346610069275, "(30, 0)": 0.8953346610069275, "(30, 16)": 0.8953346610069275}, "r_span": [383, 492], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.003104984760284424}}, {"prompt_attention_score": {"(0, 0)": 0.9222570061683655, "(0, 16)": 0.9222570061683655, "(2, 0)": 0.9222570061683655, "(2, 16)": 0.9222570061683655, "(4, 0)": 0.9222570061683655, "(4, 16)": 0.9222570061683655, "(6, 0)": 0.9222570061683655, "(6, 16)": 0.9222570061683655, "(8, 0)": 0.9222570061683655, "(8, 16)": 0.9222570061683655, "(10, 0)": 0.9222570061683655, "(10, 16)": 0.9222570061683655, "(12, 0)": 0.9222570061683655, "(12, 16)": 0.9222570061683655, "(14, 0)": 0.9222570061683655, "(14, 16)": 0.9222570061683655, "(16, 0)": 0.9222570061683655, "(16, 16)": 0.7345805764198303, "(18, 0)": 0.9222570061683655, "(18, 16)": 0.9222570061683655, "(20, 0)": 0.9222570061683655, "(20, 16)": 0.7345805764198303, "(22, 0)": 0.7345805764198303, "(22, 16)": 0.9222570061683655, "(24, 0)": 0.9222570061683655, "(24, 16)": 0.9222570061683655, "(26, 0)": 0.7345805764198303, "(26, 16)": 0.9222570061683655, "(28, 0)": 0.7345805764198303, "(28, 16)": 0.7345805764198303, "(30, 0)": 0.7345805764198303, "(30, 16)": 0.7345805764198303}, "r_span": [493, 562], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010768771171569824}}, {"prompt_attention_score": {"(0, 0)": 0.7310837507247925, "(0, 16)": 0.7310837507247925, "(2, 0)": 0.7310837507247925, "(2, 16)": 0.7274925112724304, "(4, 0)": 0.7310837507247925, "(4, 16)": 0.7310837507247925, "(6, 0)": 0.7310837507247925, "(6, 16)": 0.7081824541091919, "(8, 0)": 0.7310837507247925, "(8, 16)": 0.7310837507247925, "(10, 0)": 0.7310837507247925, "(10, 16)": 0.7310837507247925, "(12, 0)": 0.7310837507247925, "(12, 16)": 0.7310837507247925, "(14, 0)": 0.7081824541091919, "(14, 16)": 0.7310837507247925, "(16, 0)": 0.7310837507247925, "(16, 16)": 0.7081824541091919, "(18, 0)": 0.7081824541091919, "(18, 16)": 0.7310837507247925, "(20, 0)": 0.7081824541091919, "(20, 16)": 0.7081824541091919, "(22, 0)": 0.7081824541091919, "(22, 16)": 0.7310837507247925, "(24, 0)": 0.7310837507247925, "(24, 16)": 0.7310837507247925, "(26, 0)": 0.7081824541091919, "(26, 16)": 0.7081824541091919, "(28, 0)": 0.7081824541091919, "(28, 16)": 0.7081824541091919, "(30, 0)": 0.7081824541091919, "(30, 16)": 0.7081824541091919}, "r_span": [564, 615], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008924007415771484}}]}, {"id": "14133", "source_id": "15275", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 141, "end": 233, "text": "A ball rolling down a hill has gravitational potential energy due to its height (Passage 3).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *this is not mentioned in Passage 3*\nGenerative:  A ball rolling down a hill has gravitational potential energy due to its height (Passage 3).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 234, "end": 349, "text": "* Elastic potential energy: A stretched rubber band has elastic potential energy due to its stretching (Passage 3).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *this is not mentioned in Passage 3*\nGenerative:  * Elastic potential energy: A stretched rubber band has elastic potential energy due to its stretching (Passage 3).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 603, "end": 644, "text": "due to its mass and velocity (Passage 2).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *this is not mentioned in Passage 2*\nGenerative: due to the movement of water (Passage 2).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 682, "end": 723, "text": "due to the movement of water (Passage 2).", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *this is not mentioned in Passage 2*\nGenerative: due to the movement of water (Passage 2).", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Here are some examples of potential and kinetic energy based on the provided passages:\n\nPotential Energy:\n\n* Gravitational potential energy: A ball rolling down a hill has gravitational potential energy due to its height (Passage 3).\n* Elastic potential energy: A stretched rubber band has elastic potential energy due to its stretching (Passage 3).\n\nKinetic Energy:\n\n* An airplane has kinetic energy due to its large mass and fast velocity (Passage 1).\n* A baseball thrown by a pitcher has kinetic energy due to its small mass but fast velocity (Passage 1).\n* A car moving on a road has kinetic energy due to its mass and velocity (Passage 2).\n* A river flowing has kinetic energy due to the movement of water (Passage 2).\n* An athlete running has kinetic energy due to their motion (Passage 2).\n* A satellite in orbit around the Earth has kinetic energy due to its orbital motion (Passage 2).", "response_spans": [[0, 366], [368, 796], [797, 894]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8415674567222595, "(0, 16)": 0.8415674567222595, "(2, 0)": 0.8415674567222595, "(2, 16)": 0.8415674567222595, "(4, 0)": 0.8415674567222595, "(4, 16)": 0.8415674567222595, "(6, 0)": 0.8415674567222595, "(6, 16)": 0.7661291360855103, "(8, 0)": 0.8415674567222595, "(8, 16)": 0.8415674567222595, "(10, 0)": 0.8415674567222595, "(10, 16)": 0.8415674567222595, "(12, 0)": 0.8415674567222595, "(12, 16)": 0.8415674567222595, "(14, 0)": 0.8173956871032715, "(14, 16)": 0.7661291360855103, "(16, 0)": 0.8415674567222595, "(16, 16)": 0.8415674567222595, "(18, 0)": 0.8415674567222595, "(18, 16)": 0.8415674567222595, "(20, 0)": 0.8415674567222595, "(20, 16)": 0.8415674567222595, "(22, 0)": 0.8415674567222595, "(22, 16)": 0.8415674567222595, "(24, 0)": 0.8415674567222595, "(24, 16)": 0.8415674567222595, "(26, 0)": 0.8173956871032715, "(26, 16)": 0.8415674567222595, "(28, 0)": 0.8415674567222595, "(28, 16)": 0.8415674567222595, "(30, 0)": 0.8415674567222595, "(30, 16)": 0.8173956871032715}, "r_span": [348, 439], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00010055303573608398}}, {"prompt_attention_score": {"(0, 0)": 0.6354726552963257, "(0, 16)": 0.6354726552963257, "(2, 0)": 0.6354726552963257, "(2, 16)": 0.6354726552963257, "(4, 0)": 0.6354726552963257, "(4, 16)": 0.6354726552963257, "(6, 0)": 0.6354726552963257, "(6, 16)": 0.8899462819099426, "(8, 0)": 0.6354726552963257, "(8, 16)": 0.6354726552963257, "(10, 0)": 0.6354726552963257, "(10, 16)": 0.6354726552963257, "(12, 0)": 0.6354726552963257, "(12, 16)": 0.8899462819099426, "(14, 0)": 0.7479740977287292, "(14, 16)": 0.8899462819099426, "(16, 0)": 0.8899462819099426, "(16, 16)": 0.6354726552963257, "(18, 0)": 0.6354726552963257, "(18, 16)": 0.8899462819099426, "(20, 0)": 0.8899462819099426, "(20, 16)": 0.6354726552963257, "(22, 0)": 0.7479740977287292, "(22, 16)": 0.7904374599456787, "(24, 0)": 0.6354726552963257, "(24, 16)": 0.7904374599456787, "(26, 0)": 0.7479740977287292, "(26, 16)": 0.7904374599456787, "(28, 0)": 0.6354726552963257, "(28, 16)": 0.8899462819099426, "(30, 0)": 0.6354726552963257, "(30, 16)": 0.6354726552963257}, "r_span": [441, 556], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0017080903053283691}}, {"prompt_attention_score": {"(0, 0)": 0.6361905336380005, "(0, 16)": 0.6361905336380005, "(2, 0)": 0.6361905336380005, "(2, 16)": 0.6361905336380005, "(4, 0)": 0.6361905336380005, "(4, 16)": 0.6361905336380005, "(6, 0)": 0.6361905336380005, "(6, 16)": 0.6701910495758057, "(8, 0)": 0.6361905336380005, "(8, 16)": 0.6815541386604309, "(10, 0)": 0.6361905336380005, "(10, 16)": 0.6361905336380005, "(12, 0)": 0.6815541386604309, "(12, 16)": 0.6815541386604309, "(14, 0)": 0.6260198354721069, "(14, 16)": 0.6361905336380005, "(16, 0)": 0.6361905336380005, "(16, 16)": 0.6260198354721069, "(18, 0)": 0.6260198354721069, "(18, 16)": 0.6815541386604309, "(20, 0)": 0.6815541386604309, "(20, 16)": 0.6701910495758057, "(22, 0)": 0.6260198354721069, "(22, 16)": 0.6815541386604309, "(24, 0)": 0.6815541386604309, "(24, 16)": 0.6815541386604309, "(26, 0)": 0.6361905336380005, "(26, 16)": 0.6701910495758057, "(28, 0)": 0.6361905336380005, "(28, 16)": 0.6815541386604309, "(30, 0)": 0.6361905336380005, "(30, 16)": 0.6260198354721069}, "r_span": [557, 581], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001343846321105957}}]}, {"id": "14199", "source_id": "15286", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how you can make a hot water heater circulate:\n\n1. Install a recirculating pump: As described in passage 3, a recirculating pump can rapidly pull hot water from the water heater and send cool water from the hot water lines back to the water heater to be reheated and reused.\n2. Use a demand-based system: According to passage 3, demand systems can be controlled by the push of a button, a timer, or motion sensor. This means that the pump will only run when there is a demand for hot water, rather than constantly running.\n\nUnable to answer based on given passages. The passages do not provide specific instructions on how to make a hot water heater circulate, but rather describe the concept of circulation and the different types of systems used to achieve it.", "response_spans": [[0, 85], [87, 561], [563, 801]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.700346827507019, "(0, 16)": 0.700346827507019, "(2, 0)": 0.700346827507019, "(2, 16)": 0.700346827507019, "(4, 0)": 0.700346827507019, "(4, 16)": 0.700346827507019, "(6, 0)": 0.700346827507019, "(6, 16)": 0.7664923667907715, "(8, 0)": 0.700346827507019, "(8, 16)": 0.700346827507019, "(10, 0)": 0.700346827507019, "(10, 16)": 0.700346827507019, "(12, 0)": 0.700346827507019, "(12, 16)": 0.7664923667907715, "(14, 0)": 0.736591100692749, "(14, 16)": 0.700346827507019, "(16, 0)": 0.7664923667907715, "(16, 16)": 0.700346827507019, "(18, 0)": 0.700346827507019, "(18, 16)": 0.7664923667907715, "(20, 0)": 0.7664923667907715, "(20, 16)": 0.736591100692749, "(22, 0)": 0.736591100692749, "(22, 16)": 0.7664923667907715, "(24, 0)": 0.736591100692749, "(24, 16)": 0.7664923667907715, "(26, 0)": 0.736591100692749, "(26, 16)": 0.736591100692749, "(28, 0)": 0.700346827507019, "(28, 16)": 0.736591100692749, "(30, 0)": 0.736591100692749, "(30, 16)": 0.736591100692749}, "r_span": [370, 393], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00044041872024536133}}, {"prompt_attention_score": {"(0, 0)": 0.8850102424621582, "(0, 16)": 0.8850102424621582, "(2, 0)": 0.8850102424621582, "(2, 16)": 0.8850102424621582, "(4, 0)": 0.8850102424621582, "(4, 16)": 0.8850102424621582, "(6, 0)": 0.8850102424621582, "(6, 16)": 0.8850102424621582, "(8, 0)": 0.8850102424621582, "(8, 16)": 0.8850102424621582, "(10, 0)": 0.8850102424621582, "(10, 16)": 0.8850102424621582, "(12, 0)": 0.8850102424621582, "(12, 16)": 0.8850102424621582, "(14, 0)": 0.7662061452865601, "(14, 16)": 0.8850102424621582, "(16, 0)": 0.8850102424621582, "(16, 16)": 0.8850102424621582, "(18, 0)": 0.8850102424621582, "(18, 16)": 0.8850102424621582, "(20, 0)": 0.8850102424621582, "(20, 16)": 0.7662061452865601, "(22, 0)": 0.7662061452865601, "(22, 16)": 0.8850102424621582, "(24, 0)": 0.7662061452865601, "(24, 16)": 0.8850102424621582, "(26, 0)": 0.7662061452865601, "(26, 16)": 0.7662061452865601, "(28, 0)": 0.7662061452865601, "(28, 16)": 0.7662061452865601, "(30, 0)": 0.7662061452865601, "(30, 16)": 0.7662061452865601}, "r_span": [395, 512], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00034624338150024414}}, {"prompt_attention_score": {"(0, 0)": 0.737960934638977, "(0, 16)": 0.737960934638977, "(2, 0)": 0.737960934638977, "(2, 16)": 0.737960934638977, "(4, 0)": 0.737960934638977, "(4, 16)": 0.737960934638977, "(6, 0)": 0.737960934638977, "(6, 16)": 0.7798557281494141, "(8, 0)": 0.737960934638977, "(8, 16)": 0.7502982020378113, "(10, 0)": 0.737960934638977, "(10, 16)": 0.737960934638977, "(12, 0)": 0.737960934638977, "(12, 16)": 0.737960934638977, "(14, 0)": 0.7502982020378113, "(14, 16)": 0.737960934638977, "(16, 0)": 0.737960934638977, "(16, 16)": 0.737960934638977, "(18, 0)": 0.737960934638977, "(18, 16)": 0.737960934638977, "(20, 0)": 0.7798557281494141, "(20, 16)": 0.7502982020378113, "(22, 0)": 0.7502982020378113, "(22, 16)": 0.7798557281494141, "(24, 0)": 0.7502982020378113, "(24, 16)": 0.7798557281494141, "(26, 0)": 0.7502982020378113, "(26, 16)": 0.7502982020378113, "(28, 0)": 0.7502982020378113, "(28, 16)": 0.7502982020378113, "(30, 0)": 0.7502982020378113, "(30, 16)": 0.7502982020378113}, "r_span": [514, 563], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006669759750366211}}]}, {"id": "14211", "source_id": "15288", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the cause of watermelons to explode is not explicitly stated. However, it can be inferred that the buildup of gas inside the watermelon, caused by the rotting process, is the primary factor leading to the explosion. The passage suggests that the pressure inside the watermelon increases as the gas accumulates, eventually causing the skin to burst and releasing the gas in a sudden and forceful manner.\n\nTherefore, the answer to the question is:\n\nPassage 3 mentions that the gas inside the watermelon tries to escape through the skin, but since the skin is not strong enough to hold it, the gas builds up pressure until it explodes.", "response_spans": [[0, 477], [479, 664]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7995250821113586, "(0, 16)": 0.7995250821113586, "(2, 0)": 0.7995250821113586, "(2, 16)": 0.7995250821113586, "(4, 0)": 0.7995250821113586, "(4, 16)": 0.7995250821113586, "(6, 0)": 0.7995250821113586, "(6, 16)": 0.8339180946350098, "(8, 0)": 0.7995250821113586, "(8, 16)": 0.7995250821113586, "(10, 0)": 0.7995250821113586, "(10, 16)": 0.7995250821113586, "(12, 0)": 0.7995250821113586, "(12, 16)": 0.7995250821113586, "(14, 0)": 0.7132237553596497, "(14, 16)": 0.7995250821113586, "(16, 0)": 0.8339180946350098, "(16, 16)": 0.7995250821113586, "(18, 0)": 0.7995250821113586, "(18, 16)": 0.8339180946350098, "(20, 0)": 0.7995250821113586, "(20, 16)": 0.7132237553596497, "(22, 0)": 0.7132237553596497, "(22, 16)": 0.7995250821113586, "(24, 0)": 0.7132237553596497, "(24, 16)": 0.8339180946350098, "(26, 0)": 0.7132237553596497, "(26, 16)": 0.8339180946350098, "(28, 0)": 0.7132237553596497, "(28, 16)": 0.7132237553596497, "(30, 0)": 0.7132237553596497, "(30, 16)": 0.7132237553596497}, "r_span": [343, 457], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0022356510162353516}}, {"prompt_attention_score": {"(0, 0)": 0.8732805252075195, "(0, 16)": 0.8732805252075195, "(2, 0)": 0.8732805252075195, "(2, 16)": 0.8732805252075195, "(4, 0)": 0.8732805252075195, "(4, 16)": 0.8732805252075195, "(6, 0)": 0.8732805252075195, "(6, 16)": 0.7218866348266602, "(8, 0)": 0.8732805252075195, "(8, 16)": 0.8732805252075195, "(10, 0)": 0.8732805252075195, "(10, 16)": 0.8732805252075195, "(12, 0)": 0.7218866348266602, "(12, 16)": 0.8732805252075195, "(14, 0)": 0.724303126335144, "(14, 16)": 0.8732805252075195, "(16, 0)": 0.8732805252075195, "(16, 16)": 0.7218866348266602, "(18, 0)": 0.7218866348266602, "(18, 16)": 0.8732805252075195, "(20, 0)": 0.8732805252075195, "(20, 16)": 0.724303126335144, "(22, 0)": 0.724303126335144, "(22, 16)": 0.8732805252075195, "(24, 0)": 0.724303126335144, "(24, 16)": 0.8732805252075195, "(26, 0)": 0.724303126335144, "(26, 16)": 0.724303126335144, "(28, 0)": 0.724303126335144, "(28, 16)": 0.724303126335144, "(30, 0)": 0.724303126335144, "(30, 16)": 0.724303126335144}, "r_span": [459, 502], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00023996829986572266}}]}, {"id": "14283", "source_id": "15300", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 678, "end": 785, "text": "which suggests that the cost of other materials and labor for a second floor installation could be similar.", "meta": "HIGH INTRO OF NEW INFO\nIt includes a comparison of the cost of installing a second floor to the cost of installing carpet is not mentioned in the original sources.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 1062, "end": 1146, "text": "which could be used as a rough estimate for the cost of a second floor installation.", "meta": "HIGH INTRO OF NEW INFO\nIt interprets the cost of a ground-level deck from Passage 3 as a potential cost for a second floor installation is not mentioned in the original sources.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the average cost to install a second floor in a house can range from $100 to $400 per square foot, with a total cost of at least 20% more than building the same square footage at ground level. The exact cost will depend on factors such as the complexity of the addition, the quality of materials used, and local labor rates.\n\nFor example, according to Passage 1, the cost of hiring a remodeling contractor to build a second floor addition can range from $100 to $300 per square foot, depending on the complexity of the addition and the location. Similarly, Passage 2 provides a cost range of $3.74 to $4.83 per square foot for installing carpet, which suggests that the cost of other materials and labor for a second floor installation could be similar.\n\nHowever, Passage 3 provides a specific cost estimate for a ground-level deck of $30 per square foot, which may not directly apply to a second floor installation. Nonetheless, this passage does provide some insight into the overall cost range for a deck construction project, which could be used as a rough estimate for the cost of a second floor installation.\n\nOverall, based on the information provided in the passages, it is difficult to give an exact answer to the question without additional context or details about the specific project. If you have any further questions or require more detailed estimates, please let me know.", "response_spans": [[0, 356], [358, 785], [787, 1146], [1148, 1419]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7061363458633423, "(0, 16)": 0.7061363458633423, "(2, 0)": 0.7061363458633423, "(2, 16)": 0.7061363458633423, "(4, 0)": 0.7061363458633423, "(4, 16)": 0.7061363458633423, "(6, 0)": 0.7061363458633423, "(6, 16)": 0.8566585779190063, "(8, 0)": 0.7061363458633423, "(8, 16)": 0.7061363458633423, "(10, 0)": 0.3196874260902405, "(10, 16)": 0.3196874260902405, "(12, 0)": 0.7061363458633423, "(12, 16)": 0.8566585779190063, "(14, 0)": 0.8566585779190063, "(14, 16)": 0.3196874260902405, "(16, 0)": 0.8566585779190063, "(16, 16)": 0.7061363458633423, "(18, 0)": 0.3196874260902405, "(18, 16)": 0.8566585779190063, "(20, 0)": 0.8566585779190063, "(20, 16)": 0.8566585779190063, "(22, 0)": 0.8566585779190063, "(22, 16)": 0.8566585779190063, "(24, 0)": 0.8566585779190063, "(24, 16)": 0.8566585779190063, "(26, 0)": 0.8566585779190063, "(26, 16)": 0.8566585779190063, "(28, 0)": 0.8566585779190063, "(28, 16)": 0.8566585779190063, "(30, 0)": 0.8566585779190063, "(30, 16)": 0.8566585779190063}, "r_span": [602, 686], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 9.608268737792969e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7236325144767761, "(0, 16)": 0.7236325144767761, "(2, 0)": 0.7236325144767761, "(2, 16)": 0.7236325144767761, "(4, 0)": 0.7236325144767761, "(4, 16)": 0.7236325144767761, "(6, 0)": 0.7236325144767761, "(6, 16)": 0.929070234298706, "(8, 0)": 0.8077076077461243, "(8, 16)": 0.7236325144767761, "(10, 0)": 0.929070234298706, "(10, 16)": 0.7236325144767761, "(12, 0)": 0.929070234298706, "(12, 16)": 0.929070234298706, "(14, 0)": 0.929070234298706, "(14, 16)": 0.929070234298706, "(16, 0)": 0.929070234298706, "(16, 16)": 0.929070234298706, "(18, 0)": 0.929070234298706, "(18, 16)": 0.929070234298706, "(20, 0)": 0.929070234298706, "(20, 16)": 0.929070234298706, "(22, 0)": 0.929070234298706, "(22, 16)": 0.929070234298706, "(24, 0)": 0.929070234298706, "(24, 16)": 0.929070234298706, "(26, 0)": 0.929070234298706, "(26, 16)": 0.929070234298706, "(28, 0)": 0.929070234298706, "(28, 16)": 0.929070234298706, "(30, 0)": 0.929070234298706, "(30, 16)": 0.929070234298706}, "r_span": [688, 791], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0007098913192749023}}, {"prompt_attention_score": {"(0, 0)": 0.820635974407196, "(0, 16)": 0.820635974407196, "(2, 0)": 0.820635974407196, "(2, 16)": 0.820635974407196, "(4, 0)": 0.820635974407196, "(4, 16)": 0.820635974407196, "(6, 0)": 0.7725175023078918, "(6, 16)": 0.7725175023078918, "(8, 0)": 0.820635974407196, "(8, 16)": 0.820635974407196, "(10, 0)": 0.4055834114551544, "(10, 16)": 0.4055834114551544, "(12, 0)": 0.7725175023078918, "(12, 16)": 0.820635974407196, "(14, 0)": 0.7725175023078918, "(14, 16)": 0.4055834114551544, "(16, 0)": 0.820635974407196, "(16, 16)": 0.820635974407196, "(18, 0)": 0.7725175023078918, "(18, 16)": 0.820635974407196, "(20, 0)": 0.820635974407196, "(20, 16)": 0.7725175023078918, "(22, 0)": 0.7725175023078918, "(22, 16)": 0.820635974407196, "(24, 0)": 0.7725175023078918, "(24, 16)": 0.820635974407196, "(26, 0)": 0.7725175023078918, "(26, 16)": 0.7725175023078918, "(28, 0)": 0.7725175023078918, "(28, 16)": 0.7725175023078918, "(30, 0)": 0.7725175023078918, "(30, 16)": 0.7725175023078918}, "r_span": [793, 867], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001758277416229248}}, {"prompt_attention_score": {"(0, 0)": 0.5488901138305664, "(0, 16)": 0.5488901138305664, "(2, 0)": 0.5488901138305664, "(2, 16)": 0.5488901138305664, "(4, 0)": 0.7024056315422058, "(4, 16)": 0.7024056315422058, "(6, 0)": 0.5907207131385803, "(6, 16)": 0.7024056315422058, "(8, 0)": 0.5907207131385803, "(8, 16)": 0.5907207131385803, "(10, 0)": 0.7024056315422058, "(10, 16)": 0.7024056315422058, "(12, 0)": 0.7024056315422058, "(12, 16)": 0.7024056315422058, "(14, 0)": 0.5907207131385803, "(14, 16)": 0.7024056315422058, "(16, 0)": 0.7024056315422058, "(16, 16)": 0.5907207131385803, "(18, 0)": 0.5907207131385803, "(18, 16)": 0.7024056315422058, "(20, 0)": 0.7024056315422058, "(20, 16)": 0.5907207131385803, "(22, 0)": 0.5907207131385803, "(22, 16)": 0.7024056315422058, "(24, 0)": 0.5907207131385803, "(24, 16)": 0.7024056315422058, "(26, 0)": 0.5907207131385803, "(26, 16)": 0.5907207131385803, "(28, 0)": 0.5907207131385803, "(28, 16)": 0.5907207131385803, "(30, 0)": 0.5907207131385803, "(30, 16)": 0.5907207131385803}, "r_span": [869, 920], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001413881778717041}}]}, {"id": "14289", "source_id": "15301", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's how you can check if taxes were filed based on the provided passages:\n\nAccording to passage 1, you can use your mobile phone to check the status of a tax return through the IRS2Go app. This app is available for Apple users and allows you to handle taxes online. (Ref: Passage 1)\n\nPassage 2 provides three methods to check the status of a federal tax return, including online and phone options. You can check the status of your tax return online or by calling the IRS. (Ref: Passage 2)\n\nPassage 3 provides details on how to check the status of a tax return using tax software. You'll need your Social Security number, tax filing status, and the amount of any refund due. If you e-filed your return, you can check the status 24 hours after the IRS acknowledged receipt of your return. (Ref: Passage 3)\n\nBased on these passages, you can check the status of your tax return by using the IRS2Go app, calling the IRS, or using tax software that allows you to log into your account to check the status of your return. Unfortunately, the passages do not provide information on how to check the status of a tax return if it was not e-filed or if you did not receive an email confirmation from the software program used. Therefore, I am unable to answer your question based on the given passages.", "response_spans": [[0, 497], [499, 812], [814, 1299]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7405970692634583, "(0, 16)": 0.7405970692634583, "(2, 0)": 0.7405970692634583, "(2, 16)": 0.7405970692634583, "(4, 0)": 0.7405970692634583, "(4, 16)": 0.7405970692634583, "(6, 0)": 0.7405970692634583, "(6, 16)": 0.8421501517295837, "(8, 0)": 0.8275066614151001, "(8, 16)": 0.7405970692634583, "(10, 0)": 0.48356354236602783, "(10, 16)": 0.48356354236602783, "(12, 0)": 0.8275066614151001, "(12, 16)": 0.8275066614151001, "(14, 0)": 0.8421501517295837, "(14, 16)": 0.48356354236602783, "(16, 0)": 0.8421501517295837, "(16, 16)": 0.8421501517295837, "(18, 0)": 0.8421501517295837, "(18, 16)": 0.8421501517295837, "(20, 0)": 0.8421501517295837, "(20, 16)": 0.8421501517295837, "(22, 0)": 0.8421501517295837, "(22, 16)": 0.8421501517295837, "(24, 0)": 0.8421501517295837, "(24, 16)": 0.8421501517295837, "(26, 0)": 0.8421501517295837, "(26, 16)": 0.8421501517295837, "(28, 0)": 0.8421501517295837, "(28, 16)": 0.6837721467018127, "(30, 0)": 0.8421501517295837, "(30, 16)": 0.8421501517295837}, "r_span": [555, 683], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007586479187011719}}, {"prompt_attention_score": {"(0, 0)": 0.7959742546081543, "(0, 16)": 0.9350884556770325, "(2, 0)": 0.9350884556770325, "(2, 16)": 0.5062674283981323, "(4, 0)": 0.9350884556770325, "(4, 16)": 0.9350884556770325, "(6, 0)": 0.8271048069000244, "(6, 16)": 0.7959742546081543, "(8, 0)": 0.9350884556770325, "(8, 16)": 0.9350884556770325, "(10, 0)": 0.9350884556770325, "(10, 16)": 0.9350884556770325, "(12, 0)": 0.7959742546081543, "(12, 16)": 0.9350884556770325, "(14, 0)": 0.7959742546081543, "(14, 16)": 0.9350884556770325, "(16, 0)": 0.9350884556770325, "(16, 16)": 0.7959742546081543, "(18, 0)": 0.7959742546081543, "(18, 16)": 0.9350884556770325, "(20, 0)": 0.9350884556770325, "(20, 16)": 0.7959742546081543, "(22, 0)": 0.7959742546081543, "(22, 16)": 0.9350884556770325, "(24, 0)": 0.7959742546081543, "(24, 16)": 0.9350884556770325, "(26, 0)": 0.7959742546081543, "(26, 16)": 0.8037812113761902, "(28, 0)": 0.7959742546081543, "(28, 16)": 0.7959742546081543, "(30, 0)": 0.7959742546081543, "(30, 16)": 0.7959742546081543}, "r_span": [685, 766], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00038355588912963867}}, {"prompt_attention_score": {"(0, 0)": 0.7811852693557739, "(0, 16)": 0.7881949543952942, "(2, 0)": 0.7881949543952942, "(2, 16)": 0.7881949543952942, "(4, 0)": 0.7881949543952942, "(4, 16)": 0.7881949543952942, "(6, 0)": 0.7881949543952942, "(6, 16)": 0.7811852693557739, "(8, 0)": 0.7881949543952942, "(8, 16)": 0.7881949543952942, "(10, 0)": 0.513394832611084, "(10, 16)": 0.513394832611084, "(12, 0)": 0.7811852693557739, "(12, 16)": 0.7881949543952942, "(14, 0)": 0.7811852693557739, "(14, 16)": 0.513394832611084, "(16, 0)": 0.7513083219528198, "(16, 16)": 0.7811852693557739, "(18, 0)": 0.7811852693557739, "(18, 16)": 0.7881949543952942, "(20, 0)": 0.7881949543952942, "(20, 16)": 0.7811852693557739, "(22, 0)": 0.7811852693557739, "(22, 16)": 0.513394832611084, "(24, 0)": 0.7811852693557739, "(24, 16)": 0.7881949543952942, "(26, 0)": 0.7811852693557739, "(26, 16)": 0.7811852693557739, "(28, 0)": 0.7811852693557739, "(28, 16)": 0.7811852693557739, "(30, 0)": 0.7811852693557739, "(30, 16)": 0.7811852693557739}, "r_span": [768, 877], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003809332847595215}}]}, {"id": "14295", "source_id": "15302", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 822, "end": 913, "text": "such as using alternative energy sources, conserving energy, and reducing meat consumption.", "meta": "LOW INTRO OF NEW INFO\nPassages have no mention of this but may stand to be accurate and fits within the context of the question and passages. ", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the effect of carbon footprint is:\n\nPassage 1 states that carbon footprint measures the environmental impact of one's lifestyle and that even seemingly tiny changes can make a significant difference in reducing one's footprint.\n\nPassage 2 mentions that the average per capita carbon footprint is 6 tons per year, with a third of that created by automobile emissions.\n\nPassage 3 defines carbon footprint as the total amount of greenhouse gases produced by various human activities within a given time frame, and explains that different activities such as heating a home, eating food, and driving a car have a carbon footprint.\n\nTherefore, the effect of carbon footprint is that it measures the environmental impact of one's lifestyle and can be reduced by making changes to daily activities such as using alternative energy sources, conserving energy, and reducing meat consumption.", "response_spans": [[0, 398], [400, 657], [659, 913]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8124213218688965, "(0, 16)": 0.8124213218688965, "(2, 0)": 0.8124213218688965, "(2, 16)": 0.8124213218688965, "(4, 0)": 0.8124213218688965, "(4, 16)": 0.8124213218688965, "(6, 0)": 0.8124213218688965, "(6, 16)": 0.8831720352172852, "(8, 0)": 0.8124213218688965, "(8, 16)": 0.8124213218688965, "(10, 0)": 0.4067511558532715, "(10, 16)": 0.8124213218688965, "(12, 0)": 0.866352379322052, "(12, 16)": 0.8831720352172852, "(14, 0)": 0.8124213218688965, "(14, 16)": 0.4067511558532715, "(16, 0)": 0.7720293998718262, "(16, 16)": 0.8124213218688965, "(18, 0)": 0.4067511558532715, "(18, 16)": 0.866352379322052, "(20, 0)": 0.866352379322052, "(20, 16)": 0.8124213218688965, "(22, 0)": 0.866352379322052, "(22, 16)": 0.866352379322052, "(24, 0)": 0.866352379322052, "(24, 16)": 0.866352379322052, "(26, 0)": 0.866352379322052, "(26, 16)": 0.866352379322052, "(28, 0)": 0.866352379322052, "(28, 16)": 0.8124213218688965, "(30, 0)": 0.866352379322052, "(30, 16)": 0.866352379322052}, "r_span": [445, 538], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009337067604064941}}, {"prompt_attention_score": {"(0, 0)": 0.9183616638183594, "(0, 16)": 0.9183616638183594, "(2, 0)": 0.9183616638183594, "(2, 16)": 0.9183616638183594, "(4, 0)": 0.9183616638183594, "(4, 16)": 0.9183616638183594, "(6, 0)": 0.9183616638183594, "(6, 16)": 0.9183616638183594, "(8, 0)": 0.9183616638183594, "(8, 16)": 0.9183616638183594, "(10, 0)": 0.9183616638183594, "(10, 16)": 0.9183616638183594, "(12, 0)": 0.9183616638183594, "(12, 16)": 0.9183616638183594, "(14, 0)": 0.9183616638183594, "(14, 16)": 0.9183616638183594, "(16, 0)": 0.9183616638183594, "(16, 16)": 0.9183616638183594, "(18, 0)": 0.8162065744400024, "(18, 16)": 0.9183616638183594, "(20, 0)": 0.9183616638183594, "(20, 16)": 0.9183616638183594, "(22, 0)": 0.8162065744400024, "(22, 16)": 0.9183616638183594, "(24, 0)": 0.9183616638183594, "(24, 16)": 0.9183616638183594, "(26, 0)": 0.8162065744400024, "(26, 16)": 0.9183616638183594, "(28, 0)": 0.8162065744400024, "(28, 16)": 0.9183616638183594, "(30, 0)": 0.8162065744400024, "(30, 16)": 0.8162065744400024}, "r_span": [540, 594], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007651448249816895}}, {"prompt_attention_score": {"(0, 0)": 0.7933942079544067, "(0, 16)": 0.7933942079544067, "(2, 0)": 0.7933942079544067, "(2, 16)": 0.3600568175315857, "(4, 0)": 0.3600568175315857, "(4, 16)": 0.7933942079544067, "(6, 0)": 0.7933942079544067, "(6, 16)": 0.8355634808540344, "(8, 0)": 0.7933942079544067, "(8, 16)": 0.7933942079544067, "(10, 0)": 0.3600568175315857, "(10, 16)": 0.7933942079544067, "(12, 0)": 0.3600568175315857, "(12, 16)": 0.8355634808540344, "(14, 0)": 0.7933942079544067, "(14, 16)": 0.7933942079544067, "(16, 0)": 0.7694802284240723, "(16, 16)": 0.3600568175315857, "(18, 0)": 0.3600568175315857, "(18, 16)": 0.8355634808540344, "(20, 0)": 0.8355634808540344, "(20, 16)": 0.7933942079544067, "(22, 0)": 0.8355634808540344, "(22, 16)": 0.8355634808540344, "(24, 0)": 0.7933942079544067, "(24, 16)": 0.7933942079544067, "(26, 0)": 0.8355634808540344, "(26, 16)": 0.7933942079544067, "(28, 0)": 0.8355634808540344, "(28, 16)": 0.7933942079544067, "(30, 0)": 0.8355634808540344, "(30, 16)": 0.8355634808540344}, "r_span": [596, 645], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005459785461425781}}]}, {"id": "14325", "source_id": "15308", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, patterned rollers can work effectively for various applications such as:\n\n1. Creating random patterns on walls for faux finishing techniques (Passage 1).\n2. Stimulating the skin and improving its appearance by using with serums or moisturizers (Passage 2).\n3. Creating unique textures on walls by stretching and twisting rubber bands on a basic texture roller (Passage 3).\n\nTherefore, the answer to the question is: Patterned rollers can work well for various purposes, depending on the context and application.", "response_spans": [[0, 404], [406, 543]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7523975968360901, "(0, 16)": 0.7523975968360901, "(2, 0)": 0.7523975968360901, "(2, 16)": 0.7523975968360901, "(4, 0)": 0.7523975968360901, "(4, 16)": 0.7523975968360901, "(6, 0)": 0.7523975968360901, "(6, 16)": 0.8784662485122681, "(8, 0)": 0.7523975968360901, "(8, 16)": 0.7523975968360901, "(10, 0)": 0.424276202917099, "(10, 16)": 0.7523975968360901, "(12, 0)": 0.7523975968360901, "(12, 16)": 0.7523975968360901, "(14, 0)": 0.8784662485122681, "(14, 16)": 0.424276202917099, "(16, 0)": 0.8784662485122681, "(16, 16)": 0.7523975968360901, "(18, 0)": 0.424276202917099, "(18, 16)": 0.8784662485122681, "(20, 0)": 0.8784662485122681, "(20, 16)": 0.8784662485122681, "(22, 0)": 0.8784662485122681, "(22, 16)": 0.7523975968360901, "(24, 0)": 0.7523975968360901, "(24, 16)": 0.8784662485122681, "(26, 0)": 0.8784662485122681, "(26, 16)": 0.7523975968360901, "(28, 0)": 0.424276202917099, "(28, 16)": 0.7523975968360901, "(30, 0)": 0.7523975968360901, "(30, 16)": 0.7523975968360901}, "r_span": [455, 554], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007620453834533691}}, {"prompt_attention_score": {"(0, 0)": 0.6563357710838318, "(0, 16)": 0.6563357710838318, "(2, 0)": 0.6563357710838318, "(2, 16)": 0.6563357710838318, "(4, 0)": 0.6563357710838318, "(4, 16)": 0.6563357710838318, "(6, 0)": 0.6563357710838318, "(6, 16)": 0.8014164566993713, "(8, 0)": 0.6563357710838318, "(8, 16)": 0.6563357710838318, "(10, 0)": 0.46325546503067017, "(10, 16)": 0.46325546503067017, "(12, 0)": 0.46325546503067017, "(12, 16)": 0.46325546503067017, "(14, 0)": 0.8014164566993713, "(14, 16)": 0.46325546503067017, "(16, 0)": 0.8014164566993713, "(16, 16)": 0.6563357710838318, "(18, 0)": 0.8014164566993713, "(18, 16)": 0.8014164566993713, "(20, 0)": 0.8014164566993713, "(20, 16)": 0.6006799936294556, "(22, 0)": 0.8014164566993713, "(22, 16)": 0.8014164566993713, "(24, 0)": 0.8014164566993713, "(24, 16)": 0.8014164566993713, "(26, 0)": 0.46325546503067017, "(26, 16)": 0.8014164566993713, "(28, 0)": 0.6563357710838318, "(28, 16)": 0.6563357710838318, "(30, 0)": 0.6563357710838318, "(30, 16)": 0.8014164566993713}, "r_span": [556, 584], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003681182861328125}}]}, {"id": "14355", "source_id": "15313", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how to boil potatoes for easy peeling:\n\nPassage 1 recommends boiling the potatoes until they are tender, then transferring them to an ice water bath to stop the cooking process. After cooling, the skin can be easily peeled off. This method takes 15 minutes to cook the potatoes and 5 seconds to peel each one.\n\nPassage 2 suggests peeling the potatoes before cooking, as their skin can be tough and papery. However, no specific instructions are provided for peeling.\n\nPassage 3 provides a step-by-step guide for peeling cooked potatoes. The method involves scoring the potatoes all the way around the center, boiling them for about 15 minutes, then placing them in an ice water bath to cool. Once cooled, the skin can be easily removed. This method takes about 30 minutes total time.\n\nTherefore, based on the provided passages, the best way to boil potatoes for easy peeling is to boil them until tender, then transfer them to an ice water bath to stop the cooking process and make the skin easier to remove. Scoring the potatoes before boiling can also help loosen the skin for easier peeling.", "response_spans": [[0, 504], [506, 821], [823, 1132]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8578183650970459, "(0, 16)": 0.8578183650970459, "(2, 0)": 0.8578183650970459, "(2, 16)": 0.8578183650970459, "(4, 0)": 0.8578183650970459, "(4, 16)": 0.8578183650970459, "(6, 0)": 0.8578183650970459, "(6, 16)": 0.9467685222625732, "(8, 0)": 0.8578183650970459, "(8, 16)": 0.8578183650970459, "(10, 0)": 0.8578183650970459, "(10, 16)": 0.8578183650970459, "(12, 0)": 0.8578183650970459, "(12, 16)": 0.9467685222625732, "(14, 0)": 0.8578183650970459, "(14, 16)": 0.9467685222625732, "(16, 0)": 0.9467685222625732, "(16, 16)": 0.8578183650970459, "(18, 0)": 0.8578183650970459, "(18, 16)": 0.9467685222625732, "(20, 0)": 0.9467685222625732, "(20, 16)": 0.8578183650970459, "(22, 0)": 0.8578183650970459, "(22, 16)": 0.9467685222625732, "(24, 0)": 0.8578183650970459, "(24, 16)": 0.9467685222625732, "(26, 0)": 0.8578183650970459, "(26, 16)": 0.8578183650970459, "(28, 0)": 0.8578183650970459, "(28, 16)": 0.8578183650970459, "(30, 0)": 0.8578183650970459, "(30, 16)": 0.8578183650970459}, "r_span": [449, 579], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000594019889831543}}, {"prompt_attention_score": {"(0, 0)": 0.8626933693885803, "(0, 16)": 0.8626933693885803, "(2, 0)": 0.8626933693885803, "(2, 16)": 0.8626933693885803, "(4, 0)": 0.8626933693885803, "(4, 16)": 0.8626933693885803, "(6, 0)": 0.8626933693885803, "(6, 16)": 0.9022650122642517, "(8, 0)": 0.8626933693885803, "(8, 16)": 0.8626933693885803, "(10, 0)": 0.8626933693885803, "(10, 16)": 0.8626933693885803, "(12, 0)": 0.8626933693885803, "(12, 16)": 0.8626933693885803, "(14, 0)": 0.8626933693885803, "(14, 16)": 0.8626933693885803, "(16, 0)": 0.8626933693885803, "(16, 16)": 0.8626933693885803, "(18, 0)": 0.8626933693885803, "(18, 16)": 0.8626933693885803, "(20, 0)": 0.8626933693885803, "(20, 16)": 0.8626933693885803, "(22, 0)": 0.8626933693885803, "(22, 16)": 0.8626933693885803, "(24, 0)": 0.8626933693885803, "(24, 16)": 0.8626933693885803, "(26, 0)": 0.8626933693885803, "(26, 16)": 0.8626933693885803, "(28, 0)": 0.8626933693885803, "(28, 16)": 0.8626933693885803, "(30, 0)": 0.8626933693885803, "(30, 16)": 0.8626933693885803}, "r_span": [581, 659], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00024759769439697266}}, {"prompt_attention_score": {"(0, 0)": 0.8194478154182434, "(0, 16)": 0.8194478154182434, "(2, 0)": 0.8194478154182434, "(2, 16)": 0.8194478154182434, "(4, 0)": 0.8194478154182434, "(4, 16)": 0.8194478154182434, "(6, 0)": 0.8194478154182434, "(6, 16)": 0.8853543996810913, "(8, 0)": 0.8194478154182434, "(8, 16)": 0.8194478154182434, "(10, 0)": 0.8194478154182434, "(10, 16)": 0.8194478154182434, "(12, 0)": 0.8194478154182434, "(12, 16)": 0.8194478154182434, "(14, 0)": 0.8194478154182434, "(14, 16)": 0.37497997283935547, "(16, 0)": 0.8853543996810913, "(16, 16)": 0.8194478154182434, "(18, 0)": 0.8194478154182434, "(18, 16)": 0.8853543996810913, "(20, 0)": 0.8853543996810913, "(20, 16)": 0.8194478154182434, "(22, 0)": 0.8194478154182434, "(22, 16)": 0.8853543996810913, "(24, 0)": 0.8194478154182434, "(24, 16)": 0.8194478154182434, "(26, 0)": 0.8194478154182434, "(26, 16)": 0.8194478154182434, "(28, 0)": 0.8194478154182434, "(28, 16)": 0.8194478154182434, "(30, 0)": 0.8194478154182434, "(30, 16)": 0.8194478154182434}, "r_span": [661, 733], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00038117170333862305}}]}, {"id": "14367", "source_id": "15315", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here's how to get rid of ticks from dogs:\n\n1. Check inside and behind the dog's ears and around its eyes, which are common hiding places for ticks. (Passage 1)\n2. Use tick control products recommended by a veterinarian to prevent ticks from attaching to the dog. (Passage 2)\n3. Remove ticks from the dog using a pair of tweezers to grasp the head of the tick where it attaches to the skin. (Passage 1)\n\nUnable to answer based on the given passages whether there are any specific products or methods for getting rid of ticks from dogs that are already infested.", "response_spans": [[0, 433], [435, 592]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7075027227401733, "(0, 16)": 0.7075027227401733, "(2, 0)": 0.7075027227401733, "(2, 16)": 0.7075027227401733, "(4, 0)": 0.7075027227401733, "(4, 16)": 0.7075027227401733, "(6, 0)": 0.7075027227401733, "(6, 16)": 0.875821590423584, "(8, 0)": 0.7075027227401733, "(8, 16)": 0.7075027227401733, "(10, 0)": 0.3460862338542938, "(10, 16)": 0.7075027227401733, "(12, 0)": 0.7075027227401733, "(12, 16)": 0.875821590423584, "(14, 0)": 0.7075027227401733, "(14, 16)": 0.3460862338542938, "(16, 0)": 0.875821590423584, "(16, 16)": 0.875821590423584, "(18, 0)": 0.875821590423584, "(18, 16)": 0.875821590423584, "(20, 0)": 0.875821590423584, "(20, 16)": 0.7075027227401733, "(22, 0)": 0.7075027227401733, "(22, 16)": 0.875821590423584, "(24, 0)": 0.7075027227401733, "(24, 16)": 0.875821590423584, "(26, 0)": 0.875821590423584, "(26, 16)": 0.875821590423584, "(28, 0)": 0.7075027227401733, "(28, 16)": 0.7075027227401733, "(30, 0)": 0.875821590423584, "(30, 16)": 0.875821590423584}, "r_span": [568, 689], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0025032758712768555}}, {"prompt_attention_score": {"(0, 0)": 0.7133105993270874, "(0, 16)": 0.7133105993270874, "(2, 0)": 0.7133105993270874, "(2, 16)": 0.7133105993270874, "(4, 0)": 0.7133105993270874, "(4, 16)": 0.7133105993270874, "(6, 0)": 0.7133105993270874, "(6, 16)": 0.8408917188644409, "(8, 0)": 0.7133105993270874, "(8, 16)": 0.7133105993270874, "(10, 0)": 0.5468083620071411, "(10, 16)": 0.5468083620071411, "(12, 0)": 0.5468083620071411, "(12, 16)": 0.5468083620071411, "(14, 0)": 0.7133105993270874, "(14, 16)": 0.5468083620071411, "(16, 0)": 0.5468083620071411, "(16, 16)": 0.7133105993270874, "(18, 0)": 0.7437692880630493, "(18, 16)": 0.5468083620071411, "(20, 0)": 0.7350450158119202, "(20, 16)": 0.7133105993270874, "(22, 0)": 0.7437692880630493, "(22, 16)": 0.7133105993270874, "(24, 0)": 0.7133105993270874, "(24, 16)": 0.7133105993270874, "(26, 0)": 0.7437692880630493, "(26, 16)": 0.7133105993270874, "(28, 0)": 0.7437692880630493, "(28, 16)": 0.7133105993270874, "(30, 0)": 0.7437692880630493, "(30, 16)": 0.7437692880630493}, "r_span": [691, 723], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007153153419494629}}]}, {"id": "14379", "source_id": "15317", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to make ribs:\n\nTo grill the ribs:\n\n1. Heat a gas or charcoal grill to medium temperature (350¬∞F to 450¬∞F).\n2. Remove the ribs from the foil, place them meaty-side up on the grill, and brush them with some of the sauce.\n3. Cover the grill and cook for 5 minutes.\n4. Flip and brush the ribs and cook for another 5 minutes.\n5. Continue to cook, flipping and brushing every 5 minutes, until the sauce has thickened and the ribs are heated through and have grill marks, for a total grilling time of 20 minutes.\n\nTo prepare the ribs before grilling:\n\n1. Lay the ribs on top of the rack in a single layer.\n2. Season the ribs by mixing the mustard and liquid smoke (if using), and brushing the ribs on both sides.\n3. Sprinkle the ribs with the dry rub and pat gently to make sure the rub adheres to the rib meat.\n\nFor oven-cooked BBQ ribs:\n\n1. Remove the membrane from the bottom of the ribs.\n2. Put the ribs in a resealable bag.\n3. Add sufficient BBQ sauce to cover the ribs.\n4. Line the baking pan with heavy-duty foil.\n5. Place the ribs in the baking pan and bake at 350¬∞F for 2-3 hours, or until the ribs are tender and the meat starts to pull away from the bone.", "response_spans": [[0, 77], [59, 549], [551, 875], [877, 1203]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7709614634513855, "(0, 16)": 0.7709614634513855, "(2, 0)": 0.7709614634513855, "(2, 16)": 0.7709614634513855, "(4, 0)": 0.7709614634513855, "(4, 16)": 0.7709614634513855, "(6, 0)": 0.7709614634513855, "(6, 16)": 0.7953172326087952, "(8, 0)": 0.7709614634513855, "(8, 16)": 0.7709614634513855, "(10, 0)": 0.7709614634513855, "(10, 16)": 0.7709614634513855, "(12, 0)": 0.7709614634513855, "(12, 16)": 0.7883485555648804, "(14, 0)": 0.7709614634513855, "(14, 16)": 0.7709614634513855, "(16, 0)": 0.7883485555648804, "(16, 16)": 0.7709614634513855, "(18, 0)": 0.7709614634513855, "(18, 16)": 0.7883485555648804, "(20, 0)": 0.7953172326087952, "(20, 16)": 0.7709614634513855, "(22, 0)": 0.7709614634513855, "(22, 16)": 0.7883485555648804, "(24, 0)": 0.7709614634513855, "(24, 16)": 0.7953172326087952, "(26, 0)": 0.7709614634513855, "(26, 16)": 0.7953172326087952, "(28, 0)": 0.7709614634513855, "(28, 16)": 0.7709614634513855, "(30, 0)": 0.7709614634513855, "(30, 16)": 0.7709614634513855}, "r_span": [447, 472], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00014775991439819336}}, {"prompt_attention_score": {"(0, 0)": 0.7703549861907959, "(0, 16)": 0.7703549861907959, "(2, 0)": 0.7703549861907959, "(2, 16)": 0.7703549861907959, "(4, 0)": 0.7703549861907959, "(4, 16)": 0.7703549861907959, "(6, 0)": 0.7703549861907959, "(6, 16)": 0.9458386301994324, "(8, 0)": 0.7703549861907959, "(8, 16)": 0.7703549861907959, "(10, 0)": 0.7703549861907959, "(10, 16)": 0.7703549861907959, "(12, 0)": 0.7703549861907959, "(12, 16)": 0.9458386301994324, "(14, 0)": 0.7703549861907959, "(14, 16)": 0.9458386301994324, "(16, 0)": 0.9458386301994324, "(16, 16)": 0.7703549861907959, "(18, 0)": 0.7703549861907959, "(18, 16)": 0.9458386301994324, "(20, 0)": 0.9458386301994324, "(20, 16)": 0.7703549861907959, "(22, 0)": 0.7703549861907959, "(22, 16)": 0.9458386301994324, "(24, 0)": 0.9458386301994324, "(24, 16)": 0.9458386301994324, "(26, 0)": 0.7703549861907959, "(26, 16)": 0.9458386301994324, "(28, 0)": 0.7703549861907959, "(28, 16)": 0.7703549861907959, "(30, 0)": 0.9458386301994324, "(30, 16)": 0.7703549861907959}, "r_span": [465, 623], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0026033520698547363}}, {"prompt_attention_score": {"(0, 0)": 0.7854731678962708, "(0, 16)": 0.7854731678962708, "(2, 0)": 0.7854731678962708, "(2, 16)": 0.7854731678962708, "(4, 0)": 0.7854731678962708, "(4, 16)": 0.7854731678962708, "(6, 0)": 0.7854731678962708, "(6, 16)": 0.8940678834915161, "(8, 0)": 0.7854731678962708, "(8, 16)": 0.7854731678962708, "(10, 0)": 0.7854731678962708, "(10, 16)": 0.7854731678962708, "(12, 0)": 0.7854731678962708, "(12, 16)": 0.8940678834915161, "(14, 0)": 0.7854731678962708, "(14, 16)": 0.7854731678962708, "(16, 0)": 0.7854731678962708, "(16, 16)": 0.7854731678962708, "(18, 0)": 0.7854731678962708, "(18, 16)": 0.8940678834915161, "(20, 0)": 0.8940678834915161, "(20, 16)": 0.7854731678962708, "(22, 0)": 0.7854731678962708, "(22, 16)": 0.8940678834915161, "(24, 0)": 0.8051694631576538, "(24, 16)": 0.8940678834915161, "(26, 0)": 0.7854731678962708, "(26, 16)": 0.7854731678962708, "(28, 0)": 0.7854731678962708, "(28, 16)": 0.7854731678962708, "(30, 0)": 0.8940678834915161, "(30, 16)": 0.8051694631576538}, "r_span": [625, 726], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 8.463859558105469e-05}}, {"prompt_attention_score": {"(0, 0)": 0.8392766714096069, "(0, 16)": 0.8392766714096069, "(2, 0)": 0.8392766714096069, "(2, 16)": 0.8392766714096069, "(4, 0)": 0.8392766714096069, "(4, 16)": 0.8392766714096069, "(6, 0)": 0.8392766714096069, "(6, 16)": 0.8392766714096069, "(8, 0)": 0.8392766714096069, "(8, 16)": 0.8392766714096069, "(10, 0)": 0.8392766714096069, "(10, 16)": 0.8392766714096069, "(12, 0)": 0.8392766714096069, "(12, 16)": 0.8392766714096069, "(14, 0)": 0.8392766714096069, "(14, 16)": 0.8392766714096069, "(16, 0)": 0.8392766714096069, "(16, 16)": 0.8392766714096069, "(18, 0)": 0.8392766714096069, "(18, 16)": 0.8392766714096069, "(20, 0)": 0.8392766714096069, "(20, 16)": 0.8392766714096069, "(22, 0)": 0.8392766714096069, "(22, 16)": 0.8392766714096069, "(24, 0)": 0.8392766714096069, "(24, 16)": 0.8392766714096069, "(26, 0)": 0.8392766714096069, "(26, 16)": 0.8392766714096069, "(28, 0)": 0.8392766714096069, "(28, 16)": 0.8392766714096069, "(30, 0)": 0.8392766714096069, "(30, 16)": 0.7665276527404785}, "r_span": [728, 837], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0019550323486328125}}]}, {"id": "14397", "source_id": "15320", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 472, "end": 506, "text": "a combination of diet and exercise", "meta": "HIGH INTRO OF NEW INFO\nIt not mentioned in the original sources that weight loss is through \"a combination of diet and exercise.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the answer to the question \"When you have a bowel movement, do you lose weight?\" is:\n\nUnable to answer based on given passages.\n\nThe passages do not provide any information about weight loss associated with bowel movements. In fact, passage 3 specifically states that a decrease in body weight after having a bowel movement does not come from a loss of body fat in stools. Instead, weight loss comes from creating a calorie deficit through a combination of diet and exercise. Therefore, the answer to the question cannot be determined based on the provided passages.", "response_spans": [[0, 159], [161, 598]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6606467962265015, "(0, 16)": 0.6606467962265015, "(2, 0)": 0.6606467962265015, "(2, 16)": 0.6606467962265015, "(4, 0)": 0.6606467962265015, "(4, 16)": 0.830230176448822, "(6, 0)": 0.830230176448822, "(6, 16)": 0.8100433349609375, "(8, 0)": 0.6652711629867554, "(8, 16)": 0.830230176448822, "(10, 0)": 0.830230176448822, "(10, 16)": 0.830230176448822, "(12, 0)": 0.6606467962265015, "(12, 16)": 0.830230176448822, "(14, 0)": 0.6652711629867554, "(14, 16)": 0.830230176448822, "(16, 0)": 0.8100433349609375, "(16, 16)": 0.6652711629867554, "(18, 0)": 0.830230176448822, "(18, 16)": 0.8100433349609375, "(20, 0)": 0.8100433349609375, "(20, 16)": 0.6652711629867554, "(22, 0)": 0.6652711629867554, "(22, 16)": 0.8100433349609375, "(24, 0)": 0.6652711629867554, "(24, 16)": 0.830230176448822, "(26, 0)": 0.6652711629867554, "(26, 16)": 0.6652711629867554, "(28, 0)": 0.6652711629867554, "(28, 16)": 0.6652711629867554, "(30, 0)": 0.6652711629867554, "(30, 16)": 0.6652711629867554}, "r_span": [538, 579], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012195706367492676}}, {"prompt_attention_score": {"(0, 0)": 0.8926781415939331, "(0, 16)": 0.8926781415939331, "(2, 0)": 0.8926781415939331, "(2, 16)": 0.8926781415939331, "(4, 0)": 0.8926781415939331, "(4, 16)": 0.8926781415939331, "(6, 0)": 0.8926781415939331, "(6, 16)": 0.8926781415939331, "(8, 0)": 0.8926781415939331, "(8, 16)": 0.8926781415939331, "(10, 0)": 0.8926781415939331, "(10, 16)": 0.8926781415939331, "(12, 0)": 0.8926781415939331, "(12, 16)": 0.8926781415939331, "(14, 0)": 0.5088634490966797, "(14, 16)": 0.8926781415939331, "(16, 0)": 0.8926781415939331, "(16, 16)": 0.8355734348297119, "(18, 0)": 0.8355734348297119, "(18, 16)": 0.8926781415939331, "(20, 0)": 0.8926781415939331, "(20, 16)": 0.5088634490966797, "(22, 0)": 0.8355734348297119, "(22, 16)": 0.8926781415939331, "(24, 0)": 0.8355734348297119, "(24, 16)": 0.8926781415939331, "(26, 0)": 0.8355734348297119, "(26, 16)": 0.8926781415939331, "(28, 0)": 0.8355734348297119, "(28, 16)": 0.8355734348297119, "(30, 0)": 0.8355734348297119, "(30, 16)": 0.8355734348297119}, "r_span": [581, 670], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -3.331899642944336e-05}}]}, {"id": "14469", "source_id": "15332", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 384, "end": 521, "text": "* The War brought political changes, including the abolition of slavery and the establishment of the first federal income tax (Passage 3)", "meta": "HIGH INTRO OF NEW INFO\nThe abolition of slavery and the establishment of the first federal income tax as political effects are not mentioned in the original sources.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some political, economic, and social effects of immigration on the United States:\n\nPolitical Effects:\n\n* Immigration has shaped the United States as a nation since its founding (Passage 1)\n* The Civil War challenged the country with issues such as crop lien work contracts, segregation, and unresolved problems with seceded states (Passage 2)\n* The War brought political changes, including the abolition of slavery and the establishment of the first federal income tax (Passage 3)\n\nEconomic Effects:\n\n* Immigration has contributed to the country's economic growth and diversification (Passage 1)\n* The South's transition to a market economy after the Civil War led to industrialization and the rise of large economic enterprises (Passage 3)\n\nSocial Effects:\n\n* Immigrants have helped shape the country's cultural identity and demographics (Passage 1)\n* The post-Civil War period saw the settlement of freed slaves with their former owners, leading to issues of segregation and discrimination (Passage 2)\n\nUnable to answer based on given passages.", "response_spans": [[0, 142], [124, 540], [523, 798], [783, 1087]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6334020495414734, "(0, 16)": 0.6334020495414734, "(2, 0)": 0.6334020495414734, "(2, 16)": 0.6334020495414734, "(4, 0)": 0.6334020495414734, "(4, 16)": 0.6334020495414734, "(6, 0)": 0.6334020495414734, "(6, 16)": 0.7682403922080994, "(8, 0)": 0.6334020495414734, "(8, 16)": 0.6334020495414734, "(10, 0)": 0.6334020495414734, "(10, 16)": 0.6334020495414734, "(12, 0)": 0.6334020495414734, "(12, 16)": 0.7682403922080994, "(14, 0)": 0.6334020495414734, "(14, 16)": 0.6334020495414734, "(16, 0)": 0.7682403922080994, "(16, 16)": 0.6334020495414734, "(18, 0)": 0.6334020495414734, "(18, 16)": 0.7682403922080994, "(20, 0)": 0.7682403922080994, "(20, 16)": 0.6334020495414734, "(22, 0)": 0.7682403922080994, "(22, 16)": 0.7682403922080994, "(24, 0)": 0.7682403922080994, "(24, 16)": 0.7682403922080994, "(26, 0)": 0.7682403922080994, "(26, 16)": 0.7682403922080994, "(28, 0)": 0.7682403922080994, "(28, 16)": 0.7682403922080994, "(30, 0)": 0.7682403922080994, "(30, 16)": 0.7682403922080994}, "r_span": [384, 418], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007828474044799805}}, {"prompt_attention_score": {"(0, 0)": 0.7578373551368713, "(0, 16)": 0.7578373551368713, "(2, 0)": 0.7578373551368713, "(2, 16)": 0.7578373551368713, "(4, 0)": 0.7578373551368713, "(4, 16)": 0.7578373551368713, "(6, 0)": 0.7578373551368713, "(6, 16)": 0.782996416091919, "(8, 0)": 0.7578373551368713, "(8, 16)": 0.7578373551368713, "(10, 0)": 0.7578373551368713, "(10, 16)": 0.7578373551368713, "(12, 0)": 0.7578373551368713, "(12, 16)": 0.782996416091919, "(14, 0)": 0.7578373551368713, "(14, 16)": 0.7578373551368713, "(16, 0)": 0.782996416091919, "(16, 16)": 0.7578373551368713, "(18, 0)": 0.7578373551368713, "(18, 16)": 0.782996416091919, "(20, 0)": 0.782996416091919, "(20, 16)": 0.7578373551368713, "(22, 0)": 0.7943460941314697, "(22, 16)": 0.782996416091919, "(24, 0)": 0.7943460941314697, "(24, 16)": 0.782996416091919, "(26, 0)": 0.7943460941314697, "(26, 16)": 0.782996416091919, "(28, 0)": 0.7943460941314697, "(28, 16)": 0.7943460941314697, "(30, 0)": 0.7943460941314697, "(30, 16)": 0.7943460941314697}, "r_span": [412, 522], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.000295102596282959}}, {"prompt_attention_score": {"(0, 0)": 0.8099991679191589, "(0, 16)": 0.8099991679191589, "(2, 0)": 0.8099991679191589, "(2, 16)": 0.8099991679191589, "(4, 0)": 0.8099991679191589, "(4, 16)": 0.8099991679191589, "(6, 0)": 0.8099991679191589, "(6, 16)": 0.6933876872062683, "(8, 0)": 0.8099991679191589, "(8, 16)": 0.8099991679191589, "(10, 0)": 0.8099991679191589, "(10, 16)": 0.8099991679191589, "(12, 0)": 0.8099991679191589, "(12, 16)": 0.8099991679191589, "(14, 0)": 0.8099991679191589, "(14, 16)": 0.8099991679191589, "(16, 0)": 0.8099991679191589, "(16, 16)": 0.8099991679191589, "(18, 0)": 0.8099991679191589, "(18, 16)": 0.8099991679191589, "(20, 0)": 0.8099991679191589, "(20, 16)": 0.8099991679191589, "(22, 0)": 0.6933876872062683, "(22, 16)": 0.8099991679191589, "(24, 0)": 0.8099991679191589, "(24, 16)": 0.8099991679191589, "(26, 0)": 0.6933876872062683, "(26, 16)": 0.6933876872062683, "(28, 0)": 0.6933876872062683, "(28, 16)": 0.6933876872062683, "(30, 0)": 0.6933876872062683, "(30, 16)": 0.6933876872062683}, "r_span": [516, 587], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002747774124145508}}, {"prompt_attention_score": {"(0, 0)": 0.7106944918632507, "(0, 16)": 0.7106944918632507, "(2, 0)": 0.7106944918632507, "(2, 16)": 0.7723215818405151, "(4, 0)": 0.7106944918632507, "(4, 16)": 0.7106944918632507, "(6, 0)": 0.7106944918632507, "(6, 16)": 0.7723215818405151, "(8, 0)": 0.7106944918632507, "(8, 16)": 0.7106944918632507, "(10, 0)": 0.7106944918632507, "(10, 16)": 0.7106944918632507, "(12, 0)": 0.7106944918632507, "(12, 16)": 0.7723215818405151, "(14, 0)": 0.7106944918632507, "(14, 16)": 0.7106944918632507, "(16, 0)": 0.7106944918632507, "(16, 16)": 0.7153968214988708, "(18, 0)": 0.7153968214988708, "(18, 16)": 0.7723215818405151, "(20, 0)": 0.7723215818405151, "(20, 16)": 0.7106944918632507, "(22, 0)": 0.7153968214988708, "(22, 16)": 0.7723215818405151, "(24, 0)": 0.7153968214988708, "(24, 16)": 0.7723215818405151, "(26, 0)": 0.7153968214988708, "(26, 16)": 0.7153968214988708, "(28, 0)": 0.7153968214988708, "(28, 16)": 0.7106944918632507, "(30, 0)": 0.7153968214988708, "(30, 16)": 0.7153968214988708}, "r_span": [582, 663], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00026470422744750977}}]}, {"id": "14505", "source_id": "15338", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, I can confidently answer the following questions:\n\nWhat is company goodwill?\nCompany goodwill refers to the positive image and reputation of a business that is built over time through providing quality products or services, satisfying customers, and building strong relationships with them. Goodwill is a valuable asset for any business as it helps to attract new customers, retain existing ones, and attract investors.\n\nWhy is goodwill important in business?\nGoodwill is important in business because it helps to build trust and loyalty among customers, which leads to long-term relationships and repeat business. A strong reputation and goodwill can also make a business more attractive to potential investors and buyers. Additionally, goodwill can help a business to stand out from its competitors and establish a unique identity in the marketplace.", "response_spans": [[0, 451], [453, 884]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7738837599754333, "(0, 16)": 0.7738837599754333, "(2, 0)": 0.7738837599754333, "(2, 16)": 0.7738837599754333, "(4, 0)": 0.7738837599754333, "(4, 16)": 0.7738837599754333, "(6, 0)": 0.7738837599754333, "(6, 16)": 0.8273731470108032, "(8, 0)": 0.7738837599754333, "(8, 16)": 0.37830573320388794, "(10, 0)": 0.37830573320388794, "(10, 16)": 0.7738837599754333, "(12, 0)": 0.7738837599754333, "(12, 16)": 0.7738837599754333, "(14, 0)": 0.8273731470108032, "(14, 16)": 0.7738837599754333, "(16, 0)": 0.8273731470108032, "(16, 16)": 0.7738837599754333, "(18, 0)": 0.37830573320388794, "(18, 16)": 0.7738837599754333, "(20, 0)": 0.7738837599754333, "(20, 16)": 0.8273731470108032, "(22, 0)": 0.37830573320388794, "(22, 16)": 0.8273731470108032, "(24, 0)": 0.7738837599754333, "(24, 16)": 0.7738837599754333, "(26, 0)": 0.8273731470108032, "(26, 16)": 0.7738837599754333, "(28, 0)": 0.37830573320388794, "(28, 16)": 0.7738837599754333, "(30, 0)": 0.7738837599754333, "(30, 16)": 0.7738837599754333}, "r_span": [347, 434], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004509091377258301}}, {"prompt_attention_score": {"(0, 0)": 0.761919379234314, "(0, 16)": 0.761919379234314, "(2, 0)": 0.761919379234314, "(2, 16)": 0.8885120153427124, "(4, 0)": 0.761919379234314, "(4, 16)": 0.8885120153427124, "(6, 0)": 0.761919379234314, "(6, 16)": 0.8885120153427124, "(8, 0)": 0.761919379234314, "(8, 16)": 0.8885120153427124, "(10, 0)": 0.761919379234314, "(10, 16)": 0.761919379234314, "(12, 0)": 0.8885120153427124, "(12, 16)": 0.761919379234314, "(14, 0)": 0.8885120153427124, "(14, 16)": 0.761919379234314, "(16, 0)": 0.8885120153427124, "(16, 16)": 0.8885120153427124, "(18, 0)": 0.8885120153427124, "(18, 16)": 0.761919379234314, "(20, 0)": 0.761919379234314, "(20, 16)": 0.8885120153427124, "(22, 0)": 0.8885120153427124, "(22, 16)": 0.761919379234314, "(24, 0)": 0.8885120153427124, "(24, 16)": 0.761919379234314, "(26, 0)": 0.8885120153427124, "(26, 16)": 0.761919379234314, "(28, 0)": 0.761919379234314, "(28, 16)": 0.8885120153427124, "(30, 0)": 0.8885120153427124, "(30, 16)": 0.6313521265983582}, "r_span": [436, 521], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0024607181549072266}}]}, {"id": "14511", "source_id": "15339", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 320, "end": 394, "text": "This type of attack can happen at any point during a debate or discussion.", "meta": "HIGH INTRO OF NEW INFO\nIt is not mentioned in the original sources that this type of attack (Ad hominem fallacy) can happen at any point during a debate or discussion.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the main difference between ad hominem fallacy and poisoning the well fallacy is the timing of the attack.\n\nAd hominem fallacy occurs when an attack is made on a person's character, motive, or other attribute directly related to their argument, rather than attacking the argument itself. This type of attack can happen at any point during a debate or discussion.\n\nOn the other hand, poisoning the well fallacy involves making an ad hominem attack (i.e., attacking a person's character or integrity) before the merits of a case can be considered. In other words, it is an attempt to discredit a person's argument by attacking their personal integrity or intelligence before the discussion has even begun.\n\nSo, while both fallacies involve attacking a person's character rather than their argument, ad hominem fallacy happens after the argument has been presented, while poisoning the well fallacy happens before the argument is even presented.", "response_spans": [[0, 394], [396, 735], [737, 974]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8602907657623291, "(0, 16)": 0.8602907657623291, "(2, 0)": 0.8602907657623291, "(2, 16)": 0.8602907657623291, "(4, 0)": 0.8602907657623291, "(4, 16)": 0.8602907657623291, "(6, 0)": 0.8602907657623291, "(6, 16)": 0.9238172769546509, "(8, 0)": 0.8602907657623291, "(8, 16)": 0.8602907657623291, "(10, 0)": 0.8602907657623291, "(10, 16)": 0.8602907657623291, "(12, 0)": 0.8602907657623291, "(12, 16)": 0.9238172769546509, "(14, 0)": 0.8602907657623291, "(14, 16)": 0.9238172769546509, "(16, 0)": 0.9238172769546509, "(16, 16)": 0.8602907657623291, "(18, 0)": 0.8602907657623291, "(18, 16)": 0.9238172769546509, "(20, 0)": 0.9238172769546509, "(20, 16)": 0.8602907657623291, "(22, 0)": 0.8602907657623291, "(22, 16)": 0.9238172769546509, "(24, 0)": 0.8602907657623291, "(24, 16)": 0.9238172769546509, "(26, 0)": 0.8602907657623291, "(26, 16)": 0.8602907657623291, "(28, 0)": 0.8602907657623291, "(28, 16)": 0.8602907657623291, "(30, 0)": 0.8602907657623291, "(30, 16)": 0.8602907657623291}, "r_span": [309, 400], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00048273801803588867}}, {"prompt_attention_score": {"(0, 0)": 0.8788809776306152, "(0, 16)": 0.8788809776306152, "(2, 0)": 0.8788809776306152, "(2, 16)": 0.8788809776306152, "(4, 0)": 0.8788809776306152, "(4, 16)": 0.8788809776306152, "(6, 0)": 0.8788809776306152, "(6, 16)": 0.8788809776306152, "(8, 0)": 0.8788809776306152, "(8, 16)": 0.8788809776306152, "(10, 0)": 0.8788809776306152, "(10, 16)": 0.8788809776306152, "(12, 0)": 0.8788809776306152, "(12, 16)": 0.8788809776306152, "(14, 0)": 0.8788809776306152, "(14, 16)": 0.8788809776306152, "(16, 0)": 0.8788809776306152, "(16, 16)": 0.8788809776306152, "(18, 0)": 0.8788809776306152, "(18, 16)": 0.8788809776306152, "(20, 0)": 0.8788809776306152, "(20, 16)": 0.8788809776306152, "(22, 0)": 0.8788809776306152, "(22, 16)": 0.8788809776306152, "(24, 0)": 0.8788809776306152, "(24, 16)": 0.8788809776306152, "(26, 0)": 0.8788809776306152, "(26, 16)": 0.8788809776306152, "(28, 0)": 0.8788809776306152, "(28, 16)": 0.8788809776306152, "(30, 0)": 0.8788809776306152, "(30, 16)": 0.8788809776306152}, "r_span": [402, 480], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008953213691711426}}, {"prompt_attention_score": {"(0, 0)": 0.8453035354614258, "(0, 16)": 0.8453035354614258, "(2, 0)": 0.8453035354614258, "(2, 16)": 0.8626416921615601, "(4, 0)": 0.8453035354614258, "(4, 16)": 0.8453035354614258, "(6, 0)": 0.8453035354614258, "(6, 16)": 0.8626416921615601, "(8, 0)": 0.8453035354614258, "(8, 16)": 0.8453035354614258, "(10, 0)": 0.8453035354614258, "(10, 16)": 0.8453035354614258, "(12, 0)": 0.8453035354614258, "(12, 16)": 0.8453035354614258, "(14, 0)": 0.8453035354614258, "(14, 16)": 0.8453035354614258, "(16, 0)": 0.8626416921615601, "(16, 16)": 0.8453035354614258, "(18, 0)": 0.8453035354614258, "(18, 16)": 0.8626416921615601, "(20, 0)": 0.8453035354614258, "(20, 16)": 0.8453035354614258, "(22, 0)": 0.8453035354614258, "(22, 16)": 0.8453035354614258, "(24, 0)": 0.8453035354614258, "(24, 16)": 0.8453035354614258, "(26, 0)": 0.8453035354614258, "(26, 16)": 0.8453035354614258, "(28, 0)": 0.8453035354614258, "(28, 16)": 0.8453035354614258, "(30, 0)": 0.8453035354614258, "(30, 16)": 0.8453035354614258}, "r_span": [482, 533], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005796551704406738}}]}, {"id": "14691", "source_id": "15369", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some steps to achieve an antique effect on wood using normal paint:\n\n1. Apply a basecoat of flat or satin paint to the wood surface ( passage 3). Satin paint is easier to work with, but flat paint will give a more aged look.\n2. Mix paint that is two shades darker than the basecoat with an equal amount of glaze ( passage 3). Once the basecoat is dry, drizzle a crumpled rag or plastic bag in the glaze mixture to achieve an aged appearance.\n3. Layer stain on top of the paint to create a cool effect ( passage 1). This technique involves applying multiple layers of stain and allowing them to dry between coats.\n4. Use a palette knife to spread a mixture of molding paste and a rust or dull color on a canvas, letting it dry before adding additional layers ( passage 2). This can help create an embossed design with an antique finish.\n5. Apply a thin layer of burnt sienna or a similar color to give the wood a vintage look ( passage 3). Dabbing the paint with a paper towel or cloth can help remove excess paint and achieve a more subtle, aged appearance.\n\nOverall, the key to achieving an antique effect on wood using normal paint is to layer different materials and colors to create a weathered and worn appearance.", "response_spans": [[0, 108], [110, 482], [483, 876], [877, 1098], [1100, 1260]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.76780104637146, "(0, 16)": 0.76780104637146, "(2, 0)": 0.76780104637146, "(2, 16)": 0.76780104637146, "(4, 0)": 0.76780104637146, "(4, 16)": 0.76780104637146, "(6, 0)": 0.76780104637146, "(6, 16)": 0.8775529861450195, "(8, 0)": 0.6927509307861328, "(8, 16)": 0.43481552600860596, "(10, 0)": 0.43481552600860596, "(10, 16)": 0.43481552600860596, "(12, 0)": 0.76780104637146, "(12, 16)": 0.8775529861450195, "(14, 0)": 0.76780104637146, "(14, 16)": 0.43481552600860596, "(16, 0)": 0.8775529861450195, "(16, 16)": 0.76780104637146, "(18, 0)": 0.43481552600860596, "(18, 16)": 0.8775529861450195, "(20, 0)": 0.8775529861450195, "(20, 16)": 0.76780104637146, "(22, 0)": 0.7147122025489807, "(22, 16)": 0.8775529861450195, "(24, 0)": 0.76780104637146, "(24, 16)": 0.7147122025489807, "(26, 0)": 0.7147122025489807, "(26, 16)": 0.7147122025489807, "(28, 0)": 0.43481552600860596, "(28, 16)": 0.76780104637146, "(30, 0)": 0.7147122025489807, "(30, 16)": 0.7147122025489807}, "r_span": [649, 673], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0016952753067016602}}, {"prompt_attention_score": {"(0, 0)": 0.919263482093811, "(0, 16)": 0.919263482093811, "(2, 0)": 0.919263482093811, "(2, 16)": 0.919263482093811, "(4, 0)": 0.919263482093811, "(4, 16)": 0.919263482093811, "(6, 0)": 0.919263482093811, "(6, 16)": 0.919263482093811, "(8, 0)": 0.919263482093811, "(8, 16)": 0.919263482093811, "(10, 0)": 0.919263482093811, "(10, 16)": 0.919263482093811, "(12, 0)": 0.919263482093811, "(12, 16)": 0.919263482093811, "(14, 0)": 0.919263482093811, "(14, 16)": 0.919263482093811, "(16, 0)": 0.919263482093811, "(16, 16)": 0.919263482093811, "(18, 0)": 0.919263482093811, "(18, 16)": 0.919263482093811, "(20, 0)": 0.919263482093811, "(20, 16)": 0.919263482093811, "(22, 0)": 0.919263482093811, "(22, 16)": 0.919263482093811, "(24, 0)": 0.919263482093811, "(24, 16)": 0.919263482093811, "(26, 0)": 0.6787357926368713, "(26, 16)": 0.919263482093811, "(28, 0)": 0.6787357926368713, "(28, 16)": 0.919263482093811, "(30, 0)": 0.6787357926368713, "(30, 16)": 0.6787357926368713}, "r_span": [675, 778], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001679837703704834}}, {"prompt_attention_score": {"(0, 0)": 0.7380250096321106, "(0, 16)": 0.7380250096321106, "(2, 0)": 0.7380250096321106, "(2, 16)": 0.7380250096321106, "(4, 0)": 0.7380250096321106, "(4, 16)": 0.7380250096321106, "(6, 0)": 0.7380250096321106, "(6, 16)": 0.8033410906791687, "(8, 0)": 0.7380250096321106, "(8, 16)": 0.7380250096321106, "(10, 0)": 0.7380250096321106, "(10, 16)": 0.7380250096321106, "(12, 0)": 0.7380250096321106, "(12, 16)": 0.8033410906791687, "(14, 0)": 0.7380250096321106, "(14, 16)": 0.7380250096321106, "(16, 0)": 0.7137540578842163, "(16, 16)": 0.7380250096321106, "(18, 0)": 0.7137540578842163, "(18, 16)": 0.8033410906791687, "(20, 0)": 0.8033410906791687, "(20, 16)": 0.7380250096321106, "(22, 0)": 0.7380250096321106, "(22, 16)": 0.8033410906791687, "(24, 0)": 0.7380250096321106, "(24, 16)": 0.7137540578842163, "(26, 0)": 0.7137540578842163, "(26, 16)": 0.8033410906791687, "(28, 0)": 0.7380250096321106, "(28, 16)": 0.7380250096321106, "(30, 0)": 0.7137540578842163, "(30, 16)": 0.7137540578842163}, "r_span": [779, 874], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002567470073699951}}, {"prompt_attention_score": {"(0, 0)": 0.8139144778251648, "(0, 16)": 0.8139144778251648, "(2, 0)": 0.8139144778251648, "(2, 16)": 0.8139144778251648, "(4, 0)": 0.8139144778251648, "(4, 16)": 0.6721502542495728, "(6, 0)": 0.8139144778251648, "(6, 16)": 0.6721502542495728, "(8, 0)": 0.8139144778251648, "(8, 16)": 0.8139144778251648, "(10, 0)": 0.8139144778251648, "(10, 16)": 0.8139144778251648, "(12, 0)": 0.8139144778251648, "(12, 16)": 0.6936242580413818, "(14, 0)": 0.8139144778251648, "(14, 16)": 0.8139144778251648, "(16, 0)": 0.8139144778251648, "(16, 16)": 0.8139144778251648, "(18, 0)": 0.671368420124054, "(18, 16)": 0.6936242580413818, "(20, 0)": 0.6936242580413818, "(20, 16)": 0.8139144778251648, "(22, 0)": 0.8139144778251648, "(22, 16)": 0.8139144778251648, "(24, 0)": 0.8139144778251648, "(24, 16)": 0.8139144778251648, "(26, 0)": 0.671368420124054, "(26, 16)": 0.8139144778251648, "(28, 0)": 0.8139144778251648, "(28, 16)": 0.671368420124054, "(30, 0)": 0.8139144778251648, "(30, 16)": 0.671368420124054}, "r_span": [875, 933], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00030797719955444336}}, {"prompt_attention_score": {"(0, 0)": 0.6323786377906799, "(0, 16)": 0.7672982215881348, "(2, 0)": 0.6323786377906799, "(2, 16)": 0.7672982215881348, "(4, 0)": 0.6323786377906799, "(4, 16)": 0.7672982215881348, "(6, 0)": 0.7672982215881348, "(6, 16)": 0.8099362850189209, "(8, 0)": 0.7672982215881348, "(8, 16)": 0.7672982215881348, "(10, 0)": 0.3496064245700836, "(10, 16)": 0.3496064245700836, "(12, 0)": 0.7672982215881348, "(12, 16)": 0.7672982215881348, "(14, 0)": 0.7672982215881348, "(14, 16)": 0.3496064245700836, "(16, 0)": 0.8099362850189209, "(16, 16)": 0.7672982215881348, "(18, 0)": 0.6579303741455078, "(18, 16)": 0.7672982215881348, "(20, 0)": 0.6579303741455078, "(20, 16)": 0.7672982215881348, "(22, 0)": 0.7672982215881348, "(22, 16)": 0.7672982215881348, "(24, 0)": 0.7672982215881348, "(24, 16)": 0.7672982215881348, "(26, 0)": 0.6579303741455078, "(26, 16)": 0.7672982215881348, "(28, 0)": 0.6579303741455078, "(28, 16)": 0.6579303741455078, "(30, 0)": 0.7672982215881348, "(30, 16)": 0.6579303741455078}, "r_span": [935, 968], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008553266525268555}}]}, {"id": "14703", "source_id": "15371", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main difference between a rock and a stone is their size. Rocks are typically larger and more massive than stones, which are smaller and more fragmented.\n\nPassage 1 states that rocks are often used to refer to something solid, large, and grounded, such as a mountain or palisade, while stones are often used to refer to small pieces of rock or pebbles. Passage 2 defines rocks as the hard material of the earth's crust that is exposed on the surface of the earth or underlying the soil, while stones are smaller fragments of rock that can be carried in the hand.\n\nPassage 3 further clarifies the distinction by stating that rocks are made up of smaller stones, while stones are made from rocks. Additionally, rocks are described as being difficult to carry in the hand, while stones are small enough to be carried easily.\n\nIn summary, while both rocks and stones are made of the same material, they differ in size and usage. Rocks are generally larger and more massive, while stones are smaller and more fragmented.", "response_spans": [[0, 189], [191, 598], [600, 1051]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7562336921691895, "(0, 16)": 0.7562336921691895, "(2, 0)": 0.7562336921691895, "(2, 16)": 0.7562336921691895, "(4, 0)": 0.7562336921691895, "(4, 16)": 0.7562336921691895, "(6, 0)": 0.7562336921691895, "(6, 16)": 0.8422161936759949, "(8, 0)": 0.6996885538101196, "(8, 16)": 0.409706711769104, "(10, 0)": 0.409706711769104, "(10, 16)": 0.409706711769104, "(12, 0)": 0.8135546445846558, "(12, 16)": 0.7562336921691895, "(14, 0)": 0.8135546445846558, "(14, 16)": 0.409706711769104, "(16, 0)": 0.8422161936759949, "(16, 16)": 0.7562336921691895, "(18, 0)": 0.409706711769104, "(18, 16)": 0.8135546445846558, "(20, 0)": 0.7562336921691895, "(20, 16)": 0.6996885538101196, "(22, 0)": 0.6996885538101196, "(22, 16)": 0.7562336921691895, "(24, 0)": 0.8135546445846558, "(24, 16)": 0.6996885538101196, "(26, 0)": 0.6996885538101196, "(26, 16)": 0.6996885538101196, "(28, 0)": 0.6996885538101196, "(28, 16)": 0.6996885538101196, "(30, 0)": 0.6996885538101196, "(30, 16)": 0.6996885538101196}, "r_span": [558, 598], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0016596317291259766}}, {"prompt_attention_score": {"(0, 0)": 0.8502824902534485, "(0, 16)": 0.8502824902534485, "(2, 0)": 0.8502824902534485, "(2, 16)": 0.8502824902534485, "(4, 0)": 0.8502824902534485, "(4, 16)": 0.8502824902534485, "(6, 0)": 0.9146818518638611, "(6, 16)": 0.7971067428588867, "(8, 0)": 0.8502824902534485, "(8, 16)": 0.8502824902534485, "(10, 0)": 0.8502824902534485, "(10, 16)": 0.8502824902534485, "(12, 0)": 0.9146818518638611, "(12, 16)": 0.7971067428588867, "(14, 0)": 0.9146818518638611, "(14, 16)": 0.7971067428588867, "(16, 0)": 0.7971067428588867, "(16, 16)": 0.7971067428588867, "(18, 0)": 0.7971067428588867, "(18, 16)": 0.9146818518638611, "(20, 0)": 0.7971067428588867, "(20, 16)": 0.9146818518638611, "(22, 0)": 0.7971067428588867, "(22, 16)": 0.7971067428588867, "(24, 0)": 0.7971067428588867, "(24, 16)": 0.7971067428588867, "(26, 0)": 0.7971067428588867, "(26, 16)": 0.7971067428588867, "(28, 0)": 0.7971067428588867, "(28, 16)": 0.7971067428588867, "(30, 0)": 0.7971067428588867, "(30, 16)": 0.7971067428588867}, "r_span": [600, 694], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008633732795715332}}, {"prompt_attention_score": {"(0, 0)": 0.8598968982696533, "(0, 16)": 0.8598968982696533, "(2, 0)": 0.8598968982696533, "(2, 16)": 0.8598968982696533, "(4, 0)": 0.8598968982696533, "(4, 16)": 0.8598968982696533, "(6, 0)": 0.7135742902755737, "(6, 16)": 0.8598968982696533, "(8, 0)": 0.8598968982696533, "(8, 16)": 0.8598968982696533, "(10, 0)": 0.8598968982696533, "(10, 16)": 0.8598968982696533, "(12, 0)": 0.7135742902755737, "(12, 16)": 0.8598968982696533, "(14, 0)": 0.7135742902755737, "(14, 16)": 0.8598968982696533, "(16, 0)": 0.8598968982696533, "(16, 16)": 0.7135742902755737, "(18, 0)": 0.7135742902755737, "(18, 16)": 0.8598968982696533, "(20, 0)": 0.8598968982696533, "(20, 16)": 0.7135742902755737, "(22, 0)": 0.7135742902755737, "(22, 16)": 0.8598968982696533, "(24, 0)": 0.7135742902755737, "(24, 16)": 0.8598968982696533, "(26, 0)": 0.7135742902755737, "(26, 16)": 0.7135742902755737, "(28, 0)": 0.7135742902755737, "(28, 16)": 0.7135742902755737, "(30, 0)": 0.7135742902755737, "(30, 16)": 0.7135742902755737}, "r_span": [696, 789], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012565255165100098}}]}, {"id": "14715", "source_id": "15373", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 170, "end": 271, "text": "+ Whole wheat flour\n\t\t+ White flour\n\t\t+ Bran\n\t\t+ Germ\n\t\t+ Sprouted wheat\n\t\t+ Cereals containing wheat", "meta": "HIGH INTRO OF NEW INFO\nOriginal: Nomention of these types of wheat\nGenerative: Includes variety of wheat such as whole wheat flour, white flour, bran, germ, and etc.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 292, "end": 338, "text": "* Rye berries\n\t* Rye flour\n\t* Malted rye flour", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of types of ryes\nGenerative: Includes samples such as rye berries, rye flour, and malted rye flour.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 362, "end": 376, "text": "* Barley flour", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of barley flour in passage 2\nGenerative: Includes barley flour on the list", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 401, "end": 431, "text": "* Barley grain\n\t* Barley sugar", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of barley grain and barley sugar in Passage 2\nGenerative: Includes barley grain and barley sugar on the list.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 458, "end": 494, "text": "* Triticale flour\n\t* Triticale bread", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of triticale flour and bread in Passage 2\nGenerative: Includes triticale flour and triticale bread on the list.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 893, "end": 1057, "text": "it may still be safe for consumption for individuals with gluten sensitivity or celiac disease if it has been processed properly and meets certain safety standards.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of the items being safe to consume for those people with gluten sensitivity or celiac disease\nGenerative: \"...it may still be safe for consumption for individuals with gluten sensitivity or celiac disease...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some foods that contain gluten:\n\n1. Wheat (passage 2)\n\t* Wheatberries\n\t* Durum\n\t* Varieties and derivatives of wheat, such as:\n\t\t+ Whole wheat flour\n\t\t+ White flour\n\t\t+ Bran\n\t\t+ Germ\n\t\t+ Sprouted wheat\n\t\t+ Cereals containing wheat\n2. Rye (passage 2)\n\t* Rye berries\n\t* Rye flour\n\t* Malted rye flour\n3. Barley (passage 2)\n\t* Barley flour\n\t* Malted barley flour\n\t* Barley grain\n\t* Barley sugar\n4. Triticale (passage 2)\n\t* Triticale flour\n\t* Triticale bread\n5. Common foods that contain gluten (passage 3):\n\t* Pasta: ravioli, dumplings, couscous, gnocchi\n\t* Noodles: ramen, udon, soba (made with only a percentage of buckwheat flour), chow mein, egg noodles\n\t* Breads and pastries: croissants, pita, naan, bagels, flatbreads, cornbread, potato bread, muffins, donuts, rolls\n\nNote: It's important to note that even if a food is listed as containing gluten, it may still be safe for consumption for individuals with gluten sensitivity or celiac disease if it has been processed properly and meets certain safety standards. Always consult with a healthcare professional or registered dietitian for personalized dietary advice.", "response_spans": [[0, 72], [74, 543], [545, 810], [812, 1160]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8035659193992615, "(0, 16)": 0.8035659193992615, "(2, 0)": 0.8035659193992615, "(2, 16)": 0.8035659193992615, "(4, 0)": 0.8035659193992615, "(4, 16)": 0.8035659193992615, "(6, 0)": 0.8035659193992615, "(6, 16)": 0.7731869220733643, "(8, 0)": 0.8035659193992615, "(8, 16)": 0.8035659193992615, "(10, 0)": 0.8035659193992615, "(10, 16)": 0.8035659193992615, "(12, 0)": 0.8035659193992615, "(12, 16)": 0.7731869220733643, "(14, 0)": 0.7731869220733643, "(14, 16)": 0.8035659193992615, "(16, 0)": 0.7731869220733643, "(16, 16)": 0.8035659193992615, "(18, 0)": 0.8035659193992615, "(18, 16)": 0.7731869220733643, "(20, 0)": 0.7731869220733643, "(20, 16)": 0.7731869220733643, "(22, 0)": 0.7731869220733643, "(22, 16)": 0.7731869220733643, "(24, 0)": 0.7731869220733643, "(24, 16)": 0.7731869220733643, "(26, 0)": 0.7731869220733643, "(26, 16)": 0.7731869220733643, "(28, 0)": 0.8035659193992615, "(28, 16)": 0.7731869220733643, "(30, 0)": 0.7731869220733643, "(30, 16)": 0.7731869220733643}, "r_span": [426, 444], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000498354434967041}}, {"prompt_attention_score": {"(0, 0)": 0.8321271538734436, "(0, 16)": 0.8321271538734436, "(2, 0)": 0.8321271538734436, "(2, 16)": 0.8321271538734436, "(4, 0)": 0.8321271538734436, "(4, 16)": 0.8321271538734436, "(6, 0)": 0.8321271538734436, "(6, 16)": 0.9134445786476135, "(8, 0)": 0.8321271538734436, "(8, 16)": 0.8321271538734436, "(10, 0)": 0.8321271538734436, "(10, 16)": 0.8321271538734436, "(12, 0)": 0.8321271538734436, "(12, 16)": 0.9134445786476135, "(14, 0)": 0.7280044555664062, "(14, 16)": 0.9134445786476135, "(16, 0)": 0.8321271538734436, "(16, 16)": 0.8321271538734436, "(18, 0)": 0.7280044555664062, "(18, 16)": 0.9134445786476135, "(20, 0)": 0.9134445786476135, "(20, 16)": 0.7280044555664062, "(22, 0)": 0.7280044555664062, "(22, 16)": 0.9134445786476135, "(24, 0)": 0.7280044555664062, "(24, 16)": 0.9134445786476135, "(26, 0)": 0.7280044555664062, "(26, 16)": 0.8321271538734436, "(28, 0)": 0.7280044555664062, "(28, 16)": 0.7280044555664062, "(30, 0)": 0.7280044555664062, "(30, 16)": 0.7280044555664062}, "r_span": [446, 647], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0015564560890197754}}, {"prompt_attention_score": {"(0, 0)": 0.7950416803359985, "(0, 16)": 0.7950416803359985, "(2, 0)": 0.7950416803359985, "(2, 16)": 0.7950416803359985, "(4, 0)": 0.7950416803359985, "(4, 16)": 0.7950416803359985, "(6, 0)": 0.7950416803359985, "(6, 16)": 0.7950416803359985, "(8, 0)": 0.7950416803359985, "(8, 16)": 0.7950416803359985, "(10, 0)": 0.7950416803359985, "(10, 16)": 0.7950416803359985, "(12, 0)": 0.5807329416275024, "(12, 16)": 0.7950416803359985, "(14, 0)": 0.5807329416275024, "(14, 16)": 0.7950416803359985, "(16, 0)": 0.7950416803359985, "(16, 16)": 0.7950416803359985, "(18, 0)": 0.5807329416275024, "(18, 16)": 0.7950416803359985, "(20, 0)": 0.7950416803359985, "(20, 16)": 0.5807329416275024, "(22, 0)": 0.5807329416275024, "(22, 16)": 0.7950416803359985, "(24, 0)": 0.5807329416275024, "(24, 16)": 0.7950416803359985, "(26, 0)": 0.5807329416275024, "(26, 16)": 0.6345599889755249, "(28, 0)": 0.5807329416275024, "(28, 16)": 0.5807329416275024, "(30, 0)": 0.5807329416275024, "(30, 16)": 0.5807329416275024}, "r_span": [649, 754], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015128254890441895}}, {"prompt_attention_score": {"(0, 0)": 0.6939021348953247, "(0, 16)": 0.6939021348953247, "(2, 0)": 0.6939021348953247, "(2, 16)": 0.6939021348953247, "(4, 0)": 0.6939021348953247, "(4, 16)": 0.6939021348953247, "(6, 0)": 0.6939021348953247, "(6, 16)": 0.7918868064880371, "(8, 0)": 0.6939021348953247, "(8, 16)": 0.7918868064880371, "(10, 0)": 0.6939021348953247, "(10, 16)": 0.6939021348953247, "(12, 0)": 0.6939021348953247, "(12, 16)": 0.7918868064880371, "(14, 0)": 0.7918868064880371, "(14, 16)": 0.6939021348953247, "(16, 0)": 0.7918868064880371, "(16, 16)": 0.7918868064880371, "(18, 0)": 0.6939021348953247, "(18, 16)": 0.7918868064880371, "(20, 0)": 0.7918868064880371, "(20, 16)": 0.7918868064880371, "(22, 0)": 0.7918868064880371, "(22, 16)": 0.6939021348953247, "(24, 0)": 0.7918868064880371, "(24, 16)": 0.7918868064880371, "(26, 0)": 0.7918868064880371, "(26, 16)": 0.6939021348953247, "(28, 0)": 0.7918868064880371, "(28, 16)": 0.7918868064880371, "(30, 0)": 0.7918868064880371, "(30, 16)": 0.7918868064880371}, "r_span": [756, 827], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -3.0338764190673828e-05}}]}, {"id": "14745", "source_id": "15378", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, DMSO (dimethyl sulfoxide) is used for various purposes including:\n\n1. As an antifreeze in industrial applications.\n2. As a solvent for a wide range of chemicals in industrial settings.\n3. In medicine, DMSO relieves pain, reduces swelling, inflammation, and has been used to treat a variety of medical conditions such as burns, scleroderma, and minor cuts and burns.\n4. Promoting healing in cases of soft tissue damage, local tissue death, skin ulcers, and burns.\n\nTherefore, the answer to the question \"What is DMSO used for?\" is:\n\n1. Industrial applications (antifreeze and solvent).\n2. Medical applications (pain relief, inflammation reduction, and treatment of various medical conditions).\n3. Promoting healing in cases of soft tissue damage, local tissue death, skin ulcers, and burns.\n\nUnable to answer based on the given passages: Providing detailed information on the specific medical conditions or injuries that DMSO has been used to treat, as this information is not explicitly stated in the provided passages.", "response_spans": [[0, 494], [496, 821], [823, 1051]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8146666288375854, "(0, 16)": 0.8146666288375854, "(2, 0)": 0.8146666288375854, "(2, 16)": 0.8146666288375854, "(4, 0)": 0.8146666288375854, "(4, 16)": 0.8146666288375854, "(6, 0)": 0.8146666288375854, "(6, 16)": 0.9079387187957764, "(8, 0)": 0.8146666288375854, "(8, 16)": 0.8146666288375854, "(10, 0)": 0.8146666288375854, "(10, 16)": 0.8146666288375854, "(12, 0)": 0.9079387187957764, "(12, 16)": 0.8146666288375854, "(14, 0)": 0.9079387187957764, "(14, 16)": 0.8146666288375854, "(16, 0)": 0.9079387187957764, "(16, 16)": 0.8146666288375854, "(18, 0)": 0.8146666288375854, "(18, 16)": 0.9079387187957764, "(20, 0)": 0.9079387187957764, "(20, 16)": 0.9079387187957764, "(22, 0)": 0.9079387187957764, "(22, 16)": 0.863460898399353, "(24, 0)": 0.9079387187957764, "(24, 16)": 0.9079387187957764, "(26, 0)": 0.9079387187957764, "(26, 16)": 0.9079387187957764, "(28, 0)": 0.9079387187957764, "(28, 16)": 0.9079387187957764, "(30, 0)": 0.9079387187957764, "(30, 16)": 0.9079387187957764}, "r_span": [373, 509], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0028963088989257812}}, {"prompt_attention_score": {"(0, 0)": 0.8235762715339661, "(0, 16)": 0.8235762715339661, "(2, 0)": 0.8235762715339661, "(2, 16)": 0.8235762715339661, "(4, 0)": 0.8235762715339661, "(4, 16)": 0.8235762715339661, "(6, 0)": 0.8235762715339661, "(6, 16)": 0.8235762715339661, "(8, 0)": 0.8235762715339661, "(8, 16)": 0.8504563570022583, "(10, 0)": 0.8235762715339661, "(10, 16)": 0.8235762715339661, "(12, 0)": 0.8235762715339661, "(12, 16)": 0.8235762715339661, "(14, 0)": 0.887507438659668, "(14, 16)": 0.8235762715339661, "(16, 0)": 0.887507438659668, "(16, 16)": 0.8235762715339661, "(18, 0)": 0.887507438659668, "(18, 16)": 0.887507438659668, "(20, 0)": 0.887507438659668, "(20, 16)": 0.887507438659668, "(22, 0)": 0.887507438659668, "(22, 16)": 0.8504563570022583, "(24, 0)": 0.887507438659668, "(24, 16)": 0.887507438659668, "(26, 0)": 0.887507438659668, "(26, 16)": 0.887507438659668, "(28, 0)": 0.887507438659668, "(28, 16)": 0.887507438659668, "(30, 0)": 0.887507438659668, "(30, 16)": 0.887507438659668}, "r_span": [511, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007689595222473145}}, {"prompt_attention_score": {"(0, 0)": 0.781792163848877, "(0, 16)": 0.781792163848877, "(2, 0)": 0.781792163848877, "(2, 16)": 0.7012982368469238, "(4, 0)": 0.781792163848877, "(4, 16)": 0.781792163848877, "(6, 0)": 0.781792163848877, "(6, 16)": 0.6802535057067871, "(8, 0)": 0.781792163848877, "(8, 16)": 0.6802535057067871, "(10, 0)": 0.781792163848877, "(10, 16)": 0.781792163848877, "(12, 0)": 0.781792163848877, "(12, 16)": 0.781792163848877, "(14, 0)": 0.6802535057067871, "(14, 16)": 0.781792163848877, "(16, 0)": 0.781792163848877, "(16, 16)": 0.6802535057067871, "(18, 0)": 0.6802535057067871, "(18, 16)": 0.781792163848877, "(20, 0)": 0.7012982368469238, "(20, 16)": 0.6802535057067871, "(22, 0)": 0.6802535057067871, "(22, 16)": 0.7012982368469238, "(24, 0)": 0.6802535057067871, "(24, 16)": 0.781792163848877, "(26, 0)": 0.6802535057067871, "(26, 16)": 0.6802535057067871, "(28, 0)": 0.6802535057067871, "(28, 16)": 0.6802535057067871, "(30, 0)": 0.6802535057067871, "(30, 16)": 0.6802535057067871}, "r_span": [598, 644], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00018554925918579102}}]}, {"id": "14751", "source_id": "15379", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to arrange an Excel sheet alphabetically:\n\nPassage 1 suggests using Kutools for Excel, which provides a Sort Sheets tool to easily sort all worksheets in alphabetical order. However, if you prefer not to use macros or Kutools, Passage 2 provides an alternative method using the built-in Sort feature in Excel.\n\nTo sort an Excel sheet alphabetically using the built-in Sort feature, follow these steps:\n\n1. Select the data you wish to sort by clicking on the Select All button at the intersection of your row and column headings.\n2. Switch to the Data tab in the Microsoft Excel ribbon and locate the Sort & Filter group.\n3. Click on the Sort option.\n4. Click on the Sort By drop-down menu and select the column you wish to sort by (e.g., Product column in alphabetical order - A to Z).\n5. Click OK.\n\nOnce you have completed these steps, the data in your Excel sheet will be sorted alphabetically.\n\nUnable to answer based on given passages. The passages do not provide sufficient information to clarify how to arrange an Excel sheet numerically.", "response_spans": [[0, 445], [447, 940], [942, 1088]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7698279619216919, "(0, 16)": 0.7698279619216919, "(2, 0)": 0.7698279619216919, "(2, 16)": 0.7698279619216919, "(4, 0)": 0.7698279619216919, "(4, 16)": 0.7698279619216919, "(6, 0)": 0.7698279619216919, "(6, 16)": 0.9545153379440308, "(8, 0)": 0.9545153379440308, "(8, 16)": 0.7698279619216919, "(10, 0)": 0.426205039024353, "(10, 16)": 0.426205039024353, "(12, 0)": 0.9545153379440308, "(12, 16)": 0.9545153379440308, "(14, 0)": 0.9545153379440308, "(14, 16)": 0.9545153379440308, "(16, 0)": 0.9545153379440308, "(16, 16)": 0.9545153379440308, "(18, 0)": 0.9545153379440308, "(18, 16)": 0.9545153379440308, "(20, 0)": 0.9545153379440308, "(20, 16)": 0.9545153379440308, "(22, 0)": 0.9545153379440308, "(22, 16)": 0.9545153379440308, "(24, 0)": 0.9545153379440308, "(24, 16)": 0.9545153379440308, "(26, 0)": 0.9545153379440308, "(26, 16)": 0.9545153379440308, "(28, 0)": 0.9545153379440308, "(28, 16)": 0.9545153379440308, "(30, 0)": 0.9545153379440308, "(30, 16)": 0.9545153379440308}, "r_span": [384, 491], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002114415168762207}}, {"prompt_attention_score": {"(0, 0)": 0.8856775760650635, "(0, 16)": 0.8856775760650635, "(2, 0)": 0.8856775760650635, "(2, 16)": 0.8856775760650635, "(4, 0)": 0.8856775760650635, "(4, 16)": 0.8856775760650635, "(6, 0)": 0.8856775760650635, "(6, 16)": 0.8814593553543091, "(8, 0)": 0.8856775760650635, "(8, 16)": 0.8856775760650635, "(10, 0)": 0.8856775760650635, "(10, 16)": 0.8856775760650635, "(12, 0)": 0.8012212514877319, "(12, 16)": 0.8856775760650635, "(14, 0)": 0.8012212514877319, "(14, 16)": 0.8856775760650635, "(16, 0)": 0.8856775760650635, "(16, 16)": 0.8012212514877319, "(18, 0)": 0.8012212514877319, "(18, 16)": 0.8856775760650635, "(20, 0)": 0.8856775760650635, "(20, 16)": 0.8012212514877319, "(22, 0)": 0.8012212514877319, "(22, 16)": 0.8856775760650635, "(24, 0)": 0.8012212514877319, "(24, 16)": 0.8856775760650635, "(26, 0)": 0.8012212514877319, "(26, 16)": 0.8012212514877319, "(28, 0)": 0.8012212514877319, "(28, 16)": 0.8012212514877319, "(30, 0)": 0.8012212514877319, "(30, 16)": 0.8012212514877319}, "r_span": [493, 615], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006383061408996582}}, {"prompt_attention_score": {"(0, 0)": 0.6618891954421997, "(0, 16)": 0.6618891954421997, "(2, 0)": 0.6618891954421997, "(2, 16)": 0.6618891954421997, "(4, 0)": 0.6618891954421997, "(4, 16)": 0.6618891954421997, "(6, 0)": 0.6618891954421997, "(6, 16)": 0.7042239904403687, "(8, 0)": 0.7042239904403687, "(8, 16)": 0.6618891954421997, "(10, 0)": 0.7396556735038757, "(10, 16)": 0.7396556735038757, "(12, 0)": 0.7042239904403687, "(12, 16)": 0.7396556735038757, "(14, 0)": 0.7042239904403687, "(14, 16)": 0.7396556735038757, "(16, 0)": 0.7396556735038757, "(16, 16)": 0.7042239904403687, "(18, 0)": 0.7042239904403687, "(18, 16)": 0.7396556735038757, "(20, 0)": 0.7042239904403687, "(20, 16)": 0.7042239904403687, "(22, 0)": 0.7042239904403687, "(22, 16)": 0.7042239904403687, "(24, 0)": 0.6618891954421997, "(24, 16)": 0.7396556735038757, "(26, 0)": 0.7042239904403687, "(26, 16)": 0.7042239904403687, "(28, 0)": 0.7042239904403687, "(28, 16)": 0.7042239904403687, "(30, 0)": 0.7042239904403687, "(30, 16)": 0.7042239904403687}, "r_span": [617, 647], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005512237548828125}}]}, {"id": "14763", "source_id": "15381", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 302, "end": 450, "text": "which suggests that a normal value is around 0 or close to it. Therefore, the normal range for BNP is likely to be between 0-1 ng/mL or closer to 0.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of this assumption in the passages. \nGenerative: Provide an assumption about the normal value of BNP. \"...a normal value is around 0 or close to it. Therefore, the normal range for BNP is likely to be between 0-1 ng/mL or closer to 0.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the normal value for B-type natriuretic peptide (BNP) is not explicitly stated. However, it is mentioned that BNP values tend to increase with age and are higher in women than men. Additionally, the passage states that a low level of BNP is normally found in the blood, which suggests that a normal value is around 0 or close to it. Therefore, the normal range for BNP is likely to be between 0-1 ng/mL or closer to 0.", "response_spans": [[0, 450]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7775411605834961, "(0, 16)": 0.7775411605834961, "(2, 0)": 0.7775411605834961, "(2, 16)": 0.7775411605834961, "(4, 0)": 0.7775411605834961, "(4, 16)": 0.7775411605834961, "(6, 0)": 0.7775411605834961, "(6, 16)": 0.8718894124031067, "(8, 0)": 0.7891690731048584, "(8, 16)": 0.7775411605834961, "(10, 0)": 0.4763847589492798, "(10, 16)": 0.7775411605834961, "(12, 0)": 0.7891690731048584, "(12, 16)": 0.8718894124031067, "(14, 0)": 0.7891690731048584, "(14, 16)": 0.4763847589492798, "(16, 0)": 0.7891690731048584, "(16, 16)": 0.7891690731048584, "(18, 0)": 0.4763847589492798, "(18, 16)": 0.8718894124031067, "(20, 0)": 0.8718894124031067, "(20, 16)": 0.7891690731048584, "(22, 0)": 0.7891690731048584, "(22, 16)": 0.4763847589492798, "(24, 0)": 0.7891690731048584, "(24, 16)": 0.8718894124031067, "(26, 0)": 0.7891690731048584, "(26, 16)": 0.7891690731048584, "(28, 0)": 0.7891690731048584, "(28, 16)": 0.7891690731048584, "(30, 0)": 0.7891690731048584, "(30, 16)": 0.7891690731048584}, "r_span": [551, 666], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0034623146057128906}}]}, {"id": "14775", "source_id": "15383", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Here are brief answers to why we should serve others based on the provided passages:\n\n1. Love your neighbor as yourself (Matthew 22:39) - We should serve others because it shows love and kindness to everyone, regardless of how they treat us.\n2. The fact that we should serve God is obvious in Scripture (Luke 4:8) - We should serve God because He is worthy of our love and service, and it is a natural response to knowing Him.\n3. If we are serving others for selfish reasons, we are not serving or loving properly (unable to answer based on given passages) - The passages do not provide explicit reasons why we should serve others without selfish motives.\n\nTherefore, the main reasons why we should serve others based on these passages are:\n\n* To show love and kindness to everyone, regardless of their treatment towards us.\n* To express our love and appreciation for God, who deserves our service and devotion.", "response_spans": [[0, 84], [86, 426], [427, 655], [657, 911]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7633659839630127, "(0, 16)": 0.7633659839630127, "(2, 0)": 0.7633659839630127, "(2, 16)": 0.7633659839630127, "(4, 0)": 0.7633659839630127, "(4, 16)": 0.7633659839630127, "(6, 0)": 0.7633659839630127, "(6, 16)": 0.8772176504135132, "(8, 0)": 0.7633659839630127, "(8, 16)": 0.7633659839630127, "(10, 0)": 0.6142981052398682, "(10, 16)": 0.6142981052398682, "(12, 0)": 0.6142981052398682, "(12, 16)": 0.8772176504135132, "(14, 0)": 0.6213070154190063, "(14, 16)": 0.6142981052398682, "(16, 0)": 0.8772176504135132, "(16, 16)": 0.6142981052398682, "(18, 0)": 0.6142981052398682, "(18, 16)": 0.8772176504135132, "(20, 0)": 0.8772176504135132, "(20, 16)": 0.6213070154190063, "(22, 0)": 0.6213070154190063, "(22, 16)": 0.8772176504135132, "(24, 0)": 0.6213070154190063, "(24, 16)": 0.8772176504135132, "(26, 0)": 0.6213070154190063, "(26, 16)": 0.6213070154190063, "(28, 0)": 0.6142981052398682, "(28, 16)": 0.6213070154190063, "(30, 0)": 0.6213070154190063, "(30, 16)": 0.6213070154190063}, "r_span": [596, 613], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00034922361373901367}}, {"prompt_attention_score": {"(0, 0)": 0.7680975794792175, "(0, 16)": 0.7680975794792175, "(2, 0)": 0.7680975794792175, "(2, 16)": 0.7680975794792175, "(4, 0)": 0.7680975794792175, "(4, 16)": 0.7680975794792175, "(6, 0)": 0.7680975794792175, "(6, 16)": 0.806727409362793, "(8, 0)": 0.7649345397949219, "(8, 16)": 0.7680975794792175, "(10, 0)": 0.806727409362793, "(10, 16)": 0.7680975794792175, "(12, 0)": 0.7680975794792175, "(12, 16)": 0.806727409362793, "(14, 0)": 0.7649345397949219, "(14, 16)": 0.7992833256721497, "(16, 0)": 0.806727409362793, "(16, 16)": 0.7680975794792175, "(18, 0)": 0.7649345397949219, "(18, 16)": 0.7992833256721497, "(20, 0)": 0.806727409362793, "(20, 16)": 0.7649345397949219, "(22, 0)": 0.7649345397949219, "(22, 16)": 0.806727409362793, "(24, 0)": 0.7649345397949219, "(24, 16)": 0.7649345397949219, "(26, 0)": 0.7649345397949219, "(26, 16)": 0.7649345397949219, "(28, 0)": 0.7649345397949219, "(28, 16)": 0.7649345397949219, "(30, 0)": 0.7649345397949219, "(30, 16)": 0.7649345397949219}, "r_span": [615, 703], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001670539379119873}}, {"prompt_attention_score": {"(0, 0)": 0.8542107343673706, "(0, 16)": 0.8542107343673706, "(2, 0)": 0.8542107343673706, "(2, 16)": 0.8542107343673706, "(4, 0)": 0.8542107343673706, "(4, 16)": 0.8542107343673706, "(6, 0)": 0.8542107343673706, "(6, 16)": 0.8542107343673706, "(8, 0)": 0.8542107343673706, "(8, 16)": 0.6857489347457886, "(10, 0)": 0.8542107343673706, "(10, 16)": 0.8542107343673706, "(12, 0)": 0.8542107343673706, "(12, 16)": 0.8542107343673706, "(14, 0)": 0.6857489347457886, "(14, 16)": 0.8542107343673706, "(16, 0)": 0.8542107343673706, "(16, 16)": 0.6857489347457886, "(18, 0)": 0.6857489347457886, "(18, 16)": 0.8542107343673706, "(20, 0)": 0.8542107343673706, "(20, 16)": 0.6857489347457886, "(22, 0)": 0.6857489347457886, "(22, 16)": 0.8542107343673706, "(24, 0)": 0.6857489347457886, "(24, 16)": 0.8542107343673706, "(26, 0)": 0.6857489347457886, "(26, 16)": 0.8542107343673706, "(28, 0)": 0.6857489347457886, "(28, 16)": 0.6857489347457886, "(30, 0)": 0.6857489347457886, "(30, 16)": 0.6857489347457886}, "r_span": [704, 755], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009189248085021973}}, {"prompt_attention_score": {"(0, 0)": 0.7669467926025391, "(0, 16)": 0.7669467926025391, "(2, 0)": 0.7669467926025391, "(2, 16)": 0.7669467926025391, "(4, 0)": 0.7669467926025391, "(4, 16)": 0.7669467926025391, "(6, 0)": 0.7669467926025391, "(6, 16)": 0.7541475296020508, "(8, 0)": 0.7669467926025391, "(8, 16)": 0.7669467926025391, "(10, 0)": 0.46934208273887634, "(10, 16)": 0.7669467926025391, "(12, 0)": 0.7669467926025391, "(12, 16)": 0.7669467926025391, "(14, 0)": 0.7043042778968811, "(14, 16)": 0.46934208273887634, "(16, 0)": 0.8176769018173218, "(16, 16)": 0.7043042778968811, "(18, 0)": 0.7043042778968811, "(18, 16)": 0.7541475296020508, "(20, 0)": 0.7729334235191345, "(20, 16)": 0.7043042778968811, "(22, 0)": 0.7043042778968811, "(22, 16)": 0.7669467926025391, "(24, 0)": 0.7043042778968811, "(24, 16)": 0.7043042778968811, "(26, 0)": 0.7043042778968811, "(26, 16)": 0.7043042778968811, "(28, 0)": 0.7043042778968811, "(28, 16)": 0.7043042778968811, "(30, 0)": 0.7043042778968811, "(30, 16)": 0.7043042778968811}, "r_span": [757, 815], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007971525192260742}}]}, {"id": "14805", "source_id": "15388", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the current temperature in Bucharest, Romania is:\n\nPassage 1 does not provide real-time weather data, so I cannot find the current temperature in Bucharest.\n\nPassage 2 provides a map of UK weather warnings and flood warnings, but it does not provide information on the temperature in Bucharest.\n\nPassage 3 provides general information about the climate in Bucharest, including the average monthly weather patterns, but it does not provide the current temperature. Therefore, I am unable to answer your question based on these passages.", "response_spans": [[0, 326], [328, 567]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7901676893234253, "(0, 16)": 0.7901676893234253, "(2, 0)": 0.7901676893234253, "(2, 16)": 0.7901676893234253, "(4, 0)": 0.7901676893234253, "(4, 16)": 0.7901676893234253, "(6, 0)": 0.7901676893234253, "(6, 16)": 0.8610820770263672, "(8, 0)": 0.8610820770263672, "(8, 16)": 0.7901676893234253, "(10, 0)": 0.5448025465011597, "(10, 16)": 0.5448025465011597, "(12, 0)": 0.8610820770263672, "(12, 16)": 0.8610820770263672, "(14, 0)": 0.8610820770263672, "(14, 16)": 0.5448025465011597, "(16, 0)": 0.8610820770263672, "(16, 16)": 0.8610820770263672, "(18, 0)": 0.8610820770263672, "(18, 16)": 0.8610820770263672, "(20, 0)": 0.8610820770263672, "(20, 16)": 0.7901676893234253, "(22, 0)": 0.8610820770263672, "(22, 16)": 0.8610820770263672, "(24, 0)": 0.8610820770263672, "(24, 16)": 0.8610820770263672, "(26, 0)": 0.8610820770263672, "(26, 16)": 0.8610820770263672, "(28, 0)": 0.8610820770263672, "(28, 16)": 0.8610820770263672, "(30, 0)": 0.8610820770263672, "(30, 16)": 0.8610820770263672}, "r_span": [410, 489], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009698271751403809}}, {"prompt_attention_score": {"(0, 0)": 0.8393518924713135, "(0, 16)": 0.8393518924713135, "(2, 0)": 0.8393518924713135, "(2, 16)": 0.8393518924713135, "(4, 0)": 0.8393518924713135, "(4, 16)": 0.8393518924713135, "(6, 0)": 0.8393518924713135, "(6, 16)": 0.8394841551780701, "(8, 0)": 0.8393518924713135, "(8, 16)": 0.8393518924713135, "(10, 0)": 0.57646644115448, "(10, 16)": 0.57646644115448, "(12, 0)": 0.8394841551780701, "(12, 16)": 0.8393518924713135, "(14, 0)": 0.8394841551780701, "(14, 16)": 0.57646644115448, "(16, 0)": 0.57646644115448, "(16, 16)": 0.8394841551780701, "(18, 0)": 0.8394841551780701, "(18, 16)": 0.8393518924713135, "(20, 0)": 0.8393518924713135, "(20, 16)": 0.8393518924713135, "(22, 0)": 0.8394841551780701, "(22, 16)": 0.57646644115448, "(24, 0)": 0.8394841551780701, "(24, 16)": 0.8393518924713135, "(26, 0)": 0.8394841551780701, "(26, 16)": 0.8393518924713135, "(28, 0)": 0.8394841551780701, "(28, 16)": 0.8394841551780701, "(30, 0)": 0.8394841551780701, "(30, 16)": 0.8394841551780701}, "r_span": [491, 538], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004919767379760742}}]}, {"id": "14817", "source_id": "15390", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "The passage provides step-by-step instructions for removing the rear door panel on a 2006 Chevy HHR. To perform this task, the passenger must locate and remove the two screws inside the door pull cup and the middle of the inside door handle. A pin on the outside edge of the door must also be removed using a door panel removal tool. Once all these steps are completed, the door panel can be carefully pulled away from the frame, taking care not to damage any wiring connections.\n\nAccordingly, the answer to the question is:\n\nRemoving the rear door panel on a 2006 Chevy HHR involves locating and removing the screws inside the door pull cup and the middle of the inside door handle, as well as removing the pin on the outside edge of the door using a door panel removal tool.", "response_spans": [[0, 479], [481, 776]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9262223243713379, "(0, 16)": 0.9262223243713379, "(2, 0)": 0.9262223243713379, "(2, 16)": 0.9262223243713379, "(4, 0)": 0.9262223243713379, "(4, 16)": 0.9262223243713379, "(6, 0)": 0.9262223243713379, "(6, 16)": 0.9045990705490112, "(8, 0)": 0.9262223243713379, "(8, 16)": 0.9262223243713379, "(10, 0)": 0.3726276755332947, "(10, 16)": 0.9262223243713379, "(12, 0)": 0.9262223243713379, "(12, 16)": 0.9262223243713379, "(14, 0)": 0.9262223243713379, "(14, 16)": 0.9045990705490112, "(16, 0)": 0.9045990705490112, "(16, 16)": 0.9045990705490112, "(18, 0)": 0.3726276755332947, "(18, 16)": 0.9045990705490112, "(20, 0)": 0.9045990705490112, "(20, 16)": 0.9262223243713379, "(22, 0)": 0.9045990705490112, "(22, 16)": 0.9045990705490112, "(24, 0)": 0.9262223243713379, "(24, 16)": 0.9045990705490112, "(26, 0)": 0.9045990705490112, "(26, 16)": 0.9045990705490112, "(28, 0)": 0.9045990705490112, "(28, 16)": 0.9262223243713379, "(30, 0)": 0.9045990705490112, "(30, 16)": 0.9045990705490112}, "r_span": [590, 696], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0066149234771728516}}, {"prompt_attention_score": {"(0, 0)": 0.9204092025756836, "(0, 16)": 0.9204092025756836, "(2, 0)": 0.9204092025756836, "(2, 16)": 0.3614754378795624, "(4, 0)": 0.9204092025756836, "(4, 16)": 0.7170366048812866, "(6, 0)": 0.9204092025756836, "(6, 16)": 0.8937350511550903, "(8, 0)": 0.8937350511550903, "(8, 16)": 0.9204092025756836, "(10, 0)": 0.3614754378795624, "(10, 16)": 0.3614754378795624, "(12, 0)": 0.9204092025756836, "(12, 16)": 0.9204092025756836, "(14, 0)": 0.8937350511550903, "(14, 16)": 0.3614754378795624, "(16, 0)": 0.7948827147483826, "(16, 16)": 0.8937350511550903, "(18, 0)": 0.8937350511550903, "(18, 16)": 0.8937350511550903, "(20, 0)": 0.8937350511550903, "(20, 16)": 0.9204092025756836, "(22, 0)": 0.8937350511550903, "(22, 16)": 0.8937350511550903, "(24, 0)": 0.9204092025756836, "(24, 16)": 0.8937350511550903, "(26, 0)": 0.8937350511550903, "(26, 16)": 0.8937350511550903, "(28, 0)": 0.8937350511550903, "(28, 16)": 0.9204092025756836, "(30, 0)": 0.8937350511550903, "(30, 16)": 0.8937350511550903}, "r_span": [698, 771], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004405975341796875}}]}, {"id": "14847", "source_id": "15395", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to make panko crumbs:\n\nPassage 1 states to push torn pieces of bread through the shredding disk of a food processor to make coarse crumbs. Then, spread the crumbs on a baking sheet and bake in a preheated oven until they are dry but not toasted, about 6 to 8 minutes.\n\nPassage 2 provides similar instructions, stating to push chunks of white bread through the shredding disk of a food processor to make coarse crumbs. Then, spread the crumbs on a baking sheet and bake at 300¬∞F until the crumbs are dry but not toasted, about 6 to 8 minutes.\n\nPassage 3 provides additional information, suggesting to preheat the oven to 300¬∞F before making the crumbs. The passage also recommends using a blender carafe to pulse the bread until coarse crumbs form, and then spreading the crumbs evenly on two half-sheet pans and baking until they just begin to brown and are crisp, about 5 minutes. After cooling the crumbs on the pans for 15 to 20 minutes, transfer them to an airtight container and store them at room temperature for up to 2 weeks.\n\nTherefore, to make panko crumbs based on the provided passages, you can use a food processor or blender to shred or pulse bread into coarse crumbs, and then bake them in a preheated oven until they are dry but not toasted.", "response_spans": [[0, 311], [313, 585], [587, 1077], [1079, 1301]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7876840233802795, "(0, 16)": 0.7876840233802795, "(2, 0)": 0.7876840233802795, "(2, 16)": 0.7876840233802795, "(4, 0)": 0.7876840233802795, "(4, 16)": 0.7876840233802795, "(6, 0)": 0.7876840233802795, "(6, 16)": 0.868204653263092, "(8, 0)": 0.7876840233802795, "(8, 16)": 0.7876840233802795, "(10, 0)": 0.3850458860397339, "(10, 16)": 0.3850458860397339, "(12, 0)": 0.7876840233802795, "(12, 16)": 0.868204653263092, "(14, 0)": 0.7876840233802795, "(14, 16)": 0.3850458860397339, "(16, 0)": 0.868204653263092, "(16, 16)": 0.7876840233802795, "(18, 0)": 0.3850458860397339, "(18, 16)": 0.868204653263092, "(20, 0)": 0.868204653263092, "(20, 16)": 0.7876840233802795, "(22, 0)": 0.7876840233802795, "(22, 16)": 0.868204653263092, "(24, 0)": 0.7876840233802795, "(24, 16)": 0.868204653263092, "(26, 0)": 0.7876840233802795, "(26, 16)": 0.7876840233802795, "(28, 0)": 0.7876840233802795, "(28, 16)": 0.7876840233802795, "(30, 0)": 0.7876840233802795, "(30, 16)": 0.7876840233802795}, "r_span": [661, 751], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00022476911544799805}}, {"prompt_attention_score": {"(0, 0)": 0.8232897520065308, "(0, 16)": 0.8232897520065308, "(2, 0)": 0.8232897520065308, "(2, 16)": 0.7692810893058777, "(4, 0)": 0.8232897520065308, "(4, 16)": 0.8232897520065308, "(6, 0)": 0.8232897520065308, "(6, 16)": 0.9503106474876404, "(8, 0)": 0.8232897520065308, "(8, 16)": 0.8232897520065308, "(10, 0)": 0.8232897520065308, "(10, 16)": 0.8232897520065308, "(12, 0)": 0.8232897520065308, "(12, 16)": 0.9503106474876404, "(14, 0)": 0.8232897520065308, "(14, 16)": 0.9503106474876404, "(16, 0)": 0.9503106474876404, "(16, 16)": 0.8232897520065308, "(18, 0)": 0.8232897520065308, "(18, 16)": 0.9503106474876404, "(20, 0)": 0.9503106474876404, "(20, 16)": 0.8232897520065308, "(22, 0)": 0.8232897520065308, "(22, 16)": 0.9503106474876404, "(24, 0)": 0.8232897520065308, "(24, 16)": 0.9503106474876404, "(26, 0)": 0.8232897520065308, "(26, 16)": 0.8232897520065308, "(28, 0)": 0.8232897520065308, "(28, 16)": 0.8232897520065308, "(30, 0)": 0.8232897520065308, "(30, 16)": 0.8232897520065308}, "r_span": [753, 829], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009326934814453125}}, {"prompt_attention_score": {"(0, 0)": 0.9231380224227905, "(0, 16)": 0.9231380224227905, "(2, 0)": 0.9231380224227905, "(2, 16)": 0.9231380224227905, "(4, 0)": 0.9231380224227905, "(4, 16)": 0.9231380224227905, "(6, 0)": 0.9231380224227905, "(6, 16)": 0.9231380224227905, "(8, 0)": 0.9231380224227905, "(8, 16)": 0.9231380224227905, "(10, 0)": 0.9231380224227905, "(10, 16)": 0.9231380224227905, "(12, 0)": 0.9231380224227905, "(12, 16)": 0.9231380224227905, "(14, 0)": 0.9231380224227905, "(14, 16)": 0.9231380224227905, "(16, 0)": 0.9231380224227905, "(16, 16)": 0.9231380224227905, "(18, 0)": 0.9231380224227905, "(18, 16)": 0.9231380224227905, "(20, 0)": 0.9231380224227905, "(20, 16)": 0.9231380224227905, "(22, 0)": 0.9231380224227905, "(22, 16)": 0.9231380224227905, "(24, 0)": 0.9231380224227905, "(24, 16)": 0.9231380224227905, "(26, 0)": 0.9231380224227905, "(26, 16)": 0.9231380224227905, "(28, 0)": 0.9231380224227905, "(28, 16)": 0.9231380224227905, "(30, 0)": 0.9231380224227905, "(30, 16)": 0.9231380224227905}, "r_span": [831, 964], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003801584243774414}}, {"prompt_attention_score": {"(0, 0)": 0.7085217833518982, "(0, 16)": 0.7085217833518982, "(2, 0)": 0.7085217833518982, "(2, 16)": 0.6347577571868896, "(4, 0)": 0.38312557339668274, "(4, 16)": 0.7085217833518982, "(6, 0)": 0.7085217833518982, "(6, 16)": 0.7906996011734009, "(8, 0)": 0.7085217833518982, "(8, 16)": 0.7085217833518982, "(10, 0)": 0.38312557339668274, "(10, 16)": 0.38312557339668274, "(12, 0)": 0.38312557339668274, "(12, 16)": 0.7906996011734009, "(14, 0)": 0.7085217833518982, "(14, 16)": 0.38312557339668274, "(16, 0)": 0.38312557339668274, "(16, 16)": 0.7085217833518982, "(18, 0)": 0.38312557339668274, "(18, 16)": 0.7906996011734009, "(20, 0)": 0.7906996011734009, "(20, 16)": 0.7085217833518982, "(22, 0)": 0.7085217833518982, "(22, 16)": 0.7906996011734009, "(24, 0)": 0.7085217833518982, "(24, 16)": 0.7085217833518982, "(26, 0)": 0.7085217833518982, "(26, 16)": 0.7085217833518982, "(28, 0)": 0.7085217833518982, "(28, 16)": 0.7085217833518982, "(30, 0)": 0.7085217833518982, "(30, 16)": 0.7085217833518982}, "r_span": [966, 1028], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00017309188842773438}}]}, {"id": "14859", "source_id": "15397", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 139, "end": 265, "text": "This can be done by visiting the Shugabush Island and collecting the required items to trade with the other island's resident.", "meta": "HIGH INTRO OF NEW INFO\nIt mentioned visiting the Shugabush Island and collecting the required items to trade with the other island's resident which are not mentioned in the original sources.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 266, "end": 314, "text": "2. Hatch the Shugabush Monster to create an egg.", "meta": "EVIDENT CONFLICT\nOriginal: \"...turn your Shugabush Monsters into an egg then you will need to hatch them...\"\nGenerative: \"Hatch the Shugabush Monster to create an egg.\"", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "To breed a Shugabeats in My Singing Monsters, you will need to follow these steps:\n\n1. Obtain the Shugabush Monster from the other island. This can be done by visiting the Shugabush Island and collecting the required items to trade with the other island's resident.\n2. Hatch the Shugabush Monster to create an egg.\n3. Buy the breeding structure for the Shugabeats on the Shugabush Island.\n4. Breed the Shugabush and Furcorn in the breeding structure to get the Shugabeats monster.\n\nHere is the specific breeding combination needed to produce the Shugabeats:\n\n* Shugabush + Furcorn = Shugabeats\n\nIt is important to note that breeding the monsters in the correct position in the breeding structure does not matter, so feel free to try breeding them in different positions until you get the desired result.", "response_spans": [[0, 480], [482, 803]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7471593022346497, "(0, 16)": 0.7471593022346497, "(2, 0)": 0.7471593022346497, "(2, 16)": 0.7471593022346497, "(4, 0)": 0.7471593022346497, "(4, 16)": 0.7471593022346497, "(6, 0)": 0.7471593022346497, "(6, 16)": 0.948215901851654, "(8, 0)": 0.7471593022346497, "(8, 16)": 0.7471593022346497, "(10, 0)": 0.7471593022346497, "(10, 16)": 0.948215901851654, "(12, 0)": 0.948215901851654, "(12, 16)": 0.948215901851654, "(14, 0)": 0.948215901851654, "(14, 16)": 0.948215901851654, "(16, 0)": 0.948215901851654, "(16, 16)": 0.948215901851654, "(18, 0)": 0.36277320981025696, "(18, 16)": 0.948215901851654, "(20, 0)": 0.948215901851654, "(20, 16)": 0.948215901851654, "(22, 0)": 0.948215901851654, "(22, 16)": 0.948215901851654, "(24, 0)": 0.7471593022346497, "(24, 16)": 0.948215901851654, "(26, 0)": 0.948215901851654, "(26, 16)": 0.710051953792572, "(28, 0)": 0.7471593022346497, "(28, 16)": 0.948215901851654, "(30, 0)": 0.948215901851654, "(30, 16)": 0.948215901851654}, "r_span": [518, 657], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009315609931945801}}, {"prompt_attention_score": {"(0, 0)": 0.7337857484817505, "(0, 16)": 0.7337857484817505, "(2, 0)": 0.7337857484817505, "(2, 16)": 0.44889819622039795, "(4, 0)": 0.7337857484817505, "(4, 16)": 0.7337857484817505, "(6, 0)": 0.8735576868057251, "(6, 16)": 0.8735576868057251, "(8, 0)": 0.7337857484817505, "(8, 16)": 0.8735576868057251, "(10, 0)": 0.7337857484817505, "(10, 16)": 0.44889819622039795, "(12, 0)": 0.8735576868057251, "(12, 16)": 0.8735576868057251, "(14, 0)": 0.8735576868057251, "(14, 16)": 0.7337857484817505, "(16, 0)": 0.8735576868057251, "(16, 16)": 0.8735576868057251, "(18, 0)": 0.8735576868057251, "(18, 16)": 0.8735576868057251, "(20, 0)": 0.8735576868057251, "(20, 16)": 0.8735576868057251, "(22, 0)": 0.8735576868057251, "(22, 16)": 0.8735576868057251, "(24, 0)": 0.7106485366821289, "(24, 16)": 0.8735576868057251, "(26, 0)": 0.8735576868057251, "(26, 16)": 0.8735576868057251, "(28, 0)": 0.7337857484817505, "(28, 16)": 0.8735576868057251, "(30, 0)": 0.8735576868057251, "(30, 16)": 0.8735576868057251}, "r_span": [659, 735], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002604186534881592}}]}, {"id": "14889", "source_id": "15402", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, there is no straightforward way to find deleted pictures on an iPhone. Passage 1 states that once a text message is deleted, it cannot be recovered. Similarly, passage 2 provides methods for recovering deleted photos from an iPhone backup, but does not mention how to recover deleted pictures from the Messages app directly. Passage 3 also only discusses recovering data from an iPhone backup, rather than providing a method for finding deleted pictures within the Messages app.\n\nTherefore, I must reply with: \"Unable to answer based on given passages.\"", "response_spans": [[0, 510], [512, 585]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8323696851730347, "(0, 16)": 0.8323696851730347, "(2, 0)": 0.8323696851730347, "(2, 16)": 0.8323696851730347, "(4, 0)": 0.8323696851730347, "(4, 16)": 0.8323696851730347, "(6, 0)": 0.8640916347503662, "(6, 16)": 0.8640916347503662, "(8, 0)": 0.8640916347503662, "(8, 16)": 0.4673156142234802, "(10, 0)": 0.4673156142234802, "(10, 16)": 0.4673156142234802, "(12, 0)": 0.8323696851730347, "(12, 16)": 0.8640916347503662, "(14, 0)": 0.7856132984161377, "(14, 16)": 0.4673156142234802, "(16, 0)": 0.8410400152206421, "(16, 16)": 0.7856132984161377, "(18, 0)": 0.4673156142234802, "(18, 16)": 0.7856132984161377, "(20, 0)": 0.8640916347503662, "(20, 16)": 0.7856132984161377, "(22, 0)": 0.7856132984161377, "(22, 16)": 0.8640916347503662, "(24, 0)": 0.7856132984161377, "(24, 16)": 0.7856132984161377, "(26, 0)": 0.7856132984161377, "(26, 16)": 0.7856132984161377, "(28, 0)": 0.7856132984161377, "(28, 16)": 0.7856132984161377, "(30, 0)": 0.7856132984161377, "(30, 16)": 0.7856132984161377}, "r_span": [578, 681], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00040781497955322266}}, {"prompt_attention_score": {"(0, 0)": 0.4503587484359741, "(0, 16)": 0.4503587484359741, "(2, 0)": 0.4503587484359741, "(2, 16)": 0.4503587484359741, "(4, 0)": 0.4503587484359741, "(4, 16)": 0.4503587484359741, "(6, 0)": 0.3880908787250519, "(6, 16)": 0.8994010090827942, "(8, 0)": 0.3880908787250519, "(8, 16)": 0.4503587484359741, "(10, 0)": 0.8994010090827942, "(10, 16)": 0.8994010090827942, "(12, 0)": 0.8994010090827942, "(12, 16)": 0.8994010090827942, "(14, 0)": 0.4403384029865265, "(14, 16)": 0.8994010090827942, "(16, 0)": 0.8994010090827942, "(16, 16)": 0.4403384029865265, "(18, 0)": 0.4403384029865265, "(18, 16)": 0.8994010090827942, "(20, 0)": 0.8994010090827942, "(20, 16)": 0.4403384029865265, "(22, 0)": 0.4403384029865265, "(22, 16)": 0.8994010090827942, "(24, 0)": 0.4403384029865265, "(24, 16)": 0.8994010090827942, "(26, 0)": 0.4403384029865265, "(26, 16)": 0.4403384029865265, "(28, 0)": 0.4403384029865265, "(28, 16)": 0.4403384029865265, "(30, 0)": 0.4403384029865265, "(30, 16)": 0.4403384029865265}, "r_span": [683, 702], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00017398595809936523}}]}, {"id": "14997", "source_id": "15420", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, an UPDescription is:\n\n1. A barcode symbology used for tracking trade items in stores, consisting of 12 numeric digits that are uniquely assigned to each trade item. (Passage 1)\n2. A process involving receiving a specimen bottle from a member, ensuring it contains a minimum of 30 milliliters of urine, initialing the label in the member's presence, and verifying the information on the label and DD Form 2624 (a military form). (Passage 2)\n3. A barcode partner that provides GS1 Originated UPC and EAN codes, as well as a toll-free number and positive customer reviews. (Passage 3)\n\nUnable to answer based on given passages.", "response_spans": [[0, 52], [54, 471], [472, 613], [615, 656]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5425188541412354, "(0, 16)": 0.5425188541412354, "(2, 0)": 0.5425188541412354, "(2, 16)": 0.5425188541412354, "(4, 0)": 0.5425188541412354, "(4, 16)": 0.5425188541412354, "(6, 0)": 0.5425188541412354, "(6, 16)": 0.7370473146438599, "(8, 0)": 0.5425188541412354, "(8, 16)": 0.5425188541412354, "(10, 0)": 0.5425188541412354, "(10, 16)": 0.5425188541412354, "(12, 0)": 0.5425188541412354, "(12, 16)": 0.7370473146438599, "(14, 0)": 0.6254503130912781, "(14, 16)": 0.5425188541412354, "(16, 0)": 0.7370473146438599, "(16, 16)": 0.5425188541412354, "(18, 0)": 0.5425188541412354, "(18, 16)": 0.7370473146438599, "(20, 0)": 0.7370473146438599, "(20, 16)": 0.6254503130912781, "(22, 0)": 0.6254503130912781, "(22, 16)": 0.7370473146438599, "(24, 0)": 0.6254503130912781, "(24, 16)": 0.5425188541412354, "(26, 0)": 0.6254503130912781, "(26, 16)": 0.6254503130912781, "(28, 0)": 0.6254503130912781, "(28, 16)": 0.6254503130912781, "(30, 0)": 0.6254503130912781, "(30, 16)": 0.6254503130912781}, "r_span": [469, 482], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007854700088500977}}, {"prompt_attention_score": {"(0, 0)": 0.5095779299736023, "(0, 16)": 0.5095779299736023, "(2, 0)": 0.5095779299736023, "(2, 16)": 0.5095779299736023, "(4, 0)": 0.5095779299736023, "(4, 16)": 0.5095779299736023, "(6, 0)": 0.5095779299736023, "(6, 16)": 0.6857198476791382, "(8, 0)": 0.6857198476791382, "(8, 16)": 0.5095779299736023, "(10, 0)": 0.5095779299736023, "(10, 16)": 0.6857198476791382, "(12, 0)": 0.6857198476791382, "(12, 16)": 0.6857198476791382, "(14, 0)": 0.6857198476791382, "(14, 16)": 0.6857198476791382, "(16, 0)": 0.6857198476791382, "(16, 16)": 0.6857198476791382, "(18, 0)": 0.5095779299736023, "(18, 16)": 0.6857198476791382, "(20, 0)": 0.6857198476791382, "(20, 16)": 0.6857198476791382, "(22, 0)": 0.6857198476791382, "(22, 16)": 0.6857198476791382, "(24, 0)": 0.6857198476791382, "(24, 16)": 0.6857198476791382, "(26, 0)": 0.6857198476791382, "(26, 16)": 0.6857198476791382, "(28, 0)": 0.6857198476791382, "(28, 16)": 0.6857198476791382, "(30, 0)": 0.6857198476791382, "(30, 16)": 0.6857198476791382}, "r_span": [484, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001149594783782959}}, {"prompt_attention_score": {"(0, 0)": 0.8576084971427917, "(0, 16)": 0.8576084971427917, "(2, 0)": 0.8576084971427917, "(2, 16)": 0.8576084971427917, "(4, 0)": 0.8576084971427917, "(4, 16)": 0.8576084971427917, "(6, 0)": 0.5983193516731262, "(6, 16)": 0.7733443975448608, "(8, 0)": 0.5983193516731262, "(8, 16)": 0.5983193516731262, "(10, 0)": 0.8576084971427917, "(10, 16)": 0.8576084971427917, "(12, 0)": 0.8576084971427917, "(12, 16)": 0.8576084971427917, "(14, 0)": 0.5983193516731262, "(14, 16)": 0.8576084971427917, "(16, 0)": 0.8576084971427917, "(16, 16)": 0.8576084971427917, "(18, 0)": 0.8576084971427917, "(18, 16)": 0.8576084971427917, "(20, 0)": 0.8576084971427917, "(20, 16)": 0.5983193516731262, "(22, 0)": 0.5983193516731262, "(22, 16)": 0.8576084971427917, "(24, 0)": 0.5983193516731262, "(24, 16)": 0.8576084971427917, "(26, 0)": 0.5983193516731262, "(26, 16)": 0.8576084971427917, "(28, 0)": 0.8576084971427917, "(28, 16)": 0.5983193516731262, "(30, 0)": 0.5983193516731262, "(30, 16)": 0.5983193516731262}, "r_span": [597, 637], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005898475646972656}}, {"prompt_attention_score": {"(0, 0)": 0.5624086260795593, "(0, 16)": 0.5624086260795593, "(2, 0)": 0.5624086260795593, "(2, 16)": 0.5624086260795593, "(4, 0)": 0.5624086260795593, "(4, 16)": 0.5624086260795593, "(6, 0)": 0.5624086260795593, "(6, 16)": 0.5624086260795593, "(8, 0)": 0.6370489597320557, "(8, 16)": 0.5624086260795593, "(10, 0)": 0.5624086260795593, "(10, 16)": 0.5624086260795593, "(12, 0)": 0.5624086260795593, "(12, 16)": 0.5624086260795593, "(14, 0)": 0.6370489597320557, "(14, 16)": 0.5624086260795593, "(16, 0)": 0.5624086260795593, "(16, 16)": 0.5624086260795593, "(18, 0)": 0.5624086260795593, "(18, 16)": 0.5624086260795593, "(20, 0)": 0.5624086260795593, "(20, 16)": 0.6370489597320557, "(22, 0)": 0.6370489597320557, "(22, 16)": 0.5624086260795593, "(24, 0)": 0.6370489597320557, "(24, 16)": 0.5624086260795593, "(26, 0)": 0.5624086260795593, "(26, 16)": 0.6370489597320557, "(28, 0)": 0.6370489597320557, "(28, 16)": 0.6370489597320557, "(30, 0)": 0.6370489597320557, "(30, 16)": 0.6370489597320557}, "r_span": [639, 649], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000670313835144043}}]}, {"id": "15009", "source_id": "15422", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how twins happen:\n\n* Monoamniotic twins: These twins occur when the split takes place after the ninth day after fertilization.\n* Conjoined twins: When the division of the developing zygote into 2 embryos occurs, it happens within 8 days of fertilization, and mortality is highest for conjoined twins due to the many complications resulting from shared organs.\n* Dizygotic twin pregnancies: These twins are slightly more likely to occur in women who are of West African descent (especially Yoruba), between the ages of 30 and 40, are taller and heavier than average, and have had several previous pregnancies.\n* Identical twins (monozygotic): These twins develop from one zygote, which splits and forms two embryos.\n* Fraternal twins (dizygotic): These twins develop from two different eggs, and each twin is fertilized by its own sperm cell.\n\nUnable to answer based on given passages: The passage does not provide information on the exact timing or mechanism of twinning beyond what is mentioned above.", "response_spans": [[0, 57], [59, 399], [400, 881], [883, 1042]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7689288854598999, "(0, 16)": 0.7689288854598999, "(2, 0)": 0.7689288854598999, "(2, 16)": 0.7689288854598999, "(4, 0)": 0.7689288854598999, "(4, 16)": 0.7689288854598999, "(6, 0)": 0.5117141008377075, "(6, 16)": 0.6992756128311157, "(8, 0)": 0.6992756128311157, "(8, 16)": 0.5117141008377075, "(10, 0)": 0.5117141008377075, "(10, 16)": 0.5117141008377075, "(12, 0)": 0.5117141008377075, "(12, 16)": 0.6992756128311157, "(14, 0)": 0.687773585319519, "(14, 16)": 0.5117141008377075, "(16, 0)": 0.6992756128311157, "(16, 16)": 0.7689288854598999, "(18, 0)": 0.5117141008377075, "(18, 16)": 0.6992756128311157, "(20, 0)": 0.6992756128311157, "(20, 16)": 0.687773585319519, "(22, 0)": 0.687773585319519, "(22, 16)": 0.6992756128311157, "(24, 0)": 0.687773585319519, "(24, 16)": 0.6992756128311157, "(26, 0)": 0.687773585319519, "(26, 16)": 0.687773585319519, "(28, 0)": 0.687773585319519, "(28, 16)": 0.687773585319519, "(30, 0)": 0.687773585319519, "(30, 16)": 0.687773585319519}, "r_span": [434, 449], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 3.0219554901123047e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7427710890769958, "(0, 16)": 0.7427710890769958, "(2, 0)": 0.7427710890769958, "(2, 16)": 0.7427710890769958, "(4, 0)": 0.7427710890769958, "(4, 16)": 0.7427710890769958, "(6, 0)": 0.7427710890769958, "(6, 16)": 0.972561776638031, "(8, 0)": 0.7427710890769958, "(8, 16)": 0.7427710890769958, "(10, 0)": 0.972561776638031, "(10, 16)": 0.7427710890769958, "(12, 0)": 0.7427710890769958, "(12, 16)": 0.972561776638031, "(14, 0)": 0.681865930557251, "(14, 16)": 0.7427710890769958, "(16, 0)": 0.972561776638031, "(16, 16)": 0.7427710890769958, "(18, 0)": 0.681865930557251, "(18, 16)": 0.972561776638031, "(20, 0)": 0.972561776638031, "(20, 16)": 0.681865930557251, "(22, 0)": 0.681865930557251, "(22, 16)": 0.972561776638031, "(24, 0)": 0.681865930557251, "(24, 16)": 0.972561776638031, "(26, 0)": 0.681865930557251, "(26, 16)": 0.681865930557251, "(28, 0)": 0.681865930557251, "(28, 16)": 0.681865930557251, "(30, 0)": 0.681865930557251, "(30, 16)": 0.681865930557251}, "r_span": [451, 538], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014486908912658691}}, {"prompt_attention_score": {"(0, 0)": 0.7914431691169739, "(0, 16)": 0.7914431691169739, "(2, 0)": 0.7914431691169739, "(2, 16)": 0.7914431691169739, "(4, 0)": 0.7914431691169739, "(4, 16)": 0.7914431691169739, "(6, 0)": 0.7914431691169739, "(6, 16)": 0.7914431691169739, "(8, 0)": 0.7914431691169739, "(8, 16)": 0.7914431691169739, "(10, 0)": 0.7914431691169739, "(10, 16)": 0.7914431691169739, "(12, 0)": 0.8427371978759766, "(12, 16)": 0.7914431691169739, "(14, 0)": 0.8427371978759766, "(14, 16)": 0.7914431691169739, "(16, 0)": 0.7914431691169739, "(16, 16)": 0.7914431691169739, "(18, 0)": 0.8427371978759766, "(18, 16)": 0.8427371978759766, "(20, 0)": 0.8427371978759766, "(20, 16)": 0.8427371978759766, "(22, 0)": 0.8427371978759766, "(22, 16)": 0.7914431691169739, "(24, 0)": 0.8427371978759766, "(24, 16)": 0.7914431691169739, "(26, 0)": 0.8427371978759766, "(26, 16)": 0.7914431691169739, "(28, 0)": 0.8427371978759766, "(28, 16)": 0.8427371978759766, "(30, 0)": 0.8427371978759766, "(30, 16)": 0.8427371978759766}, "r_span": [539, 676], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00016230344772338867}}, {"prompt_attention_score": {"(0, 0)": 0.6925417184829712, "(0, 16)": 0.6925417184829712, "(2, 0)": 0.6925417184829712, "(2, 16)": 0.6925417184829712, "(4, 0)": 0.6925417184829712, "(4, 16)": 0.6925417184829712, "(6, 0)": 0.6925417184829712, "(6, 16)": 0.6421193480491638, "(8, 0)": 0.6925417184829712, "(8, 16)": 0.6925417184829712, "(10, 0)": 0.6420046091079712, "(10, 16)": 0.6420046091079712, "(12, 0)": 0.6420046091079712, "(12, 16)": 0.6420046091079712, "(14, 0)": 0.6660791635513306, "(14, 16)": 0.6420046091079712, "(16, 0)": 0.6420046091079712, "(16, 16)": 0.6660791635513306, "(18, 0)": 0.6660791635513306, "(18, 16)": 0.6421193480491638, "(20, 0)": 0.6421193480491638, "(20, 16)": 0.6660791635513306, "(22, 0)": 0.6660791635513306, "(22, 16)": 0.6421193480491638, "(24, 0)": 0.6660791635513306, "(24, 16)": 0.6420046091079712, "(26, 0)": 0.6660791635513306, "(26, 16)": 0.6660791635513306, "(28, 0)": 0.6660791635513306, "(28, 16)": 0.6660791635513306, "(30, 0)": 0.6660791635513306, "(30, 16)": 0.6660791635513306}, "r_span": [678, 710], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0016646981239318848}}]}, {"id": "15105", "source_id": "15438", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to clean tarnished jewelry at home:\n\n1. Mix a few drops of mild dish soap with warm water and dip a soft cloth to shine silver jewelry that is merely dull or starting to discolor. Rub the jewelry, then rinse in cool water and buff with a cloth until dry.\n2. Use warm soapy water and a soft-bristle brush or old toothbrush to clean diamonds. Pat the jewelry dry with a soft cloth.\n3. Soak tarnished silver jewelry in a saltwater solution of two cups of hot water. This method is gentle and can remove tarnish without abrading the silver. Make sure the gemstones will not be affected by the solution before submerging them.\n\nUnable to answer based on given passages. The passages do not provide information on how to clean other types of jewelry, such as gold or platinum, or what to do if the tarnish is heavy or if the jewelry has intricate designs that may be damaged during cleaning.", "response_spans": [[0, 86], [88, 430], [431, 672], [674, 936]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7846927642822266, "(0, 16)": 0.7846927642822266, "(2, 0)": 0.7846927642822266, "(2, 16)": 0.7846927642822266, "(4, 0)": 0.7846927642822266, "(4, 16)": 0.7846927642822266, "(6, 0)": 0.7846927642822266, "(6, 16)": 0.8882494568824768, "(8, 0)": 0.7739672660827637, "(8, 16)": 0.4103755056858063, "(10, 0)": 0.4103755056858063, "(10, 16)": 0.4103755056858063, "(12, 0)": 0.7846927642822266, "(12, 16)": 0.8882494568824768, "(14, 0)": 0.7846927642822266, "(14, 16)": 0.4103755056858063, "(16, 0)": 0.8882494568824768, "(16, 16)": 0.7846927642822266, "(18, 0)": 0.4103755056858063, "(18, 16)": 0.8882494568824768, "(20, 0)": 0.8882494568824768, "(20, 16)": 0.7846927642822266, "(22, 0)": 0.7846927642822266, "(22, 16)": 0.8882494568824768, "(24, 0)": 0.7846927642822266, "(24, 16)": 0.8882494568824768, "(26, 0)": 0.7846927642822266, "(26, 16)": 0.7846927642822266, "(28, 0)": 0.4103755056858063, "(28, 16)": 0.7846927642822266, "(30, 0)": 0.7846927642822266, "(30, 16)": 0.7846927642822266}, "r_span": [450, 474], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00020426511764526367}}, {"prompt_attention_score": {"(0, 0)": 0.8128947019577026, "(0, 16)": 0.8128947019577026, "(2, 0)": 0.8128947019577026, "(2, 16)": 0.8128947019577026, "(4, 0)": 0.8128947019577026, "(4, 16)": 0.8128947019577026, "(6, 0)": 0.8128947019577026, "(6, 16)": 0.8365910649299622, "(8, 0)": 0.8128947019577026, "(8, 16)": 0.8128947019577026, "(10, 0)": 0.8128947019577026, "(10, 16)": 0.8128947019577026, "(12, 0)": 0.8128947019577026, "(12, 16)": 0.8365910649299622, "(14, 0)": 0.8128947019577026, "(14, 16)": 0.8128947019577026, "(16, 0)": 0.8365910649299622, "(16, 16)": 0.8128947019577026, "(18, 0)": 0.8128947019577026, "(18, 16)": 0.8365910649299622, "(20, 0)": 0.8365910649299622, "(20, 16)": 0.8128947019577026, "(22, 0)": 0.8128947019577026, "(22, 16)": 0.8365910649299622, "(24, 0)": 0.8128947019577026, "(24, 16)": 0.8365910649299622, "(26, 0)": 0.8128947019577026, "(26, 16)": 0.8128947019577026, "(28, 0)": 0.8128947019577026, "(28, 16)": 0.8128947019577026, "(30, 0)": 0.8128947019577026, "(30, 16)": 0.8128947019577026}, "r_span": [476, 577], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015118122100830078}}, {"prompt_attention_score": {"(0, 0)": 0.9064844250679016, "(0, 16)": 0.9064844250679016, "(2, 0)": 0.9064844250679016, "(2, 16)": 0.9064844250679016, "(4, 0)": 0.9064844250679016, "(4, 16)": 0.9064844250679016, "(6, 0)": 0.9064844250679016, "(6, 16)": 0.9064844250679016, "(8, 0)": 0.9064844250679016, "(8, 16)": 0.9064844250679016, "(10, 0)": 0.9064844250679016, "(10, 16)": 0.9064844250679016, "(12, 0)": 0.9064844250679016, "(12, 16)": 0.9064844250679016, "(14, 0)": 0.9064844250679016, "(14, 16)": 0.9064844250679016, "(16, 0)": 0.9064844250679016, "(16, 16)": 0.9064844250679016, "(18, 0)": 0.9064844250679016, "(18, 16)": 0.9064844250679016, "(20, 0)": 0.9064844250679016, "(20, 16)": 0.9064844250679016, "(22, 0)": 0.9064844250679016, "(22, 16)": 0.9064844250679016, "(24, 0)": 0.9064844250679016, "(24, 16)": 0.9064844250679016, "(26, 0)": 0.9064844250679016, "(26, 16)": 0.9064844250679016, "(28, 0)": 0.9064844250679016, "(28, 16)": 0.9064844250679016, "(30, 0)": 0.9064844250679016, "(30, 16)": 0.9064844250679016}, "r_span": [578, 639], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000420987606048584}}, {"prompt_attention_score": {"(0, 0)": 0.8053044080734253, "(0, 16)": 0.8053044080734253, "(2, 0)": 0.8053044080734253, "(2, 16)": 0.8053044080734253, "(4, 0)": 0.8053044080734253, "(4, 16)": 0.8053044080734253, "(6, 0)": 0.8053044080734253, "(6, 16)": 0.8053044080734253, "(8, 0)": 0.8053044080734253, "(8, 16)": 0.8053044080734253, "(10, 0)": 0.8053044080734253, "(10, 16)": 0.8053044080734253, "(12, 0)": 0.8053044080734253, "(12, 16)": 0.578670859336853, "(14, 0)": 0.8053044080734253, "(14, 16)": 0.578670859336853, "(16, 0)": 0.8053044080734253, "(16, 16)": 0.8053044080734253, "(18, 0)": 0.8053044080734253, "(18, 16)": 0.8053044080734253, "(20, 0)": 0.7812334299087524, "(20, 16)": 0.8053044080734253, "(22, 0)": 0.8053044080734253, "(22, 16)": 0.7812334299087524, "(24, 0)": 0.8053044080734253, "(24, 16)": 0.8053044080734253, "(26, 0)": 0.8053044080734253, "(26, 16)": 0.7812334299087524, "(28, 0)": 0.8053044080734253, "(28, 16)": 0.8053044080734253, "(30, 0)": 0.8053044080734253, "(30, 16)": 0.8053044080734253}, "r_span": [641, 709], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001574873924255371}}]}, {"id": "15129", "source_id": "15442", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 79, "end": 338, "text": "1. Use a people search website in France: There are websites specifically designed for finding people in France, such as http://www.peoplefinder.com/france/. These websites can help you locate someone by entering their last name and other identifying details.", "meta": "LOW INTRO OF NEW INFO \n- Passages did not mention about using people finder in locating someone in France. However, this is likely to be true based on the context.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to find someone in France:\n\n1. Use a people search website in France: There are websites specifically designed for finding people in France, such as http://www.peoplefinder.com/france/. These websites can help you locate someone by entering their last name and other identifying details.\n2. Check the French white pages (Pages Jaunes): You can use the English version of the French white pages, http://www.pagesjaunes.fr/, to search for someone in France. Enter the person's last name in the Nom field and any additional information you may know, such as their first name or address.\n3. Post a missed connection ad on Craigslist Paris: You can post an ad on Craigslist Paris, http://paris.craigslist.org/, indicating that you are trying to find someone who you lost contact with. Provide as much detail as possible about the person you are looking for, including their last name and any other identifying information.\n\nUnable to answer based on given passages. The passages do not provide enough information to guide the user through the process of finding someone in France.", "response_spans": [[0, 77], [79, 338], [339, 634], [635, 968], [970, 1126]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7464008331298828, "(0, 16)": 0.7464008331298828, "(2, 0)": 0.7464008331298828, "(2, 16)": 0.7464008331298828, "(4, 0)": 0.7464008331298828, "(4, 16)": 0.7464008331298828, "(6, 0)": 0.7464008331298828, "(6, 16)": 0.8500956296920776, "(8, 0)": 0.7464008331298828, "(8, 16)": 0.5378705263137817, "(10, 0)": 0.5378705263137817, "(10, 16)": 0.5378705263137817, "(12, 0)": 0.5378705263137817, "(12, 16)": 0.5378705263137817, "(14, 0)": 0.7464008331298828, "(14, 16)": 0.5378705263137817, "(16, 0)": 0.8500956296920776, "(16, 16)": 0.7657745480537415, "(18, 0)": 0.5378705263137817, "(18, 16)": 0.8500956296920776, "(20, 0)": 0.8500956296920776, "(20, 16)": 0.7657745480537415, "(22, 0)": 0.7657745480537415, "(22, 16)": 0.8500956296920776, "(24, 0)": 0.7464008331298828, "(24, 16)": 0.8500956296920776, "(26, 0)": 0.7657745480537415, "(26, 16)": 0.7657745480537415, "(28, 0)": 0.5378705263137817, "(28, 16)": 0.7657745480537415, "(30, 0)": 0.7657745480537415, "(30, 16)": 0.7657745480537415}, "r_span": [587, 605], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00011593103408813477}}, {"prompt_attention_score": {"(0, 0)": 0.7779626846313477, "(0, 16)": 0.752444863319397, "(2, 0)": 0.7779626846313477, "(2, 16)": 0.7779626846313477, "(4, 0)": 0.7779626846313477, "(4, 16)": 0.7779626846313477, "(6, 0)": 0.7779626846313477, "(6, 16)": 0.7376564741134644, "(8, 0)": 0.7779626846313477, "(8, 16)": 0.7779626846313477, "(10, 0)": 0.7376564741134644, "(10, 16)": 0.7779626846313477, "(12, 0)": 0.7779626846313477, "(12, 16)": 0.752444863319397, "(14, 0)": 0.7779626846313477, "(14, 16)": 0.752444863319397, "(16, 0)": 0.7376564741134644, "(16, 16)": 0.7376564741134644, "(18, 0)": 0.7376564741134644, "(18, 16)": 0.7376564741134644, "(20, 0)": 0.7376564741134644, "(20, 16)": 0.7779626846313477, "(22, 0)": 0.7376564741134644, "(22, 16)": 0.7376564741134644, "(24, 0)": 0.7779626846313477, "(24, 16)": 0.7376564741134644, "(26, 0)": 0.7376564741134644, "(26, 16)": 0.7376564741134644, "(28, 0)": 0.7376564741134644, "(28, 16)": 0.7376564741134644, "(30, 0)": 0.7376564741134644, "(30, 16)": 0.7376564741134644}, "r_span": [607, 661], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0002453327178955078}}, {"prompt_attention_score": {"(0, 0)": 0.8804336190223694, "(0, 16)": 0.7994712591171265, "(2, 0)": 0.8804336190223694, "(2, 16)": 0.7994712591171265, "(4, 0)": 0.8804336190223694, "(4, 16)": 0.8804336190223694, "(6, 0)": 0.8804336190223694, "(6, 16)": 0.7994712591171265, "(8, 0)": 0.8804336190223694, "(8, 16)": 0.8804336190223694, "(10, 0)": 0.8804336190223694, "(10, 16)": 0.8804336190223694, "(12, 0)": 0.8804336190223694, "(12, 16)": 0.8804336190223694, "(14, 0)": 0.8804336190223694, "(14, 16)": 0.8804336190223694, "(16, 0)": 0.8804336190223694, "(16, 16)": 0.7184277772903442, "(18, 0)": 0.7184277772903442, "(18, 16)": 0.8804336190223694, "(20, 0)": 0.7994712591171265, "(20, 16)": 0.7184277772903442, "(22, 0)": 0.7184277772903442, "(22, 16)": 0.8804336190223694, "(24, 0)": 0.7184277772903442, "(24, 16)": 0.8804336190223694, "(26, 0)": 0.7184277772903442, "(26, 16)": 0.8804336190223694, "(28, 0)": 0.7184277772903442, "(28, 16)": 0.7184277772903442, "(30, 0)": 0.7184277772903442, "(30, 16)": 0.7184277772903442}, "r_span": [662, 730], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0014577507972717285}}, {"prompt_attention_score": {"(0, 0)": 0.6660284996032715, "(0, 16)": 0.7811461091041565, "(2, 0)": 0.6660284996032715, "(2, 16)": 0.6660284996032715, "(4, 0)": 0.6660284996032715, "(4, 16)": 0.6660284996032715, "(6, 0)": 0.6660284996032715, "(6, 16)": 0.7811461091041565, "(8, 0)": 0.6660284996032715, "(8, 16)": 0.6660284996032715, "(10, 0)": 0.7811461091041565, "(10, 16)": 0.6778489947319031, "(12, 0)": 0.6660284996032715, "(12, 16)": 0.7811461091041565, "(14, 0)": 0.6144099235534668, "(14, 16)": 0.6660284996032715, "(16, 0)": 0.7811461091041565, "(16, 16)": 0.6144099235534668, "(18, 0)": 0.47407814860343933, "(18, 16)": 0.7811461091041565, "(20, 0)": 0.7811461091041565, "(20, 16)": 0.6660284996032715, "(22, 0)": 0.6778489947319031, "(22, 16)": 0.7811461091041565, "(24, 0)": 0.6778489947319031, "(24, 16)": 0.7811461091041565, "(26, 0)": 0.6778489947319031, "(26, 16)": 0.6778489947319031, "(28, 0)": 0.6778489947319031, "(28, 16)": 0.6778489947319031, "(30, 0)": 0.6778489947319031, "(30, 16)": 0.6778489947319031}, "r_span": [731, 806], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008968114852905273}}, {"prompt_attention_score": {"(0, 0)": 0.7323117852210999, "(0, 16)": 0.746086597442627, "(2, 0)": 0.7323117852210999, "(2, 16)": 0.7323117852210999, "(4, 0)": 0.7323117852210999, "(4, 16)": 0.7323117852210999, "(6, 0)": 0.7323117852210999, "(6, 16)": 0.8128774166107178, "(8, 0)": 0.7323117852210999, "(8, 16)": 0.7323117852210999, "(10, 0)": 0.8001704216003418, "(10, 16)": 0.8001704216003418, "(12, 0)": 0.7323117852210999, "(12, 16)": 0.8001704216003418, "(14, 0)": 0.7323117852210999, "(14, 16)": 0.8001704216003418, "(16, 0)": 0.8001704216003418, "(16, 16)": 0.7956406474113464, "(18, 0)": 0.7323117852210999, "(18, 16)": 0.8001704216003418, "(20, 0)": 0.8001704216003418, "(20, 16)": 0.7323117852210999, "(22, 0)": 0.7956406474113464, "(22, 16)": 0.8001704216003418, "(24, 0)": 0.7323117852210999, "(24, 16)": 0.8001704216003418, "(26, 0)": 0.7956406474113464, "(26, 16)": 0.7956406474113464, "(28, 0)": 0.7956406474113464, "(28, 16)": 0.7956406474113464, "(30, 0)": 0.7956406474113464, "(30, 16)": 0.7956406474113464}, "r_span": [808, 839], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00012236833572387695}}]}, {"id": "15177", "source_id": "15450", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, forest fires are beneficial to conifers like jack pines in several ways:\n\n1. Fire helps to clear the way for new growth by consuming dead, decaying vegetation on the forest floor, creating a clean slate for seed germination and seedling establishment (Passage 2).\n2. Jack pine seeds are adapted to fire, as they are stored in serotinous cones that only open after a fire has melted the resin holding them closed. This allows the seeds to disperse and establish new populations (Passage 2).\n3. Fire can create a favorable environment for jack pine and aspen regrowth by reducing competition from other tree species, such as spruce, which have better access to sunlight while shading the other trees (Passage 3).\n\nTherefore, forest fires can benefit jack pines by providing a means of seed dispersal and creating conditions that promote their growth and regeneration.", "response_spans": [[0, 104], [106, 521], [522, 742], [744, 897]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.765498161315918, "(0, 16)": 0.765498161315918, "(2, 0)": 0.765498161315918, "(2, 16)": 0.765498161315918, "(4, 0)": 0.765498161315918, "(4, 16)": 0.765498161315918, "(6, 0)": 0.765498161315918, "(6, 16)": 0.8281957507133484, "(8, 0)": 0.765498161315918, "(8, 16)": 0.765498161315918, "(10, 0)": 0.765498161315918, "(10, 16)": 0.765498161315918, "(12, 0)": 0.765498161315918, "(12, 16)": 0.8281957507133484, "(14, 0)": 0.765498161315918, "(14, 16)": 0.765498161315918, "(16, 0)": 0.8281957507133484, "(16, 16)": 0.765498161315918, "(18, 0)": 0.765498161315918, "(18, 16)": 0.8281957507133484, "(20, 0)": 0.8281957507133484, "(20, 16)": 0.765498161315918, "(22, 0)": 0.765498161315918, "(22, 16)": 0.8281957507133484, "(24, 0)": 0.765498161315918, "(24, 16)": 0.8281957507133484, "(26, 0)": 0.765498161315918, "(26, 16)": 0.7420958280563354, "(28, 0)": 0.765498161315918, "(28, 16)": 0.765498161315918, "(30, 0)": 0.765498161315918, "(30, 16)": 0.765498161315918}, "r_span": [414, 439], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004532933235168457}}, {"prompt_attention_score": {"(0, 0)": 0.7269043922424316, "(0, 16)": 0.7269043922424316, "(2, 0)": 0.7269043922424316, "(2, 16)": 0.7269043922424316, "(4, 0)": 0.7269043922424316, "(4, 16)": 0.7269043922424316, "(6, 0)": 0.7269043922424316, "(6, 16)": 0.8042292594909668, "(8, 0)": 0.8042292594909668, "(8, 16)": 0.7269043922424316, "(10, 0)": 0.7269043922424316, "(10, 16)": 0.7269043922424316, "(12, 0)": 0.7269043922424316, "(12, 16)": 0.8042292594909668, "(14, 0)": 0.7269043922424316, "(14, 16)": 0.7269043922424316, "(16, 0)": 0.8042292594909668, "(16, 16)": 0.7269043922424316, "(18, 0)": 0.7269043922424316, "(18, 16)": 0.8042292594909668, "(20, 0)": 0.8042292594909668, "(20, 16)": 0.7269043922424316, "(22, 0)": 0.8042292594909668, "(22, 16)": 0.8042292594909668, "(24, 0)": 0.7269043922424316, "(24, 16)": 0.8042292594909668, "(26, 0)": 0.7269043922424316, "(26, 16)": 0.8042292594909668, "(28, 0)": 0.7269043922424316, "(28, 16)": 0.7269043922424316, "(30, 0)": 0.7269043922424316, "(30, 16)": 0.7269043922424316}, "r_span": [441, 545], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -3.9637088775634766e-05}}, {"prompt_attention_score": {"(0, 0)": 0.8041004538536072, "(0, 16)": 0.8041004538536072, "(2, 0)": 0.8041004538536072, "(2, 16)": 0.8041004538536072, "(4, 0)": 0.8041004538536072, "(4, 16)": 0.8041004538536072, "(6, 0)": 0.7588201761245728, "(6, 16)": 0.8041004538536072, "(8, 0)": 0.7588201761245728, "(8, 16)": 0.8041004538536072, "(10, 0)": 0.8041004538536072, "(10, 16)": 0.8041004538536072, "(12, 0)": 0.8041004538536072, "(12, 16)": 0.8041004538536072, "(14, 0)": 0.8041004538536072, "(14, 16)": 0.8041004538536072, "(16, 0)": 0.8041004538536072, "(16, 16)": 0.8041004538536072, "(18, 0)": 0.8041004538536072, "(18, 16)": 0.8041004538536072, "(20, 0)": 0.8041004538536072, "(20, 16)": 0.8041004538536072, "(22, 0)": 0.7588201761245728, "(22, 16)": 0.8041004538536072, "(24, 0)": 0.8041004538536072, "(24, 16)": 0.8041004538536072, "(26, 0)": 0.8041004538536072, "(26, 16)": 0.8041004538536072, "(28, 0)": 0.8041004538536072, "(28, 16)": 0.8041004538536072, "(30, 0)": 0.8041004538536072, "(30, 16)": 0.8041004538536072}, "r_span": [546, 597], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00035250186920166016}}, {"prompt_attention_score": {"(0, 0)": 0.7010984420776367, "(0, 16)": 0.7010984420776367, "(2, 0)": 0.7010984420776367, "(2, 16)": 0.7010984420776367, "(4, 0)": 0.7010984420776367, "(4, 16)": 0.7010984420776367, "(6, 0)": 0.7221919298171997, "(6, 16)": 0.7221919298171997, "(8, 0)": 0.7221919298171997, "(8, 16)": 0.7010984420776367, "(10, 0)": 0.7010984420776367, "(10, 16)": 0.7010984420776367, "(12, 0)": 0.7010984420776367, "(12, 16)": 0.7221919298171997, "(14, 0)": 0.7010984420776367, "(14, 16)": 0.7010984420776367, "(16, 0)": 0.7613110542297363, "(16, 16)": 0.7010984420776367, "(18, 0)": 0.7010984420776367, "(18, 16)": 0.7010984420776367, "(20, 0)": 0.7010984420776367, "(20, 16)": 0.7010984420776367, "(22, 0)": 0.7010984420776367, "(22, 16)": 0.7010984420776367, "(24, 0)": 0.7010984420776367, "(24, 16)": 0.7221919298171997, "(26, 0)": 0.7010984420776367, "(26, 16)": 0.7010984420776367, "(28, 0)": 0.7010984420776367, "(28, 16)": 0.7010984420776367, "(30, 0)": 0.7010984420776367, "(30, 16)": 0.7010984420776367}, "r_span": [599, 629], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00045931339263916016}}]}, {"id": "15195", "source_id": "15453", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 1016, "end": 1084, "text": "another copy will be sent to the Michigan Liquor Control Commission.", "meta": "HIGH INTRO OF NEW INFO\n- This specific detail about sending a copy to Michigan Liquor Control Commission is nowhere found in the passages.\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 829, "end": 871, "text": "\"OTC\" (Off-Highway Motor Vehicle Account).", "meta": "HIGH INTRO OF NEW INFO\n-  AI model defined OTC as Off-Highway Motor Vehicle Account. However, this definition is note mentioned in the passages.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the steps to file a lien on a semi:\n\nPassage 1 does not provide any information on how to file a lien on a semi. The passage discusses the rights of a judgment creditor to attach property transferred to a spouse, but it does not mention anything about filing a lien on a semi. Therefore, I cannot provide guidance on this matter based on this passage.\n\nPassage 2 explains the process for placing a lien on business property through a court order. It outlines the steps involved in filing a claim with the court and submitting proof of the amount owed to you, followed by the business's response to the debt. However, this passage does not provide information on how to file a lien on a semi.\n\nPassage 3 provides instructions on how to file a lien on a specific type of property called an \"OTC\" (Off-Highway Motor Vehicle Account). The passage explains how one copy of the lien entry form, along with supporting documents, will be attached to the titling documentation, while another copy will be sent to the Michigan Liquor Control Commission. However, this passage does not address how to file a lien on a semi.\n\nBased on the provided passages, I am unable to answer your question regarding how to file a lien on a semi.", "response_spans": [[0, 392], [394, 732], [734, 1153], [1155, 1262]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7012941837310791, "(0, 16)": 0.7012941837310791, "(2, 0)": 0.7012941837310791, "(2, 16)": 0.7012941837310791, "(4, 0)": 0.7012941837310791, "(4, 16)": 0.7012941837310791, "(6, 0)": 0.7012941837310791, "(6, 16)": 0.7995893955230713, "(8, 0)": 0.7012941837310791, "(8, 16)": 0.7012941837310791, "(10, 0)": 0.49390268325805664, "(10, 16)": 0.49390268325805664, "(12, 0)": 0.7012941837310791, "(12, 16)": 0.7643051147460938, "(14, 0)": 0.7012941837310791, "(14, 16)": 0.49390268325805664, "(16, 0)": 0.7643051147460938, "(16, 16)": 0.7012941837310791, "(18, 0)": 0.7012941837310791, "(18, 16)": 0.7643051147460938, "(20, 0)": 0.7643051147460938, "(20, 16)": 0.7012941837310791, "(22, 0)": 0.7012941837310791, "(22, 16)": 0.7643051147460938, "(24, 0)": 0.7012941837310791, "(24, 16)": 0.7643051147460938, "(26, 0)": 0.7012941837310791, "(26, 16)": 0.7012941837310791, "(28, 0)": 0.7012941837310791, "(28, 16)": 0.7012941837310791, "(30, 0)": 0.7012941837310791, "(30, 16)": 0.7012941837310791}, "r_span": [424, 517], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0012187957763671875}}, {"prompt_attention_score": {"(0, 0)": 0.7216248512268066, "(0, 16)": 0.7216248512268066, "(2, 0)": 0.7216248512268066, "(2, 16)": 0.7216248512268066, "(4, 0)": 0.7216248512268066, "(4, 16)": 0.7216248512268066, "(6, 0)": 0.7216248512268066, "(6, 16)": 0.8955727219581604, "(8, 0)": 0.7216248512268066, "(8, 16)": 0.7216248512268066, "(10, 0)": 0.7216248512268066, "(10, 16)": 0.7216248512268066, "(12, 0)": 0.7216248512268066, "(12, 16)": 0.8955727219581604, "(14, 0)": 0.7216248512268066, "(14, 16)": 0.8955727219581604, "(16, 0)": 0.6767063140869141, "(16, 16)": 0.7216248512268066, "(18, 0)": 0.7216248512268066, "(18, 16)": 0.8955727219581604, "(20, 0)": 0.8955727219581604, "(20, 16)": 0.7216248512268066, "(22, 0)": 0.7216248512268066, "(22, 16)": 0.8955727219581604, "(24, 0)": 0.7216248512268066, "(24, 16)": 0.8955727219581604, "(26, 0)": 0.7216248512268066, "(26, 16)": 0.7216248512268066, "(28, 0)": 0.7216248512268066, "(28, 16)": 0.7216248512268066, "(30, 0)": 0.7216248512268066, "(30, 16)": 0.7216248512268066}, "r_span": [519, 596], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012583136558532715}}, {"prompt_attention_score": {"(0, 0)": 0.8097621202468872, "(0, 16)": 0.8097621202468872, "(2, 0)": 0.8097621202468872, "(2, 16)": 0.8097621202468872, "(4, 0)": 0.8097621202468872, "(4, 16)": 0.8097621202468872, "(6, 0)": 0.8097621202468872, "(6, 16)": 0.8097621202468872, "(8, 0)": 0.8097621202468872, "(8, 16)": 0.8097621202468872, "(10, 0)": 0.8097621202468872, "(10, 16)": 0.8097621202468872, "(12, 0)": 0.8097621202468872, "(12, 16)": 0.8097621202468872, "(14, 0)": 0.8097621202468872, "(14, 16)": 0.8097621202468872, "(16, 0)": 0.8097621202468872, "(16, 16)": 0.8097621202468872, "(18, 0)": 0.8097621202468872, "(18, 16)": 0.8097621202468872, "(20, 0)": 0.8097621202468872, "(20, 16)": 0.8097621202468872, "(22, 0)": 0.8097621202468872, "(22, 16)": 0.8097621202468872, "(24, 0)": 0.8097621202468872, "(24, 16)": 0.8097621202468872, "(26, 0)": 0.8097621202468872, "(26, 16)": 0.8097621202468872, "(28, 0)": 0.8097621202468872, "(28, 16)": 0.8097621202468872, "(30, 0)": 0.8097621202468872, "(30, 16)": 0.8097621202468872}, "r_span": [598, 693], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0006881356239318848}}, {"prompt_attention_score": {"(0, 0)": 0.6929433941841125, "(0, 16)": 0.6929433941841125, "(2, 0)": 0.6929433941841125, "(2, 16)": 0.6929433941841125, "(4, 0)": 0.6929433941841125, "(4, 16)": 0.6929433941841125, "(6, 0)": 0.6929433941841125, "(6, 16)": 0.8535336256027222, "(8, 0)": 0.6929433941841125, "(8, 16)": 0.6929433941841125, "(10, 0)": 0.7259339094161987, "(10, 16)": 0.7259339094161987, "(12, 0)": 0.6929433941841125, "(12, 16)": 0.7259339094161987, "(14, 0)": 0.6929433941841125, "(14, 16)": 0.7259339094161987, "(16, 0)": 0.8535336256027222, "(16, 16)": 0.6929433941841125, "(18, 0)": 0.6929433941841125, "(18, 16)": 0.7259339094161987, "(20, 0)": 0.8535336256027222, "(20, 16)": 0.6929433941841125, "(22, 0)": 0.6929433941841125, "(22, 16)": 0.7259339094161987, "(24, 0)": 0.6929433941841125, "(24, 16)": 0.7259339094161987, "(26, 0)": 0.6929433941841125, "(26, 16)": 0.6929433941841125, "(28, 0)": 0.6929433941841125, "(28, 16)": 0.6929433941841125, "(30, 0)": 0.6929433941841125, "(30, 16)": 0.6929433941841125}, "r_span": [695, 721], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -2.9027462005615234e-05}}]}, {"id": "15201", "source_id": "15454", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 476, "end": 531, "text": "3. Location: Calderas are found at the top of volcanoes", "meta": "EVIDENT CONFLICT:\nAIGC:  3. Location: Calderas are found at the top of volcanoes\nOriginal:  A volcanic crater is a bowl like structure at the top of a volcano", "label_type": "Evident Conflict", "implicit_true": false, "due_to_null": false}, {"start": 533, "end": 631, "text": "while craters can be found on the surface of other planetary bodies such as the moon or asteroids.", "meta": "HIGH INTRO OF NEW INFO\n- Passages did not mention about where craters can be found on other planetary bodies.\n", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 341, "end": 475, "text": "with a diameter of at least 1 kilometer or more, while craters can range in size from very small to several hundred kilometers across.", "meta": "LOW INTRO OF NEW INFO \n- The difference between the size of caldera and crater is mentioned in the passage 2. However, the AI model expanded the explanation.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, a caldera is different from a crater in the following ways:\n\n1. Formation: Calderas are formed as a result of the collapse of a large cavity created underground when a chamber of magma and lava empties, while craters are caused by impacts from meteorites.\n2. Size: Calderas are typically larger than craters, with a diameter of at least 1 kilometer or more, while craters can range in size from very small to several hundred kilometers across.\n3. Location: Calderas are found at the top of volcanoes, while craters can be found on the surface of other planetary bodies such as the moon or asteroids.\n\nTherefore, based on the given passages, a caldera is different from a crater in terms of its formation, size, and location.", "response_spans": [[0, 91], [93, 475], [476, 631], [633, 756]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7241839170455933, "(0, 16)": 0.7241839170455933, "(2, 0)": 0.7241839170455933, "(2, 16)": 0.7241839170455933, "(4, 0)": 0.7241839170455933, "(4, 16)": 0.7241839170455933, "(6, 0)": 0.43657124042510986, "(6, 16)": 0.8448431491851807, "(8, 0)": 0.8106997609138489, "(8, 16)": 0.43657124042510986, "(10, 0)": 0.43657124042510986, "(10, 16)": 0.43657124042510986, "(12, 0)": 0.8106997609138489, "(12, 16)": 0.8448431491851807, "(14, 0)": 0.8106997609138489, "(14, 16)": 0.43657124042510986, "(16, 0)": 0.8448431491851807, "(16, 16)": 0.8106997609138489, "(18, 0)": 0.43657124042510986, "(18, 16)": 0.8448431491851807, "(20, 0)": 0.8448431491851807, "(20, 16)": 0.8106997609138489, "(22, 0)": 0.8106997609138489, "(22, 16)": 0.8448431491851807, "(24, 0)": 0.8106997609138489, "(24, 16)": 0.8106997609138489, "(26, 0)": 0.8106997609138489, "(26, 16)": 0.8106997609138489, "(28, 0)": 0.8106997609138489, "(28, 16)": 0.8106997609138489, "(30, 0)": 0.8106997609138489, "(30, 16)": 0.8106997609138489}, "r_span": [597, 620], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003533363342285156}}, {"prompt_attention_score": {"(0, 0)": 0.7017375230789185, "(0, 16)": 0.7017375230789185, "(2, 0)": 0.7017375230789185, "(2, 16)": 0.7017375230789185, "(4, 0)": 0.7017375230789185, "(4, 16)": 0.7017375230789185, "(6, 0)": 0.8750708103179932, "(6, 16)": 0.776328444480896, "(8, 0)": 0.8750708103179932, "(8, 16)": 0.8750708103179932, "(10, 0)": 0.8750708103179932, "(10, 16)": 0.8750708103179932, "(12, 0)": 0.8750708103179932, "(12, 16)": 0.8750708103179932, "(14, 0)": 0.8750708103179932, "(14, 16)": 0.8750708103179932, "(16, 0)": 0.8750708103179932, "(16, 16)": 0.8750708103179932, "(18, 0)": 0.8750708103179932, "(18, 16)": 0.8750708103179932, "(20, 0)": 0.8750708103179932, "(20, 16)": 0.8750708103179932, "(22, 0)": 0.8750708103179932, "(22, 16)": 0.776328444480896, "(24, 0)": 0.8750708103179932, "(24, 16)": 0.8750708103179932, "(26, 0)": 0.8750708103179932, "(26, 16)": 0.8750708103179932, "(28, 0)": 0.8750708103179932, "(28, 16)": 0.8750708103179932, "(30, 0)": 0.8750708103179932, "(30, 16)": 0.8750708103179932}, "r_span": [622, 715], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0006926655769348145}}, {"prompt_attention_score": {"(0, 0)": 0.699491560459137, "(0, 16)": 0.699491560459137, "(2, 0)": 0.699491560459137, "(2, 16)": 0.3420153558254242, "(4, 0)": 0.699491560459137, "(4, 16)": 0.3420153558254242, "(6, 0)": 0.8084397315979004, "(6, 16)": 0.6994514465332031, "(8, 0)": 0.8084397315979004, "(8, 16)": 0.8084397315979004, "(10, 0)": 0.8084397315979004, "(10, 16)": 0.8084397315979004, "(12, 0)": 0.8084397315979004, "(12, 16)": 0.8084397315979004, "(14, 0)": 0.8084397315979004, "(14, 16)": 0.8084397315979004, "(16, 0)": 0.8084397315979004, "(16, 16)": 0.8084397315979004, "(18, 0)": 0.8084397315979004, "(18, 16)": 0.8084397315979004, "(20, 0)": 0.8084397315979004, "(20, 16)": 0.8084397315979004, "(22, 0)": 0.8084397315979004, "(22, 16)": 0.8084397315979004, "(24, 0)": 0.8084397315979004, "(24, 16)": 0.8084397315979004, "(26, 0)": 0.8084397315979004, "(26, 16)": 0.8084397315979004, "(28, 0)": 0.8084397315979004, "(28, 16)": 0.8084397315979004, "(30, 0)": 0.8084397315979004, "(30, 16)": 0.8084397315979004}, "r_span": [716, 755], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0018070340156555176}}, {"prompt_attention_score": {"(0, 0)": 0.688774585723877, "(0, 16)": 0.688774585723877, "(2, 0)": 0.688774585723877, "(2, 16)": 0.43346619606018066, "(4, 0)": 0.43346619606018066, "(4, 16)": 0.43346619606018066, "(6, 0)": 0.43346619606018066, "(6, 16)": 0.7910845279693604, "(8, 0)": 0.7910845279693604, "(8, 16)": 0.43346619606018066, "(10, 0)": 0.43346619606018066, "(10, 16)": 0.43346619606018066, "(12, 0)": 0.43346619606018066, "(12, 16)": 0.7910845279693604, "(14, 0)": 0.7910845279693604, "(14, 16)": 0.43346619606018066, "(16, 0)": 0.8038231134414673, "(16, 16)": 0.7910845279693604, "(18, 0)": 0.7910845279693604, "(18, 16)": 0.7910845279693604, "(20, 0)": 0.8038231134414673, "(20, 16)": 0.7910845279693604, "(22, 0)": 0.7910845279693604, "(22, 16)": 0.43346619606018066, "(24, 0)": 0.7910845279693604, "(24, 16)": 0.7910845279693604, "(26, 0)": 0.7910845279693604, "(26, 16)": 0.7910845279693604, "(28, 0)": 0.7910845279693604, "(28, 16)": 0.7910845279693604, "(30, 0)": 0.7910845279693604, "(30, 16)": 0.7910845279693604}, "r_span": [757, 788], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00030863285064697266}}]}, {"id": "15207", "source_id": "15455", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the colonists responded to the Stamp Act of 1765 with a mix of violent and non-violent protests, starting with peaceful demonstrations such as holding signs and chanting slogans like \"No Taxation without Representation\". However, some of these protests led to confrontations with British soldiers, resulting in arrests.\n\nThe colonists were upset about the Stamp Act because it was the first direct tax imposed by Parliament on the colonies, which they saw as a violation of their rights as British subjects and a breach of their consent to be governed under the British Constitution. They believed that no taxes could be levied on them without their representation in Parliament, which they did not have at the time. The Stamp Act required the use of tax-stamped paper for all newspapers, legal documents, and other printed materials, which further annoyed the colonists who felt that it interfered with their freedom of speech and press.\n\nTherefore, the colonists responded to the Stamp Act with a variety of measures, including public protests, legislative resolutions, town meetings, and citizen boycotts of British goods. While the Stamp Act went into effect on November 1, 1765, it was eventually repealed by Parliament on March 18, 1766, and replaced with the Declaratory Act, which reaffirmed Parliament's authority to make laws binding on the colonies.", "response_spans": [[0, 351], [353, 855], [838, 970], [972, 1392]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7817338705062866, "(0, 16)": 0.7817338705062866, "(2, 0)": 0.7817338705062866, "(2, 16)": 0.7817338705062866, "(4, 0)": 0.7817338705062866, "(4, 16)": 0.7817338705062866, "(6, 0)": 0.7817338705062866, "(6, 16)": 0.908698320388794, "(8, 0)": 0.7817338705062866, "(8, 16)": 0.510141909122467, "(10, 0)": 0.510141909122467, "(10, 16)": 0.7817338705062866, "(12, 0)": 0.7817338705062866, "(12, 16)": 0.908698320388794, "(14, 0)": 0.908698320388794, "(14, 16)": 0.7817338705062866, "(16, 0)": 0.908698320388794, "(16, 16)": 0.7817338705062866, "(18, 0)": 0.908698320388794, "(18, 16)": 0.908698320388794, "(20, 0)": 0.908698320388794, "(20, 16)": 0.908698320388794, "(22, 0)": 0.908698320388794, "(22, 16)": 0.908698320388794, "(24, 0)": 0.908698320388794, "(24, 16)": 0.908698320388794, "(26, 0)": 0.908698320388794, "(26, 16)": 0.908698320388794, "(28, 0)": 0.7515366077423096, "(28, 16)": 0.908698320388794, "(30, 0)": 0.908698320388794, "(30, 16)": 0.908698320388794}, "r_span": [489, 572], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001873016357421875}}, {"prompt_attention_score": {"(0, 0)": 0.8196258544921875, "(0, 16)": 0.8196258544921875, "(2, 0)": 0.8196258544921875, "(2, 16)": 0.8196258544921875, "(4, 0)": 0.8196258544921875, "(4, 16)": 0.8196258544921875, "(6, 0)": 0.8196258544921875, "(6, 16)": 0.7569053769111633, "(8, 0)": 0.8196258544921875, "(8, 16)": 0.8196258544921875, "(10, 0)": 0.8196258544921875, "(10, 16)": 0.8196258544921875, "(12, 0)": 0.7569053769111633, "(12, 16)": 0.7569053769111633, "(14, 0)": 0.7786867022514343, "(14, 16)": 0.8196258544921875, "(16, 0)": 0.7786867022514343, "(16, 16)": 0.7786867022514343, "(18, 0)": 0.7786867022514343, "(18, 16)": 0.7569053769111633, "(20, 0)": 0.7569053769111633, "(20, 16)": 0.7786867022514343, "(22, 0)": 0.7786867022514343, "(22, 16)": 0.7569053769111633, "(24, 0)": 0.7786867022514343, "(24, 16)": 0.7569053769111633, "(26, 0)": 0.7786867022514343, "(26, 16)": 0.7786867022514343, "(28, 0)": 0.8196258544921875, "(28, 16)": 0.7786867022514343, "(30, 0)": 0.7786867022514343, "(30, 16)": 0.7786867022514343}, "r_span": [574, 682], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002370595932006836}}, {"prompt_attention_score": {"(0, 0)": 0.5606248378753662, "(0, 16)": 0.5606248378753662, "(2, 0)": 0.5606248378753662, "(2, 16)": 0.5606248378753662, "(4, 0)": 0.5606248378753662, "(4, 16)": 0.5606248378753662, "(6, 0)": 0.5606248378753662, "(6, 16)": 0.6453477740287781, "(8, 0)": 0.5606248378753662, "(8, 16)": 0.5606248378753662, "(10, 0)": 0.5606248378753662, "(10, 16)": 0.5606248378753662, "(12, 0)": 0.5606248378753662, "(12, 16)": 0.5365245342254639, "(14, 0)": 0.6424129009246826, "(14, 16)": 0.5606248378753662, "(16, 0)": 0.5365245342254639, "(16, 16)": 0.6424129009246826, "(18, 0)": 0.47801846265792847, "(18, 16)": 0.5365245342254639, "(20, 0)": 0.5606248378753662, "(20, 16)": 0.6424129009246826, "(22, 0)": 0.6424129009246826, "(22, 16)": 0.5365245342254639, "(24, 0)": 0.6424129009246826, "(24, 16)": 0.6424129009246826, "(26, 0)": 0.6424129009246826, "(26, 16)": 0.6424129009246826, "(28, 0)": 0.5365245342254639, "(28, 16)": 0.6424129009246826, "(30, 0)": 0.6424129009246826, "(30, 16)": 0.6424129009246826}, "r_span": [680, 706], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003281235694885254}}, {"prompt_attention_score": {"(0, 0)": 0.8415343761444092, "(0, 16)": 0.8415343761444092, "(2, 0)": 0.8415343761444092, "(2, 16)": 0.8415343761444092, "(4, 0)": 0.8415343761444092, "(4, 16)": 0.8415343761444092, "(6, 0)": 0.8415343761444092, "(6, 16)": 0.8415343761444092, "(8, 0)": 0.8415343761444092, "(8, 16)": 0.8415343761444092, "(10, 0)": 0.8415343761444092, "(10, 16)": 0.8415343761444092, "(12, 0)": 0.8415343761444092, "(12, 16)": 0.8415343761444092, "(14, 0)": 0.7712594270706177, "(14, 16)": 0.8415343761444092, "(16, 0)": 0.8415343761444092, "(16, 16)": 0.7712594270706177, "(18, 0)": 0.7712594270706177, "(18, 16)": 0.8415343761444092, "(20, 0)": 0.8415343761444092, "(20, 16)": 0.7712594270706177, "(22, 0)": 0.7712594270706177, "(22, 16)": 0.8415343761444092, "(24, 0)": 0.7877898216247559, "(24, 16)": 0.8415343761444092, "(26, 0)": 0.7712594270706177, "(26, 16)": 0.8415343761444092, "(28, 0)": 0.7877898216247559, "(28, 16)": 0.7712594270706177, "(30, 0)": 0.7712594270706177, "(30, 16)": 0.7712594270706177}, "r_span": [708, 816], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001465916633605957}}]}, {"id": "15273", "source_id": "15466", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 623, "end": 740, "text": "5. Detoxification: Cupping can help detoxify the body by removing impurities and toxins through the skin (Passage 1).", "meta": "HIGH INTRO OF NEW INFO\n-  Passages did not mention about detoxification and its benefit.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the five main benefits of cupping massage are:\n\n1. Eliminates toxins: Cupping massage is an effective way to remove toxins from the body (Passage 1, Passage 3).\n2. Improved circulation: Cupping can increase blood circulation, which can help improve overall health (Passage 2, Passage 3).\n3. Pain relief: Cupping massage can reduce inflammation and alleviate pain in tissues, improving range of motion and flexibility (Passage 2, Passage 3).\n4. Mental benefits: Cupping massage has been shown to have therapeutic effects on mental health, such as reducing anxiety and depression (Passage 2).\n5. Detoxification: Cupping can help detoxify the body by removing impurities and toxins through the skin (Passage 1).\n\nUnable to answer based on given passages. The passages do not provide additional information beyond these five benefits.", "response_spans": [[0, 78], [80, 472], [473, 740], [742, 862]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8148783445358276, "(0, 16)": 0.8148783445358276, "(2, 0)": 0.8148783445358276, "(2, 16)": 0.8148783445358276, "(4, 0)": 0.8148783445358276, "(4, 16)": 0.8148783445358276, "(6, 0)": 0.8148783445358276, "(6, 16)": 0.8456478118896484, "(8, 0)": 0.8148783445358276, "(8, 16)": 0.8148783445358276, "(10, 0)": 0.8148783445358276, "(10, 16)": 0.8148783445358276, "(12, 0)": 0.8148783445358276, "(12, 16)": 0.8456478118896484, "(14, 0)": 0.8595728874206543, "(14, 16)": 0.8148783445358276, "(16, 0)": 0.8456478118896484, "(16, 16)": 0.8148783445358276, "(18, 0)": 0.8148783445358276, "(18, 16)": 0.8456478118896484, "(20, 0)": 0.8456478118896484, "(20, 16)": 0.8595728874206543, "(22, 0)": 0.8595728874206543, "(22, 16)": 0.8456478118896484, "(24, 0)": 0.8595728874206543, "(24, 16)": 0.8456478118896484, "(26, 0)": 0.8595728874206543, "(26, 16)": 0.8595728874206543, "(28, 0)": 0.8595728874206543, "(28, 16)": 0.8595728874206543, "(30, 0)": 0.8595728874206543, "(30, 16)": 0.8595728874206543}, "r_span": [336, 355], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -2.0265579223632812e-06}}, {"prompt_attention_score": {"(0, 0)": 0.9140622615814209, "(0, 16)": 0.9140622615814209, "(2, 0)": 0.9140622615814209, "(2, 16)": 0.9140622615814209, "(4, 0)": 0.9140622615814209, "(4, 16)": 0.9140622615814209, "(6, 0)": 0.8972882628440857, "(6, 16)": 0.8972882628440857, "(8, 0)": 0.8972882628440857, "(8, 16)": 0.8972882628440857, "(10, 0)": 0.9140622615814209, "(10, 16)": 0.9140622615814209, "(12, 0)": 0.8972882628440857, "(12, 16)": 0.8972882628440857, "(14, 0)": 0.8972882628440857, "(14, 16)": 0.8972882628440857, "(16, 0)": 0.8972882628440857, "(16, 16)": 0.8972882628440857, "(18, 0)": 0.9140622615814209, "(18, 16)": 0.8972882628440857, "(20, 0)": 0.8972882628440857, "(20, 16)": 0.8972882628440857, "(22, 0)": 0.8972882628440857, "(22, 16)": 0.8972882628440857, "(24, 0)": 0.8972882628440857, "(24, 16)": 0.8972882628440857, "(26, 0)": 0.8972882628440857, "(26, 16)": 0.8972882628440857, "(28, 0)": 0.8972882628440857, "(28, 16)": 0.8972882628440857, "(30, 0)": 0.8972882628440857, "(30, 16)": 0.8972882628440857}, "r_span": [357, 471], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001761317253112793}}, {"prompt_attention_score": {"(0, 0)": 0.8533138036727905, "(0, 16)": 0.8390771150588989, "(2, 0)": 0.8390771150588989, "(2, 16)": 0.8390771150588989, "(4, 0)": 0.8390771150588989, "(4, 16)": 0.8390771150588989, "(6, 0)": 0.8533138036727905, "(6, 16)": 0.8533138036727905, "(8, 0)": 0.8533138036727905, "(8, 16)": 0.8533138036727905, "(10, 0)": 0.8390771150588989, "(10, 16)": 0.8533138036727905, "(12, 0)": 0.8533138036727905, "(12, 16)": 0.8533138036727905, "(14, 0)": 0.8533138036727905, "(14, 16)": 0.8390771150588989, "(16, 0)": 0.8533138036727905, "(16, 16)": 0.8533138036727905, "(18, 0)": 0.8533138036727905, "(18, 16)": 0.8533138036727905, "(20, 0)": 0.8533138036727905, "(20, 16)": 0.8533138036727905, "(22, 0)": 0.8533138036727905, "(22, 16)": 0.8533138036727905, "(24, 0)": 0.8533138036727905, "(24, 16)": 0.8533138036727905, "(26, 0)": 0.8533138036727905, "(26, 16)": 0.8533138036727905, "(28, 0)": 0.8533138036727905, "(28, 16)": 0.8533138036727905, "(30, 0)": 0.8533138036727905, "(30, 16)": 0.8533138036727905}, "r_span": [472, 545], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0005083680152893066}}, {"prompt_attention_score": {"(0, 0)": 0.5500140190124512, "(0, 16)": 0.5500140190124512, "(2, 0)": 0.5060850381851196, "(2, 16)": 0.5500140190124512, "(4, 0)": 0.5500140190124512, "(4, 16)": 0.5060850381851196, "(6, 0)": 0.5060850381851196, "(6, 16)": 0.5459874868392944, "(8, 0)": 0.5500140190124512, "(8, 16)": 0.5500140190124512, "(10, 0)": 0.5060850381851196, "(10, 16)": 0.5060850381851196, "(12, 0)": 0.5060850381851196, "(12, 16)": 0.5060850381851196, "(14, 0)": 0.5500140190124512, "(14, 16)": 0.5060850381851196, "(16, 0)": 0.5060850381851196, "(16, 16)": 0.5500140190124512, "(18, 0)": 0.5500140190124512, "(18, 16)": 0.5060850381851196, "(20, 0)": 0.5459874868392944, "(20, 16)": 0.5500140190124512, "(22, 0)": 0.5500140190124512, "(22, 16)": 0.5060850381851196, "(24, 0)": 0.5500140190124512, "(24, 16)": 0.5060850381851196, "(26, 0)": 0.5500140190124512, "(26, 16)": 0.5500140190124512, "(28, 0)": 0.5500140190124512, "(28, 16)": 0.5500140190124512, "(30, 0)": 0.5500140190124512, "(30, 16)": 0.5500140190124512}, "r_span": [547, 570], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00030475854873657227}}]}, {"id": "15345", "source_id": "15478", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 853, "end": 1030, "text": "* Building muscle strength and endurance\n* Improving balance and coordination\n* Enhancing cognitive function\n* Reducing the risk of chronic diseases such as obesity and diabetes", "meta": "HIGH INTRO OF NEW INFO\n-  Passages did not mention this additional benefits.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the benefits of hiking as a hobby:\n\n1. Promotes mental health: Hiking is a form of outdoor recreation that promotes mental well-being by exposing individuals to nature and allowing them to disconnect from their daily routines (Passage 1).\n2. Increases vitamin D levels: Spending time outdoors while hiking exposes individuals to sunlight, which helps to increase vitamin D levels (Passage 2).\n3. Improves cardiovascular health: Hiking is a cardiovascular activity that can help reduce the risk of heart disease and improve overall fitness (Passage 2).\n4. Combats stress and anxiety: Research suggests that hiking has a positive impact on reducing symptoms of stress and anxiety (Passage 3).\n\nUnable to answer based on given passages. The passages do not provide information on the following benefits of hiking:\n\n* Building muscle strength and endurance\n* Improving balance and coordination\n* Enhancing cognitive function\n* Reducing the risk of chronic diseases such as obesity and diabetes\n\nThe passages primarily focus on the mental and physical health benefits of hiking, but do not provide information on other potential advantages of the activity.", "response_spans": [[0, 75], [77, 433], [434, 731], [733, 1192]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6919817924499512, "(0, 16)": 0.6919817924499512, "(2, 0)": 0.6919817924499512, "(2, 16)": 0.6919817924499512, "(4, 0)": 0.6919817924499512, "(4, 16)": 0.6919817924499512, "(6, 0)": 0.6919817924499512, "(6, 16)": 0.8540817499160767, "(8, 0)": 0.6919817924499512, "(8, 16)": 0.6919817924499512, "(10, 0)": 0.6919817924499512, "(10, 16)": 0.6919817924499512, "(12, 0)": 0.6919817924499512, "(12, 16)": 0.8540817499160767, "(14, 0)": 0.7767753601074219, "(14, 16)": 0.6919817924499512, "(16, 0)": 0.8540817499160767, "(16, 16)": 0.6919817924499512, "(18, 0)": 0.6919817924499512, "(18, 16)": 0.8540817499160767, "(20, 0)": 0.8540817499160767, "(20, 16)": 0.7767753601074219, "(22, 0)": 0.7767753601074219, "(22, 16)": 0.8540817499160767, "(24, 0)": 0.7767753601074219, "(24, 16)": 0.8540817499160767, "(26, 0)": 0.7767753601074219, "(26, 16)": 0.7767753601074219, "(28, 0)": 0.7767753601074219, "(28, 16)": 0.7767753601074219, "(30, 0)": 0.7767753601074219, "(30, 16)": 0.7767753601074219}, "r_span": [376, 398], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003666877746582031}}, {"prompt_attention_score": {"(0, 0)": 0.7657784223556519, "(0, 16)": 0.7657784223556519, "(2, 0)": 0.7657784223556519, "(2, 16)": 0.7657784223556519, "(4, 0)": 0.7657784223556519, "(4, 16)": 0.7657784223556519, "(6, 0)": 0.7657784223556519, "(6, 16)": 0.8469884395599365, "(8, 0)": 0.8469884395599365, "(8, 16)": 0.7657784223556519, "(10, 0)": 0.7657784223556519, "(10, 16)": 0.7657784223556519, "(12, 0)": 0.8469884395599365, "(12, 16)": 0.8469884395599365, "(14, 0)": 0.8469884395599365, "(14, 16)": 0.7657784223556519, "(16, 0)": 0.8469884395599365, "(16, 16)": 0.8469884395599365, "(18, 0)": 0.7657784223556519, "(18, 16)": 0.8469884395599365, "(20, 0)": 0.8469884395599365, "(20, 16)": 0.8469884395599365, "(22, 0)": 0.8469884395599365, "(22, 16)": 0.8469884395599365, "(24, 0)": 0.8469884395599365, "(24, 16)": 0.8469884395599365, "(26, 0)": 0.8469884395599365, "(26, 16)": 0.8469884395599365, "(28, 0)": 0.8469884395599365, "(28, 16)": 0.8469884395599365, "(30, 0)": 0.8469884395599365, "(30, 16)": 0.8469884395599365}, "r_span": [400, 491], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001046895980834961}}, {"prompt_attention_score": {"(0, 0)": 0.8428294658660889, "(0, 16)": 0.7966862916946411, "(2, 0)": 0.7966862916946411, "(2, 16)": 0.7966862916946411, "(4, 0)": 0.7966862916946411, "(4, 16)": 0.7966862916946411, "(6, 0)": 0.7966862916946411, "(6, 16)": 0.8455730080604553, "(8, 0)": 0.7966862916946411, "(8, 16)": 0.7966862916946411, "(10, 0)": 0.7966862916946411, "(10, 16)": 0.7966862916946411, "(12, 0)": 0.8428294658660889, "(12, 16)": 0.7966862916946411, "(14, 0)": 0.8428294658660889, "(14, 16)": 0.7966862916946411, "(16, 0)": 0.7966862916946411, "(16, 16)": 0.8428294658660889, "(18, 0)": 0.8428294658660889, "(18, 16)": 0.7966862916946411, "(20, 0)": 0.8455730080604553, "(20, 16)": 0.8428294658660889, "(22, 0)": 0.8428294658660889, "(22, 16)": 0.7966862916946411, "(24, 0)": 0.8428294658660889, "(24, 16)": 0.7966862916946411, "(26, 0)": 0.8428294658660889, "(26, 16)": 0.7966862916946411, "(28, 0)": 0.8428294658660889, "(28, 16)": 0.8428294658660889, "(30, 0)": 0.8428294658660889, "(30, 16)": 0.8428294658660889}, "r_span": [492, 571], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001057267189025879}}, {"prompt_attention_score": {"(0, 0)": 0.8684630393981934, "(0, 16)": 0.7936743497848511, "(2, 0)": 0.7936743497848511, "(2, 16)": 0.7936743497848511, "(4, 0)": 0.7936743497848511, "(4, 16)": 0.7936743497848511, "(6, 0)": 0.7936743497848511, "(6, 16)": 0.8684630393981934, "(8, 0)": 0.7936743497848511, "(8, 16)": 0.8684630393981934, "(10, 0)": 0.7936743497848511, "(10, 16)": 0.7936743497848511, "(12, 0)": 0.7936743497848511, "(12, 16)": 0.7936743497848511, "(14, 0)": 0.8684630393981934, "(14, 16)": 0.7936743497848511, "(16, 0)": 0.7936743497848511, "(16, 16)": 0.8684630393981934, "(18, 0)": 0.8684630393981934, "(18, 16)": 0.788193941116333, "(20, 0)": 0.788193941116333, "(20, 16)": 0.8684630393981934, "(22, 0)": 0.8684630393981934, "(22, 16)": 0.7936743497848511, "(24, 0)": 0.8684630393981934, "(24, 16)": 0.7936743497848511, "(26, 0)": 0.8684630393981934, "(26, 16)": 0.8684630393981934, "(28, 0)": 0.8684630393981934, "(28, 16)": 0.8684630393981934, "(30, 0)": 0.8684630393981934, "(30, 16)": 0.8684630393981934}, "r_span": [573, 679], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0003306269645690918}}]}, {"id": "15459", "source_id": "15497", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main differences between refined and unrefined coconut oil are:\n\n1. Source: Refined coconut oil is made from dried coconut fruit, while unrefined coconut oil is made from the flesh of fresh coconuts.\n2. Aroma and flavor: Unrefined coconut oil retains its distinct aroma and flavor, while refined coconut oil loses these qualities during the refining process.\n3. Smoking point: Refined coconut oil has a higher smoking point (450 degrees F) than unrefined coconut oil (350 degrees F), making it more suitable for high-temperature cooking methods like frying.\n\nTherefore, the main differences between refined and unrefined coconut oil are their source, aroma, flavor, and smoking point.", "response_spans": [[0, 99], [101, 593], [595, 720]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8651061654090881, "(0, 16)": 0.8651061654090881, "(2, 0)": 0.8651061654090881, "(2, 16)": 0.8651061654090881, "(4, 0)": 0.8651061654090881, "(4, 16)": 0.8651061654090881, "(6, 0)": 0.8651061654090881, "(6, 16)": 0.9072580933570862, "(8, 0)": 0.8651061654090881, "(8, 16)": 0.8651061654090881, "(10, 0)": 0.8651061654090881, "(10, 16)": 0.8651061654090881, "(12, 0)": 0.8651061654090881, "(12, 16)": 0.9072580933570862, "(14, 0)": 0.8651061654090881, "(14, 16)": 0.8651061654090881, "(16, 0)": 0.9072580933570862, "(16, 16)": 0.8651061654090881, "(18, 0)": 0.8651061654090881, "(18, 16)": 0.9072580933570862, "(20, 0)": 0.9072580933570862, "(20, 16)": 0.8651061654090881, "(22, 0)": 0.8651061654090881, "(22, 16)": 0.9072580933570862, "(24, 0)": 0.8651061654090881, "(24, 16)": 0.9072580933570862, "(26, 0)": 0.8651061654090881, "(26, 16)": 0.9072580933570862, "(28, 0)": 0.8651061654090881, "(28, 16)": 0.8651061654090881, "(30, 0)": 0.8651061654090881, "(30, 16)": 0.8651061654090881}, "r_span": [349, 373], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010613799095153809}}, {"prompt_attention_score": {"(0, 0)": 0.9013470411300659, "(0, 16)": 0.9013470411300659, "(2, 0)": 0.9013470411300659, "(2, 16)": 0.9013470411300659, "(4, 0)": 0.9013470411300659, "(4, 16)": 0.9013470411300659, "(6, 0)": 0.9013470411300659, "(6, 16)": 0.9241839647293091, "(8, 0)": 0.9013470411300659, "(8, 16)": 0.9013470411300659, "(10, 0)": 0.9013470411300659, "(10, 16)": 0.9013470411300659, "(12, 0)": 0.9013470411300659, "(12, 16)": 0.9241839647293091, "(14, 0)": 0.9013470411300659, "(14, 16)": 0.9013470411300659, "(16, 0)": 0.9241839647293091, "(16, 16)": 0.9013470411300659, "(18, 0)": 0.9013470411300659, "(18, 16)": 0.9241839647293091, "(20, 0)": 0.9241839647293091, "(20, 16)": 0.9013470411300659, "(22, 0)": 0.9013470411300659, "(22, 16)": 0.9241839647293091, "(24, 0)": 0.9013470411300659, "(24, 16)": 0.9241839647293091, "(26, 0)": 0.9013470411300659, "(26, 16)": 0.9013470411300659, "(28, 0)": 0.9013470411300659, "(28, 16)": 0.9013470411300659, "(30, 0)": 0.9013470411300659, "(30, 16)": 0.9013470411300659}, "r_span": [375, 518], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011150836944580078}}, {"prompt_attention_score": {"(0, 0)": 0.8445732593536377, "(0, 16)": 0.8445732593536377, "(2, 0)": 0.8445732593536377, "(2, 16)": 0.8445732593536377, "(4, 0)": 0.8445732593536377, "(4, 16)": 0.8445732593536377, "(6, 0)": 0.8445732593536377, "(6, 16)": 0.8181160092353821, "(8, 0)": 0.8445732593536377, "(8, 16)": 0.8445732593536377, "(10, 0)": 0.8445732593536377, "(10, 16)": 0.8445732593536377, "(12, 0)": 0.8445732593536377, "(12, 16)": 0.8181160092353821, "(14, 0)": 0.8445732593536377, "(14, 16)": 0.8445732593536377, "(16, 0)": 0.8445732593536377, "(16, 16)": 0.8445732593536377, "(18, 0)": 0.8445732593536377, "(18, 16)": 0.8181160092353821, "(20, 0)": 0.8181160092353821, "(20, 16)": 0.8445732593536377, "(22, 0)": 0.8445732593536377, "(22, 16)": 0.8445732593536377, "(24, 0)": 0.8445732593536377, "(24, 16)": 0.8181160092353821, "(26, 0)": 0.8445732593536377, "(26, 16)": 0.8181160092353821, "(28, 0)": 0.8445732593536377, "(28, 16)": 0.8445732593536377, "(30, 0)": 0.8445732593536377, "(30, 16)": 0.8445732593536377}, "r_span": [520, 553], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003733634948730469}}]}, {"id": "15465", "source_id": "15498", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 239, "end": 279, "text": "and click on the \"Change of Address\" tab", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of clicking on the Change of Address tab\nGenerative: \"...and click on the \"Change of Address\" tab.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 811, "end": 982, "text": "If you need to change your address for a business, you will need to provide additional documentation, such as proof of ownership or authorization, to verify your identity.", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of additional documentation such as proof of ownership or authorization\nGenerative: \"If you need to change your address for a business, you will need to provide additional documentation, such as proof of ownership or authorization, to verify your identity.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 309, "end": 435, "text": "with your old and new address details, and select the type of mail you want to forward (residential, commercial, or military).", "meta": "LOW INTRO OF NEW INFO\nOriginal: It is correct that in PS Form 3575, you will include your old and new address, however, this is not directly mentioned in the passages.\nGenerative: \"...with your old and new address details, and select the type of mail you want to forward (residential, commercial, or military).\"", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's my attempt to briefly answer your question based on the provided passages:\n\nTo change your address with the United States Postal Service (USPS), you can follow these steps:\n\n1. Visit the USPS website (<https://www.usps.com/>) and click on the \"Change of Address\" tab.\n2. Fill out the online form with your old and new address details, and select the type of mail you want to forward (residential, commercial, or military).\n3. Pay a $1 validation fee using a credit or debit card to validate your identity.\n4. Submit the form and wait for the USPS to process your request.\n\nAlternatively, you can call the USPS Customer Service number at 1-800-ASK-USPS (1-800-275-8777) or visit any U.S. Post Office to fill out and submit PS Form 3575, which is available for download from the USPS website.\n\nNote: If you need to change your address for a business, you will need to provide additional documentation, such as proof of ownership or authorization, to verify your identity.", "response_spans": [[0, 185], [187, 584], [586, 982]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6479735970497131, "(0, 16)": 0.6479735970497131, "(2, 0)": 0.6479735970497131, "(2, 16)": 0.6479735970497131, "(4, 0)": 0.7550241947174072, "(4, 16)": 0.7550241947174072, "(6, 0)": 0.7550241947174072, "(6, 16)": 0.8382054567337036, "(8, 0)": 0.8382054567337036, "(8, 16)": 0.4460625648498535, "(10, 0)": 0.4460625648498535, "(10, 16)": 0.4460625648498535, "(12, 0)": 0.4460625648498535, "(12, 16)": 0.8382054567337036, "(14, 0)": 0.8382054567337036, "(14, 16)": 0.4460625648498535, "(16, 0)": 0.8382054567337036, "(16, 16)": 0.8382054567337036, "(18, 0)": 0.4460625648498535, "(18, 16)": 0.8382054567337036, "(20, 0)": 0.8382054567337036, "(20, 16)": 0.7625613212585449, "(22, 0)": 0.8382054567337036, "(22, 16)": 0.8382054567337036, "(24, 0)": 0.7625613212585449, "(24, 16)": 0.8382054567337036, "(26, 0)": 0.8382054567337036, "(26, 16)": 0.8382054567337036, "(28, 0)": 0.8382054567337036, "(28, 16)": 0.8382054567337036, "(30, 0)": 0.8382054567337036, "(30, 16)": 0.8382054567337036}, "r_span": [470, 513], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00041943788528442383}}, {"prompt_attention_score": {"(0, 0)": 0.6602193117141724, "(0, 16)": 0.7879946827888489, "(2, 0)": 0.6602193117141724, "(2, 16)": 0.6602193117141724, "(4, 0)": 0.6602193117141724, "(4, 16)": 0.6602193117141724, "(6, 0)": 0.7879946827888489, "(6, 16)": 0.788002073764801, "(8, 0)": 0.6602193117141724, "(8, 16)": 0.6602193117141724, "(10, 0)": 0.7879946827888489, "(10, 16)": 0.7879946827888489, "(12, 0)": 0.6602193117141724, "(12, 16)": 0.7879946827888489, "(14, 0)": 0.788002073764801, "(14, 16)": 0.788002073764801, "(16, 0)": 0.788002073764801, "(16, 16)": 0.788002073764801, "(18, 0)": 0.788002073764801, "(18, 16)": 0.788002073764801, "(20, 0)": 0.788002073764801, "(20, 16)": 0.7381877303123474, "(22, 0)": 0.788002073764801, "(22, 16)": 0.788002073764801, "(24, 0)": 0.7381877303123474, "(24, 16)": 0.788002073764801, "(26, 0)": 0.788002073764801, "(26, 16)": 0.788002073764801, "(28, 0)": 0.788002073764801, "(28, 16)": 0.6602193117141724, "(30, 0)": 0.788002073764801, "(30, 16)": 0.788002073764801}, "r_span": [515, 622], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009662508964538574}}, {"prompt_attention_score": {"(0, 0)": 0.8569141626358032, "(0, 16)": 0.6922979950904846, "(2, 0)": 0.8569141626358032, "(2, 16)": 0.6922979950904846, "(4, 0)": 0.8569141626358032, "(4, 16)": 0.8569141626358032, "(6, 0)": 0.6922979950904846, "(6, 16)": 0.8569141626358032, "(8, 0)": 0.8569141626358032, "(8, 16)": 0.6922979950904846, "(10, 0)": 0.4229542016983032, "(10, 16)": 0.8569141626358032, "(12, 0)": 0.7585016489028931, "(12, 16)": 0.8569141626358032, "(14, 0)": 0.7585016489028931, "(14, 16)": 0.8569141626358032, "(16, 0)": 0.7585016489028931, "(16, 16)": 0.7585016489028931, "(18, 0)": 0.7585016489028931, "(18, 16)": 0.7585016489028931, "(20, 0)": 0.6922979950904846, "(20, 16)": 0.7204917073249817, "(22, 0)": 0.7585016489028931, "(22, 16)": 0.6922979950904846, "(24, 0)": 0.7585016489028931, "(24, 16)": 0.6922979950904846, "(26, 0)": 0.7585016489028931, "(26, 16)": 0.7585016489028931, "(28, 0)": 0.7585016489028931, "(28, 16)": 0.8569141626358032, "(30, 0)": 0.7204917073249817, "(30, 16)": 0.7585016489028931}, "r_span": [624, 735], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0004830360412597656}}]}, {"id": "15483", "source_id": "15501", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is why your Snapchat account might be temporarily locked:\n\n1. Using third-party apps to access Snapchat without authorization: According to passage 2, Snapchat does not guarantee the security of accounts accessed through third-party apps. If you have been using such apps, it could result in your account being locked.\n2. Exceeding the limit of warnings for third-party app usage: Passage 1 mentions that Snapchat sends warnings before locking accounts that use third-party apps excessively. If you have exceeded the limit of warnings, your account might be temporarily locked.\n\nTherefore, the most likely reason for your Snapchat account being temporarily locked is due to the unauthorized use of third-party apps.", "response_spans": [[0, 94], [96, 355], [356, 614], [616, 752]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7027232646942139, "(0, 16)": 0.7027232646942139, "(2, 0)": 0.7027232646942139, "(2, 16)": 0.7027232646942139, "(4, 0)": 0.7027232646942139, "(4, 16)": 0.7027232646942139, "(6, 0)": 0.7027232646942139, "(6, 16)": 0.8564567565917969, "(8, 0)": 0.7027232646942139, "(8, 16)": 0.614800751209259, "(10, 0)": 0.614800751209259, "(10, 16)": 0.614800751209259, "(12, 0)": 0.7027232646942139, "(12, 16)": 0.8564567565917969, "(14, 0)": 0.7027232646942139, "(14, 16)": 0.614800751209259, "(16, 0)": 0.8564567565917969, "(16, 16)": 0.7027232646942139, "(18, 0)": 0.614800751209259, "(18, 16)": 0.8564567565917969, "(20, 0)": 0.8564567565917969, "(20, 16)": 0.7027232646942139, "(22, 0)": 0.7720218896865845, "(22, 16)": 0.8564567565917969, "(24, 0)": 0.7720218896865845, "(24, 16)": 0.8564567565917969, "(26, 0)": 0.7720218896865845, "(26, 16)": 0.7720218896865845, "(28, 0)": 0.614800751209259, "(28, 16)": 0.7027232646942139, "(30, 0)": 0.7720218896865845, "(30, 16)": 0.7720218896865845}, "r_span": [588, 610], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00038367509841918945}}, {"prompt_attention_score": {"(0, 0)": 0.7975068092346191, "(0, 16)": 0.7975068092346191, "(2, 0)": 0.7975068092346191, "(2, 16)": 0.7975068092346191, "(4, 0)": 0.7975068092346191, "(4, 16)": 0.7975068092346191, "(6, 0)": 0.7975068092346191, "(6, 16)": 0.792431116104126, "(8, 0)": 0.7975068092346191, "(8, 16)": 0.7975068092346191, "(10, 0)": 0.7975068092346191, "(10, 16)": 0.7975068092346191, "(12, 0)": 0.8689075112342834, "(12, 16)": 0.8689075112342834, "(14, 0)": 0.7975068092346191, "(14, 16)": 0.7975068092346191, "(16, 0)": 0.792431116104126, "(16, 16)": 0.792431116104126, "(18, 0)": 0.7975068092346191, "(18, 16)": 0.8689075112342834, "(20, 0)": 0.8689075112342834, "(20, 16)": 0.7975068092346191, "(22, 0)": 0.792431116104126, "(22, 16)": 0.8689075112342834, "(24, 0)": 0.7975068092346191, "(24, 16)": 0.8689075112342834, "(26, 0)": 0.792431116104126, "(26, 16)": 0.792431116104126, "(28, 0)": 0.792431116104126, "(28, 16)": 0.7975068092346191, "(30, 0)": 0.792431116104126, "(30, 16)": 0.792431116104126}, "r_span": [612, 667], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010950565338134766}}, {"prompt_attention_score": {"(0, 0)": 0.7833166718482971, "(0, 16)": 0.7833166718482971, "(2, 0)": 0.7833166718482971, "(2, 16)": 0.7833166718482971, "(4, 0)": 0.7833166718482971, "(4, 16)": 0.7833166718482971, "(6, 0)": 0.7833166718482971, "(6, 16)": 0.8108011484146118, "(8, 0)": 0.7833166718482971, "(8, 16)": 0.7833166718482971, "(10, 0)": 0.7833166718482971, "(10, 16)": 0.8408266305923462, "(12, 0)": 0.7833166718482971, "(12, 16)": 0.8108011484146118, "(14, 0)": 0.7833166718482971, "(14, 16)": 0.7833166718482971, "(16, 0)": 0.8108011484146118, "(16, 16)": 0.8108011484146118, "(18, 0)": 0.8108011484146118, "(18, 16)": 0.8108011484146118, "(20, 0)": 0.8108011484146118, "(20, 16)": 0.7833166718482971, "(22, 0)": 0.8108011484146118, "(22, 16)": 0.8108011484146118, "(24, 0)": 0.8108011484146118, "(24, 16)": 0.8108011484146118, "(26, 0)": 0.8108011484146118, "(26, 16)": 0.8108011484146118, "(28, 0)": 0.8108011484146118, "(28, 16)": 0.7833166718482971, "(30, 0)": 0.8108011484146118, "(30, 16)": 0.8108011484146118}, "r_span": [668, 726], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002607583999633789}}, {"prompt_attention_score": {"(0, 0)": 0.7152517437934875, "(0, 16)": 0.7152517437934875, "(2, 0)": 0.7152517437934875, "(2, 16)": 0.7152517437934875, "(4, 0)": 0.7152517437934875, "(4, 16)": 0.7152517437934875, "(6, 0)": 0.7152517437934875, "(6, 16)": 0.8008095026016235, "(8, 0)": 0.7152517437934875, "(8, 16)": 0.7152517437934875, "(10, 0)": 0.48719578981399536, "(10, 16)": 0.7152517437934875, "(12, 0)": 0.7152517437934875, "(12, 16)": 0.7478252649307251, "(14, 0)": 0.7152517437934875, "(14, 16)": 0.48719578981399536, "(16, 0)": 0.7715341448783875, "(16, 16)": 0.7478252649307251, "(18, 0)": 0.7478252649307251, "(18, 16)": 0.7478252649307251, "(20, 0)": 0.7715341448783875, "(20, 16)": 0.7478252649307251, "(22, 0)": 0.7478252649307251, "(22, 16)": 0.7478252649307251, "(24, 0)": 0.7478252649307251, "(24, 16)": 0.48719578981399536, "(26, 0)": 0.7478252649307251, "(26, 16)": 0.7478252649307251, "(28, 0)": 0.7478252649307251, "(28, 16)": 0.7152517437934875, "(30, 0)": 0.7478252649307251, "(30, 16)": 0.7478252649307251}, "r_span": [728, 760], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005945563316345215}}]}, {"id": "15555", "source_id": "15513", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 839, "end": 976, "text": "6. Pack accordingly: Make sure to pack appropriate clothing and gear for the season and activities you plan to do in Germany (Passage 2).", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No mention of packing accordingly in Passage 2.\nGenerative: \"Pack accordingly: Make sure to pack appropriate clothing...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 977, "end": 1104, "text": "7. Stay safe: Be aware of local laws and regulations, and take necessary precautions to stay safe during your trip (Passage 2).", "meta": "HIGH INTRO OF NEW INFO\nOriginal: No specific mention of these details in the passages. \nGenerative: \"Stay safe: Be aware of local laws and regulations...\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some steps to help you plan a trip to Germany:\n\n1. Plan ahead: Before you go to Germany, check out helpful Germany travel tips such as visa requirements, when and where to go in Germany, what to see in Germany, and how to get around in Germany (Passage 2).\n2. Research German culture: Understand the local customs and traditions of Germany to make the most of your trip (Passage 3).\n3. Book flights and accommodation: Use budget travel tips to find affordable flights and hotels or hostels in Germany (Passage 1).\n4. Plan your itinerary: Decide on the places you want to visit and create an itinerary that suits your interests and budget (Passage 2).\n5. Consider traveling with a pet: If you're planning to bring your pet along, research pet-friendly hotels and train rides in Germany (Passage 2).\n6. Pack accordingly: Make sure to pack appropriate clothing and gear for the season and activities you plan to do in Germany (Passage 2).\n7. Stay safe: Be aware of local laws and regulations, and take necessary precautions to stay safe during your trip (Passage 2).\n\nUnable to answer based on given passages. The passages do not provide specific information on how to plan a trip to Germany, such as booking tours or finding transportation.", "response_spans": [[0, 87], [89, 554], [555, 976], [977, 1104], [1106, 1279]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7028135061264038, "(0, 16)": 0.7028135061264038, "(2, 0)": 0.7028135061264038, "(2, 16)": 0.7028135061264038, "(4, 0)": 0.7028135061264038, "(4, 16)": 0.7028135061264038, "(6, 0)": 0.5394894480705261, "(6, 16)": 0.836632490158081, "(8, 0)": 0.7785736322402954, "(8, 16)": 0.5394894480705261, "(10, 0)": 0.5394894480705261, "(10, 16)": 0.5394894480705261, "(12, 0)": 0.5394894480705261, "(12, 16)": 0.836632490158081, "(14, 0)": 0.7567178010940552, "(14, 16)": 0.5394894480705261, "(16, 0)": 0.836632490158081, "(16, 16)": 0.5394894480705261, "(18, 0)": 0.5394894480705261, "(18, 16)": 0.836632490158081, "(20, 0)": 0.836632490158081, "(20, 16)": 0.7567178010940552, "(22, 0)": 0.7567178010940552, "(22, 16)": 0.836632490158081, "(24, 0)": 0.7567178010940552, "(24, 16)": 0.836632490158081, "(26, 0)": 0.7567178010940552, "(26, 16)": 0.7567178010940552, "(28, 0)": 0.7567178010940552, "(28, 16)": 0.7567178010940552, "(30, 0)": 0.7567178010940552, "(30, 16)": 0.7567178010940552}, "r_span": [433, 454], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013545751571655273}}, {"prompt_attention_score": {"(0, 0)": 0.8261972665786743, "(0, 16)": 0.6977836489677429, "(2, 0)": 0.6977836489677429, "(2, 16)": 0.6977836489677429, "(4, 0)": 0.6977836489677429, "(4, 16)": 0.6977836489677429, "(6, 0)": 0.6977836489677429, "(6, 16)": 0.8666272163391113, "(8, 0)": 0.8666272163391113, "(8, 16)": 0.6977836489677429, "(10, 0)": 0.6977836489677429, "(10, 16)": 0.6977836489677429, "(12, 0)": 0.8261972665786743, "(12, 16)": 0.8261972665786743, "(14, 0)": 0.8261972665786743, "(14, 16)": 0.8261972665786743, "(16, 0)": 0.8261972665786743, "(16, 16)": 0.6977836489677429, "(18, 0)": 0.8261972665786743, "(18, 16)": 0.8666272163391113, "(20, 0)": 0.8666272163391113, "(20, 16)": 0.8261972665786743, "(22, 0)": 0.8261972665786743, "(22, 16)": 0.8666272163391113, "(24, 0)": 0.8261972665786743, "(24, 16)": 0.8666272163391113, "(26, 0)": 0.8261972665786743, "(26, 16)": 0.8261972665786743, "(28, 0)": 0.8261972665786743, "(28, 16)": 0.8261972665786743, "(30, 0)": 0.8261972665786743, "(30, 16)": 0.8261972665786743}, "r_span": [456, 571], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0029264092445373535}}, {"prompt_attention_score": {"(0, 0)": 0.8739969730377197, "(0, 16)": 0.6977405548095703, "(2, 0)": 0.6977405548095703, "(2, 16)": 0.8739969730377197, "(4, 0)": 0.6977405548095703, "(4, 16)": 0.8739969730377197, "(6, 0)": 0.6977405548095703, "(6, 16)": 0.8739969730377197, "(8, 0)": 0.6977405548095703, "(8, 16)": 0.8739969730377197, "(10, 0)": 0.6977405548095703, "(10, 16)": 0.6977405548095703, "(12, 0)": 0.8739969730377197, "(12, 16)": 0.8739969730377197, "(14, 0)": 0.8739969730377197, "(14, 16)": 0.6977405548095703, "(16, 0)": 0.8739969730377197, "(16, 16)": 0.8739969730377197, "(18, 0)": 0.8739969730377197, "(18, 16)": 0.8739969730377197, "(20, 0)": 0.8739969730377197, "(20, 16)": 0.8739969730377197, "(22, 0)": 0.8739969730377197, "(22, 16)": 0.8739969730377197, "(24, 0)": 0.8739969730377197, "(24, 16)": 0.8112796545028687, "(26, 0)": 0.8739969730377197, "(26, 16)": 0.8739969730377197, "(28, 0)": 0.8739969730377197, "(28, 16)": 0.8739969730377197, "(30, 0)": 0.8739969730377197, "(30, 16)": 0.8739969730377197}, "r_span": [572, 681], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0001964569091796875}}, {"prompt_attention_score": {"(0, 0)": 0.6747157573699951, "(0, 16)": 0.6012629270553589, "(2, 0)": 0.6012629270553589, "(2, 16)": 0.6012629270553589, "(4, 0)": 0.6012629270553589, "(4, 16)": 0.6012629270553589, "(6, 0)": 0.6665822267532349, "(6, 16)": 0.6747157573699951, "(8, 0)": 0.6012629270553589, "(8, 16)": 0.6012629270553589, "(10, 0)": 0.6012629270553589, "(10, 16)": 0.6012629270553589, "(12, 0)": 0.6012629270553589, "(12, 16)": 0.6012629270553589, "(14, 0)": 0.6747157573699951, "(14, 16)": 0.6012629270553589, "(16, 0)": 0.6747157573699951, "(16, 16)": 0.6012629270553589, "(18, 0)": 0.6747157573699951, "(18, 16)": 0.6747157573699951, "(20, 0)": 0.6747157573699951, "(20, 16)": 0.6747157573699951, "(22, 0)": 0.6747157573699951, "(22, 16)": 0.6665822267532349, "(24, 0)": 0.6747157573699951, "(24, 16)": 0.6665822267532349, "(26, 0)": 0.6747157573699951, "(26, 16)": 0.6747157573699951, "(28, 0)": 0.6747157573699951, "(28, 16)": 0.6747157573699951, "(30, 0)": 0.6747157573699951, "(30, 16)": 0.6747157573699951}, "r_span": [682, 715], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00041097402572631836}}, {"prompt_attention_score": {"(0, 0)": 0.7703717350959778, "(0, 16)": 0.7622175812721252, "(2, 0)": 0.7622175812721252, "(2, 16)": 0.7622175812721252, "(4, 0)": 0.7622175812721252, "(4, 16)": 0.7622175812721252, "(6, 0)": 0.7622175812721252, "(6, 16)": 0.8554684519767761, "(8, 0)": 0.7622175812721252, "(8, 16)": 0.7622175812721252, "(10, 0)": 0.6965759992599487, "(10, 16)": 0.6965759992599487, "(12, 0)": 0.6965759992599487, "(12, 16)": 0.6965759992599487, "(14, 0)": 0.7703717350959778, "(14, 16)": 0.6965759992599487, "(16, 0)": 0.6965759992599487, "(16, 16)": 0.7703717350959778, "(18, 0)": 0.7703717350959778, "(18, 16)": 0.6965759992599487, "(20, 0)": 0.8554684519767761, "(20, 16)": 0.7703717350959778, "(22, 0)": 0.7703717350959778, "(22, 16)": 0.6965759992599487, "(24, 0)": 0.7703717350959778, "(24, 16)": 0.6965759992599487, "(26, 0)": 0.7703717350959778, "(26, 16)": 0.7703717350959778, "(28, 0)": 0.7703717350959778, "(28, 16)": 0.7703717350959778, "(30, 0)": 0.7703717350959778, "(30, 16)": 0.7703717350959778}, "r_span": [717, 755], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009015202522277832}}]}, {"id": "15627", "source_id": "15525", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, there are several ways to track who likes your tweets:\n\n1. Favotter.net and Favstar.fm - These websites allow you to track who has favorited your tweets and which tweets have been favorited by multiple users. (Passage 1)\n2. Using a web-based website - There are websites that allow you to check Twitter users who favorite tweets. (Passage 2)\n3. On Twitter - You can set up your account settings to receive notifications via email whenever someone marks one of your tweets as a favorite. (Passage 3)\n\nTherefore, the answer to the question is: You can use Favotter.net, Favstar.fm, or a web-based website to track who likes your tweets, or you can set up your Twitter account settings to receive email notifications.", "response_spans": [[0, 86], [88, 530], [532, 746]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7104830741882324, "(0, 16)": 0.7104830741882324, "(2, 0)": 0.7104830741882324, "(2, 16)": 0.7104830741882324, "(4, 0)": 0.7821030616760254, "(4, 16)": 0.7821030616760254, "(6, 0)": 0.7104830741882324, "(6, 16)": 0.8082528114318848, "(8, 0)": 0.7104830741882324, "(8, 16)": 0.5122164487838745, "(10, 0)": 0.5122164487838745, "(10, 16)": 0.5122164487838745, "(12, 0)": 0.5122164487838745, "(12, 16)": 0.8192923665046692, "(14, 0)": 0.7104830741882324, "(14, 16)": 0.5122164487838745, "(16, 0)": 0.8192923665046692, "(16, 16)": 0.8082528114318848, "(18, 0)": 0.5122164487838745, "(18, 16)": 0.8192923665046692, "(20, 0)": 0.8192923665046692, "(20, 16)": 0.7104830741882324, "(22, 0)": 0.8082528114318848, "(22, 16)": 0.8192923665046692, "(24, 0)": 0.7104830741882324, "(24, 16)": 0.8082528114318848, "(26, 0)": 0.8082528114318848, "(26, 16)": 0.8082528114318848, "(28, 0)": 0.8082528114318848, "(28, 16)": 0.7104830741882324, "(30, 0)": 0.8082528114318848, "(30, 16)": 0.8082528114318848}, "r_span": [503, 524], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002658367156982422}}, {"prompt_attention_score": {"(0, 0)": 0.7818741798400879, "(0, 16)": 0.7818741798400879, "(2, 0)": 0.7818741798400879, "(2, 16)": 0.7818741798400879, "(4, 0)": 0.7818741798400879, "(4, 16)": 0.7818741798400879, "(6, 0)": 0.7818741798400879, "(6, 16)": 0.8868600130081177, "(8, 0)": 0.7818741798400879, "(8, 16)": 0.7818741798400879, "(10, 0)": 0.40576785802841187, "(10, 16)": 0.7818741798400879, "(12, 0)": 0.7818741798400879, "(12, 16)": 0.8868600130081177, "(14, 0)": 0.7818741798400879, "(14, 16)": 0.7818741798400879, "(16, 0)": 0.8868600130081177, "(16, 16)": 0.7818741798400879, "(18, 0)": 0.7818741798400879, "(18, 16)": 0.7818741798400879, "(20, 0)": 0.7818741798400879, "(20, 16)": 0.7818741798400879, "(22, 0)": 0.8868600130081177, "(22, 16)": 0.8258039951324463, "(24, 0)": 0.7818741798400879, "(24, 16)": 0.7818741798400879, "(26, 0)": 0.8868600130081177, "(26, 16)": 0.8868600130081177, "(28, 0)": 0.8868600130081177, "(28, 16)": 0.7818741798400879, "(30, 0)": 0.8868600130081177, "(30, 16)": 0.8868600130081177}, "r_span": [526, 639], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00047087669372558594}}, {"prompt_attention_score": {"(0, 0)": 0.7783514261245728, "(0, 16)": 0.7783514261245728, "(2, 0)": 0.7783514261245728, "(2, 16)": 0.4219582974910736, "(4, 0)": 0.4219582974910736, "(4, 16)": 0.7783514261245728, "(6, 0)": 0.7783514261245728, "(6, 16)": 0.8153278231620789, "(8, 0)": 0.7783514261245728, "(8, 16)": 0.7783514261245728, "(10, 0)": 0.4219582974910736, "(10, 16)": 0.4219582974910736, "(12, 0)": 0.4219582974910736, "(12, 16)": 0.7783514261245728, "(14, 0)": 0.7783514261245728, "(14, 16)": 0.4219582974910736, "(16, 0)": 0.7171187400817871, "(16, 16)": 0.8153278231620789, "(18, 0)": 0.8153278231620789, "(18, 16)": 0.7783514261245728, "(20, 0)": 0.7783514261245728, "(20, 16)": 0.7783514261245728, "(22, 0)": 0.8153278231620789, "(22, 16)": 0.4219582974910736, "(24, 0)": 0.7783514261245728, "(24, 16)": 0.8153278231620789, "(26, 0)": 0.8153278231620789, "(26, 16)": 0.8153278231620789, "(28, 0)": 0.8153278231620789, "(28, 16)": 0.7783514261245728, "(30, 0)": 0.7783514261245728, "(30, 16)": 0.8153278231620789}, "r_span": [641, 696], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00044649839401245117}}]}, {"id": "15651", "source_id": "15529", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 688, "end": 849, "text": "including the University Superannuation Scheme (USS), the Universities Superannuation Scheme (USPAS), and the Scottish Universities Superannuation Scheme (SGSS).", "meta": "LOW INTRODUCTION OF NEW INFORMATION\nPassages did not mention the actual meaning of USS, USPAS, and SGSS.", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 688, "end": 849, "text": "including the University Superannuation Scheme (USS), the Universities Superannuation Scheme (USPAS), and the Scottish Universities Superannuation Scheme (SGSS).", "meta": "LOW INTRODUCTION OF NEW INFORMATION\nPassages did not mention the actual meaning of USS, USPAS, and SGSS.", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, it appears that salary exchange refers to an arrangement where an employee agrees to give up a portion of their salary or bonus in exchange for their employer making a pension contribution. This allows both parties to save money, as the employer pays lower National Insurance Contributions (NICs) on the reduced salary, while the employee receives a pension contribution. The calculator provided in passage 1 suggests that this can be a way to set up pension payments that can allow both employers and employees to make a saving. Additionally, passage 3 provides specific details about how the salary exchange works for members of certain pension schemes, including the University Superannuation Scheme (USS), the Universities Superannuation Scheme (USPAS), and the Scottish Universities Superannuation Scheme (SGSS).", "response_spans": [[0, 508], [491, 849]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7727708220481873, "(0, 16)": 0.7727708220481873, "(2, 0)": 0.7727708220481873, "(2, 16)": 0.7727708220481873, "(4, 0)": 0.7727708220481873, "(4, 16)": 0.7727708220481873, "(6, 0)": 0.7727708220481873, "(6, 16)": 0.9291205406188965, "(8, 0)": 0.7727708220481873, "(8, 16)": 0.4600968658924103, "(10, 0)": 0.7727708220481873, "(10, 16)": 0.7727708220481873, "(12, 0)": 0.7727708220481873, "(12, 16)": 0.9291205406188965, "(14, 0)": 0.7727708220481873, "(14, 16)": 0.9291205406188965, "(16, 0)": 0.9291205406188965, "(16, 16)": 0.7727708220481873, "(18, 0)": 0.4600968658924103, "(18, 16)": 0.9291205406188965, "(20, 0)": 0.9291205406188965, "(20, 16)": 0.7727708220481873, "(22, 0)": 0.7727708220481873, "(22, 16)": 0.9291205406188965, "(24, 0)": 0.7727708220481873, "(24, 16)": 0.9291205406188965, "(26, 0)": 0.9291205406188965, "(26, 16)": 0.7727708220481873, "(28, 0)": 0.9291205406188965, "(28, 16)": 0.7727708220481873, "(30, 0)": 0.9291205406188965, "(30, 16)": 0.9291205406188965}, "r_span": [549, 660], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011230707168579102}}, {"prompt_attention_score": {"(0, 0)": 0.8274837136268616, "(0, 16)": 0.8274837136268616, "(2, 0)": 0.8274837136268616, "(2, 16)": 0.8274837136268616, "(4, 0)": 0.8274837136268616, "(4, 16)": 0.8274837136268616, "(6, 0)": 0.8274837136268616, "(6, 16)": 0.7782512903213501, "(8, 0)": 0.8274837136268616, "(8, 16)": 0.8274837136268616, "(10, 0)": 0.8274837136268616, "(10, 16)": 0.8274837136268616, "(12, 0)": 0.8274837136268616, "(12, 16)": 0.8274837136268616, "(14, 0)": 0.8274837136268616, "(14, 16)": 0.8274837136268616, "(16, 0)": 0.8274837136268616, "(16, 16)": 0.8274837136268616, "(18, 0)": 0.7782512903213501, "(18, 16)": 0.8274837136268616, "(20, 0)": 0.8274837136268616, "(20, 16)": 0.8274837136268616, "(22, 0)": 0.7782512903213501, "(22, 16)": 0.8274837136268616, "(24, 0)": 0.8274837136268616, "(24, 16)": 0.8274837136268616, "(26, 0)": 0.7782512903213501, "(26, 16)": 0.8274837136268616, "(28, 0)": 0.7782512903213501, "(28, 16)": 0.8274837136268616, "(30, 0)": 0.8274837136268616, "(30, 16)": 0.7782512903213501}, "r_span": [657, 736], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0008147358894348145}}]}, {"id": "15675", "source_id": "15533", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main factors that contribute to oily skin are:\n\n1. Genetics: According to passage 1, oily skin is hereditary, meaning that if one's parents have oily skin, they are more likely to experience it themselves.\n2. Hormonal shifts: Passage 1 suggests that hormonal changes in the body can cause oily skin to come and go.\n3. Diet: While diet can aggravate acne, it does not directly cause oily skin, according to passage 1.\n4. Poor hygiene: Passage 2 mentions that poor hygiene and topical applications can contribute to oily skin.\n5. Combination skin: Passage 3 defines different skin types, including combination skin, which can be prone to oily skin in certain areas, such as the T-zone.\n\nThere is no additional information provided in the passages to suggest other factors that might contribute to oily skin. Therefore, the answer to the question is based on the information provided in the passages.", "response_spans": [[0, 82], [84, 560], [561, 719], [721, 933]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6963530778884888, "(0, 16)": 0.6963530778884888, "(2, 0)": 0.6963530778884888, "(2, 16)": 0.6963530778884888, "(4, 0)": 0.6963530778884888, "(4, 16)": 0.46849897503852844, "(6, 0)": 0.46849897503852844, "(6, 16)": 0.8253536224365234, "(8, 0)": 0.752429723739624, "(8, 16)": 0.46849897503852844, "(10, 0)": 0.46849897503852844, "(10, 16)": 0.46849897503852844, "(12, 0)": 0.46849897503852844, "(12, 16)": 0.8253536224365234, "(14, 0)": 0.752429723739624, "(14, 16)": 0.46849897503852844, "(16, 0)": 0.8253536224365234, "(16, 16)": 0.6963530778884888, "(18, 0)": 0.46849897503852844, "(18, 16)": 0.8253536224365234, "(20, 0)": 0.752429723739624, "(20, 16)": 0.752429723739624, "(22, 0)": 0.752429723739624, "(22, 16)": 0.752429723739624, "(24, 0)": 0.752429723739624, "(24, 16)": 0.752429723739624, "(26, 0)": 0.752429723739624, "(26, 16)": 0.752429723739624, "(28, 0)": 0.752429723739624, "(28, 16)": 0.752429723739624, "(30, 0)": 0.752429723739624, "(30, 16)": 0.752429723739624}, "r_span": [607, 626], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001010894775390625}}, {"prompt_attention_score": {"(0, 0)": 0.70904541015625, "(0, 16)": 0.70904541015625, "(2, 0)": 0.70904541015625, "(2, 16)": 0.70904541015625, "(4, 0)": 0.70904541015625, "(4, 16)": 0.70904541015625, "(6, 0)": 0.70904541015625, "(6, 16)": 0.890642523765564, "(8, 0)": 0.70904541015625, "(8, 16)": 0.70904541015625, "(10, 0)": 0.890642523765564, "(10, 16)": 0.890642523765564, "(12, 0)": 0.797717273235321, "(12, 16)": 0.890642523765564, "(14, 0)": 0.890642523765564, "(14, 16)": 0.890642523765564, "(16, 0)": 0.890642523765564, "(16, 16)": 0.890642523765564, "(18, 0)": 0.890642523765564, "(18, 16)": 0.890642523765564, "(20, 0)": 0.890642523765564, "(20, 16)": 0.890642523765564, "(22, 0)": 0.890642523765564, "(22, 16)": 0.890642523765564, "(24, 0)": 0.890642523765564, "(24, 16)": 0.890642523765564, "(26, 0)": 0.890642523765564, "(26, 16)": 0.890642523765564, "(28, 0)": 0.890642523765564, "(28, 16)": 0.890642523765564, "(30, 0)": 0.890642523765564, "(30, 16)": 0.890642523765564}, "r_span": [628, 762], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004870295524597168}}, {"prompt_attention_score": {"(0, 0)": 0.849236249923706, "(0, 16)": 0.849236249923706, "(2, 0)": 0.849236249923706, "(2, 16)": 0.4069831669330597, "(4, 0)": 0.4069831669330597, "(4, 16)": 0.849236249923706, "(6, 0)": 0.849236249923706, "(6, 16)": 0.849236249923706, "(8, 0)": 0.849236249923706, "(8, 16)": 0.6745451092720032, "(10, 0)": 0.849236249923706, "(10, 16)": 0.4069831669330597, "(12, 0)": 0.4069831669330597, "(12, 16)": 0.849236249923706, "(14, 0)": 0.6745451092720032, "(14, 16)": 0.849236249923706, "(16, 0)": 0.849236249923706, "(16, 16)": 0.4069831669330597, "(18, 0)": 0.4069831669330597, "(18, 16)": 0.849236249923706, "(20, 0)": 0.849236249923706, "(20, 16)": 0.6745451092720032, "(22, 0)": 0.6745451092720032, "(22, 16)": 0.849236249923706, "(24, 0)": 0.6745451092720032, "(24, 16)": 0.849236249923706, "(26, 0)": 0.6745451092720032, "(26, 16)": 0.849236249923706, "(28, 0)": 0.6745451092720032, "(28, 16)": 0.6745451092720032, "(30, 0)": 0.6745451092720032, "(30, 16)": 0.6745451092720032}, "r_span": [763, 803], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005834698677062988}}, {"prompt_attention_score": {"(0, 0)": 0.6848217248916626, "(0, 16)": 0.6848217248916626, "(2, 0)": 0.6848217248916626, "(2, 16)": 0.6848217248916626, "(4, 0)": 0.6848217248916626, "(4, 16)": 0.6753624677658081, "(6, 0)": 0.7483028173446655, "(6, 16)": 0.7957264184951782, "(8, 0)": 0.6848217248916626, "(8, 16)": 0.7483028173446655, "(10, 0)": 0.6753624677658081, "(10, 16)": 0.6753624677658081, "(12, 0)": 0.6753624677658081, "(12, 16)": 0.6753624677658081, "(14, 0)": 0.7483028173446655, "(14, 16)": 0.6753624677658081, "(16, 0)": 0.6753624677658081, "(16, 16)": 0.7483028173446655, "(18, 0)": 0.7483028173446655, "(18, 16)": 0.6753624677658081, "(20, 0)": 0.6753624677658081, "(20, 16)": 0.7483028173446655, "(22, 0)": 0.7483028173446655, "(22, 16)": 0.6753624677658081, "(24, 0)": 0.7483028173446655, "(24, 16)": 0.6753624677658081, "(26, 0)": 0.7483028173446655, "(26, 16)": 0.7483028173446655, "(28, 0)": 0.7483028173446655, "(28, 16)": 0.7483028173446655, "(30, 0)": 0.7483028173446655, "(30, 16)": 0.7483028173446655}, "r_span": [805, 845], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00022345781326293945}}]}, {"id": "15687", "source_id": "15535", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 705, "end": 723, "text": "climb up the trees", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"climb up the trees\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the characteristics of the tropical rainforest floor include:\n\n1. Abundant rainfall: Tropical rainforests receive high volumes of rainfall throughout the year, with some areas receiving over 400 inches of rain annually.\n2. High humidity: Due to the warm temperatures and abundant rainfall, the atmosphere in tropical rainforests is very humid.\n3. Rotting vegetation: The heat and humidity in tropical rainforests cause plant and animal matter to decay quickly, providing rich nutrients for other plants to grow.\n4. Presence of herbs and mushrooms: The tropical rainforest floor is home to various types of herbs, mushrooms, and ferns, which grow along the forest floor and climb up the trees.\n5. Banana growth: Vines in tropical rainforests also support the growth of bananas.", "response_spans": [[0, 93], [95, 543], [544, 808]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7002683877944946, "(0, 16)": 0.7002683877944946, "(2, 0)": 0.7002683877944946, "(2, 16)": 0.7002683877944946, "(4, 0)": 0.7002683877944946, "(4, 16)": 0.7002683877944946, "(6, 0)": 0.46843641996383667, "(6, 16)": 0.8666012287139893, "(8, 0)": 0.7002683877944946, "(8, 16)": 0.46843641996383667, "(10, 0)": 0.46843641996383667, "(10, 16)": 0.46843641996383667, "(12, 0)": 0.7002683877944946, "(12, 16)": 0.8666012287139893, "(14, 0)": 0.7002683877944946, "(14, 16)": 0.46843641996383667, "(16, 0)": 0.8666012287139893, "(16, 16)": 0.7002683877944946, "(18, 0)": 0.46843641996383667, "(18, 16)": 0.8666012287139893, "(20, 0)": 0.8666012287139893, "(20, 16)": 0.7002683877944946, "(22, 0)": 0.7002683877944946, "(22, 16)": 0.8666012287139893, "(24, 0)": 0.46843641996383667, "(24, 16)": 0.8666012287139893, "(26, 0)": 0.46843641996383667, "(26, 16)": 0.7561079263687134, "(28, 0)": 0.46843641996383667, "(28, 16)": 0.7002683877944946, "(30, 0)": 0.7002683877944946, "(30, 16)": 0.7002683877944946}, "r_span": [511, 530], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006974935531616211}}, {"prompt_attention_score": {"(0, 0)": 0.7052623629570007, "(0, 16)": 0.7052623629570007, "(2, 0)": 0.7052623629570007, "(2, 16)": 0.7052623629570007, "(4, 0)": 0.7052623629570007, "(4, 16)": 0.7052623629570007, "(6, 0)": 0.7907028198242188, "(6, 16)": 0.8084093928337097, "(8, 0)": 0.7052623629570007, "(8, 16)": 0.7052623629570007, "(10, 0)": 0.7052623629570007, "(10, 16)": 0.7052623629570007, "(12, 0)": 0.7052623629570007, "(12, 16)": 0.8084093928337097, "(14, 0)": 0.7052623629570007, "(14, 16)": 0.7052623629570007, "(16, 0)": 0.7907028198242188, "(16, 16)": 0.7052623629570007, "(18, 0)": 0.7052623629570007, "(18, 16)": 0.8084093928337097, "(20, 0)": 0.8084093928337097, "(20, 16)": 0.7052623629570007, "(22, 0)": 0.7052623629570007, "(22, 16)": 0.8084093928337097, "(24, 0)": 0.7052623629570007, "(24, 16)": 0.8084093928337097, "(26, 0)": 0.7052623629570007, "(26, 16)": 0.7052623629570007, "(28, 0)": 0.7907028198242188, "(28, 16)": 0.7907028198242188, "(30, 0)": 0.7052623629570007, "(30, 16)": 0.7052623629570007}, "r_span": [532, 644], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000741124153137207}}, {"prompt_attention_score": {"(0, 0)": 0.7811416983604431, "(0, 16)": 0.7811416983604431, "(2, 0)": 0.7811416983604431, "(2, 16)": 0.4032045304775238, "(4, 0)": 0.4032045304775238, "(4, 16)": 0.7811416983604431, "(6, 0)": 0.7811416983604431, "(6, 16)": 0.7811416983604431, "(8, 0)": 0.7811416983604431, "(8, 16)": 0.7811416983604431, "(10, 0)": 0.7811416983604431, "(10, 16)": 0.7811416983604431, "(12, 0)": 0.7811416983604431, "(12, 16)": 0.7811416983604431, "(14, 0)": 0.7811416983604431, "(14, 16)": 0.7811416983604431, "(16, 0)": 0.7811416983604431, "(16, 16)": 0.7811416983604431, "(18, 0)": 0.4032045304775238, "(18, 16)": 0.7811416983604431, "(20, 0)": 0.7811416983604431, "(20, 16)": 0.7811416983604431, "(22, 0)": 0.7811416983604431, "(22, 16)": 0.7811416983604431, "(24, 0)": 0.6907484531402588, "(24, 16)": 0.7811416983604431, "(26, 0)": 0.7811416983604431, "(26, 16)": 0.7811416983604431, "(28, 0)": 0.7811416983604431, "(28, 16)": 0.7811416983604431, "(30, 0)": 0.6648244857788086, "(30, 16)": 0.6907484531402588}, "r_span": [645, 716], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002187371253967285}}]}, {"id": "15711", "source_id": "15539", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main difference between sirloin steak and Porterhouse steak is the location from where they are cut on the cow. Sirloin steak is cut from the back of the animal, specifically the rear back portion, while Porterhouse steak is cut from further back on the sirloin, containing a bit more of the tenderloin or fillet. There is also a corresponding price difference between the two cuts.", "response_spans": [[0, 418]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7593406438827515, "(0, 16)": 0.7593406438827515, "(2, 0)": 0.7593406438827515, "(2, 16)": 0.7593406438827515, "(4, 0)": 0.7593406438827515, "(4, 16)": 0.7593406438827515, "(6, 0)": 0.7593406438827515, "(6, 16)": 0.8805369138717651, "(8, 0)": 0.7593406438827515, "(8, 16)": 0.7593406438827515, "(10, 0)": 0.3349348306655884, "(10, 16)": 0.7593406438827515, "(12, 0)": 0.7549229860305786, "(12, 16)": 0.8805369138717651, "(14, 0)": 0.8805369138717651, "(14, 16)": 0.8805369138717651, "(16, 0)": 0.8805369138717651, "(16, 16)": 0.7593406438827515, "(18, 0)": 0.3349348306655884, "(18, 16)": 0.8805369138717651, "(20, 0)": 0.8805369138717651, "(20, 16)": 0.8805369138717651, "(22, 0)": 0.8805369138717651, "(22, 16)": 0.8805369138717651, "(24, 0)": 0.8805369138717651, "(24, 16)": 0.8805369138717651, "(26, 0)": 0.8805369138717651, "(26, 16)": 0.8805369138717651, "(28, 0)": 0.8805369138717651, "(28, 16)": 0.8805369138717651, "(30, 0)": 0.8805369138717651, "(30, 16)": 0.8805369138717651}, "r_span": [537, 635], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00039005279541015625}}]}, {"id": "15717", "source_id": "15540", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the history of the word \"Gemini\" can be summarized as follows:\n\n* The word \"Gemini\" is derived from the Latin language and refers to the constellation of twins. (Passage 1)\n* The first recorded mention of the Gemini constellation was by Aristotle in his work \"Meteorologica,\" over 300 years before Christ. (Passage 1)\n* In the context of astrology, Gemini is a mutable sign that comes after Taurus and marks the beginning of summer. (Passage 2)\n* The mythological story behind the Gemini zodiac sign involves the twin brothers Castor and Pollux of Greek mythology. (Passage 3)\n\nTherefore, we can conclude that the word \"Gemini\" has its roots in Latin and refers to a constellation that represents twins, with a rich history dating back to ancient times.", "response_spans": [[0, 94], [96, 476], [477, 608], [610, 785]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6609371900558472, "(0, 16)": 0.6609371900558472, "(2, 0)": 0.6609371900558472, "(2, 16)": 0.6609371900558472, "(4, 0)": 0.6609371900558472, "(4, 16)": 0.6609371900558472, "(6, 0)": 0.6609371900558472, "(6, 16)": 0.8301746845245361, "(8, 0)": 0.6609371900558472, "(8, 16)": 0.49903804063796997, "(10, 0)": 0.49903804063796997, "(10, 16)": 0.49903804063796997, "(12, 0)": 0.49903804063796997, "(12, 16)": 0.8301746845245361, "(14, 0)": 0.6609371900558472, "(14, 16)": 0.49903804063796997, "(16, 0)": 0.8301746845245361, "(16, 16)": 0.7646358013153076, "(18, 0)": 0.49903804063796997, "(18, 16)": 0.8301746845245361, "(20, 0)": 0.8301746845245361, "(20, 16)": 0.6609371900558472, "(22, 0)": 0.7646358013153076, "(22, 16)": 0.8301746845245361, "(24, 0)": 0.7646358013153076, "(24, 16)": 0.8301746845245361, "(26, 0)": 0.7646358013153076, "(26, 16)": 0.7646358013153076, "(28, 0)": 0.7646358013153076, "(28, 16)": 0.6609371900558472, "(30, 0)": 0.7646358013153076, "(30, 16)": 0.7646358013153076}, "r_span": [428, 453], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00013709068298339844}}, {"prompt_attention_score": {"(0, 0)": 0.7633590698242188, "(0, 16)": 0.7633590698242188, "(2, 0)": 0.7633590698242188, "(2, 16)": 0.7633590698242188, "(4, 0)": 0.7633590698242188, "(4, 16)": 0.7633590698242188, "(6, 0)": 0.7633590698242188, "(6, 16)": 0.918076753616333, "(8, 0)": 0.7633590698242188, "(8, 16)": 0.7633590698242188, "(10, 0)": 0.7633590698242188, "(10, 16)": 0.7633590698242188, "(12, 0)": 0.918076753616333, "(12, 16)": 0.918076753616333, "(14, 0)": 0.7633590698242188, "(14, 16)": 0.918076753616333, "(16, 0)": 0.918076753616333, "(16, 16)": 0.918076753616333, "(18, 0)": 0.918076753616333, "(18, 16)": 0.918076753616333, "(20, 0)": 0.918076753616333, "(20, 16)": 0.7633590698242188, "(22, 0)": 0.918076753616333, "(22, 16)": 0.918076753616333, "(24, 0)": 0.918076753616333, "(24, 16)": 0.918076753616333, "(26, 0)": 0.918076753616333, "(26, 16)": 0.918076753616333, "(28, 0)": 0.918076753616333, "(28, 16)": 0.7633590698242188, "(30, 0)": 0.918076753616333, "(30, 16)": 0.918076753616333}, "r_span": [455, 564], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018355250358581543}}, {"prompt_attention_score": {"(0, 0)": 0.9157658815383911, "(0, 16)": 0.9157658815383911, "(2, 0)": 0.9157658815383911, "(2, 16)": 0.9157658815383911, "(4, 0)": 0.9157658815383911, "(4, 16)": 0.9157658815383911, "(6, 0)": 0.9157658815383911, "(6, 16)": 0.9157658815383911, "(8, 0)": 0.9157658815383911, "(8, 16)": 0.9157658815383911, "(10, 0)": 0.9157658815383911, "(10, 16)": 0.9157658815383911, "(12, 0)": 0.9157658815383911, "(12, 16)": 0.9157658815383911, "(14, 0)": 0.9157658815383911, "(14, 16)": 0.9157658815383911, "(16, 0)": 0.9157658815383911, "(16, 16)": 0.9157658815383911, "(18, 0)": 0.7307934761047363, "(18, 16)": 0.9157658815383911, "(20, 0)": 0.9157658815383911, "(20, 16)": 0.9157658815383911, "(22, 0)": 0.7307934761047363, "(22, 16)": 0.9157658815383911, "(24, 0)": 0.9157658815383911, "(24, 16)": 0.9157658815383911, "(26, 0)": 0.7307934761047363, "(26, 16)": 0.9157658815383911, "(28, 0)": 0.7307934761047363, "(28, 16)": 0.9157658815383911, "(30, 0)": 0.7307934761047363, "(30, 16)": 0.7307934761047363}, "r_span": [565, 600], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004279613494873047}}, {"prompt_attention_score": {"(0, 0)": 0.6941869258880615, "(0, 16)": 0.6941869258880615, "(2, 0)": 0.6941869258880615, "(2, 16)": 0.6956314444541931, "(4, 0)": 0.6941869258880615, "(4, 16)": 0.6941869258880615, "(6, 0)": 0.6941869258880615, "(6, 16)": 0.7944536209106445, "(8, 0)": 0.6956314444541931, "(8, 16)": 0.6941869258880615, "(10, 0)": 0.34546682238578796, "(10, 16)": 0.34546682238578796, "(12, 0)": 0.6941869258880615, "(12, 16)": 0.7944536209106445, "(14, 0)": 0.6941869258880615, "(14, 16)": 0.34546682238578796, "(16, 0)": 0.7944536209106445, "(16, 16)": 0.7944536209106445, "(18, 0)": 0.7944536209106445, "(18, 16)": 0.7944536209106445, "(20, 0)": 0.7944536209106445, "(20, 16)": 0.6941869258880615, "(22, 0)": 0.7944536209106445, "(22, 16)": 0.7944536209106445, "(24, 0)": 0.7944536209106445, "(24, 16)": 0.7944536209106445, "(26, 0)": 0.7944536209106445, "(26, 16)": 0.7944536209106445, "(28, 0)": 0.7944536209106445, "(28, 16)": 0.6941869258880615, "(30, 0)": 0.7944536209106445, "(30, 16)": 0.7944536209106445}, "r_span": [602, 644], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005794763565063477}}]}, {"id": "15729", "source_id": "15542", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how raffles work:\n\n1. Reverse Raffle: In this type of raffle, the numbers on the entry tickets are drawn in reverse order, starting with the last number and ending with the first number. For example, if there are 55 entries, the last number drawn wins the grand prize, followed by the next-to-last number, and so on until the first number. Each entry ticket costs $50, and a table of 20 individuals constitutes one complete ticket worth $1,000 and two $500 prizes (for the early bird drawing and the first ticket pulled).\n2. 50-50 Draw: This is a raffle held during a single day at a specific event. Tickets are sold to patrons throughout the event by roving staff with handheld electronic devices. The gross proceeds of 50-50 tickets sold at the event go into a prize pool, and 50% of the prize pool is awarded to the winner of a random draw that takes place at the end of the event. The remaining 50% goes to a charitable purpose chosen by the sporting club.\n3. Additional Raffles: In addition to the main raffle, there may be additional raffles for drinks and dinner. These raffles are not included in the original ticket price and require separate entry fees. One of these raffles offers the chance to win $10,000!\n\nUnable to answer based on given passages.", "response_spans": [[0, 57], [59, 561], [562, 1000], [1001, 1258], [1260, 1301]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6729564666748047, "(0, 16)": 0.6729564666748047, "(2, 0)": 0.6729564666748047, "(2, 16)": 0.6729564666748047, "(4, 0)": 0.6729564666748047, "(4, 16)": 0.6729564666748047, "(6, 0)": 0.6729564666748047, "(6, 16)": 0.850412905216217, "(8, 0)": 0.6729564666748047, "(8, 16)": 0.6729564666748047, "(10, 0)": 0.6729564666748047, "(10, 16)": 0.6729564666748047, "(12, 0)": 0.6729564666748047, "(12, 16)": 0.6729564666748047, "(14, 0)": 0.6729564666748047, "(14, 16)": 0.6729564666748047, "(16, 0)": 0.850412905216217, "(16, 16)": 0.6729564666748047, "(18, 0)": 0.6729564666748047, "(18, 16)": 0.850412905216217, "(20, 0)": 0.850412905216217, "(20, 16)": 0.7210791707038879, "(22, 0)": 0.7210791707038879, "(22, 16)": 0.850412905216217, "(24, 0)": 0.7210791707038879, "(24, 16)": 0.850412905216217, "(26, 0)": 0.7210791707038879, "(26, 16)": 0.7210791707038879, "(28, 0)": 0.6729564666748047, "(28, 16)": 0.7210791707038879, "(30, 0)": 0.7210791707038879, "(30, 16)": 0.7210791707038879}, "r_span": [415, 431], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 9.47713851928711e-06}}, {"prompt_attention_score": {"(0, 0)": 0.6848177909851074, "(0, 16)": 0.6848177909851074, "(2, 0)": 0.6848177909851074, "(2, 16)": 0.6848177909851074, "(4, 0)": 0.6848177909851074, "(4, 16)": 0.6848177909851074, "(6, 0)": 0.6848177909851074, "(6, 16)": 0.9353957772254944, "(8, 0)": 0.9353957772254944, "(8, 16)": 0.6848177909851074, "(10, 0)": 0.6848177909851074, "(10, 16)": 0.7526187300682068, "(12, 0)": 0.7526187300682068, "(12, 16)": 0.9353957772254944, "(14, 0)": 0.7526187300682068, "(14, 16)": 0.9353957772254944, "(16, 0)": 0.9353957772254944, "(16, 16)": 0.7526187300682068, "(18, 0)": 0.6848177909851074, "(18, 16)": 0.9353957772254944, "(20, 0)": 0.9353957772254944, "(20, 16)": 0.7526187300682068, "(22, 0)": 0.7526187300682068, "(22, 16)": 0.9353957772254944, "(24, 0)": 0.7526187300682068, "(24, 16)": 0.9353957772254944, "(26, 0)": 0.7526187300682068, "(26, 16)": 0.7526187300682068, "(28, 0)": 0.7526187300682068, "(28, 16)": 0.7526187300682068, "(30, 0)": 0.7526187300682068, "(30, 16)": 0.7526187300682068}, "r_span": [433, 560], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007535219192504883}}, {"prompt_attention_score": {"(0, 0)": 0.9198307991027832, "(0, 16)": 0.6833218336105347, "(2, 0)": 0.6833218336105347, "(2, 16)": 0.6833218336105347, "(4, 0)": 0.6833218336105347, "(4, 16)": 0.6833218336105347, "(6, 0)": 0.6833218336105347, "(6, 16)": 0.9198307991027832, "(8, 0)": 0.9198307991027832, "(8, 16)": 0.9198307991027832, "(10, 0)": 0.6833218336105347, "(10, 16)": 0.6833218336105347, "(12, 0)": 0.9198307991027832, "(12, 16)": 0.9198307991027832, "(14, 0)": 0.9198307991027832, "(14, 16)": 0.9198307991027832, "(16, 0)": 0.9198307991027832, "(16, 16)": 0.9198307991027832, "(18, 0)": 0.9198307991027832, "(18, 16)": 0.9198307991027832, "(20, 0)": 0.9198307991027832, "(20, 16)": 0.9198307991027832, "(22, 0)": 0.9198307991027832, "(22, 16)": 0.9198307991027832, "(24, 0)": 0.9198307991027832, "(24, 16)": 0.9198307991027832, "(26, 0)": 0.9198307991027832, "(26, 16)": 0.9198307991027832, "(28, 0)": 0.9198307991027832, "(28, 16)": 0.9198307991027832, "(30, 0)": 0.9198307991027832, "(30, 16)": 0.9198307991027832}, "r_span": [561, 679], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004699230194091797}}, {"prompt_attention_score": {"(0, 0)": 0.6575713157653809, "(0, 16)": 0.6575713157653809, "(2, 0)": 0.8049933910369873, "(2, 16)": 0.8049933910369873, "(4, 0)": 0.8049933910369873, "(4, 16)": 0.8049933910369873, "(6, 0)": 0.8049933910369873, "(6, 16)": 0.8049933910369873, "(8, 0)": 0.8049933910369873, "(8, 16)": 0.8049933910369873, "(10, 0)": 0.8049933910369873, "(10, 16)": 0.8049933910369873, "(12, 0)": 0.8049933910369873, "(12, 16)": 0.8049933910369873, "(14, 0)": 0.6575713157653809, "(14, 16)": 0.8049933910369873, "(16, 0)": 0.8049933910369873, "(16, 16)": 0.8049933910369873, "(18, 0)": 0.6575713157653809, "(18, 16)": 0.8049933910369873, "(20, 0)": 0.8049933910369873, "(20, 16)": 0.6575713157653809, "(22, 0)": 0.6575713157653809, "(22, 16)": 0.8049933910369873, "(24, 0)": 0.6575713157653809, "(24, 16)": 0.8049933910369873, "(26, 0)": 0.6575713157653809, "(26, 16)": 0.6575713157653809, "(28, 0)": 0.6575713157653809, "(28, 16)": 0.6575713157653809, "(30, 0)": 0.6575713157653809, "(30, 16)": 0.6575713157653809}, "r_span": [680, 748], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005972385406494141}}, {"prompt_attention_score": {"(0, 0)": 0.5395528078079224, "(0, 16)": 0.6644088625907898, "(2, 0)": 0.6644088625907898, "(2, 16)": 0.6644088625907898, "(4, 0)": 0.6644088625907898, "(4, 16)": 0.6644088625907898, "(6, 0)": 0.6644088625907898, "(6, 16)": 0.6644088625907898, "(8, 0)": 0.6644088625907898, "(8, 16)": 0.6644088625907898, "(10, 0)": 0.6644088625907898, "(10, 16)": 0.6644088625907898, "(12, 0)": 0.6644088625907898, "(12, 16)": 0.6644088625907898, "(14, 0)": 0.5395528078079224, "(14, 16)": 0.6644088625907898, "(16, 0)": 0.6644088625907898, "(16, 16)": 0.5395528078079224, "(18, 0)": 0.6644088625907898, "(18, 16)": 0.6644088625907898, "(20, 0)": 0.6644088625907898, "(20, 16)": 0.5395528078079224, "(22, 0)": 0.5395528078079224, "(22, 16)": 0.6644088625907898, "(24, 0)": 0.5395528078079224, "(24, 16)": 0.6644088625907898, "(26, 0)": 0.6644088625907898, "(26, 16)": 0.5395528078079224, "(28, 0)": 0.5395528078079224, "(28, 16)": 0.5395528078079224, "(30, 0)": 0.5395528078079224, "(30, 16)": 0.5395528078079224}, "r_span": [750, 760], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 8.845329284667969e-05}}]}, {"id": "15735", "source_id": "15543", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 271, "end": 361, "text": "Average temperature in Tallahassee, Florida: 79 ¬∞F (26 ¬∞C) - 56 ¬∞F (13 ¬∞C) = 23 ¬∞F (12 ¬∞C)", "meta": "LOW INTRO OF NEW INFO \n- Passage 1 mentioned 79 degrees F (ave. high temp) and 56 degrees F(ave. low temp). However, AI added information specifically \"23 degrees F \"( difference of average high temperature and low temperature.)", "label_type": "Subtle Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the average temperature in Tallahassee, Florida is:\n\n* Average high temperature: 79 ¬∞F (26 ¬∞C)\n* Average low temperature: 56 ¬∞F (13 ¬∞C)\n\nTherefore, the answer to the question \"What is the average temperature in Tallahassee, Florida?\" is:\n\nAverage temperature in Tallahassee, Florida: 79 ¬∞F (26 ¬∞C) - 56 ¬∞F (13 ¬∞C) = 23 ¬∞F (12 ¬∞C)", "response_spans": [[0, 361]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8464156985282898, "(0, 16)": 0.8464156985282898, "(2, 0)": 0.8464156985282898, "(2, 16)": 0.8464156985282898, "(4, 0)": 0.8464156985282898, "(4, 16)": 0.8464156985282898, "(6, 0)": 0.8464156985282898, "(6, 16)": 0.9217875003814697, "(8, 0)": 0.8464156985282898, "(8, 16)": 0.8464156985282898, "(10, 0)": 0.38103827834129333, "(10, 16)": 0.38103827834129333, "(12, 0)": 0.9217875003814697, "(12, 16)": 0.9217875003814697, "(14, 0)": 0.9217875003814697, "(14, 16)": 0.38103827834129333, "(16, 0)": 0.9217875003814697, "(16, 16)": 0.9217875003814697, "(18, 0)": 0.9217875003814697, "(18, 16)": 0.9217875003814697, "(20, 0)": 0.9217875003814697, "(20, 16)": 0.9217875003814697, "(22, 0)": 0.9217875003814697, "(22, 16)": 0.9217875003814697, "(24, 0)": 0.9217875003814697, "(24, 16)": 0.9217875003814697, "(26, 0)": 0.9217875003814697, "(26, 16)": 0.9217875003814697, "(28, 0)": 0.9217875003814697, "(28, 16)": 0.8464156985282898, "(30, 0)": 0.9217875003814697, "(30, 16)": 0.9217875003814697}, "r_span": [418, 549], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0020685195922851562}}]}, {"id": "15753", "source_id": "15546", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 436, "end": 547, "text": "This process continues until the customer's account is debited no more than five times within a 24-hour period.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"This process continues until the customer's account is debited no more than five times within a 24-hour period.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, I can explain how Ez Pass charges work as follows:\n\nEz Pass charges are deducted from a prepaid balance on a customer's credit card. The initial balance is set at $100 for the EZ-Tag and $25 for the TX-Tag. Tolls are deducted from this balance until the balance drops below a certain threshold ($10 for the TX-Tag), at which point another $100 or $25 is charged to the credit card to top up the balance. This process continues until the customer's account is debited no more than five times within a 24-hour period.\n\nIt is important to note that the passages do not provide details on the specific amounts charged for each toll transaction, so it is unclear whether there are any additional fees or charges beyond the initial $100 or $25 prepaid balance. Furthermore, the passage about reporting abuse mentions that customers may be charged $100 or $25 for each occurrence of abuse, suggesting that these amounts may also be deducted from their prepaid balance.", "response_spans": [[0, 82], [84, 547], [549, 993]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7364820241928101, "(0, 16)": 0.7364820241928101, "(2, 0)": 0.7364820241928101, "(2, 16)": 0.7364820241928101, "(4, 0)": 0.7364820241928101, "(4, 16)": 0.7364820241928101, "(6, 0)": 0.7364820241928101, "(6, 16)": 0.7611228823661804, "(8, 0)": 0.7611228823661804, "(8, 16)": 0.5646392107009888, "(10, 0)": 0.5646392107009888, "(10, 16)": 0.5646392107009888, "(12, 0)": 0.7611228823661804, "(12, 16)": 0.7611228823661804, "(14, 0)": 0.7611228823661804, "(14, 16)": 0.5646392107009888, "(16, 0)": 0.7611228823661804, "(16, 16)": 0.7611228823661804, "(18, 0)": 0.5646392107009888, "(18, 16)": 0.7611228823661804, "(20, 0)": 0.7611228823661804, "(20, 16)": 0.7364820241928101, "(22, 0)": 0.7611228823661804, "(22, 16)": 0.7611228823661804, "(24, 0)": 0.7611228823661804, "(24, 16)": 0.7611228823661804, "(26, 0)": 0.7611228823661804, "(26, 16)": 0.7611228823661804, "(28, 0)": 0.7611228823661804, "(28, 16)": 0.7611228823661804, "(30, 0)": 0.7611228823661804, "(30, 16)": 0.7611228823661804}, "r_span": [387, 406], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001480579376220703}}, {"prompt_attention_score": {"(0, 0)": 0.7648227214813232, "(0, 16)": 0.7648227214813232, "(2, 0)": 0.7648227214813232, "(2, 16)": 0.7648227214813232, "(4, 0)": 0.7648227214813232, "(4, 16)": 0.7648227214813232, "(6, 0)": 0.7648227214813232, "(6, 16)": 0.9117488861083984, "(8, 0)": 0.9117488861083984, "(8, 16)": 0.7648227214813232, "(10, 0)": 0.9117488861083984, "(10, 16)": 0.7648227214813232, "(12, 0)": 0.9117488861083984, "(12, 16)": 0.9117488861083984, "(14, 0)": 0.9117488861083984, "(14, 16)": 0.9117488861083984, "(16, 0)": 0.9117488861083984, "(16, 16)": 0.9117488861083984, "(18, 0)": 0.9117488861083984, "(18, 16)": 0.9117488861083984, "(20, 0)": 0.9117488861083984, "(20, 16)": 0.7648227214813232, "(22, 0)": 0.9117488861083984, "(22, 16)": 0.9117488861083984, "(24, 0)": 0.9117488861083984, "(24, 16)": 0.9117488861083984, "(26, 0)": 0.9117488861083984, "(26, 16)": 0.9117488861083984, "(28, 0)": 0.9117488861083984, "(28, 16)": 0.9117488861083984, "(30, 0)": 0.9117488861083984, "(30, 16)": 0.9117488861083984}, "r_span": [408, 534], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0003910660743713379}}, {"prompt_attention_score": {"(0, 0)": 0.5954005718231201, "(0, 16)": 0.5954005718231201, "(2, 0)": 0.5954005718231201, "(2, 16)": 0.5954005718231201, "(4, 0)": 0.5954005718231201, "(4, 16)": 0.5954005718231201, "(6, 0)": 0.5954005718231201, "(6, 16)": 0.6991615295410156, "(8, 0)": 0.6991615295410156, "(8, 16)": 0.5954005718231201, "(10, 0)": 0.6991615295410156, "(10, 16)": 0.5954005718231201, "(12, 0)": 0.5217402577400208, "(12, 16)": 0.6991615295410156, "(14, 0)": 0.6991615295410156, "(14, 16)": 0.5217402577400208, "(16, 0)": 0.6991615295410156, "(16, 16)": 0.6991615295410156, "(18, 0)": 0.6991615295410156, "(18, 16)": 0.6991615295410156, "(20, 0)": 0.6991615295410156, "(20, 16)": 0.5954005718231201, "(22, 0)": 0.6991615295410156, "(22, 16)": 0.5247044563293457, "(24, 0)": 0.6991615295410156, "(24, 16)": 0.6991615295410156, "(26, 0)": 0.6991615295410156, "(26, 16)": 0.6991615295410156, "(28, 0)": 0.6991615295410156, "(28, 16)": 0.5954005718231201, "(30, 0)": 0.6991615295410156, "(30, 16)": 0.6991615295410156}, "r_span": [536, 634], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0019150972366333008}}]}, {"id": "15777", "source_id": "15550", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 552, "end": 841, "text": "6. Holding a dressing or bandage in place.\n7. Hanging a picture or ornament.\n8. Repairing a ripped seam.\n9. Closing openings on a backpack or tent.\n10. Creating a makeshift fishing hook.\n11. Making a simple tool for cutting or prying.\n12. Creating a makeshift mirror or reflective surface.", "meta": "HIGH INTRO OF NEW INFO\n- Passages did not mention the additional 6 uses of safety pins (from 6 to 12)", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, safety pins in a first aid box are used for the following purposes:\n\n1. Immobilizing an arm by pinning the cuff of a long sleeve shirt to its chest to fashion a makeshift arm sling.\n2. Securing a bandana over a wounded and bleeding arm or leg.\n3. Helping to keep a severe wound closed in place of stitches in dire circumstances.\n4. Removing splinters in the wilderness.\n\nAdditionally, the third passage mentions 12 additional uses for safety pins, which include:\n\n5. Fastening two pieces of fabric or clothing together.\n6. Holding a dressing or bandage in place.\n7. Hanging a picture or ornament.\n8. Repairing a ripped seam.\n9. Closing openings on a backpack or tent.\n10. Creating a makeshift fishing hook.\n11. Making a simple tool for cutting or prying.\n12. Creating a makeshift mirror or reflective surface.\n\nTherefore, based on the given passages, safety pins in a first aid box are useful for both general first aid purposes and as a multipurpose tool for various tasks in the outdoors or daily life.", "response_spans": [[0, 494], [496, 841], [843, 1036]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7881923317909241, "(0, 16)": 0.7881923317909241, "(2, 0)": 0.7881923317909241, "(2, 16)": 0.7881923317909241, "(4, 0)": 0.7881923317909241, "(4, 16)": 0.7881923317909241, "(6, 0)": 0.7881923317909241, "(6, 16)": 0.8834435939788818, "(8, 0)": 0.8264991641044617, "(8, 16)": 0.7881923317909241, "(10, 0)": 0.7881923317909241, "(10, 16)": 0.7881923317909241, "(12, 0)": 0.7881923317909241, "(12, 16)": 0.8264991641044617, "(14, 0)": 0.8058245778083801, "(14, 16)": 0.7881923317909241, "(16, 0)": 0.7881923317909241, "(16, 16)": 0.7881923317909241, "(18, 0)": 0.7881923317909241, "(18, 16)": 0.8834435939788818, "(20, 0)": 0.8264991641044617, "(20, 16)": 0.8058245778083801, "(22, 0)": 0.8058245778083801, "(22, 16)": 0.8834435939788818, "(24, 0)": 0.8058245778083801, "(24, 16)": 0.8834435939788818, "(26, 0)": 0.8058245778083801, "(26, 16)": 0.8058245778083801, "(28, 0)": 0.8058245778083801, "(28, 16)": 0.8058245778083801, "(30, 0)": 0.8058245778083801, "(30, 16)": 0.8058245778083801}, "r_span": [590, 727], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007639527320861816}}, {"prompt_attention_score": {"(0, 0)": 0.6378592848777771, "(0, 16)": 0.6378592848777771, "(2, 0)": 0.6378592848777771, "(2, 16)": 0.6378592848777771, "(4, 0)": 0.6378592848777771, "(4, 16)": 0.6378592848777771, "(6, 0)": 0.6410713195800781, "(6, 16)": 0.6547095775604248, "(8, 0)": 0.6378592848777771, "(8, 16)": 0.6094422340393066, "(10, 0)": 0.6378592848777771, "(10, 16)": 0.6378592848777771, "(12, 0)": 0.6378592848777771, "(12, 16)": 0.6378592848777771, "(14, 0)": 0.6094422340393066, "(14, 16)": 0.6378592848777771, "(16, 0)": 0.6378592848777771, "(16, 16)": 0.6410713195800781, "(18, 0)": 0.6094422340393066, "(18, 16)": 0.6378592848777771, "(20, 0)": 0.6378592848777771, "(20, 16)": 0.6094422340393066, "(22, 0)": 0.6094422340393066, "(22, 16)": 0.6378592848777771, "(24, 0)": 0.6094422340393066, "(24, 16)": 0.6378592848777771, "(26, 0)": 0.6094422340393066, "(26, 16)": 0.6094422340393066, "(28, 0)": 0.6094422340393066, "(28, 16)": 0.6094422340393066, "(30, 0)": 0.6094422340393066, "(30, 16)": 0.6094422340393066}, "r_span": [729, 836], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0019756555557250977}}, {"prompt_attention_score": {"(0, 0)": 0.7618938684463501, "(0, 16)": 0.7245770692825317, "(2, 0)": 0.7245770692825317, "(2, 16)": 0.7245770692825317, "(4, 0)": 0.7245770692825317, "(4, 16)": 0.7245770692825317, "(6, 0)": 0.7245770692825317, "(6, 16)": 0.7618938684463501, "(8, 0)": 0.7245770692825317, "(8, 16)": 0.7618938684463501, "(10, 0)": 0.7245770692825317, "(10, 16)": 0.7245770692825317, "(12, 0)": 0.7245770692825317, "(12, 16)": 0.7245770692825317, "(14, 0)": 0.7618938684463501, "(14, 16)": 0.7245770692825317, "(16, 0)": 0.7245770692825317, "(16, 16)": 0.7245770692825317, "(18, 0)": 0.7618938684463501, "(18, 16)": 0.7245770692825317, "(20, 0)": 0.7245770692825317, "(20, 16)": 0.7618938684463501, "(22, 0)": 0.7618938684463501, "(22, 16)": 0.7464656829833984, "(24, 0)": 0.7618938684463501, "(24, 16)": 0.7618938684463501, "(26, 0)": 0.7618938684463501, "(26, 16)": 0.7618938684463501, "(28, 0)": 0.7618938684463501, "(28, 16)": 0.7618938684463501, "(30, 0)": 0.7618938684463501, "(30, 16)": 0.7618938684463501}, "r_span": [838, 883], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015094876289367676}}]}, {"id": "15783", "source_id": "15551", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "truncated", "response": "Based on the provided passages, the lyrics \"he was a friend of mine\" are mentioned in the following passages:\n\n* Passage 1: In the context of the Greenbriar Boys recording the song \"He Was a Friend of Mine\" with singer Dian James in 1963.\n* Passage 2: As part of a fragmented repetition of the line \"He was a friend of mine\" in the passage.\n\nTherefore, the answer to the question is:\n\nPassage 1 and Passage 2", "response_spans": [[0, 408]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7558737993240356, "(0, 16)": 0.7558737993240356, "(2, 0)": 0.7558737993240356, "(2, 16)": 0.7558737993240356, "(4, 0)": 0.7558737993240356, "(4, 16)": 0.7558737993240356, "(6, 0)": 0.8458968997001648, "(6, 16)": 0.8458968997001648, "(8, 0)": 0.7558737993240356, "(8, 16)": 0.7558737993240356, "(10, 0)": 0.47870656847953796, "(10, 16)": 0.47870656847953796, "(12, 0)": 0.8458968997001648, "(12, 16)": 0.8458968997001648, "(14, 0)": 0.8458968997001648, "(14, 16)": 0.47870656847953796, "(16, 0)": 0.8458968997001648, "(16, 16)": 0.8458968997001648, "(18, 0)": 0.8458968997001648, "(18, 16)": 0.8458968997001648, "(20, 0)": 0.8458968997001648, "(20, 16)": 0.8458968997001648, "(22, 0)": 0.8458968997001648, "(22, 16)": 0.8458968997001648, "(24, 0)": 0.8458968997001648, "(24, 16)": 0.8458968997001648, "(26, 0)": 0.8458968997001648, "(26, 16)": 0.8458968997001648, "(28, 0)": 0.8458968997001648, "(28, 16)": 0.8458968997001648, "(30, 0)": 0.8458968997001648, "(30, 16)": 0.8458968997001648}, "r_span": [434, 555], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0018361806869506836}}]}, {"id": "15789", "source_id": "15552", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some traits associated with people born in October:\n\n* Interest in form and structure (Passage 1)\n* Success-oriented, charming, and personally powerful individuals (Passage 2)\n* Crave stability and security (Passage 3)\n\nIt's important to note that these are generalizations and may not apply to every individual born in October. Additionally, it's worth mentioning that the passages provide insights into personality traits based on astrology, numerology, and cartomancy, which are not scientifically proven methods of predicting personality.", "response_spans": [[0, 259], [261, 583]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7228142619132996, "(0, 16)": 0.7228142619132996, "(2, 0)": 0.7228142619132996, "(2, 16)": 0.7228142619132996, "(4, 0)": 0.7228142619132996, "(4, 16)": 0.7228142619132996, "(6, 0)": 0.7228142619132996, "(6, 16)": 0.8336241245269775, "(8, 0)": 0.7228142619132996, "(8, 16)": 0.7228142619132996, "(10, 0)": 0.7228142619132996, "(10, 16)": 0.7228142619132996, "(12, 0)": 0.7228142619132996, "(12, 16)": 0.7228142619132996, "(14, 0)": 0.8336241245269775, "(14, 16)": 0.7228142619132996, "(16, 0)": 0.8336241245269775, "(16, 16)": 0.7228142619132996, "(18, 0)": 0.7228142619132996, "(18, 16)": 0.8336241245269775, "(20, 0)": 0.8336241245269775, "(20, 16)": 0.7228142619132996, "(22, 0)": 0.7228142619132996, "(22, 16)": 0.8336241245269775, "(24, 0)": 0.7228142619132996, "(24, 16)": 0.8156952857971191, "(26, 0)": 0.7228142619132996, "(26, 16)": 0.8156952857971191, "(28, 0)": 0.7228142619132996, "(28, 16)": 0.7228142619132996, "(30, 0)": 0.7228142619132996, "(30, 16)": 0.7228142619132996}, "r_span": [374, 441], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002067744731903076}}, {"prompt_attention_score": {"(0, 0)": 0.6553257703781128, "(0, 16)": 0.6553257703781128, "(2, 0)": 0.6553257703781128, "(2, 16)": 0.6553257703781128, "(4, 0)": 0.6553257703781128, "(4, 16)": 0.6553257703781128, "(6, 0)": 0.6553257703781128, "(6, 16)": 0.7856235504150391, "(8, 0)": 0.7856235504150391, "(8, 16)": 0.6553257703781128, "(10, 0)": 0.6553257703781128, "(10, 16)": 0.6553257703781128, "(12, 0)": 0.6553257703781128, "(12, 16)": 0.7856235504150391, "(14, 0)": 0.7359113097190857, "(14, 16)": 0.6553257703781128, "(16, 0)": 0.6553257703781128, "(16, 16)": 0.6553257703781128, "(18, 0)": 0.7359113097190857, "(18, 16)": 0.7856235504150391, "(20, 0)": 0.7856235504150391, "(20, 16)": 0.7359113097190857, "(22, 0)": 0.6553257703781128, "(22, 16)": 0.6553257703781128, "(24, 0)": 0.6553257703781128, "(24, 16)": 0.6553257703781128, "(26, 0)": 0.6553257703781128, "(26, 16)": 0.6553257703781128, "(28, 0)": 0.6553257703781128, "(28, 16)": 0.6553257703781128, "(30, 0)": 0.6553257703781128, "(30, 16)": 0.6553257703781128}, "r_span": [443, 513], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009314417839050293}}]}, {"id": "15903", "source_id": "15572", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how a transistor works:\n\n1. A transistor functions as both an amplifier and a switch.\n2. The transistor's design allows it to control a larger supply of electricity with a small amount of electricity, much like turning a valve to control a supply of water.\n3. The base of the transistor pulls electrons from the emitter, creating a flow of electricity through the transistor.\n4. The transistor can take in a tiny electric current at one end (the input current) and produce a much bigger electric current at the other end (the output current) when it works as an amplifier.\n5. The holes in the base of the transistor act as a barrier, preventing any significant current flow from the emitter to the collector when the transistor is in its off state.\n6. When the electrons and holes move across the two junctions between the n-type and p-type silicon, the transistor begins to work.\n7. The collector current is approximately beta (common-emitter current gain) times the base current, and it is typically greater than 100 for small-signal transistors but can be smaller in transistors designed for high-power applications.\n\nUnable to answer based on the given passages.", "response_spans": [[0, 63], [65, 415], [416, 920], [921, 1159], [1161, 1206]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7721802592277527, "(0, 16)": 0.7721802592277527, "(2, 0)": 0.7721802592277527, "(2, 16)": 0.7721802592277527, "(4, 0)": 0.7721802592277527, "(4, 16)": 0.7721802592277527, "(6, 0)": 0.5785146951675415, "(6, 16)": 0.8405753374099731, "(8, 0)": 0.7721802592277527, "(8, 16)": 0.5785146951675415, "(10, 0)": 0.5785146951675415, "(10, 16)": 0.5785146951675415, "(12, 0)": 0.5785146951675415, "(12, 16)": 0.8405753374099731, "(14, 0)": 0.7721802592277527, "(14, 16)": 0.5785146951675415, "(16, 0)": 0.8405753374099731, "(16, 16)": 0.7721802592277527, "(18, 0)": 0.5785146951675415, "(18, 16)": 0.8405753374099731, "(20, 0)": 0.8405753374099731, "(20, 16)": 0.7721802592277527, "(22, 0)": 0.7721802592277527, "(22, 16)": 0.8405753374099731, "(24, 0)": 0.7721802592277527, "(24, 16)": 0.8405753374099731, "(26, 0)": 0.7721802592277527, "(26, 16)": 0.7721802592277527, "(28, 0)": 0.7721802592277527, "(28, 16)": 0.7721802592277527, "(30, 0)": 0.7721802592277527, "(30, 16)": 0.7721802592277527}, "r_span": [503, 519], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004795193672180176}}, {"prompt_attention_score": {"(0, 0)": 0.8214272260665894, "(0, 16)": 0.8214272260665894, "(2, 0)": 0.8214272260665894, "(2, 16)": 0.8214272260665894, "(4, 0)": 0.8214272260665894, "(4, 16)": 0.8214272260665894, "(6, 0)": 0.8214272260665894, "(6, 16)": 0.8487613201141357, "(8, 0)": 0.8214272260665894, "(8, 16)": 0.8214272260665894, "(10, 0)": 0.8214272260665894, "(10, 16)": 0.8214272260665894, "(12, 0)": 0.8214272260665894, "(12, 16)": 0.8487613201141357, "(14, 0)": 0.8214272260665894, "(14, 16)": 0.8487613201141357, "(16, 0)": 0.8487613201141357, "(16, 16)": 0.8214272260665894, "(18, 0)": 0.8214272260665894, "(18, 16)": 0.8487613201141357, "(20, 0)": 0.8487613201141357, "(20, 16)": 0.8214272260665894, "(22, 0)": 0.8214272260665894, "(22, 16)": 0.8487613201141357, "(24, 0)": 0.8214272260665894, "(24, 16)": 0.8487613201141357, "(26, 0)": 0.8214272260665894, "(26, 16)": 0.8214272260665894, "(28, 0)": 0.8214272260665894, "(28, 16)": 0.8214272260665894, "(30, 0)": 0.8214272260665894, "(30, 16)": 0.8214272260665894}, "r_span": [521, 604], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00012415647506713867}}, {"prompt_attention_score": {"(0, 0)": 0.7870209813117981, "(0, 16)": 0.7870209813117981, "(2, 0)": 0.7870209813117981, "(2, 16)": 0.7870209813117981, "(4, 0)": 0.7870209813117981, "(4, 16)": 0.7870209813117981, "(6, 0)": 0.7870209813117981, "(6, 16)": 0.8469439148902893, "(8, 0)": 0.7870209813117981, "(8, 16)": 0.7870209813117981, "(10, 0)": 0.7870209813117981, "(10, 16)": 0.7870209813117981, "(12, 0)": 0.7870209813117981, "(12, 16)": 0.8469439148902893, "(14, 0)": 0.7870209813117981, "(14, 16)": 0.7870209813117981, "(16, 0)": 0.8469439148902893, "(16, 16)": 0.7870209813117981, "(18, 0)": 0.7870209813117981, "(18, 16)": 0.8469439148902893, "(20, 0)": 0.8469439148902893, "(20, 16)": 0.7870209813117981, "(22, 0)": 0.7870209813117981, "(22, 16)": 0.8469439148902893, "(24, 0)": 0.7870209813117981, "(24, 16)": 0.8469439148902893, "(26, 0)": 0.7870209813117981, "(26, 16)": 0.7870209813117981, "(28, 0)": 0.7870209813117981, "(28, 16)": 0.7870209813117981, "(30, 0)": 0.7870209813117981, "(30, 16)": 0.7870209813117981}, "r_span": [605, 725], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0027292966842651367}}, {"prompt_attention_score": {"(0, 0)": 0.7768691778182983, "(0, 16)": 0.7768691778182983, "(2, 0)": 0.7768691778182983, "(2, 16)": 0.7768691778182983, "(4, 0)": 0.7768691778182983, "(4, 16)": 0.7768691778182983, "(6, 0)": 0.7768691778182983, "(6, 16)": 0.7768691778182983, "(8, 0)": 0.7768691778182983, "(8, 16)": 0.7768691778182983, "(10, 0)": 0.7768691778182983, "(10, 16)": 0.7768691778182983, "(12, 0)": 0.7768691778182983, "(12, 16)": 0.7768691778182983, "(14, 0)": 0.7768691778182983, "(14, 16)": 0.7768691778182983, "(16, 0)": 0.7768691778182983, "(16, 16)": 0.7768691778182983, "(18, 0)": 0.7768691778182983, "(18, 16)": 0.7768691778182983, "(20, 0)": 0.7768691778182983, "(20, 16)": 0.7768691778182983, "(22, 0)": 0.7768691778182983, "(22, 16)": 0.7768691778182983, "(24, 0)": 0.7768691778182983, "(24, 16)": 0.7768691778182983, "(26, 0)": 0.7768691778182983, "(26, 16)": 0.7768691778182983, "(28, 0)": 0.7768691778182983, "(28, 16)": 0.7768691778182983, "(30, 0)": 0.7768691778182983, "(30, 16)": 0.7768691778182983}, "r_span": [726, 780], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010213851928710938}}, {"prompt_attention_score": {"(0, 0)": 0.5036253929138184, "(0, 16)": 0.5036253929138184, "(2, 0)": 0.5036253929138184, "(2, 16)": 0.5036253929138184, "(4, 0)": 0.5036253929138184, "(4, 16)": 0.5036253929138184, "(6, 0)": 0.8885274529457092, "(6, 16)": 0.8885274529457092, "(8, 0)": 0.5036253929138184, "(8, 16)": 0.5036253929138184, "(10, 0)": 0.8885274529457092, "(10, 16)": 0.8885274529457092, "(12, 0)": 0.5036253929138184, "(12, 16)": 0.8885274529457092, "(14, 0)": 0.5036253929138184, "(14, 16)": 0.8885274529457092, "(16, 0)": 0.8885274529457092, "(16, 16)": 0.5036253929138184, "(18, 0)": 0.5036253929138184, "(18, 16)": 0.8885274529457092, "(20, 0)": 0.8885274529457092, "(20, 16)": 0.5036253929138184, "(22, 0)": 0.5036253929138184, "(22, 16)": 0.8885274529457092, "(24, 0)": 0.5036253929138184, "(24, 16)": 0.8885274529457092, "(26, 0)": 0.5036253929138184, "(26, 16)": 0.5036253929138184, "(28, 0)": 0.5036253929138184, "(28, 16)": 0.5036253929138184, "(30, 0)": 0.5036253929138184, "(30, 16)": 0.5036253929138184}, "r_span": [782, 793], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 9.000301361083984e-06}}]}, {"id": "15927", "source_id": "15576", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 275, "end": 437, "text": "The reason for having two CEOs is to provide stability and continuity in leadership, as well as to distribute responsibilities between two experienced executives.", "meta": "LOW INTRODUCTION OF NEW INFORMATION \nOriginal: *did not sicuss the reason*\nGenerative: \"The reason for having two CEOs is to provide stability and continuity in leadership, as well as to distribute responsibilities between two experienced executives.\"", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, Oracle has two CEOs because Larry Ellison, the company's founder and former CEO, has stepped down from the position and has been replaced by two co-CEOs: Safra Catz and Mark Hurd. This decision was unexpected and announced by Ellison himself. The reason for having two CEOs is to provide stability and continuity in leadership, as well as to distribute responsibilities between two experienced executives.", "response_spans": [[0, 437]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7903507351875305, "(0, 16)": 0.7903507351875305, "(2, 0)": 0.7903507351875305, "(2, 16)": 0.7903507351875305, "(4, 0)": 0.7903507351875305, "(4, 16)": 0.7903507351875305, "(6, 0)": 0.7903507351875305, "(6, 16)": 0.7953266501426697, "(8, 0)": 0.7903507351875305, "(8, 16)": 0.7903507351875305, "(10, 0)": 0.7903507351875305, "(10, 16)": 0.7903507351875305, "(12, 0)": 0.7903507351875305, "(12, 16)": 0.7903507351875305, "(14, 0)": 0.7903507351875305, "(14, 16)": 0.7903507351875305, "(16, 0)": 0.8481569290161133, "(16, 16)": 0.7903507351875305, "(18, 0)": 0.7903507351875305, "(18, 16)": 0.7953266501426697, "(20, 0)": 0.7903507351875305, "(20, 16)": 0.7903507351875305, "(22, 0)": 0.7903507351875305, "(22, 16)": 0.7903507351875305, "(24, 0)": 0.7903507351875305, "(24, 16)": 0.7953266501426697, "(26, 0)": 0.7903507351875305, "(26, 16)": 0.7903507351875305, "(28, 0)": 0.7903507351875305, "(28, 16)": 0.7903507351875305, "(30, 0)": 0.7903507351875305, "(30, 16)": 0.7903507351875305}, "r_span": [482, 579], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001321554183959961}}]}, {"id": "15933", "source_id": "15577", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is my understanding of the term \"global egalitarianism\":\n\nGlobal egalitarianism refers to a concept of global justice that emphasizes the importance of equality among individuals and groups worldwide. According to this perspective, global justice requires that all individuals have equal access to resources and opportunities, regardless of their cultural background or location.\n\nThe first passage highlights the limitations of global egalitarianism by arguing that measuring the resources or opportunities available to people in different societies in a way that is neutral as between cultures is impossible. Therefore, the principle of global justice cannot be based solely on equality of resources or equality of opportunity.\n\nThe second passage notes that the world is highly unequal in socio-economic terms, with certain individuals and groups having more wealth and opportunities than others. This inequality is seen as a major challenge to global justice.\n\nThe third passage distinguishes between instrumental and non-instrumental forms of egalitarianism. Instrumental egalitarianism seeks to promote equality as a means to achieve some other goal, while non-instrumental egalitarianism values equality for its own sake or as partially constituting some other end.\n\nTherefore, based on the given passages, global egalitarianism can be understood as a conception of global justice that prioritizes equality among individuals and groups worldwide, but recognizes the challenges involved in measuring and achieving equality in a global context.", "response_spans": [[0, 416], [418, 766], [768, 1000], [1002, 1309], [1311, 1586]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7834442853927612, "(0, 16)": 0.7209339141845703, "(2, 0)": 0.7209339141845703, "(2, 16)": 0.7209339141845703, "(4, 0)": 0.7209339141845703, "(4, 16)": 0.7209339141845703, "(6, 0)": 0.7209339141845703, "(6, 16)": 0.8259996175765991, "(8, 0)": 0.7209339141845703, "(8, 16)": 0.7209339141845703, "(10, 0)": 0.7209339141845703, "(10, 16)": 0.7209339141845703, "(12, 0)": 0.7209339141845703, "(12, 16)": 0.8259996175765991, "(14, 0)": 0.7209339141845703, "(14, 16)": 0.7209339141845703, "(16, 0)": 0.8592824935913086, "(16, 16)": 0.7209339141845703, "(18, 0)": 0.7209339141845703, "(18, 16)": 0.8259996175765991, "(20, 0)": 0.8259996175765991, "(20, 16)": 0.8259996175765991, "(22, 0)": 0.8592824935913086, "(22, 16)": 0.8259996175765991, "(24, 0)": 0.8259996175765991, "(24, 16)": 0.8259996175765991, "(26, 0)": 0.8592824935913086, "(26, 16)": 0.8592824935913086, "(28, 0)": 0.8592824935913086, "(28, 16)": 0.8259996175765991, "(30, 0)": 0.8592824935913086, "(30, 16)": 0.8592824935913086}, "r_span": [425, 505], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0004991888999938965}}, {"prompt_attention_score": {"(0, 0)": 0.783611536026001, "(0, 16)": 0.7268584966659546, "(2, 0)": 0.7268584966659546, "(2, 16)": 0.7268584966659546, "(4, 0)": 0.7268584966659546, "(4, 16)": 0.7268584966659546, "(6, 0)": 0.7268584966659546, "(6, 16)": 0.9127402305603027, "(8, 0)": 0.7268584966659546, "(8, 16)": 0.7268584966659546, "(10, 0)": 0.9127402305603027, "(10, 16)": 0.9127402305603027, "(12, 0)": 0.9127402305603027, "(12, 16)": 0.9127402305603027, "(14, 0)": 0.9127402305603027, "(14, 16)": 0.9127402305603027, "(16, 0)": 0.9127402305603027, "(16, 16)": 0.7268584966659546, "(18, 0)": 0.7268584966659546, "(18, 16)": 0.9127402305603027, "(20, 0)": 0.9127402305603027, "(20, 16)": 0.9127402305603027, "(22, 0)": 0.8072746992111206, "(22, 16)": 0.9127402305603027, "(24, 0)": 0.9127402305603027, "(24, 16)": 0.9127402305603027, "(26, 0)": 0.8072746992111206, "(26, 16)": 0.9127402305603027, "(28, 0)": 0.783611536026001, "(28, 16)": 0.8072746992111206, "(30, 0)": 0.8072746992111206, "(30, 16)": 0.8072746992111206}, "r_span": [507, 573], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004334449768066406}}, {"prompt_attention_score": {"(0, 0)": 0.8488026261329651, "(0, 16)": 0.6624385714530945, "(2, 0)": 0.6624385714530945, "(2, 16)": 0.6624385714530945, "(4, 0)": 0.6624385714530945, "(4, 16)": 0.6624385714530945, "(6, 0)": 0.8488026261329651, "(6, 16)": 0.8488026261329651, "(8, 0)": 0.8488026261329651, "(8, 16)": 0.6624385714530945, "(10, 0)": 0.7503551244735718, "(10, 16)": 0.7503551244735718, "(12, 0)": 0.6624385714530945, "(12, 16)": 0.8488026261329651, "(14, 0)": 0.6624385714530945, "(14, 16)": 0.8488026261329651, "(16, 0)": 0.8488026261329651, "(16, 16)": 0.6624385714530945, "(18, 0)": 0.6624385714530945, "(18, 16)": 0.8488026261329651, "(20, 0)": 0.8488026261329651, "(20, 16)": 0.6624385714530945, "(22, 0)": 0.7128630876541138, "(22, 16)": 0.8488026261329651, "(24, 0)": 0.7128630876541138, "(24, 16)": 0.8488026261329651, "(26, 0)": 0.7128630876541138, "(26, 16)": 0.8488026261329651, "(28, 0)": 0.7128630876541138, "(28, 16)": 0.7128630876541138, "(30, 0)": 0.7128630876541138, "(30, 16)": 0.7128630876541138}, "r_span": [575, 621], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001074373722076416}}, {"prompt_attention_score": {"(0, 0)": 0.6457618474960327, "(0, 16)": 0.6457618474960327, "(2, 0)": 0.8461644053459167, "(2, 16)": 0.6457618474960327, "(4, 0)": 0.8461644053459167, "(4, 16)": 0.8461644053459167, "(6, 0)": 0.6457618474960327, "(6, 16)": 0.8461644053459167, "(8, 0)": 0.8461644053459167, "(8, 16)": 0.6457618474960327, "(10, 0)": 0.8461644053459167, "(10, 16)": 0.8461644053459167, "(12, 0)": 0.8461644053459167, "(12, 16)": 0.8461644053459167, "(14, 0)": 0.6947103142738342, "(14, 16)": 0.8461644053459167, "(16, 0)": 0.8461644053459167, "(16, 16)": 0.6947103142738342, "(18, 0)": 0.6457618474960327, "(18, 16)": 0.8461644053459167, "(20, 0)": 0.8461644053459167, "(20, 16)": 0.6947103142738342, "(22, 0)": 0.7093839049339294, "(22, 16)": 0.8461644053459167, "(24, 0)": 0.6457618474960327, "(24, 16)": 0.8461644053459167, "(26, 0)": 0.7093839049339294, "(26, 16)": 0.6947103142738342, "(28, 0)": 0.6457618474960327, "(28, 16)": 0.7093839049339294, "(30, 0)": 0.7093839049339294, "(30, 16)": 0.7093839049339294}, "r_span": [623, 694], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005651712417602539}}, {"prompt_attention_score": {"(0, 0)": 0.7560259103775024, "(0, 16)": 0.7560259103775024, "(2, 0)": 0.6946633458137512, "(2, 16)": 0.6946633458137512, "(4, 0)": 0.6946633458137512, "(4, 16)": 0.6946633458137512, "(6, 0)": 0.7860307693481445, "(6, 16)": 0.7860307693481445, "(8, 0)": 0.6946633458137512, "(8, 16)": 0.6946633458137512, "(10, 0)": 0.6946633458137512, "(10, 16)": 0.6946633458137512, "(12, 0)": 0.6946633458137512, "(12, 16)": 0.6946633458137512, "(14, 0)": 0.6946633458137512, "(14, 16)": 0.6946633458137512, "(16, 0)": 0.6946633458137512, "(16, 16)": 0.8175833225250244, "(18, 0)": 0.6946633458137512, "(18, 16)": 0.7860307693481445, "(20, 0)": 0.7860307693481445, "(20, 16)": 0.6946633458137512, "(22, 0)": 0.8175833225250244, "(22, 16)": 0.6946633458137512, "(24, 0)": 0.7860307693481445, "(24, 16)": 0.7860307693481445, "(26, 0)": 0.8175833225250244, "(26, 16)": 0.8175833225250244, "(28, 0)": 0.8175833225250244, "(28, 16)": 0.8175833225250244, "(30, 0)": 0.8175833225250244, "(30, 16)": 0.8175833225250244}, "r_span": [696, 752], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009110569953918457}}]}, {"id": "15969", "source_id": "15583", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the recommended time to bake bratwurst in the oven is approximately 30 minutes at 350¬∞F (175¬∞C) with the top removed. According to passage 1, this should allow most of the beer to evaporate during the cooking process. Passage 2 suggests parboiling the brats for 10 minutes before browning them in the broiler and serving them the next day in beer and onions. Finally, passage 3 provides instructions for baking bratwurst in a toaster oven, including checking the internal temperature with a meat thermometer until it reaches 160¬∞F. However, the passage does not provide specific cooking time recommendations for this method. Therefore, I am able to answer the question based on the given passages.", "response_spans": [[0, 503], [491, 729]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8234395980834961, "(0, 16)": 0.8234395980834961, "(2, 0)": 0.8234395980834961, "(2, 16)": 0.8234395980834961, "(4, 0)": 0.8234395980834961, "(4, 16)": 0.8234395980834961, "(6, 0)": 0.8234395980834961, "(6, 16)": 0.8317811489105225, "(8, 0)": 0.760229766368866, "(8, 16)": 0.760229766368866, "(10, 0)": 0.41157984733581543, "(10, 16)": 0.8234395980834961, "(12, 0)": 0.760229766368866, "(12, 16)": 0.8317811489105225, "(14, 0)": 0.760229766368866, "(14, 16)": 0.41157984733581543, "(16, 0)": 0.760229766368866, "(16, 16)": 0.760229766368866, "(18, 0)": 0.41157984733581543, "(18, 16)": 0.760229766368866, "(20, 0)": 0.8317811489105225, "(20, 16)": 0.760229766368866, "(22, 0)": 0.760229766368866, "(22, 16)": 0.760229766368866, "(24, 0)": 0.760229766368866, "(24, 16)": 0.8317811489105225, "(26, 0)": 0.760229766368866, "(26, 16)": 0.8234395980834961, "(28, 0)": 0.760229766368866, "(28, 16)": 0.760229766368866, "(30, 0)": 0.760229766368866, "(30, 16)": 0.760229766368866}, "r_span": [566, 699], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0015263557434082031}}, {"prompt_attention_score": {"(0, 0)": 0.563957691192627, "(0, 16)": 0.563957691192627, "(2, 0)": 0.563957691192627, "(2, 16)": 0.5233234167098999, "(4, 0)": 0.563957691192627, "(4, 16)": 0.563957691192627, "(6, 0)": 0.563957691192627, "(6, 16)": 0.772814154624939, "(8, 0)": 0.563957691192627, "(8, 16)": 0.563957691192627, "(10, 0)": 0.5233234167098999, "(10, 16)": 0.5233234167098999, "(12, 0)": 0.5233234167098999, "(12, 16)": 0.772814154624939, "(14, 0)": 0.6028469800949097, "(14, 16)": 0.5233234167098999, "(16, 0)": 0.5233234167098999, "(16, 16)": 0.5233234167098999, "(18, 0)": 0.5233234167098999, "(18, 16)": 0.5233234167098999, "(20, 0)": 0.5233234167098999, "(20, 16)": 0.6028469800949097, "(22, 0)": 0.6028469800949097, "(22, 16)": 0.5233234167098999, "(24, 0)": 0.6028469800949097, "(24, 16)": 0.5233234167098999, "(26, 0)": 0.6265089511871338, "(26, 16)": 0.772814154624939, "(28, 0)": 0.6028469800949097, "(28, 16)": 0.772814154624939, "(30, 0)": 0.6028469800949097, "(30, 16)": 0.6028469800949097}, "r_span": [698, 748], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0009936094284057617}}]}, {"id": "16059", "source_id": "12167", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to perform skill moves on FIFA 16 for Xbox One:\n\n1. Ball Juggle (while standing): Press and hold the LT button on the Xbox controller, followed by a quick tap of the RB button.\n\nThat's it! This combination will allow you to perform the ball juggling skill move while standing on the field in FIFA 16 on Xbox One.", "response_spans": [[0, 356]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7389310598373413, "(0, 16)": 0.7389310598373413, "(2, 0)": 0.7389310598373413, "(2, 16)": 0.7389310598373413, "(4, 0)": 0.7389310598373413, "(4, 16)": 0.7389310598373413, "(6, 0)": 0.7389310598373413, "(6, 16)": 0.8988707065582275, "(8, 0)": 0.7389310598373413, "(8, 16)": 0.7389310598373413, "(10, 0)": 0.7389310598373413, "(10, 16)": 0.7389310598373413, "(12, 0)": 0.7389310598373413, "(12, 16)": 0.8988707065582275, "(14, 0)": 0.7389310598373413, "(14, 16)": 0.7389310598373413, "(16, 0)": 0.8988707065582275, "(16, 16)": 0.7389310598373413, "(18, 0)": 0.7389310598373413, "(18, 16)": 0.8988707065582275, "(20, 0)": 0.8988707065582275, "(20, 16)": 0.7389310598373413, "(22, 0)": 0.7389310598373413, "(22, 16)": 0.8988707065582275, "(24, 0)": 0.7389310598373413, "(24, 16)": 0.8988707065582275, "(26, 0)": 0.7389310598373413, "(26, 16)": 0.8988707065582275, "(28, 0)": 0.7389310598373413, "(28, 16)": 0.7389310598373413, "(30, 0)": 0.7389310598373413, "(30, 16)": 0.7389310598373413}, "r_span": [368, 464], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.000957190990447998}}]}, {"id": "16119", "source_id": "12177", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to quickly get rid of mice:\n\n1. Take immediate action to get rid of mice as soon as possible, as they can quickly take up residence in your home and start nesting (Passage 1).\n2. Seal off all entry points into your home, including holes around pipes and vents, using steel wool to prevent mice from getting back in (Passage 2).\n3. Get rid of any sources of food for mice and rats, as they will quickly take advantage of any food left behind by humans (Passage 3).\n\nUnable to answer based on given passages. The passages do not provide specific instructions on how to quickly get rid of mice once they have entered a home.", "response_spans": [[0, 78], [80, 514], [516, 672]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7559317350387573, "(0, 16)": 0.7559317350387573, "(2, 0)": 0.7559317350387573, "(2, 16)": 0.7559317350387573, "(4, 0)": 0.7559317350387573, "(4, 16)": 0.7559317350387573, "(6, 0)": 0.7559317350387573, "(6, 16)": 0.801646888256073, "(8, 0)": 0.7559317350387573, "(8, 16)": 0.7559317350387573, "(10, 0)": 0.7559317350387573, "(10, 16)": 0.7559317350387573, "(12, 0)": 0.7559317350387573, "(12, 16)": 0.801646888256073, "(14, 0)": 0.7559317350387573, "(14, 16)": 0.7559317350387573, "(16, 0)": 0.801646888256073, "(16, 16)": 0.7559317350387573, "(18, 0)": 0.7559317350387573, "(18, 16)": 0.801646888256073, "(20, 0)": 0.801646888256073, "(20, 16)": 0.7559317350387573, "(22, 0)": 0.7559317350387573, "(22, 16)": 0.801646888256073, "(24, 0)": 0.7559317350387573, "(24, 16)": 0.801646888256073, "(26, 0)": 0.7559317350387573, "(26, 16)": 0.7559317350387573, "(28, 0)": 0.7559317350387573, "(28, 16)": 0.7559317350387573, "(30, 0)": 0.7559317350387573, "(30, 16)": 0.7559317350387573}, "r_span": [333, 353], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00046181678771972656}}, {"prompt_attention_score": {"(0, 0)": 0.8530349731445312, "(0, 16)": 0.8530349731445312, "(2, 0)": 0.8530349731445312, "(2, 16)": 0.8530349731445312, "(4, 0)": 0.8530349731445312, "(4, 16)": 0.8530349731445312, "(6, 0)": 0.8530349731445312, "(6, 16)": 0.8948415517807007, "(8, 0)": 0.8530349731445312, "(8, 16)": 0.8530349731445312, "(10, 0)": 0.8530349731445312, "(10, 16)": 0.8530349731445312, "(12, 0)": 0.8530349731445312, "(12, 16)": 0.8530349731445312, "(14, 0)": 0.8530349731445312, "(14, 16)": 0.8530349731445312, "(16, 0)": 0.8530349731445312, "(16, 16)": 0.8530349731445312, "(18, 0)": 0.8530349731445312, "(18, 16)": 0.8530349731445312, "(20, 0)": 0.8530349731445312, "(20, 16)": 0.8530349731445312, "(22, 0)": 0.8530349731445312, "(22, 16)": 0.8530349731445312, "(24, 0)": 0.8530349731445312, "(24, 16)": 0.8530349731445312, "(26, 0)": 0.8530349731445312, "(26, 16)": 0.8530349731445312, "(28, 0)": 0.8530349731445312, "(28, 16)": 0.8530349731445312, "(30, 0)": 0.8530349731445312, "(30, 16)": 0.8530349731445312}, "r_span": [355, 467], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0002792477607727051}}, {"prompt_attention_score": {"(0, 0)": 0.8163408637046814, "(0, 16)": 0.8163408637046814, "(2, 0)": 0.8163408637046814, "(2, 16)": 0.8163408637046814, "(4, 0)": 0.8163408637046814, "(4, 16)": 0.8163408637046814, "(6, 0)": 0.8163408637046814, "(6, 16)": 0.8211754560470581, "(8, 0)": 0.8163408637046814, "(8, 16)": 0.8163408637046814, "(10, 0)": 0.8163408637046814, "(10, 16)": 0.8163408637046814, "(12, 0)": 0.8163408637046814, "(12, 16)": 0.8163408637046814, "(14, 0)": 0.8163408637046814, "(14, 16)": 0.8163408637046814, "(16, 0)": 0.8163408637046814, "(16, 16)": 0.8163408637046814, "(18, 0)": 0.8163408637046814, "(18, 16)": 0.8163408637046814, "(20, 0)": 0.8211754560470581, "(20, 16)": 0.8163408637046814, "(22, 0)": 0.8163408637046814, "(22, 16)": 0.8211754560470581, "(24, 0)": 0.8163408637046814, "(24, 16)": 0.8163408637046814, "(26, 0)": 0.8163408637046814, "(26, 16)": 0.8163408637046814, "(28, 0)": 0.8163408637046814, "(28, 16)": 0.8163408637046814, "(30, 0)": 0.8163408637046814, "(30, 16)": 0.8163408637046814}, "r_span": [469, 503], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007067322731018066}}]}, {"id": "16149", "source_id": "12182", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, if you got your Sperry shoes wet, here is what you can do:\n\nIf you have the regular, dark brown Sperry shoes, you don't need to worry about getting them wet as they won't be affected. However, if you have the light tan ones, there is a chance of water staining them, but it's unlikely. In either case, you can use a suede bar and leather brush to clean the shoes and remove any stains. These tools are available for purchase at a cost of $5-$10.\n\nUnable to answer based on given passages.", "response_spans": [[0, 477], [479, 520]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7518229484558105, "(0, 16)": 0.7518229484558105, "(2, 0)": 0.7518229484558105, "(2, 16)": 0.7518229484558105, "(4, 0)": 0.7518229484558105, "(4, 16)": 0.7518229484558105, "(6, 0)": 0.7518229484558105, "(6, 16)": 0.8065118789672852, "(8, 0)": 0.7518229484558105, "(8, 16)": 0.7518229484558105, "(10, 0)": 0.7518229484558105, "(10, 16)": 0.7518229484558105, "(12, 0)": 0.7518229484558105, "(12, 16)": 0.7185633182525635, "(14, 0)": 0.7185633182525635, "(14, 16)": 0.7518229484558105, "(16, 0)": 0.8065118789672852, "(16, 16)": 0.7518229484558105, "(18, 0)": 0.7518229484558105, "(18, 16)": 0.7518229484558105, "(20, 0)": 0.7185633182525635, "(20, 16)": 0.7185633182525635, "(22, 0)": 0.7185633182525635, "(22, 16)": 0.7518229484558105, "(24, 0)": 0.7185633182525635, "(24, 16)": 0.7185633182525635, "(26, 0)": 0.7185633182525635, "(26, 16)": 0.8065118789672852, "(28, 0)": 0.7185633182525635, "(28, 16)": 0.7185633182525635, "(30, 0)": 0.7185633182525635, "(30, 16)": 0.7185633182525635}, "r_span": [348, 478], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -9.66787338256836e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6122183203697205, "(0, 16)": 0.6122183203697205, "(2, 0)": 0.6122183203697205, "(2, 16)": 0.6122183203697205, "(4, 0)": 0.6122183203697205, "(4, 16)": 0.6122183203697205, "(6, 0)": 0.6122183203697205, "(6, 16)": 0.6122183203697205, "(8, 0)": 0.45234301686286926, "(8, 16)": 0.6122183203697205, "(10, 0)": 0.6122183203697205, "(10, 16)": 0.6122183203697205, "(12, 0)": 0.6122183203697205, "(12, 16)": 0.6122183203697205, "(14, 0)": 0.5318171381950378, "(14, 16)": 0.6122183203697205, "(16, 0)": 0.6122183203697205, "(16, 16)": 0.6122183203697205, "(18, 0)": 0.6122183203697205, "(18, 16)": 0.6122183203697205, "(20, 0)": 0.6122183203697205, "(20, 16)": 0.5318171381950378, "(22, 0)": 0.5318171381950378, "(22, 16)": 0.6122183203697205, "(24, 0)": 0.5318171381950378, "(24, 16)": 0.6122183203697205, "(26, 0)": 0.6122183203697205, "(26, 16)": 0.5318171381950378, "(28, 0)": 0.5318171381950378, "(28, 16)": 0.5318171381950378, "(30, 0)": 0.5318171381950378, "(30, 16)": 0.5318171381950378}, "r_span": [480, 490], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -5.543231964111328e-05}}]}, {"id": "16155", "source_id": "12183", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 320, "end": 562, "text": "This suggests that the allocation of delegates is not solely determined by a simple majority vote, but rather takes into account the distribution of support among the various candidates. Therefore, the answer to the question is: Proportional.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"This suggests that the allocation of delegates is not solely determined by a simple majority vote, but rather takes into account the distribution of support among the various candidates. Therefore, the answer to the question is: Proportional.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, Republicans use a proportional method to allocate delegates in their presidential nominating procedure. According to passage 1, some states award delegates to candidates on a winner-take-all basis, while others award delegates in proportion to each candidate's share of the primary vote. This suggests that the allocation of delegates is not solely determined by a simple majority vote, but rather takes into account the distribution of support among the various candidates. Therefore, the answer to the question is: Proportional.", "response_spans": [[0, 506], [487, 562]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7153940200805664, "(0, 16)": 0.7153940200805664, "(2, 0)": 0.7153940200805664, "(2, 16)": 0.7153940200805664, "(4, 0)": 0.7153940200805664, "(4, 16)": 0.7153940200805664, "(6, 0)": 0.7153940200805664, "(6, 16)": 0.9219256043434143, "(8, 0)": 0.9219256043434143, "(8, 16)": 0.7153940200805664, "(10, 0)": 0.7153940200805664, "(10, 16)": 0.7153940200805664, "(12, 0)": 0.9219256043434143, "(12, 16)": 0.9219256043434143, "(14, 0)": 0.9219256043434143, "(14, 16)": 0.7153940200805664, "(16, 0)": 0.9219256043434143, "(16, 16)": 0.7153940200805664, "(18, 0)": 0.7153940200805664, "(18, 16)": 0.9219256043434143, "(20, 0)": 0.9219256043434143, "(20, 16)": 0.9219256043434143, "(22, 0)": 0.9219256043434143, "(22, 16)": 0.9219256043434143, "(24, 0)": 0.9219256043434143, "(24, 16)": 0.9219256043434143, "(26, 0)": 0.9219256043434143, "(26, 16)": 0.9219256043434143, "(28, 0)": 0.9219256043434143, "(28, 16)": 0.9219256043434143, "(30, 0)": 0.9219256043434143, "(30, 16)": 0.9219256043434143}, "r_span": [332, 431], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009136795997619629}}, {"prompt_attention_score": {"(0, 0)": 0.6481517553329468, "(0, 16)": 0.6481517553329468, "(2, 0)": 0.6481517553329468, "(2, 16)": 0.6481517553329468, "(4, 0)": 0.6481517553329468, "(4, 16)": 0.6481517553329468, "(6, 0)": 0.6481517553329468, "(6, 16)": 0.6304301023483276, "(8, 0)": 0.6481517553329468, "(8, 16)": 0.6304301023483276, "(10, 0)": 0.6481517553329468, "(10, 16)": 0.6481517553329468, "(12, 0)": 0.6481517553329468, "(12, 16)": 0.6481517553329468, "(14, 0)": 0.6481517553329468, "(14, 16)": 0.6481517553329468, "(16, 0)": 0.6304301023483276, "(16, 16)": 0.6481517553329468, "(18, 0)": 0.6304301023483276, "(18, 16)": 0.6304301023483276, "(20, 0)": 0.6304301023483276, "(20, 16)": 0.6304301023483276, "(22, 0)": 0.6304301023483276, "(22, 16)": 0.6481517553329468, "(24, 0)": 0.6304301023483276, "(24, 16)": 0.6304301023483276, "(26, 0)": 0.6304301023483276, "(26, 16)": 0.6304301023483276, "(28, 0)": 0.6304301023483276, "(28, 16)": 0.6304301023483276, "(30, 0)": 0.6304301023483276, "(30, 16)": 0.6304301023483276}, "r_span": [429, 444], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0011382102966308594}}]}, {"id": "16359", "source_id": "12218", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 282, "end": 482, "text": "Schedule F (Farmer's Taxable Income) is used to report income from farming, including patronage dividends and other distributions from cooperatives. Therefore, 1099-PATR goes on Line 21 of Schedule F.", "meta": "HIGH INTRO OF NEW INFO\nThe original source did not mention about Farmer's Taxable Income and did not specify that 1099-PATR goes on Line 21 of the 1040 tax return or Line 21 of Schedule F.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, 1099-PATR goes on Line 21 of the 1040 tax return as follows:\n\nPassage 1 states, \"Per the IRS instructions, patronage dividends and other distributions in boxes 1, 2, 3, and 5 from a cooperative are reported on Schedule C, Schedule F, or Form 4835.\"\n\nSchedule F (Farmer's Taxable Income) is used to report income from farming, including patronage dividends and other distributions from cooperatives. Therefore, 1099-PATR goes on Line 21 of Schedule F.\n\nPassage 2 also mentions that 1099-PATR is used to report taxable distributions received from cooperatives, and Line 21 of Schedule F is specifically designated for reporting farm income and losses.\n\nUnable to answer based on given passages.", "response_spans": [[0, 482], [484, 724]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6087385416030884, "(0, 16)": 0.6087385416030884, "(2, 0)": 0.6087385416030884, "(2, 16)": 0.6087385416030884, "(4, 0)": 0.6087385416030884, "(4, 16)": 0.8867310285568237, "(6, 0)": 0.6087385416030884, "(6, 16)": 0.8867310285568237, "(8, 0)": 0.8867310285568237, "(8, 16)": 0.6087385416030884, "(10, 0)": 0.6087385416030884, "(10, 16)": 0.6087385416030884, "(12, 0)": 0.6087385416030884, "(12, 16)": 0.8867310285568237, "(14, 0)": 0.6087385416030884, "(14, 16)": 0.8867310285568237, "(16, 0)": 0.8867310285568237, "(16, 16)": 0.8867310285568237, "(18, 0)": 0.6087385416030884, "(18, 16)": 0.8867310285568237, "(20, 0)": 0.8867310285568237, "(20, 16)": 0.8867310285568237, "(22, 0)": 0.8867310285568237, "(22, 16)": 0.8867310285568237, "(24, 0)": 0.8867310285568237, "(24, 16)": 0.8867310285568237, "(26, 0)": 0.8867310285568237, "(26, 16)": 0.8867310285568237, "(28, 0)": 0.6087385416030884, "(28, 16)": 0.8867310285568237, "(30, 0)": 0.8867310285568237, "(30, 16)": 0.6087385416030884}, "r_span": [342, 497], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002634882926940918}}, {"prompt_attention_score": {"(0, 0)": 0.8185721635818481, "(0, 16)": 0.6112202405929565, "(2, 0)": 0.6112202405929565, "(2, 16)": 0.6112202405929565, "(4, 0)": 0.6112202405929565, "(4, 16)": 0.6112202405929565, "(6, 0)": 0.8185721635818481, "(6, 16)": 0.8185721635818481, "(8, 0)": 0.8185721635818481, "(8, 16)": 0.6112202405929565, "(10, 0)": 0.6112202405929565, "(10, 16)": 0.6112202405929565, "(12, 0)": 0.6112202405929565, "(12, 16)": 0.6112202405929565, "(14, 0)": 0.8185721635818481, "(14, 16)": 0.6112202405929565, "(16, 0)": 0.6112202405929565, "(16, 16)": 0.8185721635818481, "(18, 0)": 0.6112202405929565, "(18, 16)": 0.8185721635818481, "(20, 0)": 0.8185721635818481, "(20, 16)": 0.8185721635818481, "(22, 0)": 0.8185721635818481, "(22, 16)": 0.6112202405929565, "(24, 0)": 0.8185721635818481, "(24, 16)": 0.8185721635818481, "(26, 0)": 0.8185721635818481, "(26, 16)": 0.8185721635818481, "(28, 0)": 0.6112202405929565, "(28, 16)": 0.8185721635818481, "(30, 0)": 0.8185721635818481, "(30, 16)": 0.8185721635818481}, "r_span": [499, 559], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002925992012023926}}]}, {"id": "16419", "source_id": "12228", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [{"start": 0, "end": 1062, "text": "Based on the provided passages, here is how you can draw a truncated cone in GeoGebra:\n\n1. Start by drawing a cone with a base diameter of 2 inches and a height of 7 inches as shown in Passage 3.\n2. Use the command \"Cone\" in GeoGebra to create the cone.\n3. To create the truncated cone, cut off the top quarter of the cone using the \"Slice\" command. This will give you a frustum of a cone.\n4. Adjust the size of the slice as needed to match the dimensions given in Passage 1. For example, if the top diameter of the cone is 3.5 inches, then set the \"Top Slice Radius\" to 3.5 / 2 = 1.75 inches.\n5. The remaining steps are the same as for creating a standard cone. Draw the circle at the base of the truncated cone using the \"Circle\" command, and then use the \"ConicalSurface\" command to create the surface of the truncated cone.\n\nHere is an example of what the truncated cone might look like in GeoGebra:\n\n(Note: This is just one possible way to create a truncated cone in GeoGebra, and there may be other methods depending on your familiarity with the software.)", "meta": "HIGH INTRO OF NEW INFO\nPassages was not able to provide answer on how to draw a truncated cone in geogebra", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how you can draw a truncated cone in GeoGebra:\n\n1. Start by drawing a cone with a base diameter of 2 inches and a height of 7 inches as shown in Passage 3.\n2. Use the command \"Cone\" in GeoGebra to create the cone.\n3. To create the truncated cone, cut off the top quarter of the cone using the \"Slice\" command. This will give you a frustum of a cone.\n4. Adjust the size of the slice as needed to match the dimensions given in Passage 1. For example, if the top diameter of the cone is 3.5 inches, then set the \"Top Slice Radius\" to 3.5 / 2 = 1.75 inches.\n5. The remaining steps are the same as for creating a standard cone. Draw the circle at the base of the truncated cone using the \"Circle\" command, and then use the \"ConicalSurface\" command to create the surface of the truncated cone.\n\nHere is an example of what the truncated cone might look like in GeoGebra:\n\n(Note: This is just one possible way to create a truncated cone in GeoGebra, and there may be other methods depending on your familiarity with the software.)\n\nUnable to answer based on given passages.", "response_spans": [[0, 86], [88, 593], [594, 827], [829, 1105]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6392595767974854, "(0, 16)": 0.6392595767974854, "(2, 0)": 0.6392595767974854, "(2, 16)": 0.6392595767974854, "(4, 0)": 0.6392595767974854, "(4, 16)": 0.6392595767974854, "(6, 0)": 0.6392595767974854, "(6, 16)": 0.863766610622406, "(8, 0)": 0.863766610622406, "(8, 16)": 0.6392595767974854, "(10, 0)": 0.6392595767974854, "(10, 16)": 0.6392595767974854, "(12, 0)": 0.6392595767974854, "(12, 16)": 0.863766610622406, "(14, 0)": 0.6392595767974854, "(14, 16)": 0.863766610622406, "(16, 0)": 0.863766610622406, "(16, 16)": 0.6392595767974854, "(18, 0)": 0.6392595767974854, "(18, 16)": 0.863766610622406, "(20, 0)": 0.863766610622406, "(20, 16)": 0.7361934185028076, "(22, 0)": 0.7361934185028076, "(22, 16)": 0.863766610622406, "(24, 0)": 0.7361934185028076, "(24, 16)": 0.863766610622406, "(26, 0)": 0.7361934185028076, "(26, 16)": 0.7361934185028076, "(28, 0)": 0.6392595767974854, "(28, 16)": 0.7361934185028076, "(30, 0)": 0.7361934185028076, "(30, 16)": 0.7361934185028076}, "r_span": [377, 402], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0016432404518127441}}, {"prompt_attention_score": {"(0, 0)": 0.7559041976928711, "(0, 16)": 0.7559041976928711, "(2, 0)": 0.7559041976928711, "(2, 16)": 0.7559041976928711, "(4, 0)": 0.7559041976928711, "(4, 16)": 0.7559041976928711, "(6, 0)": 0.7559041976928711, "(6, 16)": 0.9073748588562012, "(8, 0)": 0.9073748588562012, "(8, 16)": 0.7559041976928711, "(10, 0)": 0.7559041976928711, "(10, 16)": 0.7559041976928711, "(12, 0)": 0.7559041976928711, "(12, 16)": 0.9073748588562012, "(14, 0)": 0.7449954748153687, "(14, 16)": 0.7559041976928711, "(16, 0)": 0.9073748588562012, "(16, 16)": 0.9073748588562012, "(18, 0)": 0.7559041976928711, "(18, 16)": 0.9073748588562012, "(20, 0)": 0.9073748588562012, "(20, 16)": 0.7449954748153687, "(22, 0)": 0.7449954748153687, "(22, 16)": 0.9073748588562012, "(24, 0)": 0.7449954748153687, "(24, 16)": 0.9073748588562012, "(26, 0)": 0.7449954748153687, "(26, 16)": 0.7449954748153687, "(28, 0)": 0.7449954748153687, "(28, 16)": 0.7449954748153687, "(30, 0)": 0.7449954748153687, "(30, 16)": 0.7449954748153687}, "r_span": [404, 559], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.0013066530227661133}}, {"prompt_attention_score": {"(0, 0)": 0.7447812557220459, "(0, 16)": 0.7447812557220459, "(2, 0)": 0.7447812557220459, "(2, 16)": 0.7447812557220459, "(4, 0)": 0.7447812557220459, "(4, 16)": 0.7447812557220459, "(6, 0)": 0.7447812557220459, "(6, 16)": 0.7955021858215332, "(8, 0)": 0.7955021858215332, "(8, 16)": 0.7292043566703796, "(10, 0)": 0.7447812557220459, "(10, 16)": 0.7447812557220459, "(12, 0)": 0.7292043566703796, "(12, 16)": 0.7292043566703796, "(14, 0)": 0.7292043566703796, "(14, 16)": 0.7955021858215332, "(16, 0)": 0.7955021858215332, "(16, 16)": 0.7955021858215332, "(18, 0)": 0.7292043566703796, "(18, 16)": 0.7955021858215332, "(20, 0)": 0.7955021858215332, "(20, 16)": 0.7292043566703796, "(22, 0)": 0.7292043566703796, "(22, 16)": 0.7955021858215332, "(24, 0)": 0.7292043566703796, "(24, 16)": 0.7955021858215332, "(26, 0)": 0.7292043566703796, "(26, 16)": 0.7955021858215332, "(28, 0)": 0.7292043566703796, "(28, 16)": 0.7292043566703796, "(30, 0)": 0.7292043566703796, "(30, 16)": 0.7292043566703796}, "r_span": [560, 615], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": -0.00038927793502807617}}, {"prompt_attention_score": {"(0, 0)": 0.6320720911026001, "(0, 16)": 0.6320720911026001, "(2, 0)": 0.6320720911026001, "(2, 16)": 0.6320720911026001, "(4, 0)": 0.6320720911026001, "(4, 16)": 0.6320720911026001, "(6, 0)": 0.6320720911026001, "(6, 16)": 0.8544356822967529, "(8, 0)": 0.8544356822967529, "(8, 16)": 0.6320720911026001, "(10, 0)": 0.6320720911026001, "(10, 16)": 0.6320720911026001, "(12, 0)": 0.6320720911026001, "(12, 16)": 0.6320720911026001, "(14, 0)": 0.7106349468231201, "(14, 16)": 0.6320720911026001, "(16, 0)": 0.6320720911026001, "(16, 16)": 0.8544356822967529, "(18, 0)": 0.6320720911026001, "(18, 16)": 0.8544356822967529, "(20, 0)": 0.6320720911026001, "(20, 16)": 0.7106349468231201, "(22, 0)": 0.7106349468231201, "(22, 16)": 0.6320720911026001, "(24, 0)": 0.7106349468231201, "(24, 16)": 0.6320720911026001, "(26, 0)": 0.7106349468231201, "(26, 16)": 0.7106349468231201, "(28, 0)": 0.7106349468231201, "(28, 16)": 0.7106349468231201, "(30, 0)": 0.7106349468231201, "(30, 16)": 0.7106349468231201}, "r_span": [617, 688], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0010652542114257812}}]}, {"id": "16455", "source_id": "12234", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the headquarters of Dove Soap can be located in:\n\nPassage 1 states that if you want to speak to a live representative, you can call them at 1-800-761-DOVE (3683) from Monday to Friday between 8:30 AM to 6:00 PM Eastern Time. This suggests that the headquarters of Dove Soap is located in the Eastern Time zone.\n\nPassage 2 provides the same phone number as Passage 1 for contacting a live representative, but also notes that this number is available 24 hours a day / 7 days a week for medical or product safety emergencies. This indicates that the headquarters of Dove Soap is open for business operations 24/7.\n\nPassage 3 does not provide any information about the location of Dove Soap's headquarters.\n\nTherefore, based on the given passages, the headquarters of Dove Soap can be located in the Eastern Time zone and is open for business operations 24/7.", "response_spans": [[0, 342], [344, 734], [736, 887]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.5502679347991943, "(0, 16)": 0.5502679347991943, "(2, 0)": 0.5502679347991943, "(2, 16)": 0.5502679347991943, "(4, 0)": 0.5502679347991943, "(4, 16)": 0.5502679347991943, "(6, 0)": 0.5502679347991943, "(6, 16)": 0.9233134984970093, "(8, 0)": 0.9233134984970093, "(8, 16)": 0.5502679347991943, "(10, 0)": 0.5502679347991943, "(10, 16)": 0.5502679347991943, "(12, 0)": 0.9233134984970093, "(12, 16)": 0.8116027116775513, "(14, 0)": 0.9233134984970093, "(14, 16)": 0.5502679347991943, "(16, 0)": 0.9233134984970093, "(16, 16)": 0.9233134984970093, "(18, 0)": 0.5502679347991943, "(18, 16)": 0.9233134984970093, "(20, 0)": 0.9233134984970093, "(20, 16)": 0.9233134984970093, "(22, 0)": 0.9233134984970093, "(22, 16)": 0.9233134984970093, "(24, 0)": 0.8116027116775513, "(24, 16)": 0.9233134984970093, "(26, 0)": 0.9233134984970093, "(26, 16)": 0.9233134984970093, "(28, 0)": 0.5502679347991943, "(28, 16)": 0.9233134984970093, "(30, 0)": 0.9233134984970093, "(30, 16)": 0.9233134984970093}, "r_span": [421, 522], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00047975778579711914}}, {"prompt_attention_score": {"(0, 0)": 0.6365879774093628, "(0, 16)": 0.6365879774093628, "(2, 0)": 0.6365879774093628, "(2, 16)": 0.6365879774093628, "(4, 0)": 0.6365879774093628, "(4, 16)": 0.6365879774093628, "(6, 0)": 0.6365879774093628, "(6, 16)": 0.8486534953117371, "(8, 0)": 0.6365879774093628, "(8, 16)": 0.6365879774093628, "(10, 0)": 0.6365879774093628, "(10, 16)": 0.6365879774093628, "(12, 0)": 0.6365879774093628, "(12, 16)": 0.8116730451583862, "(14, 0)": 0.8486534953117371, "(14, 16)": 0.6365879774093628, "(16, 0)": 0.8486534953117371, "(16, 16)": 0.6365879774093628, "(18, 0)": 0.8486534953117371, "(18, 16)": 0.8486534953117371, "(20, 0)": 0.8116730451583862, "(20, 16)": 0.8116730451583862, "(22, 0)": 0.8486534953117371, "(22, 16)": 0.8486534953117371, "(24, 0)": 0.8116730451583862, "(24, 16)": 0.8486534953117371, "(26, 0)": 0.8486534953117371, "(26, 16)": 0.8486534953117371, "(28, 0)": 0.6365879774093628, "(28, 16)": 0.8116730451583862, "(30, 0)": 0.8486534953117371, "(30, 16)": 0.8486534953117371}, "r_span": [524, 618], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002428889274597168}}, {"prompt_attention_score": {"(0, 0)": 0.45057111978530884, "(0, 16)": 0.45057111978530884, "(2, 0)": 0.45057111978530884, "(2, 16)": 0.45057111978530884, "(4, 0)": 0.45057111978530884, "(4, 16)": 0.45057111978530884, "(6, 0)": 0.45057111978530884, "(6, 16)": 0.5779225826263428, "(8, 0)": 0.45057111978530884, "(8, 16)": 0.45057111978530884, "(10, 0)": 0.45057111978530884, "(10, 16)": 0.45057111978530884, "(12, 0)": 0.6321300864219666, "(12, 16)": 0.45057111978530884, "(14, 0)": 0.6321300864219666, "(14, 16)": 0.45057111978530884, "(16, 0)": 0.45057111978530884, "(16, 16)": 0.6321300864219666, "(18, 0)": 0.6321300864219666, "(18, 16)": 0.6321300864219666, "(20, 0)": 0.45057111978530884, "(20, 16)": 0.5779225826263428, "(22, 0)": 0.5779225826263428, "(22, 16)": 0.45057111978530884, "(24, 0)": 0.5779225826263428, "(24, 16)": 0.45057111978530884, "(26, 0)": 0.5779225826263428, "(26, 16)": 0.6321300864219666, "(28, 0)": 0.45057111978530884, "(28, 16)": 0.5779225826263428, "(30, 0)": 0.5779225826263428, "(30, 16)": 0.5779225826263428}, "r_span": [620, 657], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005487203598022461}}]}, {"id": "16467", "source_id": "12236", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 583, "end": 623, "text": "which may be more stressful on the body.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this information. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, it appears that both cycling and aerobic exercise have their own benefits and can be beneficial for different individuals. Here's a summary of the key points:\n\n* Passage 1 suggests that aerobic exercise, such as running or cycling, is generally good for overall health and fitness.\n* Passage 2 specifically highlights cycling as an alternative to walking for those with joint problems or other mobility issues.\n* Passage 3 notes that indoor cycling provides a low-impact workout compared to other indoor exercises like treadmills and rowing machines, which may be more stressful on the body.\n\nTherefore, based on these passages, it's difficult to say definitively which is better between cycling and aerobic exercise. Both forms of exercise have their own advantages and can be suitable for different individuals depending on their specific needs and goals. It's important to consult with a healthcare professional before starting any new exercise program.", "response_spans": [[0, 190], [192, 623], [625, 988]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6583503484725952, "(0, 16)": 0.6583503484725952, "(2, 0)": 0.6583503484725952, "(2, 16)": 0.6583503484725952, "(4, 0)": 0.6583503484725952, "(4, 16)": 0.6583503484725952, "(6, 0)": 0.6583503484725952, "(6, 16)": 0.8170790076255798, "(8, 0)": 0.6583503484725952, "(8, 16)": 0.6583503484725952, "(10, 0)": 0.6583503484725952, "(10, 16)": 0.6583503484725952, "(12, 0)": 0.6583503484725952, "(12, 16)": 0.8170790076255798, "(14, 0)": 0.6583503484725952, "(14, 16)": 0.6583503484725952, "(16, 0)": 0.8170790076255798, "(16, 16)": 0.6583503484725952, "(18, 0)": 0.6583503484725952, "(18, 16)": 0.8170790076255798, "(20, 0)": 0.8170790076255798, "(20, 16)": 0.8170790076255798, "(22, 0)": 0.8170790076255798, "(22, 16)": 0.8170790076255798, "(24, 0)": 0.6583503484725952, "(24, 16)": 0.8170790076255798, "(26, 0)": 0.8170790076255798, "(26, 16)": 0.8170790076255798, "(28, 0)": 0.6583503484725952, "(28, 16)": 0.8170790076255798, "(30, 0)": 0.8170790076255798, "(30, 16)": 0.6583503484725952}, "r_span": [288, 330], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006883144378662109}}, {"prompt_attention_score": {"(0, 0)": 0.8220270276069641, "(0, 16)": 0.8220270276069641, "(2, 0)": 0.8220270276069641, "(2, 16)": 0.8220270276069641, "(4, 0)": 0.8220270276069641, "(4, 16)": 0.8220270276069641, "(6, 0)": 0.8220270276069641, "(6, 16)": 0.8326807022094727, "(8, 0)": 0.8220270276069641, "(8, 16)": 0.8220270276069641, "(10, 0)": 0.8220270276069641, "(10, 16)": 0.8220270276069641, "(12, 0)": 0.8220270276069641, "(12, 16)": 0.8220270276069641, "(14, 0)": 0.8326807022094727, "(14, 16)": 0.8220270276069641, "(16, 0)": 0.8326807022094727, "(16, 16)": 0.8326807022094727, "(18, 0)": 0.8326807022094727, "(18, 16)": 0.8326807022094727, "(20, 0)": 0.8220270276069641, "(20, 16)": 0.8326807022094727, "(22, 0)": 0.8220270276069641, "(22, 16)": 0.8220270276069641, "(24, 0)": 0.8326807022094727, "(24, 16)": 0.8326807022094727, "(26, 0)": 0.8326807022094727, "(26, 16)": 0.8220270276069641, "(28, 0)": 0.8326807022094727, "(28, 16)": 0.8326807022094727, "(30, 0)": 0.8326807022094727, "(30, 16)": 0.8326807022094727}, "r_span": [332, 436], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.00018042325973510742}}, {"prompt_attention_score": {"(0, 0)": 0.6894022226333618, "(0, 16)": 0.6894022226333618, "(2, 0)": 0.6894022226333618, "(2, 16)": 0.6894022226333618, "(4, 0)": 0.6894022226333618, "(4, 16)": 0.6894022226333618, "(6, 0)": 0.6894022226333618, "(6, 16)": 0.8801372051239014, "(8, 0)": 0.6894022226333618, "(8, 16)": 0.6894022226333618, "(10, 0)": 0.6894022226333618, "(10, 16)": 0.6894022226333618, "(12, 0)": 0.6894022226333618, "(12, 16)": 0.8801372051239014, "(14, 0)": 0.8801372051239014, "(14, 16)": 0.6894022226333618, "(16, 0)": 0.8801372051239014, "(16, 16)": 0.8801372051239014, "(18, 0)": 0.8801372051239014, "(18, 16)": 0.8801372051239014, "(20, 0)": 0.8801372051239014, "(20, 16)": 0.8801372051239014, "(22, 0)": 0.8801372051239014, "(22, 16)": 0.6894022226333618, "(24, 0)": 0.8801372051239014, "(24, 16)": 0.8801372051239014, "(26, 0)": 0.8801372051239014, "(26, 16)": 0.6894022226333618, "(28, 0)": 0.8801372051239014, "(28, 16)": 0.8801372051239014, "(30, 0)": 0.8801372051239014, "(30, 16)": 0.8801372051239014}, "r_span": [438, 508], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 4.929304122924805e-05}}]}, {"id": "16509", "source_id": "12243", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [{"start": 649, "end": 1201, "text": "3. Insufficient intensity or duration of workouts: To build muscle and burn fat, your workouts need to be intense enough to challenge your muscles and raise your heart rate. If your workouts are too easy or too short, you may not be stimulating enough growth and fat loss to achieve a toned body.\n4. Poor nutrition: Adequate nutrition is crucial for building muscle and losing fat. If you're not consuming enough protein, calories, and other essential nutrients, your muscle growth and fat loss may be limited, making it harder to achieve a toned body.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this information. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 462, "end": 507, "text": "and make them appear flabby instead of toned.", "meta": "LOW INTRO OF NEW INFO\nNo mention of this but fits within the context of the topic. ", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here is why you may not be getting a toned body despite exercising every day:\n\n1. Lack of muscle mass: According to passage 1, having muscle is essential for having a toned body. If you don't have enough muscle mass, then you won't be able to see definition or tone, even if you have a low body fat percentage.\n2. High body fat percentage: Passage 2 states that having too much fat covering your muscles can hide their definition and make them appear flabby instead of toned. Therefore, if you have a high body fat percentage, it could be difficult to achieve a toned appearance, regardless of how much you exercise.\n3. Insufficient intensity or duration of workouts: To build muscle and burn fat, your workouts need to be intense enough to challenge your muscles and raise your heart rate. If your workouts are too easy or too short, you may not be stimulating enough growth and fat loss to achieve a toned body.\n4. Poor nutrition: Adequate nutrition is crucial for building muscle and losing fat. If you're not consuming enough protein, calories, and other essential nutrients, your muscle growth and fat loss may be limited, making it harder to achieve a toned body.\n\nUnable to answer based on given passages.", "response_spans": [[0, 109], [111, 342], [343, 648], [649, 945], [946, 1201], [1203, 1244]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7110737562179565, "(0, 16)": 0.7110737562179565, "(2, 0)": 0.7110737562179565, "(2, 16)": 0.7110737562179565, "(4, 0)": 0.7110737562179565, "(4, 16)": 0.7649877071380615, "(6, 0)": 0.7110737562179565, "(6, 16)": 0.7649877071380615, "(8, 0)": 0.7649877071380615, "(8, 16)": 0.5680451989173889, "(10, 0)": 0.5680451989173889, "(10, 16)": 0.7649877071380615, "(12, 0)": 0.7649877071380615, "(12, 16)": 0.7649877071380615, "(14, 0)": 0.7649877071380615, "(14, 16)": 0.7649877071380615, "(16, 0)": 0.7649877071380615, "(16, 16)": 0.7649877071380615, "(18, 0)": 0.7649877071380615, "(18, 16)": 0.7649877071380615, "(20, 0)": 0.7649877071380615, "(20, 16)": 0.7649877071380615, "(22, 0)": 0.7649877071380615, "(22, 16)": 0.7649877071380615, "(24, 0)": 0.7649877071380615, "(24, 16)": 0.7649877071380615, "(26, 0)": 0.7649877071380615, "(26, 16)": 0.7649877071380615, "(28, 0)": 0.7649877071380615, "(28, 16)": 0.7649877071380615, "(30, 0)": 0.7649877071380615, "(30, 16)": 0.7649877071380615}, "r_span": [310, 337], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004984140396118164}}, {"prompt_attention_score": {"(0, 0)": 0.8326411247253418, "(0, 16)": 0.8326411247253418, "(2, 0)": 0.8326411247253418, "(2, 16)": 0.8326411247253418, "(4, 0)": 0.8326411247253418, "(4, 16)": 0.8326411247253418, "(6, 0)": 0.8326411247253418, "(6, 16)": 0.8440089821815491, "(8, 0)": 0.8440089821815491, "(8, 16)": 0.8440089821815491, "(10, 0)": 0.8440089821815491, "(10, 16)": 0.8440089821815491, "(12, 0)": 0.8440089821815491, "(12, 16)": 0.8440089821815491, "(14, 0)": 0.8440089821815491, "(14, 16)": 0.8326411247253418, "(16, 0)": 0.8440089821815491, "(16, 16)": 0.8440089821815491, "(18, 0)": 0.8440089821815491, "(18, 16)": 0.8440089821815491, "(20, 0)": 0.8440089821815491, "(20, 16)": 0.8440089821815491, "(22, 0)": 0.8440089821815491, "(22, 16)": 0.8440089821815491, "(24, 0)": 0.8440089821815491, "(24, 16)": 0.8440089821815491, "(26, 0)": 0.8440089821815491, "(26, 16)": 0.8440089821815491, "(28, 0)": 0.8440089821815491, "(28, 16)": 0.8440089821815491, "(30, 0)": 0.8440089821815491, "(30, 16)": 0.8440089821815491}, "r_span": [339, 400], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013000965118408203}}, {"prompt_attention_score": {"(0, 0)": 0.8048022985458374, "(0, 16)": 0.8048022985458374, "(2, 0)": 0.8048022985458374, "(2, 16)": 0.8048022985458374, "(4, 0)": 0.8048022985458374, "(4, 16)": 0.8048022985458374, "(6, 0)": 0.8124920129776001, "(6, 16)": 0.8124920129776001, "(8, 0)": 0.8124920129776001, "(8, 16)": 0.8124920129776001, "(10, 0)": 0.8124920129776001, "(10, 16)": 0.8124920129776001, "(12, 0)": 0.8124920129776001, "(12, 16)": 0.8048022985458374, "(14, 0)": 0.8124920129776001, "(14, 16)": 0.8048022985458374, "(16, 0)": 0.8124920129776001, "(16, 16)": 0.8124920129776001, "(18, 0)": 0.8124920129776001, "(18, 16)": 0.8124920129776001, "(20, 0)": 0.8124920129776001, "(20, 16)": 0.8124920129776001, "(22, 0)": 0.8124920129776001, "(22, 16)": 0.8124920129776001, "(24, 0)": 0.8124920129776001, "(24, 16)": 0.8124920129776001, "(26, 0)": 0.8124920129776001, "(26, 16)": 0.8124920129776001, "(28, 0)": 0.8124920129776001, "(28, 16)": 0.8124920129776001, "(30, 0)": 0.8124920129776001, "(30, 16)": 0.8124920129776001}, "r_span": [401, 467], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.001190781593322754}}, {"prompt_attention_score": {"(0, 0)": 0.7263982892036438, "(0, 16)": 0.7263982892036438, "(2, 0)": 0.7263982892036438, "(2, 16)": 0.7392897009849548, "(4, 0)": 0.7263982892036438, "(4, 16)": 0.7263982892036438, "(6, 0)": 0.7392897009849548, "(6, 16)": 0.7392897009849548, "(8, 0)": 0.7392897009849548, "(8, 16)": 0.7392897009849548, "(10, 0)": 0.7392897009849548, "(10, 16)": 0.7392897009849548, "(12, 0)": 0.7392897009849548, "(12, 16)": 0.7392897009849548, "(14, 0)": 0.7392897009849548, "(14, 16)": 0.7263982892036438, "(16, 0)": 0.7392897009849548, "(16, 16)": 0.7392897009849548, "(18, 0)": 0.7392897009849548, "(18, 16)": 0.7392897009849548, "(20, 0)": 0.7392897009849548, "(20, 16)": 0.7392897009849548, "(22, 0)": 0.7392897009849548, "(22, 16)": 0.7392897009849548, "(24, 0)": 0.7392897009849548, "(24, 16)": 0.7392897009849548, "(26, 0)": 0.7392897009849548, "(26, 16)": 0.7392897009849548, "(28, 0)": 0.7392897009849548, "(28, 16)": 0.7392897009849548, "(30, 0)": 0.7392897009849548, "(30, 16)": 0.7392897009849548}, "r_span": [468, 537], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0018898844718933105}}, {"prompt_attention_score": {"(0, 0)": 0.7261199951171875, "(0, 16)": 0.7261199951171875, "(2, 0)": 0.7261199951171875, "(2, 16)": 0.7261199951171875, "(4, 0)": 0.7261199951171875, "(4, 16)": 0.7261199951171875, "(6, 0)": 0.7392703294754028, "(6, 16)": 0.7392703294754028, "(8, 0)": 0.7392703294754028, "(8, 16)": 0.7392703294754028, "(10, 0)": 0.7392703294754028, "(10, 16)": 0.7392703294754028, "(12, 0)": 0.7392703294754028, "(12, 16)": 0.7392703294754028, "(14, 0)": 0.7392703294754028, "(14, 16)": 0.7392703294754028, "(16, 0)": 0.7392703294754028, "(16, 16)": 0.7392703294754028, "(18, 0)": 0.7392703294754028, "(18, 16)": 0.7392703294754028, "(20, 0)": 0.7392703294754028, "(20, 16)": 0.7392703294754028, "(22, 0)": 0.7392703294754028, "(22, 16)": 0.7392703294754028, "(24, 0)": 0.7392703294754028, "(24, 16)": 0.7392703294754028, "(26, 0)": 0.7392703294754028, "(26, 16)": 0.7392703294754028, "(28, 0)": 0.7392703294754028, "(28, 16)": 0.7392703294754028, "(30, 0)": 0.7392703294754028, "(30, 16)": 0.7392703294754028}, "r_span": [538, 605], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 9.02414321899414e-05}}, {"prompt_attention_score": {"(0, 0)": 0.5416510105133057, "(0, 16)": 0.5416510105133057, "(2, 0)": 0.5416510105133057, "(2, 16)": 0.5416510105133057, "(4, 0)": 0.5227649211883545, "(4, 16)": 0.5227649211883545, "(6, 0)": 0.5227649211883545, "(6, 16)": 0.9034074544906616, "(8, 0)": 0.5227649211883545, "(8, 16)": 0.5227649211883545, "(10, 0)": 0.9034074544906616, "(10, 16)": 0.9034074544906616, "(12, 0)": 0.5227649211883545, "(12, 16)": 0.9034074544906616, "(14, 0)": 0.5227649211883545, "(14, 16)": 0.9034074544906616, "(16, 0)": 0.9034074544906616, "(16, 16)": 0.5227649211883545, "(18, 0)": 0.5227649211883545, "(18, 16)": 0.9034074544906616, "(20, 0)": 0.9034074544906616, "(20, 16)": 0.5227649211883545, "(22, 0)": 0.5227649211883545, "(22, 16)": 0.9034074544906616, "(24, 0)": 0.5227649211883545, "(24, 16)": 0.9034074544906616, "(26, 0)": 0.5227649211883545, "(26, 16)": 0.5227649211883545, "(28, 0)": 0.5227649211883545, "(28, 16)": 0.5227649211883545, "(30, 0)": 0.5227649211883545, "(30, 16)": 0.5227649211883545}, "r_span": [607, 617], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00048023462295532227}}]}, {"id": "16563", "source_id": "12252", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how to create an employee schedule:\n\n1. Talk to a lawyer about work laws: It is important to understand the legal requirements for creating an employee schedule, including paying overtime for hours worked beyond 40 per week. Additionally, there may be other laws to consider, such as restrictions for employees under the age of 18.\n2. Use scheduling software or a simple word processing program: You can create an employee schedule using scheduling software, a simple word processing program, or even a sheet of paper. Make a list of all employees and their duties, and create a chart of work days and hours for each day.\n3. Print or send schedules to employees: Once you have created the schedule, print out copies for each employee or send them to their email accounts. Keep a master schedule for making any changes. If you are using a digital tool, you can easily edit and share the schedule with employees.\n\nUnable to answer based on given passages. The passages do not provide specific instructions on how to create an employee schedule, such as setting up the schedule format, determining pay rates, or communicating the schedule to employees.", "response_spans": [[0, 75], [77, 371], [372, 661], [662, 950], [952, 1189]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7634483575820923, "(0, 16)": 0.7634483575820923, "(2, 0)": 0.7634483575820923, "(2, 16)": 0.7634483575820923, "(4, 0)": 0.7634483575820923, "(4, 16)": 0.7634483575820923, "(6, 0)": 0.7634483575820923, "(6, 16)": 0.7038028836250305, "(8, 0)": 0.7634483575820923, "(8, 16)": 0.7634483575820923, "(10, 0)": 0.7634483575820923, "(10, 16)": 0.7634483575820923, "(12, 0)": 0.7634483575820923, "(12, 16)": 0.7038028836250305, "(14, 0)": 0.8280729055404663, "(14, 16)": 0.7634483575820923, "(16, 0)": 0.7038028836250305, "(16, 16)": 0.7634483575820923, "(18, 0)": 0.7634483575820923, "(18, 16)": 0.7038028836250305, "(20, 0)": 0.7038028836250305, "(20, 16)": 0.8280729055404663, "(22, 0)": 0.8280729055404663, "(22, 16)": 0.7038028836250305, "(24, 0)": 0.8280729055404663, "(24, 16)": 0.7038028836250305, "(26, 0)": 0.8280729055404663, "(26, 16)": 0.8280729055404663, "(28, 0)": 0.8280729055404663, "(28, 16)": 0.8280729055404663, "(30, 0)": 0.8280729055404663, "(30, 16)": 0.8280729055404663}, "r_span": [293, 310], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006665587425231934}}, {"prompt_attention_score": {"(0, 0)": 0.6600700616836548, "(0, 16)": 0.6600700616836548, "(2, 0)": 0.6600700616836548, "(2, 16)": 0.6600700616836548, "(4, 0)": 0.6600700616836548, "(4, 16)": 0.6600700616836548, "(6, 0)": 0.6600700616836548, "(6, 16)": 0.9200211763381958, "(8, 0)": 0.7219679951667786, "(8, 16)": 0.7219679951667786, "(10, 0)": 0.6600700616836548, "(10, 16)": 0.6600700616836548, "(12, 0)": 0.7219679951667786, "(12, 16)": 0.9200211763381958, "(14, 0)": 0.7219679951667786, "(14, 16)": 0.6600700616836548, "(16, 0)": 0.9200211763381958, "(16, 16)": 0.7219679951667786, "(18, 0)": 0.7219679951667786, "(18, 16)": 0.9200211763381958, "(20, 0)": 0.9200211763381958, "(20, 16)": 0.7219679951667786, "(22, 0)": 0.7219679951667786, "(22, 16)": 0.9200211763381958, "(24, 0)": 0.7219679951667786, "(24, 16)": 0.9200211763381958, "(26, 0)": 0.7219679951667786, "(26, 16)": 0.7219679951667786, "(28, 0)": 0.7219679951667786, "(28, 16)": 0.7219679951667786, "(30, 0)": 0.7219679951667786, "(30, 16)": 0.7219679951667786}, "r_span": [312, 375], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009796619415283203}}, {"prompt_attention_score": {"(0, 0)": 0.7992199063301086, "(0, 16)": 0.7992199063301086, "(2, 0)": 0.7992199063301086, "(2, 16)": 0.7992199063301086, "(4, 0)": 0.7992199063301086, "(4, 16)": 0.7992199063301086, "(6, 0)": 0.7992199063301086, "(6, 16)": 0.937813401222229, "(8, 0)": 0.937813401222229, "(8, 16)": 0.7992199063301086, "(10, 0)": 0.7992199063301086, "(10, 16)": 0.7992199063301086, "(12, 0)": 0.7992199063301086, "(12, 16)": 0.937813401222229, "(14, 0)": 0.937813401222229, "(14, 16)": 0.7992199063301086, "(16, 0)": 0.937813401222229, "(16, 16)": 0.7992199063301086, "(18, 0)": 0.7992199063301086, "(18, 16)": 0.937813401222229, "(20, 0)": 0.937813401222229, "(20, 16)": 0.937813401222229, "(22, 0)": 0.937813401222229, "(22, 16)": 0.937813401222229, "(24, 0)": 0.937813401222229, "(24, 16)": 0.937813401222229, "(26, 0)": 0.937813401222229, "(26, 16)": 0.937813401222229, "(28, 0)": 0.937813401222229, "(28, 16)": 0.937813401222229, "(30, 0)": 0.937813401222229, "(30, 16)": 0.937813401222229}, "r_span": [376, 436], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0015627741813659668}}, {"prompt_attention_score": {"(0, 0)": 0.8597696423530579, "(0, 16)": 0.8597696423530579, "(2, 0)": 0.8597696423530579, "(2, 16)": 0.8597696423530579, "(4, 0)": 0.8597696423530579, "(4, 16)": 0.8597696423530579, "(6, 0)": 0.8597696423530579, "(6, 16)": 0.8597696423530579, "(8, 0)": 0.8103533983230591, "(8, 16)": 0.8597696423530579, "(10, 0)": 0.8597696423530579, "(10, 16)": 0.8597696423530579, "(12, 0)": 0.8103533983230591, "(12, 16)": 0.8597696423530579, "(14, 0)": 0.8103533983230591, "(14, 16)": 0.8597696423530579, "(16, 0)": 0.8597696423530579, "(16, 16)": 0.6840636730194092, "(18, 0)": 0.8597696423530579, "(18, 16)": 0.8597696423530579, "(20, 0)": 0.8597696423530579, "(20, 16)": 0.8103533983230591, "(22, 0)": 0.8103533983230591, "(22, 16)": 0.8597696423530579, "(24, 0)": 0.8103533983230591, "(24, 16)": 0.8597696423530579, "(26, 0)": 0.8103533983230591, "(26, 16)": 0.8103533983230591, "(28, 0)": 0.8103533983230591, "(28, 16)": 0.8103533983230591, "(30, 0)": 0.8103533983230591, "(30, 16)": 0.8103533983230591}, "r_span": [437, 496], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0005398988723754883}}, {"prompt_attention_score": {"(0, 0)": 0.7786335945129395, "(0, 16)": 0.7786335945129395, "(2, 0)": 0.7786335945129395, "(2, 16)": 0.8081387877464294, "(4, 0)": 0.7786335945129395, "(4, 16)": 0.7786335945129395, "(6, 0)": 0.7786335945129395, "(6, 16)": 0.7786335945129395, "(8, 0)": 0.7786335945129395, "(8, 16)": 0.8081387877464294, "(10, 0)": 0.7786335945129395, "(10, 16)": 0.7786335945129395, "(12, 0)": 0.8081387877464294, "(12, 16)": 0.7786335945129395, "(14, 0)": 0.8081387877464294, "(14, 16)": 0.7786335945129395, "(16, 0)": 0.7786335945129395, "(16, 16)": 0.8081387877464294, "(18, 0)": 0.8081387877464294, "(18, 16)": 0.7786335945129395, "(20, 0)": 0.7506911754608154, "(20, 16)": 0.8081387877464294, "(22, 0)": 0.8081387877464294, "(22, 16)": 0.7506911754608154, "(24, 0)": 0.8081387877464294, "(24, 16)": 0.7786335945129395, "(26, 0)": 0.8081387877464294, "(26, 16)": 0.8081387877464294, "(28, 0)": 0.8081387877464294, "(28, 16)": 0.8081387877464294, "(30, 0)": 0.8081387877464294, "(30, 16)": 0.8081387877464294}, "r_span": [498, 545], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0008121132850646973}}]}, {"id": "16635", "source_id": "12264", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the steps to force the removal of a printer in Windows:\n\nPassage 1:\n\n* Open the Print Manager or Printers folder.\n* Right-click the printer you want to remove and select \"Delete\".\n* Close the Print Manager or Printers folder.\n* Stop and restart the Spooler Service.\n\nPassage 2:\n\n* Click on Control Panel.\n* Click on Hardware and Sound.\n* Click on Printers.\n* Right-click the printer you want to remove and select \"Delete\".\n* If unable to delete the printer, right-click it again, click \"Run as administrator\", and then click \"Delete\".\n\nPassage 3:\n\n* Remove the printer from the devices list by right-clicking it and selecting \"Remove\".\n* Uninstall any Windows print drivers using Windows Devices and Printers.\n* Disconnect the USB cable from the printer (if it connects to the computer via USB).\n* Turn the printer off and on again and ensure it is in a ready state.\n\nBased on the provided passages, there is no specific instruction on how to force the removal of a printer if the above steps fail. Therefore, the answer to the question \"How to force removal of a printer in devices and printers\" is: Unable to answer based on given passages.", "response_spans": [[0, 318], [308, 587], [577, 907], [909, 1183]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8170943260192871, "(0, 16)": 0.8170943260192871, "(2, 0)": 0.8170943260192871, "(2, 16)": 0.8170943260192871, "(4, 0)": 0.8170943260192871, "(4, 16)": 0.8170943260192871, "(6, 0)": 0.8170943260192871, "(6, 16)": 0.9239844679832458, "(8, 0)": 0.8586891889572144, "(8, 16)": 0.8170943260192871, "(10, 0)": 0.8170943260192871, "(10, 16)": 0.8170943260192871, "(12, 0)": 0.8586891889572144, "(12, 16)": 0.9239844679832458, "(14, 0)": 0.8586891889572144, "(14, 16)": 0.8170943260192871, "(16, 0)": 0.9239844679832458, "(16, 16)": 0.8586891889572144, "(18, 0)": 0.8586891889572144, "(18, 16)": 0.9239844679832458, "(20, 0)": 0.9239844679832458, "(20, 16)": 0.8586891889572144, "(22, 0)": 0.8586891889572144, "(22, 16)": 0.9239844679832458, "(24, 0)": 0.8586891889572144, "(24, 16)": 0.9239844679832458, "(26, 0)": 0.8586891889572144, "(26, 16)": 0.8586891889572144, "(28, 0)": 0.8586891889572144, "(28, 16)": 0.8586891889572144, "(30, 0)": 0.8586891889572144, "(30, 16)": 0.8586891889572144}, "r_span": [315, 403], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010301470756530762}}, {"prompt_attention_score": {"(0, 0)": 0.8729733228683472, "(0, 16)": 0.8729733228683472, "(2, 0)": 0.8729733228683472, "(2, 16)": 0.8729733228683472, "(4, 0)": 0.8729733228683472, "(4, 16)": 0.8729733228683472, "(6, 0)": 0.8729733228683472, "(6, 16)": 0.9774390459060669, "(8, 0)": 0.9774390459060669, "(8, 16)": 0.8729733228683472, "(10, 0)": 0.8729733228683472, "(10, 16)": 0.8729733228683472, "(12, 0)": 0.9774390459060669, "(12, 16)": 0.9774390459060669, "(14, 0)": 0.9774390459060669, "(14, 16)": 0.9774390459060669, "(16, 0)": 0.9774390459060669, "(16, 16)": 0.9774390459060669, "(18, 0)": 0.9774390459060669, "(18, 16)": 0.9774390459060669, "(20, 0)": 0.9774390459060669, "(20, 16)": 0.9774390459060669, "(22, 0)": 0.9774390459060669, "(22, 16)": 0.9774390459060669, "(24, 0)": 0.9774390459060669, "(24, 16)": 0.9774390459060669, "(26, 0)": 0.9774390459060669, "(26, 16)": 0.9774390459060669, "(28, 0)": 0.9774390459060669, "(28, 16)": 0.9774390459060669, "(30, 0)": 0.9774390459060669, "(30, 16)": 0.9774390459060669}, "r_span": [398, 479], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 6.914138793945312e-05}}, {"prompt_attention_score": {"(0, 0)": 0.974107027053833, "(0, 16)": 0.974107027053833, "(2, 0)": 0.974107027053833, "(2, 16)": 0.974107027053833, "(4, 0)": 0.974107027053833, "(4, 16)": 0.974107027053833, "(6, 0)": 0.974107027053833, "(6, 16)": 0.974107027053833, "(8, 0)": 0.8829518556594849, "(8, 16)": 0.8829518556594849, "(10, 0)": 0.974107027053833, "(10, 16)": 0.974107027053833, "(12, 0)": 0.8829518556594849, "(12, 16)": 0.974107027053833, "(14, 0)": 0.8829518556594849, "(14, 16)": 0.974107027053833, "(16, 0)": 0.974107027053833, "(16, 16)": 0.8829518556594849, "(18, 0)": 0.8829518556594849, "(18, 16)": 0.974107027053833, "(20, 0)": 0.974107027053833, "(20, 16)": 0.8829518556594849, "(22, 0)": 0.8829518556594849, "(22, 16)": 0.974107027053833, "(24, 0)": 0.8829518556594849, "(24, 16)": 0.974107027053833, "(26, 0)": 0.8829518556594849, "(26, 16)": 0.8829518556594849, "(28, 0)": 0.8829518556594849, "(28, 16)": 0.8829518556594849, "(30, 0)": 0.8829518556594849, "(30, 16)": 0.8829518556594849}, "r_span": [474, 556], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007241964340209961}}, {"prompt_attention_score": {"(0, 0)": 0.7630772590637207, "(0, 16)": 0.7630772590637207, "(2, 0)": 0.7630772590637207, "(2, 16)": 0.7630772590637207, "(4, 0)": 0.7630772590637207, "(4, 16)": 0.7630772590637207, "(6, 0)": 0.7630772590637207, "(6, 16)": 0.8419913053512573, "(8, 0)": 0.7630772590637207, "(8, 16)": 0.747014045715332, "(10, 0)": 0.7630772590637207, "(10, 16)": 0.7630772590637207, "(12, 0)": 0.7630772590637207, "(12, 16)": 0.7630772590637207, "(14, 0)": 0.747014045715332, "(14, 16)": 0.7630772590637207, "(16, 0)": 0.8419913053512573, "(16, 16)": 0.747014045715332, "(18, 0)": 0.747014045715332, "(18, 16)": 0.7630772590637207, "(20, 0)": 0.8419913053512573, "(20, 16)": 0.747014045715332, "(22, 0)": 0.747014045715332, "(22, 16)": 0.8419913053512573, "(24, 0)": 0.747014045715332, "(24, 16)": 0.7630772590637207, "(26, 0)": 0.747014045715332, "(26, 16)": 0.747014045715332, "(28, 0)": 0.747014045715332, "(28, 16)": 0.747014045715332, "(30, 0)": 0.747014045715332, "(30, 16)": 0.747014045715332}, "r_span": [558, 618], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0024399161338806152}}]}, {"id": "16665", "source_id": "12269", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways technology has changed the workplace:\n\n1. Increased efficiency and productivity (Passage 1) - Technology has enabled workers to complete tasks faster and more accurately, leading to increased productivity and efficiency.\n2. Changes in the dynamics of the workplace (Passage 2) - Technology has transformed the way people work together, communicate, and collaborate, resulting in new dynamics in the workplace.\n3. Global connectivity (Passage 3) - With the advent of technology, employees can now work remotely and interact with a global market, expanding the reach of their work.\n\nUnable to answer based on given passages.", "response_spans": [[0, 88], [90, 460], [461, 630], [632, 673]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7317789196968079, "(0, 16)": 0.7317789196968079, "(2, 0)": 0.7317789196968079, "(2, 16)": 0.7317789196968079, "(4, 0)": 0.7317789196968079, "(4, 16)": 0.7317789196968079, "(6, 0)": 0.7317789196968079, "(6, 16)": 0.8230603933334351, "(8, 0)": 0.7317789196968079, "(8, 16)": 0.7317789196968079, "(10, 0)": 0.7317789196968079, "(10, 16)": 0.7317789196968079, "(12, 0)": 0.7317789196968079, "(12, 16)": 0.8230603933334351, "(14, 0)": 0.8082506060600281, "(14, 16)": 0.7317789196968079, "(16, 0)": 0.8230603933334351, "(16, 16)": 0.7317789196968079, "(18, 0)": 0.7317789196968079, "(18, 16)": 0.8230603933334351, "(20, 0)": 0.8230603933334351, "(20, 16)": 0.8082506060600281, "(22, 0)": 0.8082506060600281, "(22, 16)": 0.8230603933334351, "(24, 0)": 0.8082506060600281, "(24, 16)": 0.8230603933334351, "(26, 0)": 0.8082506060600281, "(26, 16)": 0.8082506060600281, "(28, 0)": 0.7317789196968079, "(28, 16)": 0.8082506060600281, "(30, 0)": 0.8082506060600281, "(30, 16)": 0.8082506060600281}, "r_span": [312, 331], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007172822952270508}}, {"prompt_attention_score": {"(0, 0)": 0.7648158073425293, "(0, 16)": 0.7648158073425293, "(2, 0)": 0.7648158073425293, "(2, 16)": 0.7648158073425293, "(4, 0)": 0.7648158073425293, "(4, 16)": 0.7648158073425293, "(6, 0)": 0.7648158073425293, "(6, 16)": 0.8149951696395874, "(8, 0)": 0.7648158073425293, "(8, 16)": 0.7648158073425293, "(10, 0)": 0.7648158073425293, "(10, 16)": 0.7648158073425293, "(12, 0)": 0.7648158073425293, "(12, 16)": 0.7984437942504883, "(14, 0)": 0.7984437942504883, "(14, 16)": 0.7648158073425293, "(16, 0)": 0.8149951696395874, "(16, 16)": 0.7984437942504883, "(18, 0)": 0.7984437942504883, "(18, 16)": 0.7984437942504883, "(20, 0)": 0.7984437942504883, "(20, 16)": 0.7984437942504883, "(22, 0)": 0.7984437942504883, "(22, 16)": 0.7984437942504883, "(24, 0)": 0.7984437942504883, "(24, 16)": 0.7984437942504883, "(26, 0)": 0.7984437942504883, "(26, 16)": 0.7984437942504883, "(28, 0)": 0.7984437942504883, "(28, 16)": 0.7984437942504883, "(30, 0)": 0.7984437942504883, "(30, 16)": 0.7984437942504883}, "r_span": [333, 413], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00283968448638916}}, {"prompt_attention_score": {"(0, 0)": 0.7560459971427917, "(0, 16)": 0.7560459971427917, "(2, 0)": 0.7560459971427917, "(2, 16)": 0.7560459971427917, "(4, 0)": 0.7560459971427917, "(4, 16)": 0.7560459971427917, "(6, 0)": 0.7560459971427917, "(6, 16)": 0.7560459971427917, "(8, 0)": 0.7560459971427917, "(8, 16)": 0.7560459971427917, "(10, 0)": 0.7560459971427917, "(10, 16)": 0.7560459971427917, "(12, 0)": 0.7560459971427917, "(12, 16)": 0.7560459971427917, "(14, 0)": 0.7154691219329834, "(14, 16)": 0.7560459971427917, "(16, 0)": 0.7560459971427917, "(16, 16)": 0.6882244348526001, "(18, 0)": 0.7560459971427917, "(18, 16)": 0.7560459971427917, "(20, 0)": 0.7560459971427917, "(20, 16)": 0.7154691219329834, "(22, 0)": 0.7154691219329834, "(22, 16)": 0.7560459971427917, "(24, 0)": 0.7154691219329834, "(24, 16)": 0.7560459971427917, "(26, 0)": 0.7154691219329834, "(26, 16)": 0.7154691219329834, "(28, 0)": 0.7154691219329834, "(28, 16)": 0.7154691219329834, "(30, 0)": 0.7154691219329834, "(30, 16)": 0.7154691219329834}, "r_span": [414, 454], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013636946678161621}}, {"prompt_attention_score": {"(0, 0)": 0.6856639981269836, "(0, 16)": 0.6856639981269836, "(2, 0)": 0.6856639981269836, "(2, 16)": 0.6856639981269836, "(4, 0)": 0.6856639981269836, "(4, 16)": 0.6856639981269836, "(6, 0)": 0.6856639981269836, "(6, 16)": 0.6856639981269836, "(8, 0)": 0.6856639981269836, "(8, 16)": 0.6856639981269836, "(10, 0)": 0.6856639981269836, "(10, 16)": 0.6856639981269836, "(12, 0)": 0.6856639981269836, "(12, 16)": 0.6856639981269836, "(14, 0)": 0.552066445350647, "(14, 16)": 0.6856639981269836, "(16, 0)": 0.6856639981269836, "(16, 16)": 0.6856639981269836, "(18, 0)": 0.6856639981269836, "(18, 16)": 0.6856639981269836, "(20, 0)": 0.6856639981269836, "(20, 16)": 0.552066445350647, "(22, 0)": 0.552066445350647, "(22, 16)": 0.6856639981269836, "(24, 0)": 0.552066445350647, "(24, 16)": 0.6856639981269836, "(26, 0)": 0.552066445350647, "(26, 16)": 0.552066445350647, "(28, 0)": 0.552066445350647, "(28, 16)": 0.552066445350647, "(30, 0)": 0.552066445350647, "(30, 16)": 0.552066445350647}, "r_span": [456, 466], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00011485815048217773}}]}, {"id": "16689", "source_id": "12273", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some strategies for guarding a tall person in basketball:\n\n1. Stay as close as possible to a tall, skilled shooter when you guard them near the three-point line and actively slide your feet from side to side to stay near your opponent and minimize shot opportunities (Passage 1).\n2. Keep a wedge between the basket and the offensive player to defend against a tall player (Passage 3).\n\nTherefore, to guard a tall person in basketball, it is important to stay close to them and create a barrier between them and the basket. These strategies can help limit their shooting opportunities and make it more difficult for them to score.", "response_spans": [[0, 425], [427, 670]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8850363492965698, "(0, 16)": 0.8850363492965698, "(2, 0)": 0.8850363492965698, "(2, 16)": 0.8850363492965698, "(4, 0)": 0.8850363492965698, "(4, 16)": 0.8850363492965698, "(6, 0)": 0.8850363492965698, "(6, 16)": 0.9552483558654785, "(8, 0)": 0.8850363492965698, "(8, 16)": 0.8850363492965698, "(10, 0)": 0.8850363492965698, "(10, 16)": 0.8850363492965698, "(12, 0)": 0.8850363492965698, "(12, 16)": 0.9552483558654785, "(14, 0)": 0.6876715421676636, "(14, 16)": 0.8850363492965698, "(16, 0)": 0.9552483558654785, "(16, 16)": 0.8850363492965698, "(18, 0)": 0.8850363492965698, "(18, 16)": 0.9552483558654785, "(20, 0)": 0.9552483558654785, "(20, 16)": 0.6876715421676636, "(22, 0)": 0.6876715421676636, "(22, 16)": 0.9552483558654785, "(24, 0)": 0.6876715421676636, "(24, 16)": 0.9552483558654785, "(26, 0)": 0.6876715421676636, "(26, 16)": 0.6876715421676636, "(28, 0)": 0.6876715421676636, "(28, 16)": 0.6876715421676636, "(30, 0)": 0.6876715421676636, "(30, 16)": 0.6876715421676636}, "r_span": [306, 411], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0009620785713195801}}, {"prompt_attention_score": {"(0, 0)": 0.8268322348594666, "(0, 16)": 0.8268322348594666, "(2, 0)": 0.8268322348594666, "(2, 16)": 0.8268322348594666, "(4, 0)": 0.8268322348594666, "(4, 16)": 0.8268322348594666, "(6, 0)": 0.8268322348594666, "(6, 16)": 0.8778619170188904, "(8, 0)": 0.6875886917114258, "(8, 16)": 0.8268322348594666, "(10, 0)": 0.8268322348594666, "(10, 16)": 0.8268322348594666, "(12, 0)": 0.8778619170188904, "(12, 16)": 0.8268322348594666, "(14, 0)": 0.6875886917114258, "(14, 16)": 0.8268322348594666, "(16, 0)": 0.8268322348594666, "(16, 16)": 0.8268322348594666, "(18, 0)": 0.8268322348594666, "(18, 16)": 0.8778619170188904, "(20, 0)": 0.8778619170188904, "(20, 16)": 0.6875886917114258, "(22, 0)": 0.6875886917114258, "(22, 16)": 0.8778619170188904, "(24, 0)": 0.6875886917114258, "(24, 16)": 0.8778619170188904, "(26, 0)": 0.6875886917114258, "(26, 16)": 0.6875886917114258, "(28, 0)": 0.6875886917114258, "(28, 16)": 0.6875886917114258, "(30, 0)": 0.6875886917114258, "(30, 16)": 0.6875886917114258}, "r_span": [413, 463], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001775503158569336}}]}, {"id": "16773", "source_id": "12287", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the key similarities and differences between the nervous system and the endocrine system:\n\nSimilarities:\n\n* Both systems are involved in maintaining homeostasis by coordinating and regulating the activities of other cells, tissues, organs, and systems.\n* Both systems use chemical messengers (neurotransmitters and hormones) to transmit signals.\n* Both systems have negative feedback mechanisms to regulate their function.\n\nDifferences:\n\n* The nervous system is made up of neuron cells, while the endocrine system is composed of glands.\n* Transmission of signals occurs through electrical impulses in the nervous system, while hormones are responsible for signal transmission in the endocrine system.\n* The nervous system has a continuous structure, with cells connected to each other, while the endocrine system consists of discrete organs not physically connected to each other.\n* The nervous system uses neurons to transmit signals, while the endocrine system relies on the circulatory system to transmit signals.\n\nUnable to answer based on given passages.", "response_spans": [[0, 477], [479, 921], [922, 1057], [1059, 1100]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9583647847175598, "(0, 16)": 0.9583647847175598, "(2, 0)": 0.9583647847175598, "(2, 16)": 0.9583647847175598, "(4, 0)": 0.9583647847175598, "(4, 16)": 0.9583647847175598, "(6, 0)": 0.9583647847175598, "(6, 16)": 0.9583647847175598, "(8, 0)": 0.9583647847175598, "(8, 16)": 0.4074208736419678, "(10, 0)": 0.4074208736419678, "(10, 16)": 0.9583647847175598, "(12, 0)": 0.9583647847175598, "(12, 16)": 0.9583647847175598, "(14, 0)": 0.9583647847175598, "(14, 16)": 0.9583647847175598, "(16, 0)": 0.9042956233024597, "(16, 16)": 0.9583647847175598, "(18, 0)": 0.4074208736419678, "(18, 16)": 0.9583647847175598, "(20, 0)": 0.9583647847175598, "(20, 16)": 0.8264487981796265, "(22, 0)": 0.9042956233024597, "(22, 16)": 0.9583647847175598, "(24, 0)": 0.9042956233024597, "(24, 16)": 0.9583647847175598, "(26, 0)": 0.9042956233024597, "(26, 16)": 0.9042956233024597, "(28, 0)": 0.9042956233024597, "(28, 16)": 0.9042956233024597, "(30, 0)": 0.9042956233024597, "(30, 16)": 0.9042956233024597}, "r_span": [358, 470], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018537640571594238}}, {"prompt_attention_score": {"(0, 0)": 0.8469911217689514, "(0, 16)": 0.8469911217689514, "(2, 0)": 0.8469911217689514, "(2, 16)": 0.9287148118019104, "(4, 0)": 0.8469911217689514, "(4, 16)": 0.8469911217689514, "(6, 0)": 0.8469911217689514, "(6, 16)": 0.9287148118019104, "(8, 0)": 0.9287148118019104, "(8, 16)": 0.8727287650108337, "(10, 0)": 0.8469911217689514, "(10, 16)": 0.8727287650108337, "(12, 0)": 0.9287148118019104, "(12, 16)": 0.9287148118019104, "(14, 0)": 0.8727287650108337, "(14, 16)": 0.8469911217689514, "(16, 0)": 0.9287148118019104, "(16, 16)": 0.9287148118019104, "(18, 0)": 0.9287148118019104, "(18, 16)": 0.9287148118019104, "(20, 0)": 0.8727287650108337, "(20, 16)": 0.8727287650108337, "(22, 0)": 0.8727287650108337, "(22, 16)": 0.9287148118019104, "(24, 0)": 0.8727287650108337, "(24, 16)": 0.9287148118019104, "(26, 0)": 0.9287148118019104, "(26, 16)": 0.9287148118019104, "(28, 0)": 0.9287148118019104, "(28, 16)": 0.9287148118019104, "(30, 0)": 0.9287148118019104, "(30, 16)": 0.9287148118019104}, "r_span": [472, 569], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0025716423988342285}}, {"prompt_attention_score": {"(0, 0)": 0.8355742692947388, "(0, 16)": 0.8355742692947388, "(2, 0)": 0.8355742692947388, "(2, 16)": 0.9037275314331055, "(4, 0)": 0.8355742692947388, "(4, 16)": 0.8355742692947388, "(6, 0)": 0.8355742692947388, "(6, 16)": 0.9037275314331055, "(8, 0)": 0.8355742692947388, "(8, 16)": 0.9037275314331055, "(10, 0)": 0.8355742692947388, "(10, 16)": 0.9037275314331055, "(12, 0)": 0.9037275314331055, "(12, 16)": 0.9037275314331055, "(14, 0)": 0.9037275314331055, "(14, 16)": 0.8355742692947388, "(16, 0)": 0.9037275314331055, "(16, 16)": 0.865525484085083, "(18, 0)": 0.865525484085083, "(18, 16)": 0.9037275314331055, "(20, 0)": 0.9037275314331055, "(20, 16)": 0.9037275314331055, "(22, 0)": 0.9037275314331055, "(22, 16)": 0.9037275314331055, "(24, 0)": 0.9037275314331055, "(24, 16)": 0.9037275314331055, "(26, 0)": 0.865525484085083, "(26, 16)": 0.865525484085083, "(28, 0)": 0.865525484085083, "(28, 16)": 0.9037275314331055, "(30, 0)": 0.9037275314331055, "(30, 16)": 0.865525484085083}, "r_span": [570, 599], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0010804533958435059}}, {"prompt_attention_score": {"(0, 0)": 0.47803595662117004, "(0, 16)": 0.4643857777118683, "(2, 0)": 0.47803595662117004, "(2, 16)": 0.47803595662117004, "(4, 0)": 0.47803595662117004, "(4, 16)": 0.4643857777118683, "(6, 0)": 0.9034074544906616, "(6, 16)": 0.9034074544906616, "(8, 0)": 0.4643857777118683, "(8, 16)": 0.47803595662117004, "(10, 0)": 0.9034074544906616, "(10, 16)": 0.9034074544906616, "(12, 0)": 0.4643857777118683, "(12, 16)": 0.9034074544906616, "(14, 0)": 0.4643857777118683, "(14, 16)": 0.9034074544906616, "(16, 0)": 0.9034074544906616, "(16, 16)": 0.4643857777118683, "(18, 0)": 0.4643857777118683, "(18, 16)": 0.9034074544906616, "(20, 0)": 0.9034074544906616, "(20, 16)": 0.5330108404159546, "(22, 0)": 0.4643857777118683, "(22, 16)": 0.9034074544906616, "(24, 0)": 0.4643857777118683, "(24, 16)": 0.9034074544906616, "(26, 0)": 0.4643857777118683, "(26, 16)": 0.4643857777118683, "(28, 0)": 0.4643857777118683, "(28, 16)": 0.4643857777118683, "(30, 0)": 0.5330108404159546, "(30, 16)": 0.4643857777118683}, "r_span": [601, 611], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00016802549362182617}}]}, {"id": "16797", "source_id": "12291", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 280, "end": 344, "text": "which can increase metabolism and suppress appetite (Passage 2).", "meta": "LOW INTRO OF NEW INFO\nNo mention of this but may stand to be accurate since it fits within the context of the topic. ", "label_type": "Subtle Baseless Info", "implicit_true": true, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some of the health benefits of jalapenos:\n\n1. Pain relief: Jalape√±os have pain-killing properties, making them a natural remedy for alleviating pain (Passage 1).\n2. Weight loss: Jalape√±os may help with weight loss due to their spicy heat, which can increase metabolism and suppress appetite (Passage 2).\n3. Nasal decongestant: Jalape√±os can act as a natural nasal decongestant, helping to relieve congestion and sinus pressure (Passage 2).\n4. Heart health: Jalape√±os may help prevent heart disease, heart attack, and even cancer due to their high levels of antioxidants and other nutrients (Passage 3).\n5. Vitamin and mineral rich: Jalape√±os are full of vitamins, minerals, and antioxidants, making them a nutritious addition to a healthy diet (Passage 2).\n\nUnable to answer based on given passages:\n\n* Whether jalapenos have anti-inflammatory properties\n* Whether they can improve cognitive function or memory\n* Any specific recommendations for consumption frequency or amount.", "response_spans": [[0, 82], [84, 480], [481, 797], [799, 1019]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8045992851257324, "(0, 16)": 0.8045992851257324, "(2, 0)": 0.8045992851257324, "(2, 16)": 0.8045992851257324, "(4, 0)": 0.8045992851257324, "(4, 16)": 0.8045992851257324, "(6, 0)": 0.8045992851257324, "(6, 16)": 0.786691427230835, "(8, 0)": 0.8045992851257324, "(8, 16)": 0.8045992851257324, "(10, 0)": 0.8045992851257324, "(10, 16)": 0.8045992851257324, "(12, 0)": 0.8045992851257324, "(12, 16)": 0.786691427230835, "(14, 0)": 0.8371363878250122, "(14, 16)": 0.8045992851257324, "(16, 0)": 0.786691427230835, "(16, 16)": 0.8045992851257324, "(18, 0)": 0.8045992851257324, "(18, 16)": 0.786691427230835, "(20, 0)": 0.786691427230835, "(20, 16)": 0.8371363878250122, "(22, 0)": 0.8371363878250122, "(22, 16)": 0.786691427230835, "(24, 0)": 0.8371363878250122, "(24, 16)": 0.786691427230835, "(26, 0)": 0.8371363878250122, "(26, 16)": 0.8371363878250122, "(28, 0)": 0.8371363878250122, "(28, 16)": 0.8371363878250122, "(30, 0)": 0.8371363878250122, "(30, 16)": 0.8371363878250122}, "r_span": [366, 388], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001019597053527832}}, {"prompt_attention_score": {"(0, 0)": 0.7632900476455688, "(0, 16)": 0.7632900476455688, "(2, 0)": 0.7632900476455688, "(2, 16)": 0.7632900476455688, "(4, 0)": 0.7632900476455688, "(4, 16)": 0.7632900476455688, "(6, 0)": 0.7632900476455688, "(6, 16)": 0.8938995599746704, "(8, 0)": 0.8938995599746704, "(8, 16)": 0.7632900476455688, "(10, 0)": 0.7632900476455688, "(10, 16)": 0.7632900476455688, "(12, 0)": 0.8938995599746704, "(12, 16)": 0.8938995599746704, "(14, 0)": 0.8938995599746704, "(14, 16)": 0.8938995599746704, "(16, 0)": 0.8938995599746704, "(16, 16)": 0.8938995599746704, "(18, 0)": 0.7632900476455688, "(18, 16)": 0.8938995599746704, "(20, 0)": 0.8938995599746704, "(20, 16)": 0.8938995599746704, "(22, 0)": 0.8938995599746704, "(22, 16)": 0.8938995599746704, "(24, 0)": 0.8938995599746704, "(24, 16)": 0.8938995599746704, "(26, 0)": 0.8938995599746704, "(26, 16)": 0.8938995599746704, "(28, 0)": 0.8938995599746704, "(28, 16)": 0.8938995599746704, "(30, 0)": 0.8938995599746704, "(30, 16)": 0.8938995599746704}, "r_span": [390, 507], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.002010822296142578}}, {"prompt_attention_score": {"(0, 0)": 0.8687708377838135, "(0, 16)": 0.8687708377838135, "(2, 0)": 0.8687708377838135, "(2, 16)": 0.8687708377838135, "(4, 0)": 0.8687708377838135, "(4, 16)": 0.8687708377838135, "(6, 0)": 0.8687708377838135, "(6, 16)": 0.8666822910308838, "(8, 0)": 0.8687708377838135, "(8, 16)": 0.8666822910308838, "(10, 0)": 0.8687708377838135, "(10, 16)": 0.8687708377838135, "(12, 0)": 0.8666822910308838, "(12, 16)": 0.8666822910308838, "(14, 0)": 0.8666822910308838, "(14, 16)": 0.8666822910308838, "(16, 0)": 0.8666822910308838, "(16, 16)": 0.8687708377838135, "(18, 0)": 0.8666822910308838, "(18, 16)": 0.8666822910308838, "(20, 0)": 0.8666822910308838, "(20, 16)": 0.8666822910308838, "(22, 0)": 0.8666822910308838, "(22, 16)": 0.8666822910308838, "(24, 0)": 0.8666822910308838, "(24, 16)": 0.8666822910308838, "(26, 0)": 0.8666822910308838, "(26, 16)": 0.8187422752380371, "(28, 0)": 0.8666822910308838, "(28, 16)": 0.8666822910308838, "(30, 0)": 0.8666822910308838, "(30, 16)": 0.8666822910308838}, "r_span": [508, 602], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012661218643188477}}, {"prompt_attention_score": {"(0, 0)": 0.767233669757843, "(0, 16)": 0.767233669757843, "(2, 0)": 0.767233669757843, "(2, 16)": 0.767233669757843, "(4, 0)": 0.767233669757843, "(4, 16)": 0.767233669757843, "(6, 0)": 0.767233669757843, "(6, 16)": 0.7199909090995789, "(8, 0)": 0.7789009213447571, "(8, 16)": 0.7789009213447571, "(10, 0)": 0.767233669757843, "(10, 16)": 0.767233669757843, "(12, 0)": 0.767233669757843, "(12, 16)": 0.767233669757843, "(14, 0)": 0.7789009213447571, "(14, 16)": 0.767233669757843, "(16, 0)": 0.767233669757843, "(16, 16)": 0.7789009213447571, "(18, 0)": 0.7789009213447571, "(18, 16)": 0.7199909090995789, "(20, 0)": 0.7789009213447571, "(20, 16)": 0.7789009213447571, "(22, 0)": 0.7789009213447571, "(22, 16)": 0.7789009213447571, "(24, 0)": 0.7789009213447571, "(24, 16)": 0.767233669757843, "(26, 0)": 0.7789009213447571, "(26, 16)": 0.7789009213447571, "(28, 0)": 0.7789009213447571, "(28, 16)": 0.7789009213447571, "(30, 0)": 0.7789009213447571, "(30, 16)": 0.7789009213447571}, "r_span": [604, 654], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007651448249816895}}]}, {"id": "16851", "source_id": "12300", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 325, "end": 436, "text": "2. Structure: RBCs are round and flexible, while WBCs are irregular in shape and have a more complex structure.", "meta": "HIGH INTRO OF NEW INFO\nIt includes information about the structure of red and white blood cells, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 550, "end": 575, "text": "at a lower rate than RBCs", "meta": "HIGH INTRO OF NEW INFO\nIt includes information that the production of white blood cells is at a lower rate than red blood cells, which is not mentioned in the original source.", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the differences and similarities between red blood cells (RBCs) and white blood cells (WBCs):\n\nDifferences:\n\n1. Function: RBCs are responsible for carrying oxygen from the lungs to the tissues, while WBCs are part of the immune system and help the body combat diseases, viruses, etc.\n2. Structure: RBCs are round and flexible, while WBCs are irregular in shape and have a more complex structure.\n3. Production: RBCs are produced in the red bone marrow, while WBCs are also produced in the red bone marrow but at a lower rate than RBCs.\n\nSimilarities:\n\n1. Composition: Both RBCs and WBCs are formed elements of blood.\n2. Formation: Both RBCs and WBCs are formed from pluripotent stem cells in the red bone marrow.\n3. Presence in blood: Both RBCs and WBCs can be carried by blood from one part of the body to another.\n4. Cell membrane and cytoplasm: Both RBCs and WBCs have a cell membrane and cytoplasm.\n\nTherefore, the main difference between RBCs and WBCs is their function, with RBCs primarily responsible for carrying oxygen and WBCs playing a crucial role in the immune system. However, they share some similarities in terms of composition, formation, and presence in the blood.", "response_spans": [[0, 148], [136, 591], [578, 943], [945, 1223]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.837770938873291, "(0, 16)": 0.837770938873291, "(2, 0)": 0.837770938873291, "(2, 16)": 0.837770938873291, "(4, 0)": 0.837770938873291, "(4, 16)": 0.837770938873291, "(6, 0)": 0.837770938873291, "(6, 16)": 0.8818546533584595, "(8, 0)": 0.837770938873291, "(8, 16)": 0.837770938873291, "(10, 0)": 0.837770938873291, "(10, 16)": 0.837770938873291, "(12, 0)": 0.837770938873291, "(12, 16)": 0.837770938873291, "(14, 0)": 0.837770938873291, "(14, 16)": 0.837770938873291, "(16, 0)": 0.837770938873291, "(16, 16)": 0.837770938873291, "(18, 0)": 0.837770938873291, "(18, 16)": 0.8818546533584595, "(20, 0)": 0.8818546533584595, "(20, 16)": 0.837770938873291, "(22, 0)": 0.837770938873291, "(22, 16)": 0.8818546533584595, "(24, 0)": 0.837770938873291, "(24, 16)": 0.8818546533584595, "(26, 0)": 0.837770938873291, "(26, 16)": 0.8818546533584595, "(28, 0)": 0.837770938873291, "(28, 16)": 0.837770938873291, "(30, 0)": 0.837770938873291, "(30, 16)": 0.8818546533584595}, "r_span": [481, 520], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0006679892539978027}}, {"prompt_attention_score": {"(0, 0)": 0.7864353656768799, "(0, 16)": 0.7864353656768799, "(2, 0)": 0.7864353656768799, "(2, 16)": 0.7864353656768799, "(4, 0)": 0.7864353656768799, "(4, 16)": 0.7864353656768799, "(6, 0)": 0.7864353656768799, "(6, 16)": 0.760280430316925, "(8, 0)": 0.7864353656768799, "(8, 16)": 0.7864353656768799, "(10, 0)": 0.7864353656768799, "(10, 16)": 0.7864353656768799, "(12, 0)": 0.7864353656768799, "(12, 16)": 0.7751314640045166, "(14, 0)": 0.760280430316925, "(14, 16)": 0.7864353656768799, "(16, 0)": 0.7751314640045166, "(16, 16)": 0.7864353656768799, "(18, 0)": 0.7864353656768799, "(18, 16)": 0.7751314640045166, "(20, 0)": 0.7864353656768799, "(20, 16)": 0.7864353656768799, "(22, 0)": 0.7864353656768799, "(22, 16)": 0.760280430316925, "(24, 0)": 0.7864353656768799, "(24, 16)": 0.760280430316925, "(26, 0)": 0.7864353656768799, "(26, 16)": 0.760280430316925, "(28, 0)": 0.7751314640045166, "(28, 16)": 0.7864353656768799, "(30, 0)": 0.7864353656768799, "(30, 16)": 0.7730168104171753}, "r_span": [516, 645], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0008157491683959961}}, {"prompt_attention_score": {"(0, 0)": 0.899273693561554, "(0, 16)": 0.899273693561554, "(2, 0)": 0.899273693561554, "(2, 16)": 0.899273693561554, "(4, 0)": 0.899273693561554, "(4, 16)": 0.899273693561554, "(6, 0)": 0.899273693561554, "(6, 16)": 0.8106159567832947, "(8, 0)": 0.899273693561554, "(8, 16)": 0.899273693561554, "(10, 0)": 0.899273693561554, "(10, 16)": 0.899273693561554, "(12, 0)": 0.899273693561554, "(12, 16)": 0.899273693561554, "(14, 0)": 0.7642102241516113, "(14, 16)": 0.899273693561554, "(16, 0)": 0.8106159567832947, "(16, 16)": 0.899273693561554, "(18, 0)": 0.899273693561554, "(18, 16)": 0.899273693561554, "(20, 0)": 0.8106159567832947, "(20, 16)": 0.899273693561554, "(22, 0)": 0.7745233178138733, "(22, 16)": 0.8106159567832947, "(24, 0)": 0.899273693561554, "(24, 16)": 0.7642102241516113, "(26, 0)": 0.899273693561554, "(26, 16)": 0.8106159567832947, "(28, 0)": 0.899273693561554, "(28, 16)": 0.899273693561554, "(30, 0)": 0.8106159567832947, "(30, 16)": 0.7745233178138733}, "r_span": [641, 759], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0002778768539428711}}, {"prompt_attention_score": {"(0, 0)": 0.7736687660217285, "(0, 16)": 0.7736687660217285, "(2, 0)": 0.7736687660217285, "(2, 16)": 0.7736687660217285, "(4, 0)": 0.7736687660217285, "(4, 16)": 0.7736687660217285, "(6, 0)": 0.7736687660217285, "(6, 16)": 0.7736687660217285, "(8, 0)": 0.7736687660217285, "(8, 16)": 0.7736687660217285, "(10, 0)": 0.7736687660217285, "(10, 16)": 0.7736687660217285, "(12, 0)": 0.7736687660217285, "(12, 16)": 0.7736687660217285, "(14, 0)": 0.751753032207489, "(14, 16)": 0.7736687660217285, "(16, 0)": 0.7736687660217285, "(16, 16)": 0.7736687660217285, "(18, 0)": 0.7736687660217285, "(18, 16)": 0.7736687660217285, "(20, 0)": 0.7689523100852966, "(20, 16)": 0.7736687660217285, "(22, 0)": 0.7867801189422607, "(22, 16)": 0.7736687660217285, "(24, 0)": 0.7736687660217285, "(24, 16)": 0.751753032207489, "(26, 0)": 0.7867801189422607, "(26, 16)": 0.7689523100852966, "(28, 0)": 0.7736687660217285, "(28, 16)": 0.7736687660217285, "(30, 0)": 0.7736687660217285, "(30, 16)": 0.7867801189422607}, "r_span": [761, 824], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003275871276855469}}]}, {"id": "16881", "source_id": "12305", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [{"start": 368, "end": 485, "text": "This step is important as it helps prevent rot and ensures the potatoes have the best chance of growing successfully.", "meta": "HIGH INTRO OF NEW INFO\nNo mention of this additional information. ", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Sure! Here's how to plant a potato that has sprouted based on the provided passages:\n\nPassage 1 mentions cutting large, sprouted potatoes into chunks with two or three eyes each, using a sharp knife. It recommends placing the potato chunks on a tray or cookie sheet and setting them in a cool, dark location overnight to allow the cut ends to dry out before planting. This step is important as it helps prevent rot and ensures the potatoes have the best chance of growing successfully.\n\nPassage 2 provides an overview of the process of planting seed potatoes, including the fact that they go through three stages: young seed, middle aged, and old. However, it does not provide specific instructions for planting sprouted potatoes.\n\nPassage 3 provides more detailed instructions for planting potatoes, including turning the soil over in the planned planting area, digging a trench, and cutting the potatoes into cubes with a sprout on each cube. It recommends covering the potatoes with a layer of compost and replacing the dirt on top of the plantings.\n\nBased on these passages, here are the steps to plant a sprouted potato:\n\n1. Cut the sprouted potato into chunks with two or three eyes each, using a sharp knife.\n2. Allow the cut ends to dry out in a cool, dark location overnight.\n3. Dig a trench about 4 inches wide and 6 to 8 inches deep in the planned planting area.\n4. Place the dried-out potato chunks into the bottom of the trench, separating each chunk by about 6 to 8 inches.\n5. Cover the potatoes with a layer of compost.\n6. Replace the dirt on top of the plantings.\n\nI hope this helps! Let me know if you have any further questions.", "response_spans": [[0, 485], [487, 730], [732, 1125], [1127, 1579], [1581, 1646]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.762562096118927, "(0, 16)": 0.762562096118927, "(2, 0)": 0.762562096118927, "(2, 16)": 0.762562096118927, "(4, 0)": 0.762562096118927, "(4, 16)": 0.762562096118927, "(6, 0)": 0.7431508302688599, "(6, 16)": 0.8880446553230286, "(8, 0)": 0.7431508302688599, "(8, 16)": 0.762562096118927, "(10, 0)": 0.383661687374115, "(10, 16)": 0.383661687374115, "(12, 0)": 0.762562096118927, "(12, 16)": 0.8880446553230286, "(14, 0)": 0.7431508302688599, "(14, 16)": 0.383661687374115, "(16, 0)": 0.8336358666419983, "(16, 16)": 0.762562096118927, "(18, 0)": 0.383661687374115, "(18, 16)": 0.8880446553230286, "(20, 0)": 0.8880446553230286, "(20, 16)": 0.762562096118927, "(22, 0)": 0.6386649012565613, "(22, 16)": 0.8880446553230286, "(24, 0)": 0.7431508302688599, "(24, 16)": 0.8880446553230286, "(26, 0)": 0.6386649012565613, "(26, 16)": 0.7061812877655029, "(28, 0)": 0.6386649012565613, "(28, 16)": 0.6386649012565613, "(30, 0)": 0.6386649012565613, "(30, 16)": 0.6386649012565613}, "r_span": [649, 766], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0017742514610290527}}, {"prompt_attention_score": {"(0, 0)": 0.684294581413269, "(0, 16)": 0.684294581413269, "(2, 0)": 0.684294581413269, "(2, 16)": 0.7279593348503113, "(4, 0)": 0.684294581413269, "(4, 16)": 0.684294581413269, "(6, 0)": 0.7279593348503113, "(6, 16)": 0.8949561715126038, "(8, 0)": 0.7279593348503113, "(8, 16)": 0.7279593348503113, "(10, 0)": 0.45020902156829834, "(10, 16)": 0.45020902156829834, "(12, 0)": 0.7279593348503113, "(12, 16)": 0.8949561715126038, "(14, 0)": 0.7279593348503113, "(14, 16)": 0.45020902156829834, "(16, 0)": 0.8949561715126038, "(16, 16)": 0.8949561715126038, "(18, 0)": 0.45020902156829834, "(18, 16)": 0.8949561715126038, "(20, 0)": 0.8949561715126038, "(20, 16)": 0.5952972769737244, "(22, 0)": 0.5952972769737244, "(22, 16)": 0.8949561715126038, "(24, 0)": 0.7279593348503113, "(24, 16)": 0.8949561715126038, "(26, 0)": 0.5952972769737244, "(26, 16)": 0.8949561715126038, "(28, 0)": 0.5952972769737244, "(28, 16)": 0.5952972769737244, "(30, 0)": 0.5952972769737244, "(30, 16)": 0.5952972769737244}, "r_span": [768, 822], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000345766544342041}}, {"prompt_attention_score": {"(0, 0)": 0.8379344940185547, "(0, 16)": 0.8379344940185547, "(2, 0)": 0.8379344940185547, "(2, 16)": 0.8379344940185547, "(4, 0)": 0.8379344940185547, "(4, 16)": 0.8379344940185547, "(6, 0)": 0.8379344940185547, "(6, 16)": 0.8274531364440918, "(8, 0)": 0.8274531364440918, "(8, 16)": 0.8379344940185547, "(10, 0)": 0.4328039884567261, "(10, 16)": 0.4328039884567261, "(12, 0)": 0.8379344940185547, "(12, 16)": 0.8379344940185547, "(14, 0)": 0.6463075280189514, "(14, 16)": 0.8379344940185547, "(16, 0)": 0.8379344940185547, "(16, 16)": 0.8379344940185547, "(18, 0)": 0.8379344940185547, "(18, 16)": 0.8379344940185547, "(20, 0)": 0.8379344940185547, "(20, 16)": 0.6463075280189514, "(22, 0)": 0.6463075280189514, "(22, 16)": 0.8274531364440918, "(24, 0)": 0.6463075280189514, "(24, 16)": 0.8379344940185547, "(26, 0)": 0.6463075280189514, "(26, 16)": 0.8274531364440918, "(28, 0)": 0.6463075280189514, "(28, 16)": 0.6463075280189514, "(30, 0)": 0.6463075280189514, "(30, 16)": 0.6463075280189514}, "r_span": [824, 919], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0017638802528381348}}, {"prompt_attention_score": {"(0, 0)": 0.8575671911239624, "(0, 16)": 0.8575671911239624, "(2, 0)": 0.8575671911239624, "(2, 16)": 0.8575671911239624, "(4, 0)": 0.8575671911239624, "(4, 16)": 0.8137352466583252, "(6, 0)": 0.8575671911239624, "(6, 16)": 0.8575671911239624, "(8, 0)": 0.8137352466583252, "(8, 16)": 0.6530075073242188, "(10, 0)": 0.8137352466583252, "(10, 16)": 0.8137352466583252, "(12, 0)": 0.6486550569534302, "(12, 16)": 0.8575671911239624, "(14, 0)": 0.6486550569534302, "(14, 16)": 0.8575671911239624, "(16, 0)": 0.8575671911239624, "(16, 16)": 0.6486550569534302, "(18, 0)": 0.34432125091552734, "(18, 16)": 0.8575671911239624, "(20, 0)": 0.8575671911239624, "(20, 16)": 0.8575671911239624, "(22, 0)": 0.6486550569534302, "(22, 16)": 0.8575671911239624, "(24, 0)": 0.8137352466583252, "(24, 16)": 0.8575671911239624, "(26, 0)": 0.6486550569534302, "(26, 16)": 0.6486550569534302, "(28, 0)": 0.6486550569534302, "(28, 16)": 0.6486550569534302, "(30, 0)": 0.6486550569534302, "(30, 16)": 0.6486550569534302}, "r_span": [921, 1055], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00022298097610473633}}, {"prompt_attention_score": {"(0, 0)": 0.4309041500091553, "(0, 16)": 0.4309041500091553, "(2, 0)": 0.4309041500091553, "(2, 16)": 0.5375855565071106, "(4, 0)": 0.5375855565071106, "(4, 16)": 0.5375855565071106, "(6, 0)": 0.5375855565071106, "(6, 16)": 0.49034902453422546, "(8, 0)": 0.4291536808013916, "(8, 16)": 0.4291536808013916, "(10, 0)": 0.5375855565071106, "(10, 16)": 0.5375855565071106, "(12, 0)": 0.5375855565071106, "(12, 16)": 0.5375855565071106, "(14, 0)": 0.4058873653411865, "(14, 16)": 0.5375855565071106, "(16, 0)": 0.5375855565071106, "(16, 16)": 0.4058873653411865, "(18, 0)": 0.5375855565071106, "(18, 16)": 0.5375855565071106, "(20, 0)": 0.5375855565071106, "(20, 16)": 0.4058873653411865, "(22, 0)": 0.4058873653411865, "(22, 16)": 0.5375855565071106, "(24, 0)": 0.4058873653411865, "(24, 16)": 0.5375855565071106, "(26, 0)": 0.4058873653411865, "(26, 16)": 0.4058873653411865, "(28, 0)": 0.4058873653411865, "(28, 16)": 0.4058873653411865, "(30, 0)": 0.4058873653411865, "(30, 16)": 0.4058873653411865}, "r_span": [1057, 1072], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00010991096496582031}}]}, {"id": "16893", "source_id": "12307", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the color of urine can indicate various things, including:\n\n* Blood in the urine (passage 1)\n* Porphyria (a rare inherited disorder) (passage 2)\n* Kidney diseases (passage 3)\n\nTherefore, the answer to the question \"What does the color of urine mean?\" is:\n\nAnswer: Depending on the passage, the color of urine can indicate different things, such as blood, porphyria, or kidney diseases.", "response_spans": [[0, 417]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.81773841381073, "(0, 16)": 0.81773841381073, "(2, 0)": 0.81773841381073, "(2, 16)": 0.81773841381073, "(4, 0)": 0.81773841381073, "(4, 16)": 0.81773841381073, "(6, 0)": 0.81773841381073, "(6, 16)": 0.8694486618041992, "(8, 0)": 0.81773841381073, "(8, 16)": 0.81773841381073, "(10, 0)": 0.81773841381073, "(10, 16)": 0.81773841381073, "(12, 0)": 0.81773841381073, "(12, 16)": 0.81773841381073, "(14, 0)": 0.8694486618041992, "(14, 16)": 0.81773841381073, "(16, 0)": 0.8694486618041992, "(16, 16)": 0.81773841381073, "(18, 0)": 0.81773841381073, "(18, 16)": 0.8694486618041992, "(20, 0)": 0.8694486618041992, "(20, 16)": 0.8694486618041992, "(22, 0)": 0.8694486618041992, "(22, 16)": 0.8694486618041992, "(24, 0)": 0.8694486618041992, "(24, 16)": 0.8694486618041992, "(26, 0)": 0.8694486618041992, "(26, 16)": 0.8374410271644592, "(28, 0)": 0.81773841381073, "(28, 16)": 0.81773841381073, "(30, 0)": 0.81773841381073, "(30, 16)": 0.8694486618041992}, "r_span": [317, 437], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001973092555999756}}]}, {"id": "16899", "source_id": "12308", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the steps to properly clean your hair:\n\n1. Rinse your hair completely with warm water, then use a wide-tooth comb to remove tangles and smooth the hair (Passage 1, step 6).\n2. Select the proper shampoo and conditioner for your hair type, and apply a nickel-sized amount of shampoo into the palm of your hand while in the shower (Passage 2, steps 1-3). Work the shampoo through your hair without piling it up on your head, and avoid tangling it while it's still wet.\n3. After applying shampoo, rinse your hair thoroughly with warm water, and then comb through it with your fingers to remove any remaining tangles (Passage 1, step 7).\n4. Apply a conditioner to your hair, allowing it to remain on for a few minutes before rinsing it out with cool water (Passage 1, step 8).\n5. To dry your hair, gently pat it with a towel or wrap it around your head to absorb excess water, avoiding rubbing it vigorously with a towel (Passage 3).\n\nUnable to answer based on given passages. The passages do not provide instructions on how to style or dry your hair after cleaning it.", "response_spans": [[0, 79], [81, 506], [507, 969], [971, 1105]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6865068674087524, "(0, 16)": 0.6865068674087524, "(2, 0)": 0.6865068674087524, "(2, 16)": 0.6865068674087524, "(4, 0)": 0.6865068674087524, "(4, 16)": 0.6865068674087524, "(6, 0)": 0.6865068674087524, "(6, 16)": 0.8208518028259277, "(8, 0)": 0.6865068674087524, "(8, 16)": 0.6865068674087524, "(10, 0)": 0.6865068674087524, "(10, 16)": 0.6865068674087524, "(12, 0)": 0.6865068674087524, "(12, 16)": 0.8208518028259277, "(14, 0)": 0.7282418012619019, "(14, 16)": 0.6865068674087524, "(16, 0)": 0.8208518028259277, "(16, 16)": 0.6865068674087524, "(18, 0)": 0.6865068674087524, "(18, 16)": 0.8208518028259277, "(20, 0)": 0.8208518028259277, "(20, 16)": 0.7282418012619019, "(22, 0)": 0.7282418012619019, "(22, 16)": 0.8208518028259277, "(24, 0)": 0.7282418012619019, "(24, 16)": 0.8208518028259277, "(26, 0)": 0.7282418012619019, "(26, 16)": 0.7282418012619019, "(28, 0)": 0.6865068674087524, "(28, 16)": 0.7282418012619019, "(30, 0)": 0.7282418012619019, "(30, 16)": 0.7282418012619019}, "r_span": [488, 506], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -3.2842159271240234e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7649452686309814, "(0, 16)": 0.7649452686309814, "(2, 0)": 0.7649452686309814, "(2, 16)": 0.7649452686309814, "(4, 0)": 0.7649452686309814, "(4, 16)": 0.7649452686309814, "(6, 0)": 0.7649452686309814, "(6, 16)": 0.8550252914428711, "(8, 0)": 0.7649452686309814, "(8, 16)": 0.7649452686309814, "(10, 0)": 0.7649452686309814, "(10, 16)": 0.7649452686309814, "(12, 0)": 0.8702765703201294, "(12, 16)": 0.8702765703201294, "(14, 0)": 0.8702765703201294, "(14, 16)": 0.7649452686309814, "(16, 0)": 0.8702765703201294, "(16, 16)": 0.8702765703201294, "(18, 0)": 0.7649452686309814, "(18, 16)": 0.8702765703201294, "(20, 0)": 0.8702765703201294, "(20, 16)": 0.8702765703201294, "(22, 0)": 0.8702765703201294, "(22, 16)": 0.8702765703201294, "(24, 0)": 0.8702765703201294, "(24, 16)": 0.8702765703201294, "(26, 0)": 0.8702765703201294, "(26, 16)": 0.8702765703201294, "(28, 0)": 0.8702765703201294, "(28, 16)": 0.8702765703201294, "(30, 0)": 0.8702765703201294, "(30, 16)": 0.8702765703201294}, "r_span": [508, 632], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0010532736778259277}}, {"prompt_attention_score": {"(0, 0)": 0.829721212387085, "(0, 16)": 0.829721212387085, "(2, 0)": 0.8037346601486206, "(2, 16)": 0.8037346601486206, "(4, 0)": 0.8037346601486206, "(4, 16)": 0.8037346601486206, "(6, 0)": 0.8037346601486206, "(6, 16)": 0.9023000001907349, "(8, 0)": 0.8037346601486206, "(8, 16)": 0.829721212387085, "(10, 0)": 0.8037346601486206, "(10, 16)": 0.8037346601486206, "(12, 0)": 0.8037346601486206, "(12, 16)": 0.8037346601486206, "(14, 0)": 0.829721212387085, "(14, 16)": 0.8037346601486206, "(16, 0)": 0.829721212387085, "(16, 16)": 0.829721212387085, "(18, 0)": 0.829721212387085, "(18, 16)": 0.9023000001907349, "(20, 0)": 0.9023000001907349, "(20, 16)": 0.829721212387085, "(22, 0)": 0.829721212387085, "(22, 16)": 0.8037346601486206, "(24, 0)": 0.829721212387085, "(24, 16)": 0.829721212387085, "(26, 0)": 0.829721212387085, "(26, 16)": 0.8037346601486206, "(28, 0)": 0.829721212387085, "(28, 16)": 0.829721212387085, "(30, 0)": 0.829721212387085, "(30, 16)": 0.829721212387085}, "r_span": [633, 761], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -6.133317947387695e-05}}, {"prompt_attention_score": {"(0, 0)": 0.7457820773124695, "(0, 16)": 0.7457820773124695, "(2, 0)": 0.8034883141517639, "(2, 16)": 0.8034883141517639, "(4, 0)": 0.8034883141517639, "(4, 16)": 0.8034883141517639, "(6, 0)": 0.8034883141517639, "(6, 16)": 0.8034883141517639, "(8, 0)": 0.8034883141517639, "(8, 16)": 0.8034883141517639, "(10, 0)": 0.8034883141517639, "(10, 16)": 0.8034883141517639, "(12, 0)": 0.8034883141517639, "(12, 16)": 0.8034883141517639, "(14, 0)": 0.7457820773124695, "(14, 16)": 0.8034883141517639, "(16, 0)": 0.8034883141517639, "(16, 16)": 0.7457820773124695, "(18, 0)": 0.7457820773124695, "(18, 16)": 0.8034883141517639, "(20, 0)": 0.8034883141517639, "(20, 16)": 0.7457820773124695, "(22, 0)": 0.7457820773124695, "(22, 16)": 0.8034883141517639, "(24, 0)": 0.7457820773124695, "(24, 16)": 0.8034883141517639, "(26, 0)": 0.7457820773124695, "(26, 16)": 0.7457820773124695, "(28, 0)": 0.7457820773124695, "(28, 16)": 0.7457820773124695, "(30, 0)": 0.7457820773124695, "(30, 16)": 0.7457820773124695}, "r_span": [763, 793], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00032269954681396484}}]}, {"id": "16905", "source_id": "12309", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways vinegar can be used for dogs:\n\n1. Rejuvenates the coat and helps balance skin pH levels (Passage 1)\n2. Improves skin and coat (Passage 2, point 1)\n3. Cleans the ears (Passage 2, points 2 and 3)\n4. Repels fleas (Passage 2, point 3)\n5. Fights fleas when bathed in an ACV-soap mixture (Passage 2, point 4)\n6. Soothes itchy ears (Passage 3)\n\nTherefore, the answer to the question \"What are some uses for vinegar on dogs?\" is:\n\nUses for vinegar on dogs:\n\n* Rejuvenates the coat and helps balance skin pH levels\n* Improves skin and coat\n* Cleans the ears\n* Repels fleas\n* Fights fleas when bathed in an ACV-soap mixture\n* Soothes itchy ears", "response_spans": [[0, 499], [501, 685]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8251869678497314, "(0, 16)": 0.8251869678497314, "(2, 0)": 0.8251869678497314, "(2, 16)": 0.8251869678497314, "(4, 0)": 0.8251869678497314, "(4, 16)": 0.8251869678497314, "(6, 0)": 0.8251869678497314, "(6, 16)": 0.876436710357666, "(8, 0)": 0.8251869678497314, "(8, 16)": 0.8251869678497314, "(10, 0)": 0.8251869678497314, "(10, 16)": 0.8251869678497314, "(12, 0)": 0.8251869678497314, "(12, 16)": 0.8316733837127686, "(14, 0)": 0.876436710357666, "(14, 16)": 0.8251869678497314, "(16, 0)": 0.876436710357666, "(16, 16)": 0.8251869678497314, "(18, 0)": 0.8251869678497314, "(18, 16)": 0.876436710357666, "(20, 0)": 0.876436710357666, "(20, 16)": 0.876436710357666, "(22, 0)": 0.876436710357666, "(22, 16)": 0.8316733837127686, "(24, 0)": 0.876436710357666, "(24, 16)": 0.8316733837127686, "(26, 0)": 0.876436710357666, "(26, 16)": 0.876436710357666, "(28, 0)": 0.876436710357666, "(28, 16)": 0.876436710357666, "(30, 0)": 0.876436710357666, "(30, 16)": 0.876436710357666}, "r_span": [393, 570], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.003915250301361084}}, {"prompt_attention_score": {"(0, 0)": 0.7251531481742859, "(0, 16)": 0.7570626139640808, "(2, 0)": 0.7251531481742859, "(2, 16)": 0.7570626139640808, "(4, 0)": 0.7251531481742859, "(4, 16)": 0.7251531481742859, "(6, 0)": 0.7570626139640808, "(6, 16)": 0.7570626139640808, "(8, 0)": 0.7570626139640808, "(8, 16)": 0.7570626139640808, "(10, 0)": 0.7251531481742859, "(10, 16)": 0.7251531481742859, "(12, 0)": 0.7127664089202881, "(12, 16)": 0.7570626139640808, "(14, 0)": 0.7127664089202881, "(14, 16)": 0.7251531481742859, "(16, 0)": 0.7127664089202881, "(16, 16)": 0.7127664089202881, "(18, 0)": 0.7127664089202881, "(18, 16)": 0.7127664089202881, "(20, 0)": 0.7570626139640808, "(20, 16)": 0.7127664089202881, "(22, 0)": 0.7127664089202881, "(22, 16)": 0.7570626139640808, "(24, 0)": 0.7127664089202881, "(24, 16)": 0.7570626139640808, "(26, 0)": 0.7127664089202881, "(26, 16)": 0.7127664089202881, "(28, 0)": 0.7127664089202881, "(28, 16)": 0.7127664089202881, "(30, 0)": 0.7127664089202881, "(30, 16)": 0.7127664089202881}, "r_span": [572, 630], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00046753883361816406}}]}, {"id": "16935", "source_id": "12314", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are the answers to the question \"What happens when you breathe in and out?\":\n\nWhen you breathe in (inspiration):\n\n* The intercostal muscles contract, expanding the ribcage.\n* The diaphragm contracts, pulling downwards to increase the volume of the chest.\n* Pressure inside the chest is lowered and air is sucked into the lungs.\n\nWhen you breathe out (exhalation):\n\n* Your diaphragm relaxes and moves upward into the chest cavity.\n* The intercostal muscles between the ribs also relax to reduce the space in the chest cavity.\n* Air rich in carbon dioxide is forced out of your lungs and windpipe, and then out of your nose or mouth.\n\nTherefore, when you breathe in, the lungs take in oxygen-rich air, and when you breathe out, the lungs expel carbon dioxide-rich air.", "response_spans": [[0, 400], [402, 803]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7835004925727844, "(0, 16)": 0.7835004925727844, "(2, 0)": 0.7835004925727844, "(2, 16)": 0.7835004925727844, "(4, 0)": 0.7835004925727844, "(4, 16)": 0.7835004925727844, "(6, 0)": 0.7835004925727844, "(6, 16)": 0.8212960362434387, "(8, 0)": 0.7835004925727844, "(8, 16)": 0.7835004925727844, "(10, 0)": 0.7835004925727844, "(10, 16)": 0.7835004925727844, "(12, 0)": 0.7835004925727844, "(12, 16)": 0.8656255006790161, "(14, 0)": 0.7835004925727844, "(14, 16)": 0.8212960362434387, "(16, 0)": 0.7472133636474609, "(16, 16)": 0.8212960362434387, "(18, 0)": 0.7835004925727844, "(18, 16)": 0.8656255006790161, "(20, 0)": 0.8656255006790161, "(20, 16)": 0.7835004925727844, "(22, 0)": 0.8212960362434387, "(22, 16)": 0.8212960362434387, "(24, 0)": 0.8212960362434387, "(24, 16)": 0.8212960362434387, "(26, 0)": 0.8212960362434387, "(26, 16)": 0.8212960362434387, "(28, 0)": 0.8212960362434387, "(28, 16)": 0.8212960362434387, "(30, 0)": 0.8212960362434387, "(30, 16)": 0.8212960362434387}, "r_span": [388, 504], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0024776458740234375}}, {"prompt_attention_score": {"(0, 0)": 0.77585768699646, "(0, 16)": 0.77585768699646, "(2, 0)": 0.77585768699646, "(2, 16)": 0.77585768699646, "(4, 0)": 0.77585768699646, "(4, 16)": 0.77585768699646, "(6, 0)": 0.77585768699646, "(6, 16)": 0.9184476137161255, "(8, 0)": 0.77585768699646, "(8, 16)": 0.77585768699646, "(10, 0)": 0.77585768699646, "(10, 16)": 0.77585768699646, "(12, 0)": 0.77585768699646, "(12, 16)": 0.9184476137161255, "(14, 0)": 0.77585768699646, "(14, 16)": 0.77585768699646, "(16, 0)": 0.9184476137161255, "(16, 16)": 0.9184476137161255, "(18, 0)": 0.9184476137161255, "(18, 16)": 0.9184476137161255, "(20, 0)": 0.9184476137161255, "(20, 16)": 0.9184476137161255, "(22, 0)": 0.9184476137161255, "(22, 16)": 0.9184476137161255, "(24, 0)": 0.77585768699646, "(24, 16)": 0.9184476137161255, "(26, 0)": 0.9184476137161255, "(26, 16)": 0.9184476137161255, "(28, 0)": 0.9184476137161255, "(28, 16)": 0.77585768699646, "(30, 0)": 0.9184476137161255, "(30, 16)": 0.9184476137161255}, "r_span": [506, 623], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0003020763397216797}}]}, {"id": "17055", "source_id": "12334", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's my answer to the question:\n\nThe weighted average method of costing inventory assigns an average cost to each piece of inventory when it is sold. When a unit of inventory is sold, the weighted average method takes the average cost of all inventories currently available and assigns that average price to the item sold. Since inventory prices fluctuate, the weighted average cost will also change.\n\nTo calculate the weighted average cost per unit, divide the cost of goods available for sale by the number of units available for sale. The weighted-average figure can then be used to assign costs to both ending inventory and cost of goods sold. The recorded amount of inventory on hand using the weighted average costing method represents a value between the oldest and newest units purchased into stock.\n\nWeighted average costing is commonly used in situations where inventory items are intermingled and it is impossible to assign a specific cost to an individual unit, or when the accounting system is not sophisticated enough to track FIFO or LIFO inventory layers.", "response_spans": [[0, 408], [410, 815], [817, 1079]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9267607927322388, "(0, 16)": 0.9267607927322388, "(2, 0)": 0.9267607927322388, "(2, 16)": 0.9267607927322388, "(4, 0)": 0.9267607927322388, "(4, 16)": 0.9267607927322388, "(6, 0)": 0.9267607927322388, "(6, 16)": 0.9408198595046997, "(8, 0)": 0.7773536443710327, "(8, 16)": 0.422347754240036, "(10, 0)": 0.422347754240036, "(10, 16)": 0.9267607927322388, "(12, 0)": 0.8591616153717041, "(12, 16)": 0.9408198595046997, "(14, 0)": 0.9408198595046997, "(14, 16)": 0.9267607927322388, "(16, 0)": 0.818378210067749, "(16, 16)": 0.9408198595046997, "(18, 0)": 0.422347754240036, "(18, 16)": 0.9408198595046997, "(20, 0)": 0.9408198595046997, "(20, 16)": 0.7773536443710327, "(22, 0)": 0.9408198595046997, "(22, 16)": 0.9408198595046997, "(24, 0)": 0.7773536443710327, "(24, 16)": 0.9408198595046997, "(26, 0)": 0.9408198595046997, "(26, 16)": 0.9408198595046997, "(28, 0)": 0.9408198595046997, "(28, 16)": 0.7773536443710327, "(30, 0)": 0.7773536443710327, "(30, 16)": 0.9408198595046997}, "r_span": [589, 681], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002579808235168457}}, {"prompt_attention_score": {"(0, 0)": 0.8933944702148438, "(0, 16)": 0.8933944702148438, "(2, 0)": 0.8933944702148438, "(2, 16)": 0.41410985589027405, "(4, 0)": 0.8933944702148438, "(4, 16)": 0.8933944702148438, "(6, 0)": 0.8933944702148438, "(6, 16)": 0.9223744869232178, "(8, 0)": 0.7845607399940491, "(8, 16)": 0.7845607399940491, "(10, 0)": 0.7845607399940491, "(10, 16)": 0.8933944702148438, "(12, 0)": 0.7845607399940491, "(12, 16)": 0.9223744869232178, "(14, 0)": 0.7845607399940491, "(14, 16)": 0.8933944702148438, "(16, 0)": 0.9223744869232178, "(16, 16)": 0.8615680932998657, "(18, 0)": 0.8615680932998657, "(18, 16)": 0.9223744869232178, "(20, 0)": 0.9223744869232178, "(20, 16)": 0.7845607399940491, "(22, 0)": 0.8615680932998657, "(22, 16)": 0.7845607399940491, "(24, 0)": 0.7845607399940491, "(24, 16)": 0.9223744869232178, "(26, 0)": 0.8615680932998657, "(26, 16)": 0.8615680932998657, "(28, 0)": 0.7845607399940491, "(28, 16)": 0.7845607399940491, "(30, 0)": 0.7845607399940491, "(30, 16)": 0.8615680932998657}, "r_span": [683, 765], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.001128852367401123}}, {"prompt_attention_score": {"(0, 0)": 0.7949733138084412, "(0, 16)": 0.7949733138084412, "(2, 0)": 0.7949733138084412, "(2, 16)": 0.7949733138084412, "(4, 0)": 0.7949733138084412, "(4, 16)": 0.7949733138084412, "(6, 0)": 0.8261914253234863, "(6, 16)": 0.8261914253234863, "(8, 0)": 0.8261914253234863, "(8, 16)": 0.8261914253234863, "(10, 0)": 0.8261914253234863, "(10, 16)": 0.7949733138084412, "(12, 0)": 0.7949733138084412, "(12, 16)": 0.8261914253234863, "(14, 0)": 0.8261914253234863, "(14, 16)": 0.8261914253234863, "(16, 0)": 0.8261914253234863, "(16, 16)": 0.8261914253234863, "(18, 0)": 0.8261914253234863, "(18, 16)": 0.8261914253234863, "(20, 0)": 0.8261914253234863, "(20, 16)": 0.8261914253234863, "(22, 0)": 0.7734242677688599, "(22, 16)": 0.8261914253234863, "(24, 0)": 0.8261914253234863, "(24, 16)": 0.8261914253234863, "(26, 0)": 0.7734242677688599, "(26, 16)": 0.8261914253234863, "(28, 0)": 0.8261914253234863, "(28, 16)": 0.8261914253234863, "(30, 0)": 0.8261914253234863, "(30, 16)": 0.7734242677688599}, "r_span": [767, 823], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0013783574104309082}}]}, {"id": "17061", "source_id": "12335", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some benefits and side effects of drinking clove tea:\n\nBenefits:\n\n* Relieves stress and anxiety (Passage 1)\n* Provides relief from muscle, joint, or ligament injuries (Passage 2)\n* Soothes abdominal pain (Passage 3)\n* Stimulates blood flow, saliva production, and gastric secretions to aid in digestion (Passage 3)\n\nSide Effects:\n\n* Unknown (no passage mentions any potential side effects)\n\nTherefore, based on the provided passages, it appears that drinking clove tea may have several benefits, including relieving stress and abdominal pain, and aiding in digestion. However, there is no mention of any potential side effects in the given passages.", "response_spans": [[0, 430], [432, 690]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8452743887901306, "(0, 16)": 0.8452743887901306, "(2, 0)": 0.8452743887901306, "(2, 16)": 0.8452743887901306, "(4, 0)": 0.8452743887901306, "(4, 16)": 0.8452743887901306, "(6, 0)": 0.8452743887901306, "(6, 16)": 0.8915024995803833, "(8, 0)": 0.8452743887901306, "(8, 16)": 0.8452743887901306, "(10, 0)": 0.8452743887901306, "(10, 16)": 0.8452743887901306, "(12, 0)": 0.8452743887901306, "(12, 16)": 0.8452743887901306, "(14, 0)": 0.7710829377174377, "(14, 16)": 0.8452743887901306, "(16, 0)": 0.8915024995803833, "(16, 16)": 0.8452743887901306, "(18, 0)": 0.8452743887901306, "(18, 16)": 0.8452743887901306, "(20, 0)": 0.8452743887901306, "(20, 16)": 0.7710829377174377, "(22, 0)": 0.8452743887901306, "(22, 16)": 0.8915024995803833, "(24, 0)": 0.8452743887901306, "(24, 16)": 0.8452743887901306, "(26, 0)": 0.8915024995803833, "(26, 16)": 0.8452743887901306, "(28, 0)": 0.8452743887901306, "(28, 16)": 0.8452743887901306, "(30, 0)": 0.8452743887901306, "(30, 16)": 0.8452743887901306}, "r_span": [344, 473], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.000433504581451416}}, {"prompt_attention_score": {"(0, 0)": 0.8422562479972839, "(0, 16)": 0.8422562479972839, "(2, 0)": 0.8422562479972839, "(2, 16)": 0.8422562479972839, "(4, 0)": 0.8422562479972839, "(4, 16)": 0.8422562479972839, "(6, 0)": 0.8422562479972839, "(6, 16)": 0.8724578619003296, "(8, 0)": 0.8724578619003296, "(8, 16)": 0.8422562479972839, "(10, 0)": 0.8422562479972839, "(10, 16)": 0.8422562479972839, "(12, 0)": 0.8422562479972839, "(12, 16)": 0.8422562479972839, "(14, 0)": 0.7616071701049805, "(14, 16)": 0.8422562479972839, "(16, 0)": 0.8724578619003296, "(16, 16)": 0.8422562479972839, "(18, 0)": 0.8422562479972839, "(18, 16)": 0.8422562479972839, "(20, 0)": 0.8422562479972839, "(20, 16)": 0.7616071701049805, "(22, 0)": 0.8724578619003296, "(22, 16)": 0.8724578619003296, "(24, 0)": 0.8724578619003296, "(24, 16)": 0.8422562479972839, "(26, 0)": 0.8724578619003296, "(26, 16)": 0.8422562479972839, "(28, 0)": 0.8422562479972839, "(28, 16)": 0.8724578619003296, "(30, 0)": 0.8724578619003296, "(30, 16)": 0.8724578619003296}, "r_span": [475, 532], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005710721015930176}}]}, {"id": "17103", "source_id": "12342", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here are some ways to get free VoIP service and phone numbers:\n\n1. Free DID (incoming numbers) from around the world: There are several companies offering free or paid VoIP services that provide incoming numbers from around the world. These numbers can be obtained by signing up for a VoIP service provider and paying a flat yearly rate or monthly fee.\n2. Get a free Virtual Phone Number (VOIP) from Google: According to the passage, Google offers free virtual phone numbers that can be used to place and receive calls using the internet. To get a free number, visit the author's YouTube channel and follow the instructions provided.\n3. Cloud VoIP Service: The passage mentions a cloud VoIP service that provides toll-free numbers and US local numbers that can be forwarded to any US number (including cell phones) or used with a SIP device. While there is no direct mention of free service, the passage does indicate that the pricing has been lowered.\n\nUnable to answer based on given passages. None of the passages provide detailed information on how to get free VoIP service and phone numbers without any additional costs or requirements.", "response_spans": [[0, 94], [96, 384], [385, 665], [666, 984], [986, 1173]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7084197402000427, "(0, 16)": 0.7084197402000427, "(2, 0)": 0.7084197402000427, "(2, 16)": 0.7084197402000427, "(4, 0)": 0.7084197402000427, "(4, 16)": 0.7084197402000427, "(6, 0)": 0.7084197402000427, "(6, 16)": 0.8280775547027588, "(8, 0)": 0.7084197402000427, "(8, 16)": 0.5337308645248413, "(10, 0)": 0.5337308645248413, "(10, 16)": 0.5337308645248413, "(12, 0)": 0.5337308645248413, "(12, 16)": 0.8280775547027588, "(14, 0)": 0.7084197402000427, "(14, 16)": 0.5337308645248413, "(16, 0)": 0.8280775547027588, "(16, 16)": 0.7084197402000427, "(18, 0)": 0.5337308645248413, "(18, 16)": 0.8280775547027588, "(20, 0)": 0.8280775547027588, "(20, 16)": 0.7084197402000427, "(22, 0)": 0.7574131488800049, "(22, 16)": 0.8280775547027588, "(24, 0)": 0.7084197402000427, "(24, 16)": 0.7574131488800049, "(26, 0)": 0.7574131488800049, "(26, 16)": 0.7574131488800049, "(28, 0)": 0.5337308645248413, "(28, 16)": 0.7084197402000427, "(30, 0)": 0.7574131488800049, "(30, 16)": 0.7574131488800049}, "r_span": [598, 620], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001245737075805664}}, {"prompt_attention_score": {"(0, 0)": 0.6958167552947998, "(0, 16)": 0.6958167552947998, "(2, 0)": 0.6958167552947998, "(2, 16)": 0.6958167552947998, "(4, 0)": 0.6958167552947998, "(4, 16)": 0.6958167552947998, "(6, 0)": 0.6958167552947998, "(6, 16)": 0.8678263425827026, "(8, 0)": 0.6958167552947998, "(8, 16)": 0.6958167552947998, "(10, 0)": 0.8678263425827026, "(10, 16)": 0.6958167552947998, "(12, 0)": 0.6958167552947998, "(12, 16)": 0.8678263425827026, "(14, 0)": 0.6958167552947998, "(14, 16)": 0.8678263425827026, "(16, 0)": 0.8678263425827026, "(16, 16)": 0.6958167552947998, "(18, 0)": 0.8678263425827026, "(18, 16)": 0.8678263425827026, "(20, 0)": 0.8678263425827026, "(20, 16)": 0.6958167552947998, "(22, 0)": 0.8678263425827026, "(22, 16)": 0.8678263425827026, "(24, 0)": 0.6958167552947998, "(24, 16)": 0.8678263425827026, "(26, 0)": 0.8678263425827026, "(26, 16)": 0.8678263425827026, "(28, 0)": 0.8678263425827026, "(28, 16)": 0.6958167552947998, "(30, 0)": 0.8678263425827026, "(30, 16)": 0.8678263425827026}, "r_span": [622, 684], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0023707151412963867}}, {"prompt_attention_score": {"(0, 0)": 0.660642147064209, "(0, 16)": 0.660642147064209, "(2, 0)": 0.660642147064209, "(2, 16)": 0.6546107530593872, "(4, 0)": 0.660642147064209, "(4, 16)": 0.660642147064209, "(6, 0)": 0.660642147064209, "(6, 16)": 0.8231599926948547, "(8, 0)": 0.660642147064209, "(8, 16)": 0.660642147064209, "(10, 0)": 0.660642147064209, "(10, 16)": 0.660642147064209, "(12, 0)": 0.660642147064209, "(12, 16)": 0.8231599926948547, "(14, 0)": 0.660642147064209, "(14, 16)": 0.4243478775024414, "(16, 0)": 0.8231599926948547, "(16, 16)": 0.660642147064209, "(18, 0)": 0.6714563369750977, "(18, 16)": 0.8231599926948547, "(20, 0)": 0.8231599926948547, "(20, 16)": 0.660642147064209, "(22, 0)": 0.6714563369750977, "(22, 16)": 0.8231599926948547, "(24, 0)": 0.660642147064209, "(24, 16)": 0.8231599926948547, "(26, 0)": 0.6714563369750977, "(26, 16)": 0.6714563369750977, "(28, 0)": 0.6714563369750977, "(28, 16)": 0.660642147064209, "(30, 0)": 0.6714563369750977, "(30, 16)": 0.6714563369750977}, "r_span": [685, 743], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0001932382583618164}}, {"prompt_attention_score": {"(0, 0)": 0.8964605331420898, "(0, 16)": 0.8964605331420898, "(2, 0)": 0.8964605331420898, "(2, 16)": 0.8964605331420898, "(4, 0)": 0.8964605331420898, "(4, 16)": 0.8964605331420898, "(6, 0)": 0.8964605331420898, "(6, 16)": 0.8964605331420898, "(8, 0)": 0.8964605331420898, "(8, 16)": 0.8964605331420898, "(10, 0)": 0.8964605331420898, "(10, 16)": 0.8964605331420898, "(12, 0)": 0.8964605331420898, "(12, 16)": 0.8964605331420898, "(14, 0)": 0.8964605331420898, "(14, 16)": 0.4212803244590759, "(16, 0)": 0.8964605331420898, "(16, 16)": 0.4212803244590759, "(18, 0)": 0.4212803244590759, "(18, 16)": 0.8964605331420898, "(20, 0)": 0.8964605331420898, "(20, 16)": 0.8964605331420898, "(22, 0)": 0.7329815626144409, "(22, 16)": 0.8964605331420898, "(24, 0)": 0.8964605331420898, "(24, 16)": 0.8964605331420898, "(26, 0)": 0.7329815626144409, "(26, 16)": 0.8964605331420898, "(28, 0)": 0.7329815626144409, "(28, 16)": 0.8964605331420898, "(30, 0)": 0.7329815626144409, "(30, 16)": 0.7329815626144409}, "r_span": [744, 816], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018805861473083496}}, {"prompt_attention_score": {"(0, 0)": 0.740405797958374, "(0, 16)": 0.740405797958374, "(2, 0)": 0.740405797958374, "(2, 16)": 0.740405797958374, "(4, 0)": 0.740405797958374, "(4, 16)": 0.740405797958374, "(6, 0)": 0.740405797958374, "(6, 16)": 0.8098602294921875, "(8, 0)": 0.740405797958374, "(8, 16)": 0.740405797958374, "(10, 0)": 0.7260656356811523, "(10, 16)": 0.7260656356811523, "(12, 0)": 0.7260656356811523, "(12, 16)": 0.7260656356811523, "(14, 0)": 0.740405797958374, "(14, 16)": 0.7260656356811523, "(16, 0)": 0.7260656356811523, "(16, 16)": 0.740405797958374, "(18, 0)": 0.740405797958374, "(18, 16)": 0.8098602294921875, "(20, 0)": 0.8098602294921875, "(20, 16)": 0.740405797958374, "(22, 0)": 0.7410808801651001, "(22, 16)": 0.7260656356811523, "(24, 0)": 0.740405797958374, "(24, 16)": 0.7260656356811523, "(26, 0)": 0.7410808801651001, "(26, 16)": 0.7410808801651001, "(28, 0)": 0.7410808801651001, "(28, 16)": 0.7410808801651001, "(30, 0)": 0.7410808801651001, "(30, 16)": 0.7410808801651001}, "r_span": [818, 854], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00040656328201293945}}]}, {"id": "17115", "source_id": "12344", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the cost of replacing a sewer line in Michigan can vary widely depending on the extent of the damage, the location of the pipe, and the accessibility of the area. According to passage 2, the cost of a pipe camera inspection to determine the extent of the damage can range from $250 to $500. The cost of repairing a damaged section of pipe can range from $50 per foot to almost double the price or more, depending on the severity of the damage. In extreme cases where the entire sewer line needs to be replaced, the cost can range from $3,000 to $12,000. Therefore, the total cost of replacing a sewer line in Michigan can range from a few thousand dollars to over $12,000.\n\nUnable to answer based on given passages.", "response_spans": [[0, 509], [493, 704], [706, 747]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.3968029022216797, "(0, 16)": 0.3968029022216797, "(2, 0)": 0.3968029022216797, "(2, 16)": 0.3968029022216797, "(4, 0)": 0.3968029022216797, "(4, 16)": 0.3968029022216797, "(6, 0)": 0.3968029022216797, "(6, 16)": 0.8567688465118408, "(8, 0)": 0.8567688465118408, "(8, 16)": 0.3968029022216797, "(10, 0)": 0.3968029022216797, "(10, 16)": 0.3968029022216797, "(12, 0)": 0.3968029022216797, "(12, 16)": 0.8567688465118408, "(14, 0)": 0.3968029022216797, "(14, 16)": 0.3968029022216797, "(16, 0)": 0.7590222358703613, "(16, 16)": 0.3968029022216797, "(18, 0)": 0.3968029022216797, "(18, 16)": 0.8567688465118408, "(20, 0)": 0.8567688465118408, "(20, 16)": 0.3968029022216797, "(22, 0)": 0.7590222358703613, "(22, 16)": 0.8567688465118408, "(24, 0)": 0.3968029022216797, "(24, 16)": 0.8567688465118408, "(26, 0)": 0.7590222358703613, "(26, 16)": 0.7590222358703613, "(28, 0)": 0.7590222358703613, "(28, 16)": 0.7590222358703613, "(30, 0)": 0.7590222358703613, "(30, 16)": 0.7590222358703613}, "r_span": [444, 563], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 8.243322372436523e-05}}, {"prompt_attention_score": {"(0, 0)": 0.36654168367385864, "(0, 16)": 0.36654168367385864, "(2, 0)": 0.36654168367385864, "(2, 16)": 0.36654168367385864, "(4, 0)": 0.36654168367385864, "(4, 16)": 0.36654168367385864, "(6, 0)": 0.36654168367385864, "(6, 16)": 0.8840159773826599, "(8, 0)": 0.8840159773826599, "(8, 16)": 0.36654168367385864, "(10, 0)": 0.36654168367385864, "(10, 16)": 0.36654168367385864, "(12, 0)": 0.36654168367385864, "(12, 16)": 0.8840159773826599, "(14, 0)": 0.36654168367385864, "(14, 16)": 0.36654168367385864, "(16, 0)": 0.36654168367385864, "(16, 16)": 0.36654168367385864, "(18, 0)": 0.36654168367385864, "(18, 16)": 0.8840159773826599, "(20, 0)": 0.8840159773826599, "(20, 16)": 0.36654168367385864, "(22, 0)": 0.8436037302017212, "(22, 16)": 0.8840159773826599, "(24, 0)": 0.36654168367385864, "(24, 16)": 0.8436037302017212, "(26, 0)": 0.36654168367385864, "(26, 16)": 0.8436037302017212, "(28, 0)": 0.36654168367385864, "(28, 16)": 0.36654168367385864, "(30, 0)": 0.8436037302017212, "(30, 16)": 0.8436037302017212}, "r_span": [561, 621], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00017768144607543945}}, {"prompt_attention_score": {"(0, 0)": 0.6218137145042419, "(0, 16)": 0.6218137145042419, "(2, 0)": 0.6218137145042419, "(2, 16)": 0.6218137145042419, "(4, 0)": 0.6218137145042419, "(4, 16)": 0.6218137145042419, "(6, 0)": 0.6218137145042419, "(6, 16)": 0.6218137145042419, "(8, 0)": 0.4869736433029175, "(8, 16)": 0.6218137145042419, "(10, 0)": 0.6218137145042419, "(10, 16)": 0.6218137145042419, "(12, 0)": 0.6218137145042419, "(12, 16)": 0.6218137145042419, "(14, 0)": 0.4282902181148529, "(14, 16)": 0.6218137145042419, "(16, 0)": 0.6218137145042419, "(16, 16)": 0.6218137145042419, "(18, 0)": 0.6218137145042419, "(18, 16)": 0.6218137145042419, "(20, 0)": 0.6218137145042419, "(20, 16)": 0.4282902181148529, "(22, 0)": 0.4282902181148529, "(22, 16)": 0.6218137145042419, "(24, 0)": 0.6218137145042419, "(24, 16)": 0.6218137145042419, "(26, 0)": 0.6218137145042419, "(26, 16)": 0.6218137145042419, "(28, 0)": 0.4282902181148529, "(28, 16)": 0.4282902181148529, "(30, 0)": 0.4282902181148529, "(30, 16)": 0.4282902181148529}, "r_span": [623, 633], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00042688846588134766}}]}, {"id": "17199", "source_id": "12358", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [{"start": 32, "end": 123, "text": "it appears that watching Snapchat stories does indeed increase one's score on the platform.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \" it appears that watching Snapchat stories does indeed increase one's score on the platform.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}, {"start": 642, "end": 791, "text": "In conclusion, the answer to the question \"Does watching Snapchat stories increase score?\" is yes, based on the information provided in the passages.", "meta": "HIGH INTRODUCTION OF NEW INFORMATION\nOriginal: *not mentioned*\nGenerative: \"In conclusion, the answer to the question \"Does watching Snapchat stories increase score?\" is yes, based on the information provided in the passages.\"", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, it appears that watching Snapchat stories does indeed increase one's score on the platform. According to Passage 2, every user on Snapchat has a score tethered to their activity, which is calculated based on the number of snaps sent and received. Passage 3 specifically states that sending and receiving snaps is the primary way to increase one's score, and suggests that adding more friends and increasing Snapchat interaction can also help boost one's score. Therefore, actively engaging with Snapchat stories and content by watching and interacting with them can help increase one's score on the platform.\n\nIn conclusion, the answer to the question \"Does watching Snapchat stories increase score?\" is yes, based on the information provided in the passages.", "response_spans": [[0, 512], [493, 640], [642, 791]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.9026398658752441, "(0, 16)": 0.9026398658752441, "(2, 0)": 0.9026398658752441, "(2, 16)": 0.9026398658752441, "(4, 0)": 0.9026398658752441, "(4, 16)": 0.9026398658752441, "(6, 0)": 0.9026398658752441, "(6, 16)": 0.9134935140609741, "(8, 0)": 0.9026398658752441, "(8, 16)": 0.9026398658752441, "(10, 0)": 0.5111105442047119, "(10, 16)": 0.9026398658752441, "(12, 0)": 0.9026398658752441, "(12, 16)": 0.9134935140609741, "(14, 0)": 0.9026398658752441, "(14, 16)": 0.5111105442047119, "(16, 0)": 0.9026398658752441, "(16, 16)": 0.8889683485031128, "(18, 0)": 0.8889683485031128, "(18, 16)": 0.9026398658752441, "(20, 0)": 0.9026398658752441, "(20, 16)": 0.8889683485031128, "(22, 0)": 0.8889683485031128, "(22, 16)": 0.9134935140609741, "(24, 0)": 0.8889683485031128, "(24, 16)": 0.9026398658752441, "(26, 0)": 0.8889683485031128, "(26, 16)": 0.8889683485031128, "(28, 0)": 0.8889683485031128, "(28, 16)": 0.8889683485031128, "(30, 0)": 0.8889683485031128, "(30, 16)": 0.8889683485031128}, "r_span": [505, 617], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0019202232360839844}}, {"prompt_attention_score": {"(0, 0)": 0.7596496939659119, "(0, 16)": 0.7596496939659119, "(2, 0)": 0.7596496939659119, "(2, 16)": 0.7596496939659119, "(4, 0)": 0.7596496939659119, "(4, 16)": 0.7596496939659119, "(6, 0)": 0.7596496939659119, "(6, 16)": 0.7661375999450684, "(8, 0)": 0.7596496939659119, "(8, 16)": 0.7596496939659119, "(10, 0)": 0.7596496939659119, "(10, 16)": 0.7596496939659119, "(12, 0)": 0.7661375999450684, "(12, 16)": 0.7661375999450684, "(14, 0)": 0.7661375999450684, "(14, 16)": 0.40955573320388794, "(16, 0)": 0.7661375999450684, "(16, 16)": 0.7661375999450684, "(18, 0)": 0.7661375999450684, "(18, 16)": 0.7661375999450684, "(20, 0)": 0.7657936811447144, "(20, 16)": 0.7661375999450684, "(22, 0)": 0.7661375999450684, "(22, 16)": 0.7661375999450684, "(24, 0)": 0.7661375999450684, "(24, 16)": 0.7661375999450684, "(26, 0)": 0.7661375999450684, "(26, 16)": 0.7661375999450684, "(28, 0)": 0.7661375999450684, "(28, 16)": 0.7661375999450684, "(30, 0)": 0.7661375999450684, "(30, 16)": 0.7661375999450684}, "r_span": [614, 644], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0003763437271118164}}, {"prompt_attention_score": {"(0, 0)": 0.7543789148330688, "(0, 16)": 0.7543789148330688, "(2, 0)": 0.7543789148330688, "(2, 16)": 0.5941528081893921, "(4, 0)": 0.5941528081893921, "(4, 16)": 0.5941528081893921, "(6, 0)": 0.7543789148330688, "(6, 16)": 0.8741865158081055, "(8, 0)": 0.7543789148330688, "(8, 16)": 0.7543789148330688, "(10, 0)": 0.5941528081893921, "(10, 16)": 0.5941528081893921, "(12, 0)": 0.5941528081893921, "(12, 16)": 0.5941528081893921, "(14, 0)": 0.7325694561004639, "(14, 16)": 0.5941528081893921, "(16, 0)": 0.8741865158081055, "(16, 16)": 0.7325694561004639, "(18, 0)": 0.7325694561004639, "(18, 16)": 0.8741865158081055, "(20, 0)": 0.8741865158081055, "(20, 16)": 0.7325694561004639, "(22, 0)": 0.7325694561004639, "(22, 16)": 0.8741865158081055, "(24, 0)": 0.7325694561004639, "(24, 16)": 0.5941528081893921, "(26, 0)": 0.7325694561004639, "(26, 16)": 0.7325694561004639, "(28, 0)": 0.7325694561004639, "(28, 16)": 0.7325694561004639, "(30, 0)": 0.7325694561004639, "(30, 16)": 0.7325694561004639}, "r_span": [646, 677], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0009581446647644043}}]}, {"id": "17235", "source_id": "12364", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, here is how you can make ice cream:\n\nPassage 1 provides instructions for making ice cream using an ice cream maker. To make ice cream, pour cold ice cream mix into the ice cream maker, turn on the machine, and churn according to the manufacturer's directions (usually 20-25 minutes). Once the ice cream is softly frozen, you can serve it immediately or place a piece of plastic wrap directly on the ice cream and place it in the freezer for 2-3 hours to ripen.\n\nPassage 2 provides a recipe for making ice cream from scratch. To make ice cream, stir sugar, cream, and milk together in a saucepan over low heat until the sugar has dissolved. Then, heat the mixture until a small ring of foam appears around the edges. Transfer the mixture to a pourable container such as a large measuring cup and stir in vanilla extract. Chill the mixture thoroughly for at least 2 hours before serving.\n\nPassage 3 provides general instructions for making ice cream bases. To make ice cream, you will need to start with a good vanilla ice cream base. This type of base is made with cream rather than custard, and it results in a lighter and less icy texture. To make one quart of ice cream, you will need to double the recipe.\n\nTherefore, to summarize:\n\nTo make ice cream using an ice cream maker:\n\n1. Pour cold ice cream mix into the ice cream maker and turn on the machine.\n2. Churn the ice cream according to the manufacturer's directions (usually 20-25 minutes).\n3. Serve the ice cream immediately or place it in the freezer for 2-3 hours to ripen.\n\nTo make ice cream from scratch:\n\n1. Stir sugar, cream, and milk together in a saucepan over low heat until the sugar has dissolved.\n2. Heat the mixture until a small ring of foam appears around the edges.\n3. Transfer the mixture to a pourable container and stir in vanilla extract.\n4. Chill the mixture thoroughly for at least 2 hours before serving.\n", "response_spans": [[0, 492], [494, 917], [919, 1311], [1313, 1599], [1601, 1918]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7688815593719482, "(0, 16)": 0.7688815593719482, "(2, 0)": 0.7688815593719482, "(2, 16)": 0.7688815593719482, "(4, 0)": 0.7688815593719482, "(4, 16)": 0.7688815593719482, "(6, 0)": 0.7688815593719482, "(6, 16)": 0.9675011038780212, "(8, 0)": 0.9675011038780212, "(8, 16)": 0.7688815593719482, "(10, 0)": 0.7688815593719482, "(10, 16)": 0.7688815593719482, "(12, 0)": 0.9675011038780212, "(12, 16)": 0.9675011038780212, "(14, 0)": 0.9675011038780212, "(14, 16)": 0.7688815593719482, "(16, 0)": 0.9675011038780212, "(16, 16)": 0.9675011038780212, "(18, 0)": 0.7688815593719482, "(18, 16)": 0.9675011038780212, "(20, 0)": 0.9675011038780212, "(20, 16)": 0.9675011038780212, "(22, 0)": 0.9675011038780212, "(22, 16)": 0.9675011038780212, "(24, 0)": 0.9675011038780212, "(24, 16)": 0.9675011038780212, "(26, 0)": 0.9675011038780212, "(26, 16)": 0.9675011038780212, "(28, 0)": 0.9675011038780212, "(28, 16)": 0.9675011038780212, "(30, 0)": 0.9675011038780212, "(30, 16)": 0.9675011038780212}, "r_span": [367, 500], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008944869041442871}}, {"prompt_attention_score": {"(0, 0)": 0.7744238972663879, "(0, 16)": 0.7744238972663879, "(2, 0)": 0.7744238972663879, "(2, 16)": 0.7744238972663879, "(4, 0)": 0.7744238972663879, "(4, 16)": 0.7744238972663879, "(6, 0)": 0.7744238972663879, "(6, 16)": 0.8790812492370605, "(8, 0)": 0.7744238972663879, "(8, 16)": 0.7744238972663879, "(10, 0)": 0.7744238972663879, "(10, 16)": 0.7744238972663879, "(12, 0)": 0.7744238972663879, "(12, 16)": 0.8790812492370605, "(14, 0)": 0.8751899003982544, "(14, 16)": 0.7744238972663879, "(16, 0)": 0.7744238972663879, "(16, 16)": 0.8751899003982544, "(18, 0)": 0.8751899003982544, "(18, 16)": 0.8790812492370605, "(20, 0)": 0.8790812492370605, "(20, 16)": 0.8751899003982544, "(22, 0)": 0.8751899003982544, "(22, 16)": 0.8790812492370605, "(24, 0)": 0.8751899003982544, "(24, 16)": 0.8790812492370605, "(26, 0)": 0.8751899003982544, "(26, 16)": 0.7744238972663879, "(28, 0)": 0.8751899003982544, "(28, 16)": 0.8751899003982544, "(30, 0)": 0.8751899003982544, "(30, 16)": 0.8751899003982544}, "r_span": [502, 601], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0018297433853149414}}, {"prompt_attention_score": {"(0, 0)": 0.9066101312637329, "(0, 16)": 0.9066101312637329, "(2, 0)": 0.9066101312637329, "(2, 16)": 0.9066101312637329, "(4, 0)": 0.9066101312637329, "(4, 16)": 0.9066101312637329, "(6, 0)": 0.9066101312637329, "(6, 16)": 0.9066101312637329, "(8, 0)": 0.9066101312637329, "(8, 16)": 0.9066101312637329, "(10, 0)": 0.9066101312637329, "(10, 16)": 0.9066101312637329, "(12, 0)": 0.9066101312637329, "(12, 16)": 0.9066101312637329, "(14, 0)": 0.7799398899078369, "(14, 16)": 0.9066101312637329, "(16, 0)": 0.9066101312637329, "(16, 16)": 0.7799398899078369, "(18, 0)": 0.7799398899078369, "(18, 16)": 0.9066101312637329, "(20, 0)": 0.9066101312637329, "(20, 16)": 0.7799398899078369, "(22, 0)": 0.7799398899078369, "(22, 16)": 0.9066101312637329, "(24, 0)": 0.7799398899078369, "(24, 16)": 0.9066101312637329, "(26, 0)": 0.7799398899078369, "(26, 16)": 0.7799398899078369, "(28, 0)": 0.7799398899078369, "(28, 16)": 0.7799398899078369, "(30, 0)": 0.7799398899078369, "(30, 16)": 0.7799398899078369}, "r_span": [603, 707], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.001927018165588379}}, {"prompt_attention_score": {"(0, 0)": 0.7347313165664673, "(0, 16)": 0.7347313165664673, "(2, 0)": 0.7347313165664673, "(2, 16)": 0.7347313165664673, "(4, 0)": 0.7347313165664673, "(4, 16)": 0.7347313165664673, "(6, 0)": 0.7347313165664673, "(6, 16)": 0.9526059627532959, "(8, 0)": 0.9526059627532959, "(8, 16)": 0.9526059627532959, "(10, 0)": 0.7347313165664673, "(10, 16)": 0.9526059627532959, "(12, 0)": 0.9526059627532959, "(12, 16)": 0.9526059627532959, "(14, 0)": 0.9526059627532959, "(14, 16)": 0.7347313165664673, "(16, 0)": 0.9526059627532959, "(16, 16)": 0.9526059627532959, "(18, 0)": 0.7347313165664673, "(18, 16)": 0.9526059627532959, "(20, 0)": 0.9526059627532959, "(20, 16)": 0.9526059627532959, "(22, 0)": 0.9526059627532959, "(22, 16)": 0.9526059627532959, "(24, 0)": 0.9526059627532959, "(24, 16)": 0.9526059627532959, "(26, 0)": 0.9526059627532959, "(26, 16)": 0.7347313165664673, "(28, 0)": 0.9526059627532959, "(28, 16)": 0.9526059627532959, "(30, 0)": 0.9526059627532959, "(30, 16)": 0.9526059627532959}, "r_span": [709, 795], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0006306171417236328}}, {"prompt_attention_score": {"(0, 0)": 0.6925597190856934, "(0, 16)": 0.6925597190856934, "(2, 0)": 0.6925597190856934, "(2, 16)": 0.6925597190856934, "(4, 0)": 0.6925597190856934, "(4, 16)": 0.6925597190856934, "(6, 0)": 0.7708196640014648, "(6, 16)": 0.949484646320343, "(8, 0)": 0.7708196640014648, "(8, 16)": 0.7708196640014648, "(10, 0)": 0.6925597190856934, "(10, 16)": 0.7708196640014648, "(12, 0)": 0.7708196640014648, "(12, 16)": 0.949484646320343, "(14, 0)": 0.7708196640014648, "(14, 16)": 0.6925597190856934, "(16, 0)": 0.7708196640014648, "(16, 16)": 0.7708196640014648, "(18, 0)": 0.7708196640014648, "(18, 16)": 0.949484646320343, "(20, 0)": 0.949484646320343, "(20, 16)": 0.7708196640014648, "(22, 0)": 0.7708196640014648, "(22, 16)": 0.949484646320343, "(24, 0)": 0.7708196640014648, "(24, 16)": 0.949484646320343, "(26, 0)": 0.7708196640014648, "(26, 16)": 0.7708196640014648, "(28, 0)": 0.7708196640014648, "(28, 16)": 0.7708196640014648, "(30, 0)": 0.7708196640014648, "(30, 16)": 0.7708196640014648}, "r_span": [797, 878], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0011116862297058105}}]}, {"id": "17253", "source_id": "12367", "model": "llama-2-7b-chat", "temperature": 0.7, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, children learn the following through water play:\n\n1. Gross motor skills: Children develop their coordination, balance, and movement skills through water play activities like running through sprinklers or pouring water. (Passage 1)\n2. Academic learning: Water play helps children learn about floating and sinking, and they can practice measuring and comparing quantities of water. (Passage 1)\n3. Creativity: Water play encourages children to use their imagination and creativity while playing. (Passage 1)\n4. Problem-solving skills: Children can use critical thinking and problem-solving skills when designing and building structures with water, such as bridges or dams. (Passage 2)\n5. Science concepts: Water play provides opportunities for children to learn about science concepts such as buoyancy, volume, and density. (Passage 3)\n\nUnable to answer based on given passages.", "response_spans": [[0, 80], [82, 536], [537, 864], [866, 907]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7344319224357605, "(0, 16)": 0.7344319224357605, "(2, 0)": 0.7344319224357605, "(2, 16)": 0.7344319224357605, "(4, 0)": 0.7344319224357605, "(4, 16)": 0.7344319224357605, "(6, 0)": 0.7344319224357605, "(6, 16)": 0.7911339998245239, "(8, 0)": 0.7344319224357605, "(8, 16)": 0.7344319224357605, "(10, 0)": 0.7344319224357605, "(10, 16)": 0.7344319224357605, "(12, 0)": 0.7344319224357605, "(12, 16)": 0.7911339998245239, "(14, 0)": 0.7344319224357605, "(14, 16)": 0.7344319224357605, "(16, 0)": 0.7911339998245239, "(16, 16)": 0.7344319224357605, "(18, 0)": 0.7344319224357605, "(18, 16)": 0.7911339998245239, "(20, 0)": 0.7911339998245239, "(20, 16)": 0.7385149002075195, "(22, 0)": 0.7385149002075195, "(22, 16)": 0.7575567960739136, "(24, 0)": 0.7385149002075195, "(24, 16)": 0.7911339998245239, "(26, 0)": 0.7344319224357605, "(26, 16)": 0.7575567960739136, "(28, 0)": 0.7344319224357605, "(28, 16)": 0.7385149002075195, "(30, 0)": 0.7385149002075195, "(30, 16)": 0.7575567960739136}, "r_span": [437, 453], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.00020587444305419922}}, {"prompt_attention_score": {"(0, 0)": 0.7724171280860901, "(0, 16)": 0.7724171280860901, "(2, 0)": 0.7724171280860901, "(2, 16)": 0.7724171280860901, "(4, 0)": 0.7724171280860901, "(4, 16)": 0.7724171280860901, "(6, 0)": 0.7724171280860901, "(6, 16)": 0.8671150207519531, "(8, 0)": 0.7724171280860901, "(8, 16)": 0.7724171280860901, "(10, 0)": 0.7724171280860901, "(10, 16)": 0.7724171280860901, "(12, 0)": 0.7724171280860901, "(12, 16)": 0.8671150207519531, "(14, 0)": 0.7678748965263367, "(14, 16)": 0.8671150207519531, "(16, 0)": 0.8671150207519531, "(16, 16)": 0.7724171280860901, "(18, 0)": 0.7724171280860901, "(18, 16)": 0.8671150207519531, "(20, 0)": 0.8671150207519531, "(20, 16)": 0.7678748965263367, "(22, 0)": 0.7678748965263367, "(22, 16)": 0.8671150207519531, "(24, 0)": 0.7678748965263367, "(24, 16)": 0.8671150207519531, "(26, 0)": 0.8671150207519531, "(26, 16)": 0.8671150207519531, "(28, 0)": 0.7724171280860901, "(28, 16)": 0.7678748965263367, "(30, 0)": 0.7678748965263367, "(30, 16)": 0.8671150207519531}, "r_span": [455, 557], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0024744272232055664}}, {"prompt_attention_score": {"(0, 0)": 0.75431227684021, "(0, 16)": 0.75431227684021, "(2, 0)": 0.75431227684021, "(2, 16)": 0.75431227684021, "(4, 0)": 0.75431227684021, "(4, 16)": 0.75431227684021, "(6, 0)": 0.75431227684021, "(6, 16)": 0.7392221689224243, "(8, 0)": 0.75431227684021, "(8, 16)": 0.75431227684021, "(10, 0)": 0.75431227684021, "(10, 16)": 0.75431227684021, "(12, 0)": 0.75431227684021, "(12, 16)": 0.75431227684021, "(14, 0)": 0.7353777289390564, "(14, 16)": 0.75431227684021, "(16, 0)": 0.75431227684021, "(16, 16)": 0.75431227684021, "(18, 0)": 0.75431227684021, "(18, 16)": 0.7353777289390564, "(20, 0)": 0.7353777289390564, "(20, 16)": 0.7353777289390564, "(22, 0)": 0.7353777289390564, "(22, 16)": 0.7353777289390564, "(24, 0)": 0.7353777289390564, "(24, 16)": 0.7353777289390564, "(26, 0)": 0.7392221689224243, "(26, 16)": 0.7392221689224243, "(28, 0)": 0.7353777289390564, "(28, 16)": 0.7353777289390564, "(30, 0)": 0.7353777289390564, "(30, 16)": 0.7392221689224243}, "r_span": [558, 635], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00013637542724609375}}, {"prompt_attention_score": {"(0, 0)": 0.5919743180274963, "(0, 16)": 0.5919743180274963, "(2, 0)": 0.5919743180274963, "(2, 16)": 0.5919743180274963, "(4, 0)": 0.5919743180274963, "(4, 16)": 0.5919743180274963, "(6, 0)": 0.5919743180274963, "(6, 16)": 0.5919743180274963, "(8, 0)": 0.5919743180274963, "(8, 16)": 0.5919743180274963, "(10, 0)": 0.5919743180274963, "(10, 16)": 0.5919743180274963, "(12, 0)": 0.5919743180274963, "(12, 16)": 0.5919743180274963, "(14, 0)": 0.5709457397460938, "(14, 16)": 0.5919743180274963, "(16, 0)": 0.5919743180274963, "(16, 16)": 0.5919743180274963, "(18, 0)": 0.5919743180274963, "(18, 16)": 0.5919743180274963, "(20, 0)": 0.5919743180274963, "(20, 16)": 0.5709457397460938, "(22, 0)": 0.5709457397460938, "(22, 16)": 0.5919743180274963, "(24, 0)": 0.5709457397460938, "(24, 16)": 0.5919743180274963, "(26, 0)": 0.5919743180274963, "(26, 16)": 0.5709457397460938, "(28, 0)": 0.5919743180274963, "(28, 16)": 0.5709457397460938, "(30, 0)": 0.5709457397460938, "(30, 16)": 0.5103788375854492}, "r_span": [637, 647], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -1.5795230865478516e-05}}]}, {"id": "17283", "source_id": "12372", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [{"start": 121, "end": 134, "text": "and innocence", "meta": "HIGH INTRO OF NEW INFO\nOriginal: It is not mentioned in the original source.\nGenerative: White represents... innocence", "label_type": "Evident Baseless Info", "implicit_true": false, "due_to_null": false}], "split": "test", "quality": "good", "response": "Based on the provided passages, the colors of the Tennessee flag have the following meanings:\n\n* White represents purity and innocence\n* Blue represents the patriotism of the people of Tennessee\n* Red represents the willingness of the people of Tennessee to shed blood during warfare\n\nAdditionally, the three white stars on the flag represent the three grand divisions of Tennessee - East, Middle, and West - which are bound together by the endless circle of the blue field.", "response_spans": [[0, 474]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8204826712608337, "(0, 16)": 0.8204826712608337, "(2, 0)": 0.8204826712608337, "(2, 16)": 0.8204826712608337, "(4, 0)": 0.8204826712608337, "(4, 16)": 0.8204826712608337, "(6, 0)": 0.8204826712608337, "(6, 16)": 0.9400678277015686, "(8, 0)": 0.8204826712608337, "(8, 16)": 0.8204826712608337, "(10, 0)": 0.4037628769874573, "(10, 16)": 0.8204826712608337, "(12, 0)": 0.8204826712608337, "(12, 16)": 0.9400678277015686, "(14, 0)": 0.8322659730911255, "(14, 16)": 0.8204826712608337, "(16, 0)": 0.8561193943023682, "(16, 16)": 0.8204826712608337, "(18, 0)": 0.4037628769874573, "(18, 16)": 0.9400678277015686, "(20, 0)": 0.9400678277015686, "(20, 16)": 0.8322659730911255, "(22, 0)": 0.8322659730911255, "(22, 16)": 0.9400678277015686, "(24, 0)": 0.8322659730911255, "(24, 16)": 0.9400678277015686, "(26, 0)": 0.8322659730911255, "(26, 16)": 0.8322659730911255, "(28, 0)": 0.8322659730911255, "(28, 16)": 0.8322659730911255, "(30, 0)": 0.8322659730911255, "(30, 16)": 0.8322659730911255}, "r_span": [658, 760], "hallucination_label": 1, "parameter_knowledge_scores": {"layer_0": 0.0016444921493530273}}]}, {"id": "17397", "source_id": "12391", "model": "llama-2-7b-chat", "temperature": 1.0, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the following are exercises that tone the chest:\n\n1. Modified tri-set for the chest (passage 2)\n2. Pushups (passage 2)\n3. Dumbbell bench presses (passage 2)\n\nThese exercises are specifically mentioned in the passages as targeting the chest muscles.", "response_spans": [[0, 280]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6924096345901489, "(0, 16)": 0.6924096345901489, "(2, 0)": 0.6924096345901489, "(2, 16)": 0.6924096345901489, "(4, 0)": 0.6924096345901489, "(4, 16)": 0.6924096345901489, "(6, 0)": 0.6924096345901489, "(6, 16)": 0.7056336998939514, "(8, 0)": 0.6924096345901489, "(8, 16)": 0.6924096345901489, "(10, 0)": 0.6924096345901489, "(10, 16)": 0.6924096345901489, "(12, 0)": 0.6924096345901489, "(12, 16)": 0.8231779336929321, "(14, 0)": 0.7056336998939514, "(14, 16)": 0.6924096345901489, "(16, 0)": 0.7056336998939514, "(16, 16)": 0.7056336998939514, "(18, 0)": 0.6924096345901489, "(18, 16)": 0.7056336998939514, "(20, 0)": 0.8231779336929321, "(20, 16)": 0.7056336998939514, "(22, 0)": 0.7056336998939514, "(22, 16)": 0.8231779336929321, "(24, 0)": 0.7056336998939514, "(24, 16)": 0.7056336998939514, "(26, 0)": 0.7056336998939514, "(26, 16)": 0.8231779336929321, "(28, 0)": 0.7056336998939514, "(28, 16)": 0.7056336998939514, "(30, 0)": 0.7056336998939514, "(30, 16)": 0.7056336998939514}, "r_span": [338, 428], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0012174248695373535}}]}, {"id": "17517", "source_id": "12414", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Sure! Here's how to poach an egg using a PoachPod¬Æ based on the provided passages:\n\n1. Bring a large pot of water to a boil. (Passage 1)\n2. Carefully crack an egg into the PoachPod¬Æ, being careful not to break the yolk. (Passage 2)\n3. Gently slide the PoachPod¬Æ into the boiling water, making sure it floats upright and no water enters the pod. (Passage 2)\n4. Cover the pot with a lid and cook for 6 minutes. (Passage 2)\n5. Use a large slotted spoon or tongs to carefully remove the PoachPod¬Æ from the water and flip it upside down over a plate. (Passage 2)\n6. Press gently on the bottom of the PoachPod¬Æ to release the poached egg onto the plate. (Passage 2)\n\nThat's it! According to the passages, the PoachPod¬Æ makes it easy to poach eggs by allowing you to float them in boiling water without breaking the yolk. Just make sure to lightly oil the pod before adding the egg to prevent sticking.", "response_spans": [[0, 82], [84, 557], [558, 659], [661, 895]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.7055532932281494, "(0, 16)": 0.7055532932281494, "(2, 0)": 0.7055532932281494, "(2, 16)": 0.7055532932281494, "(4, 0)": 0.7055532932281494, "(4, 16)": 0.7055532932281494, "(6, 0)": 0.7055532932281494, "(6, 16)": 0.8964221477508545, "(8, 0)": 0.7055532932281494, "(8, 16)": 0.508421003818512, "(10, 0)": 0.508421003818512, "(10, 16)": 0.508421003818512, "(12, 0)": 0.7055532932281494, "(12, 16)": 0.8964221477508545, "(14, 0)": 0.777453601360321, "(14, 16)": 0.508421003818512, "(16, 0)": 0.8964221477508545, "(16, 16)": 0.7055532932281494, "(18, 0)": 0.508421003818512, "(18, 16)": 0.8964221477508545, "(20, 0)": 0.8964221477508545, "(20, 16)": 0.777453601360321, "(22, 0)": 0.777453601360321, "(22, 16)": 0.8964221477508545, "(24, 0)": 0.777453601360321, "(24, 16)": 0.8964221477508545, "(26, 0)": 0.777453601360321, "(26, 16)": 0.777453601360321, "(28, 0)": 0.777453601360321, "(28, 16)": 0.777453601360321, "(30, 0)": 0.777453601360321, "(30, 16)": 0.777453601360321}, "r_span": [631, 656], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005994439125061035}}, {"prompt_attention_score": {"(0, 0)": 0.768046498298645, "(0, 16)": 0.768046498298645, "(2, 0)": 0.768046498298645, "(2, 16)": 0.768046498298645, "(4, 0)": 0.768046498298645, "(4, 16)": 0.768046498298645, "(6, 0)": 0.768046498298645, "(6, 16)": 0.8882325887680054, "(8, 0)": 0.768046498298645, "(8, 16)": 0.8882325887680054, "(10, 0)": 0.768046498298645, "(10, 16)": 0.768046498298645, "(12, 0)": 0.8882325887680054, "(12, 16)": 0.8882325887680054, "(14, 0)": 0.8882325887680054, "(14, 16)": 0.8882325887680054, "(16, 0)": 0.8882325887680054, "(16, 16)": 0.8882325887680054, "(18, 0)": 0.8882325887680054, "(18, 16)": 0.8882325887680054, "(20, 0)": 0.8882325887680054, "(20, 16)": 0.8882325887680054, "(22, 0)": 0.8882325887680054, "(22, 16)": 0.8882325887680054, "(24, 0)": 0.8882325887680054, "(24, 16)": 0.8882325887680054, "(26, 0)": 0.8882325887680054, "(26, 16)": 0.8882325887680054, "(28, 0)": 0.8882325887680054, "(28, 16)": 0.8882325887680054, "(30, 0)": 0.8882325887680054, "(30, 16)": 0.8882325887680054}, "r_span": [658, 809], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00021564960479736328}}, {"prompt_attention_score": {"(0, 0)": 0.7045657634735107, "(0, 16)": 0.7045657634735107, "(2, 0)": 0.7045657634735107, "(2, 16)": 0.7045657634735107, "(4, 0)": 0.4057321548461914, "(4, 16)": 0.7045657634735107, "(6, 0)": 0.7045657634735107, "(6, 16)": 0.8633312582969666, "(8, 0)": 0.7045657634735107, "(8, 16)": 0.7045657634735107, "(10, 0)": 0.7045657634735107, "(10, 16)": 0.7045657634735107, "(12, 0)": 0.8210592269897461, "(12, 16)": 0.8633312582969666, "(14, 0)": 0.8210592269897461, "(14, 16)": 0.8210592269897461, "(16, 0)": 0.7045657634735107, "(16, 16)": 0.8210592269897461, "(18, 0)": 0.4057321548461914, "(18, 16)": 0.7959918975830078, "(20, 0)": 0.8210592269897461, "(20, 16)": 0.8210592269897461, "(22, 0)": 0.8210592269897461, "(22, 16)": 0.8210592269897461, "(24, 0)": 0.8210592269897461, "(24, 16)": 0.8210592269897461, "(26, 0)": 0.8210592269897461, "(26, 16)": 0.8210592269897461, "(28, 0)": 0.8210592269897461, "(28, 16)": 0.8210592269897461, "(30, 0)": 0.8210592269897461, "(30, 16)": 0.8210592269897461}, "r_span": [810, 840], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -1.4603137969970703e-05}}, {"prompt_attention_score": {"(0, 0)": 0.6869145631790161, "(0, 16)": 0.6869145631790161, "(2, 0)": 0.6869145631790161, "(2, 16)": 0.6869145631790161, "(4, 0)": 0.6869145631790161, "(4, 16)": 0.6869145631790161, "(6, 0)": 0.6869145631790161, "(6, 16)": 0.7872917652130127, "(8, 0)": 0.6869145631790161, "(8, 16)": 0.6869145631790161, "(10, 0)": 0.3650757670402527, "(10, 16)": 0.6869145631790161, "(12, 0)": 0.7872917652130127, "(12, 16)": 0.6869145631790161, "(14, 0)": 0.7562851905822754, "(14, 16)": 0.3650757670402527, "(16, 0)": 0.6869145631790161, "(16, 16)": 0.7562851905822754, "(18, 0)": 0.7562851905822754, "(18, 16)": 0.7872917652130127, "(20, 0)": 0.7872917652130127, "(20, 16)": 0.7562851905822754, "(22, 0)": 0.7562851905822754, "(22, 16)": 0.7872917652130127, "(24, 0)": 0.7562851905822754, "(24, 16)": 0.7562851905822754, "(26, 0)": 0.7562851905822754, "(26, 16)": 0.7562851905822754, "(28, 0)": 0.7562851905822754, "(28, 16)": 0.7562851905822754, "(30, 0)": 0.7562851905822754, "(30, 16)": 0.7562851905822754}, "r_span": [842, 899], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004642605781555176}}]}, {"id": "17565", "source_id": "12422", "model": "llama-2-7b-chat", "temperature": 0.925, "labels": [], "split": "test", "quality": "good", "response": "Sure! Based on the provided passages, here are the answers to the question:\n\nWhat is the average temperature in Wellesey over the next 5 days?\n\nAnswer: The average temperature in Wellesey over the next 5 days is 81 degrees (based on passages 1 and 3).\n\nWhat is the probability of rain in Wellesey over the next 5 days?\n\nAnswer: The probability of rain in Wellesey over the next 5 days ranges from 28% to 52%, with a total of 36% to 52% (based on passages 1, 2, and 3).", "response_spans": [[0, 468]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6153290271759033, "(0, 16)": 0.6153290271759033, "(2, 0)": 0.6153290271759033, "(2, 16)": 0.6153290271759033, "(4, 0)": 0.6153290271759033, "(4, 16)": 0.6153290271759033, "(6, 0)": 0.6153290271759033, "(6, 16)": 0.6211175918579102, "(8, 0)": 0.6211175918579102, "(8, 16)": 0.6153290271759033, "(10, 0)": 0.6153290271759033, "(10, 16)": 0.6153290271759033, "(12, 0)": 0.6153290271759033, "(12, 16)": 0.6153290271759033, "(14, 0)": 0.6211175918579102, "(14, 16)": 0.6153290271759033, "(16, 0)": 0.6211175918579102, "(16, 16)": 0.6211175918579102, "(18, 0)": 0.6211175918579102, "(18, 16)": 0.6211175918579102, "(20, 0)": 0.6211175918579102, "(20, 16)": 0.6211175918579102, "(22, 0)": 0.6211175918579102, "(22, 16)": 0.6211175918579102, "(24, 0)": 0.6211175918579102, "(24, 16)": 0.6211175918579102, "(26, 0)": 0.6211175918579102, "(26, 16)": 0.6211175918579102, "(28, 0)": 0.6211175918579102, "(28, 16)": 0.6211175918579102, "(30, 0)": 0.6211175918579102, "(30, 16)": 0.6211175918579102}, "r_span": [405, 550], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -1.1563301086425781e-05}}]}, {"id": "17571", "source_id": "12423", "model": "llama-2-7b-chat", "temperature": 0.775, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the process of processing the air we breathe before it reaches the lungs involves the following steps:\n\n1. The diaphragm muscle contracts to take air into the lungs, moving down from the bottom of the rib cage towards the abdominal region. (Passage 1)\n2. The process of breathing involves the exchange of gases between the body and the outside environment, occurring in the lungs. (Passage 2)\n3. Increasing the volume of the thoracic cavity, including the lungs, decreases the air pressure in the lungs below the atmospheric pressure, forcing air from the atmosphere into the lungs, causing us to inhale. (Passage 3)\n\nTherefore, the main steps in processing the air we breathe before it reaches the lungs are:\n\n1. Contraction of the diaphragm muscle to draw air into the lungs.\n2. Exchange of gases between the body and the outside environment in the lungs.\n3. Expansion of the thoracic cavity to decrease air pressure in the lungs and facilitate inhalation.\n\nUnable to answer based on given passages.", "response_spans": [[0, 134], [136, 424], [425, 648], [650, 1033]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.6616302728652954, "(0, 16)": 0.6616302728652954, "(2, 0)": 0.6616302728652954, "(2, 16)": 0.6616302728652954, "(4, 0)": 0.6616302728652954, "(4, 16)": 0.6616302728652954, "(6, 0)": 0.6616302728652954, "(6, 16)": 0.8322544693946838, "(8, 0)": 0.6616302728652954, "(8, 16)": 0.6616302728652954, "(10, 0)": 0.6616302728652954, "(10, 16)": 0.6616302728652954, "(12, 0)": 0.6616302728652954, "(12, 16)": 0.8322544693946838, "(14, 0)": 0.6616302728652954, "(14, 16)": 0.6616302728652954, "(16, 0)": 0.8322544693946838, "(16, 16)": 0.6616302728652954, "(18, 0)": 0.6616302728652954, "(18, 16)": 0.8322544693946838, "(20, 0)": 0.8322544693946838, "(20, 16)": 0.7607508897781372, "(22, 0)": 0.8322544693946838, "(22, 16)": 0.8322544693946838, "(24, 0)": 0.7607508897781372, "(24, 16)": 0.8322544693946838, "(26, 0)": 0.8322544693946838, "(26, 16)": 0.8322544693946838, "(28, 0)": 0.6616302728652954, "(28, 16)": 0.7607508897781372, "(30, 0)": 0.8322544693946838, "(30, 16)": 0.8322544693946838}, "r_span": [466, 495], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00018143653869628906}}, {"prompt_attention_score": {"(0, 0)": 0.6999102830886841, "(0, 16)": 0.6999102830886841, "(2, 0)": 0.6999102830886841, "(2, 16)": 0.6999102830886841, "(4, 0)": 0.6999102830886841, "(4, 16)": 0.6999102830886841, "(6, 0)": 0.6999102830886841, "(6, 16)": 0.8463660478591919, "(8, 0)": 0.8151620626449585, "(8, 16)": 0.6999102830886841, "(10, 0)": 0.6999102830886841, "(10, 16)": 0.6999102830886841, "(12, 0)": 0.6999102830886841, "(12, 16)": 0.8463660478591919, "(14, 0)": 0.8151620626449585, "(14, 16)": 0.6999102830886841, "(16, 0)": 0.8151620626449585, "(16, 16)": 0.6999102830886841, "(18, 0)": 0.6999102830886841, "(18, 16)": 0.8151620626449585, "(20, 0)": 0.8463660478591919, "(20, 16)": 0.8151620626449585, "(22, 0)": 0.6857049465179443, "(22, 16)": 0.8463660478591919, "(24, 0)": 0.8151620626449585, "(24, 16)": 0.8151620626449585, "(26, 0)": 0.6857049465179443, "(26, 16)": 0.8151620626449585, "(28, 0)": 0.6857049465179443, "(28, 16)": 0.6857049465179443, "(30, 0)": 0.6857049465179443, "(30, 16)": 0.6857049465179443}, "r_span": [497, 574], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0007778406143188477}}, {"prompt_attention_score": {"(0, 0)": 0.9311122894287109, "(0, 16)": 0.9311122894287109, "(2, 0)": 0.9311122894287109, "(2, 16)": 0.9311122894287109, "(4, 0)": 0.9311122894287109, "(4, 16)": 0.9311122894287109, "(6, 0)": 0.9311122894287109, "(6, 16)": 0.9311122894287109, "(8, 0)": 0.6558281183242798, "(8, 16)": 0.6558281183242798, "(10, 0)": 0.9311122894287109, "(10, 16)": 0.9311122894287109, "(12, 0)": 0.9311122894287109, "(12, 16)": 0.9311122894287109, "(14, 0)": 0.6558281183242798, "(14, 16)": 0.9311122894287109, "(16, 0)": 0.9311122894287109, "(16, 16)": 0.9311122894287109, "(18, 0)": 0.6457862854003906, "(18, 16)": 0.9311122894287109, "(20, 0)": 0.9311122894287109, "(20, 16)": 0.6558281183242798, "(22, 0)": 0.6457862854003906, "(22, 16)": 0.9311122894287109, "(24, 0)": 0.6558281183242798, "(24, 16)": 0.9311122894287109, "(26, 0)": 0.6457862854003906, "(26, 16)": 0.6457862854003906, "(28, 0)": 0.6457862854003906, "(28, 16)": 0.6457862854003906, "(30, 0)": 0.6457862854003906, "(30, 16)": 0.6457862854003906}, "r_span": [575, 634], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.00024324655532836914}}, {"prompt_attention_score": {"(0, 0)": 0.705687403678894, "(0, 16)": 0.705687403678894, "(2, 0)": 0.705687403678894, "(2, 16)": 0.705687403678894, "(4, 0)": 0.705687403678894, "(4, 16)": 0.705687403678894, "(6, 0)": 0.705687403678894, "(6, 16)": 0.7219762802124023, "(8, 0)": 0.7894750833511353, "(8, 16)": 0.7894750833511353, "(10, 0)": 0.705687403678894, "(10, 16)": 0.705687403678894, "(12, 0)": 0.705687403678894, "(12, 16)": 0.705687403678894, "(14, 0)": 0.7894750833511353, "(14, 16)": 0.705687403678894, "(16, 0)": 0.814407229423523, "(16, 16)": 0.705687403678894, "(18, 0)": 0.814407229423523, "(18, 16)": 0.7894750833511353, "(20, 0)": 0.7219762802124023, "(20, 16)": 0.7894750833511353, "(22, 0)": 0.814407229423523, "(22, 16)": 0.705687403678894, "(24, 0)": 0.7894750833511353, "(24, 16)": 0.705687403678894, "(26, 0)": 0.814407229423523, "(26, 16)": 0.814407229423523, "(28, 0)": 0.814407229423523, "(28, 16)": 0.814407229423523, "(30, 0)": 0.814407229423523, "(30, 16)": 0.814407229423523}, "r_span": [636, 738], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.002135157585144043}}]}, {"id": "17757", "source_id": "12455", "model": "llama-2-7b-chat", "temperature": 0.85, "labels": [], "split": "test", "quality": "good", "response": "Based on the provided passages, the main differences between SMS (Short Message Service) and MMS (Multimedia Messaging Service) are:\n\n1. Content types: SMS allows sending only text messages, while MMS enables sending multimedia content such as images, videos, audio, and combinations of these.\n2. Message size: MMS messages can have a larger size limit of up to 300 KB, while SMS messages are limited to 160 characters or less.\n3. Capability to send multimedia content: MMS supports sending multimedia content, while SMS only allows text messages.\n4. Size extension: MMS allows message extensions in formats like WAV, JPEG, and GIF, while SMS does not.\n\nTherefore, the key differences between SMS and MMS are the ability to send multimedia content and the larger message size limit for MMS.", "response_spans": [[0, 132], [134, 547], [548, 652], [654, 790]], "scores": [{"prompt_attention_score": {"(0, 0)": 0.8031260967254639, "(0, 16)": 0.8031260967254639, "(2, 0)": 0.8031260967254639, "(2, 16)": 0.8031260967254639, "(4, 0)": 0.8031260967254639, "(4, 16)": 0.8031260967254639, "(6, 0)": 0.8469730615615845, "(6, 16)": 0.8274438977241516, "(8, 0)": 0.8031260967254639, "(8, 16)": 0.4334597885608673, "(10, 0)": 0.4334597885608673, "(10, 16)": 0.4334597885608673, "(12, 0)": 0.8031260967254639, "(12, 16)": 0.8274438977241516, "(14, 0)": 0.8469730615615845, "(14, 16)": 0.4334597885608673, "(16, 0)": 0.8451548218727112, "(16, 16)": 0.8031260967254639, "(18, 0)": 0.4334597885608673, "(18, 16)": 0.8274438977241516, "(20, 0)": 0.8451548218727112, "(20, 16)": 0.8469730615615845, "(22, 0)": 0.8469730615615845, "(22, 16)": 0.8451548218727112, "(24, 0)": 0.8469730615615845, "(24, 16)": 0.8274438977241516, "(26, 0)": 0.8469730615615845, "(26, 16)": 0.8469730615615845, "(28, 0)": 0.8469730615615845, "(28, 16)": 0.8469730615615845, "(30, 0)": 0.8469730615615845, "(30, 16)": 0.8469730615615845}, "r_span": [550, 580], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0004426240921020508}}, {"prompt_attention_score": {"(0, 0)": 0.9273101687431335, "(0, 16)": 0.9273101687431335, "(2, 0)": 0.9273101687431335, "(2, 16)": 0.9273101687431335, "(4, 0)": 0.9273101687431335, "(4, 16)": 0.9273101687431335, "(6, 0)": 0.9273101687431335, "(6, 16)": 0.844558596611023, "(8, 0)": 0.9273101687431335, "(8, 16)": 0.9273101687431335, "(10, 0)": 0.9273101687431335, "(10, 16)": 0.9273101687431335, "(12, 0)": 0.9273101687431335, "(12, 16)": 0.9273101687431335, "(14, 0)": 0.7920520305633545, "(14, 16)": 0.9273101687431335, "(16, 0)": 0.9273101687431335, "(16, 16)": 0.9273101687431335, "(18, 0)": 0.7920520305633545, "(18, 16)": 0.9273101687431335, "(20, 0)": 0.9273101687431335, "(20, 16)": 0.7920520305633545, "(22, 0)": 0.7920520305633545, "(22, 16)": 0.9273101687431335, "(24, 0)": 0.7920520305633545, "(24, 16)": 0.9273101687431335, "(26, 0)": 0.7920520305633545, "(26, 16)": 0.7920520305633545, "(28, 0)": 0.7920520305633545, "(28, 16)": 0.7920520305633545, "(30, 0)": 0.7920520305633545, "(30, 16)": 0.7920520305633545}, "r_span": [582, 680], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0008858442306518555}}, {"prompt_attention_score": {"(0, 0)": 0.8419045209884644, "(0, 16)": 0.8419045209884644, "(2, 0)": 0.8419045209884644, "(2, 16)": 0.8419045209884644, "(4, 0)": 0.8419045209884644, "(4, 16)": 0.8419045209884644, "(6, 0)": 0.704939067363739, "(6, 16)": 0.757408082485199, "(8, 0)": 0.8419045209884644, "(8, 16)": 0.704939067363739, "(10, 0)": 0.8419045209884644, "(10, 16)": 0.8419045209884644, "(12, 0)": 0.704939067363739, "(12, 16)": 0.8419045209884644, "(14, 0)": 0.704939067363739, "(14, 16)": 0.8419045209884644, "(16, 0)": 0.8419045209884644, "(16, 16)": 0.704939067363739, "(18, 0)": 0.704939067363739, "(18, 16)": 0.8419045209884644, "(20, 0)": 0.8419045209884644, "(20, 16)": 0.704939067363739, "(22, 0)": 0.704939067363739, "(22, 16)": 0.8419045209884644, "(24, 0)": 0.704939067363739, "(24, 16)": 0.8419045209884644, "(26, 0)": 0.704939067363739, "(26, 16)": 0.8419045209884644, "(28, 0)": 0.704939067363739, "(28, 16)": 0.704939067363739, "(30, 0)": 0.704939067363739, "(30, 16)": 0.704939067363739}, "r_span": [681, 711], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": -0.0007928609848022461}}, {"prompt_attention_score": {"(0, 0)": 0.8218342065811157, "(0, 16)": 0.8218342065811157, "(2, 0)": 0.8218342065811157, "(2, 16)": 0.39402318000793457, "(4, 0)": 0.39402318000793457, "(4, 16)": 0.8218342065811157, "(6, 0)": 0.7583339810371399, "(6, 16)": 0.7656218409538269, "(8, 0)": 0.7583339810371399, "(8, 16)": 0.7583339810371399, "(10, 0)": 0.39402318000793457, "(10, 16)": 0.39402318000793457, "(12, 0)": 0.39402318000793457, "(12, 16)": 0.8218342065811157, "(14, 0)": 0.7583339810371399, "(14, 16)": 0.39402318000793457, "(16, 0)": 0.7529392838478088, "(16, 16)": 0.39402318000793457, "(18, 0)": 0.7583339810371399, "(18, 16)": 0.7656218409538269, "(20, 0)": 0.7529392838478088, "(20, 16)": 0.7583339810371399, "(22, 0)": 0.7583339810371399, "(22, 16)": 0.39402318000793457, "(24, 0)": 0.7583339810371399, "(24, 16)": 0.39402318000793457, "(26, 0)": 0.7583339810371399, "(26, 16)": 0.7583339810371399, "(28, 0)": 0.7583339810371399, "(28, 16)": 0.7583339810371399, "(30, 0)": 0.7583339810371399, "(30, 16)": 0.7583339810371399}, "r_span": [713, 742], "hallucination_label": 0, "parameter_knowledge_scores": {"layer_0": 0.0005581378936767578}}]}]